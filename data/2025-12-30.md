<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration](https://arxiv.org/abs/2512.21360)
*Shuide Wen,Yu Sun,Beier Ku,Zhi Gao,Lijun Ma,Yang Yang,Can Jiao*

Main category: cs.AI

TL;DR: 本研究提出基于多模态大语言模型的多智能体系统，用于标准化HTP绘画测试分析，实现专家级解读水平


<details>
  <summary>Details</summary>
Motivation: 传统HTP绘画测试存在评分标准不统一、依赖评估者主观经验、缺乏统一量化编码系统等问题，需要标准化工具

Method: 采用多模态大语言模型构建多智能体协作框架，通过角色分工将特征识别与心理推理解耦，整合社会心理学视角和去污名化叙事

Result: MLLM解释与人类专家解释的平均语义相似度约0.75，在结构化专家数据集中提升至0.85；多智能体系统能有效纠正视觉幻觉，生成具有高生态效度和内部一致性的心理报告

Conclusion: 多模态大模型可作为投射评估的标准化工具，多智能体框架为数字心理健康服务提供了新范式

Abstract: Background: The House-Tree-Person (HTP) drawing test, introduced by John Buck in 1948, remains a widely used projective technique in clinical psychology. However, it has long faced challenges such as heterogeneous scoring standards, reliance on examiners subjective experience, and a lack of a unified quantitative coding system.
  Results: Quantitative experiments showed that the mean semantic similarity between Multimodal Large Language Model (MLLM) interpretations and human expert interpretations was approximately 0.75 (standard deviation about 0.05). In structurally oriented expert data sets, this similarity rose to 0.85, indicating expert-level baseline comprehension. Qualitative analyses demonstrated that the multi-agent system, by integrating social-psychological perspectives and destigmatizing narratives, effectively corrected visual hallucinations and produced psychological reports with high ecological validity and internal coherence.
  Conclusions: The findings confirm the potential of multimodal large models as standardized tools for projective assessment. The proposed multi-agent framework, by dividing roles, decouples feature recognition from psychological inference and offers a new paradigm for digital mental-health services.
  Keywords: House-Tree-Person test; multimodal large language model; multi-agent collaboration; cosine similarity; computational psychology; artificial intelligence

</details>


### [2] [A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers](https://arxiv.org/abs/2512.21365)
*Chung-Chin Shih,Ti-Rong Wu,Ting Han Wei,Yu-Shan Hsu,Hung Guei,I-Chen Wu*

Main category: cs.AI

TL;DR: 该论文分析了使用最先进的计算机围棋求解器（基于相关区域搜索和相关区域模式表）解决围棋死活题的行为，发现求解器能识别关键区域、发现罕见模式，甚至在某些问题上给出与标准答案不同的解法，但也存在对罕见模式价值误判和优先求活而非最大化地盘的问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是分析当前最先进的计算机围棋求解器在解决围棋死活题时的行为表现，特别是使用相关区域搜索和相关区域模式表这两种技术时，求解器如何工作以及存在哪些局限性。

Method: 研究方法包括：1）使用基于相关区域搜索和相关区域模式表的计算机围棋求解器；2）测试7个来自著名围棋死活题集《死活辞典》（赵治勋著）的问题；3）分析求解器识别的相关区域、发现的模式序列以及求解结果。

Result: 研究结果包括：1）对每个问题，求解器都能识别出解决问题的关键相关区域；2）求解器发现了一系列模式，包括一些罕见模式；3）在两个问题上，求解器找到了与给定答案不同的解法；4）发现了求解器的两个问题：对罕见模式的价值误判，以及倾向于优先求活而非最大化地盘（与人类棋手行为不同）。

Conclusion: 结论是当前基于相关区域搜索的计算机围棋求解器在解决死活题时表现出有趣的能力，但也存在局限性，特别是对罕见模式的价值评估和与人类棋手策略差异的问题，未来需要改进这些方面。

Abstract: This paper analyzes the behavior of solving Life-and-Death (L&D) problems in the game of Go using current state-of-the-art computer Go solvers with two techniques: the Relevance-Zone Based Search (RZS) and the relevance-zone pattern table. We examined the solutions derived by relevance-zone based solvers on seven L&D problems from the renowned book "Life and Death Dictionary" written by Cho Chikun, a Go grandmaster, and found several interesting results. First, for each problem, the solvers identify a relevance-zone that highlights the critical areas for solving. Second, the solvers discover a series of patterns, including some that are rare. Finally, the solvers even find different answers compared to the given solutions for two problems. We also identified two issues with the solver: (a) it misjudges values of rare patterns, and (b) it tends to prioritize living directly rather than maximizing territory, which differs from the behavior of human Go players. We suggest possible approaches to address these issues in future work. Our code and data are available at https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ.

</details>


### [3] [Three-way decision with incomplete information based on similarity and satisfiability](https://arxiv.org/abs/2512.21421)
*Junfang Luo,Mengjun Hu,Keyun Qin*

Main category: cs.AI

TL;DR: 该论文将三支决策从完全信息推广到不完全信息场景，提出了计算和概念两种形式化方法的新泛化版本，分别基于对象相似度度量和公式满足度度量。


<details>
  <summary>Details</summary>
Motivation: 现实应用中信息往往不完全，而现有的三支决策方法主要针对完全信息场景。需要将三支决策推广到更实用的不完全信息场景，为实际应用提供理论支持。

Method: 1. 计算形式化：提出对象相似度度量作为等价关系的泛化，基于α-相似类和对象可逼近性两种方法实现三支决策；2. 概念形式化：提出公式满足度度量作为完全信息下满足性的量化泛化，基于α-意义集和公式置信度两种方法实现三支决策。

Result: 成功将三支决策从完全信息推广到不完全信息，提出了四种新的三支决策方法：基于α-相似类、对象可逼近性、α-意义集和公式置信度的方法。其中对象可逼近性和概念形式化的两种方法为不完全信息分析指出了新的研究方向。

Conclusion: 该研究为三支决策在不完全信息场景下的应用提供了系统的理论框架，扩展了粗糙集理论的实际应用范围，特别是指出了对象可逼近性和概念形式化的新研究方向，具有重要的理论和实践价值。

Abstract: Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual formulations. The computational formulation uses equivalence relations, and the conceptual formulation uses satisfiability of logic formulas. In this paper, based on a briefly review of these two formulations, we generalize both formulations into three-way decision with incomplete information that is more practical in real-world applications. For the computational formulation, we propose a new measure of similarity degree of objects as a generalization of equivalence relations. Based on it, we discuss two approaches to three-way decision using alpha-similarity classes and approximability of objects, respectively. For the conceptual formulation, we propose a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability with complete information. Based on it, we study two approaches to three-way decision using alpha-meaning sets of formulas and confidence of formulas, respectively. While using similarity classes is a common method of analyzing incomplete information in the literature, the proposed concept of approximability and the two approaches in conceptual formulation point out new promising directions.

</details>


### [4] [LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis](https://arxiv.org/abs/2512.21482)
*Fanwei Zeng,Changtao Miao,Jing Huang,Zhiya Tan,Shutao Gong,Xiaoming Yu,Yang Wang,Huazhe Tan,Weibin Yao,Jianshu Li*

Main category: cs.AI

TL;DR: LogicLens是一个统一的视觉-文本协同推理框架，用于分析文本中心伪造图像，通过跨线索感知思维链机制实现检测、定位和解释的联合任务，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前文本中心伪造分析方法存在三个主要问题：1）通常只进行粗粒度的视觉分析，缺乏复杂推理能力；2）将检测、定位和解释作为离散的子任务处理，忽视了它们之间的内在联系；3）缺乏能够全面增强性能的统一框架。

Method: 提出了LogicLens框架，包含三个核心创新：1）跨线索感知思维链（CCT）机制，迭代交叉验证视觉线索与文本逻辑；2）基于GRPO优化的加权多任务奖励函数，确保所有任务的鲁棒对齐；3）PR²（感知器、推理器、审阅器）流水线，生成高质量认知对齐的标注数据；4）构建了包含5,397张图像的RealText数据集，包含细粒度标注。

Result: 在T-IC13数据集上的零样本评估中，LogicLens比专用框架高出41.4%，比GPT-4o高出23.4%（宏平均F1分数）。在密集文本T-SROIE数据集上，在mF1、CSS和宏平均F1指标上显著领先其他MLLM方法。

Conclusion: LogicLens通过统一的视觉-文本协同推理框架，有效解决了文本中心伪造分析的现有局限性，在检测、定位和解释任务上实现了显著性能提升，为信息真实性验证提供了强有力的工具。

Abstract: Sophisticated text-centric forgeries, fueled by rapid AIGC advancements, pose a significant threat to societal security and information authenticity. Current methods for text-centric forgery analysis are often limited to coarse-grained visual analysis and lack the capacity for sophisticated reasoning. Moreover, they typically treat detection, grounding, and explanation as discrete sub-tasks, overlooking their intrinsic relationships for holistic performance enhancement. To address these challenges, we introduce LogicLens, a unified framework for Visual-Textual Co-reasoning that reformulates these objectives into a joint task. The deep reasoning of LogicLens is powered by our novel Cross-Cues-aware Chain of Thought (CCT) mechanism, which iteratively cross-validates visual cues against textual logic. To ensure robust alignment across all tasks, we further propose a weighted multi-task reward function for GRPO-based optimization. Complementing this framework, we first designed the PR$^2$ (Perceiver, Reasoner, Reviewer) pipeline, a hierarchical and iterative multi-agent system that generates high-quality, cognitively-aligned annotations. Then, we constructed RealText, a diverse dataset comprising 5,397 images with fine-grained annotations, including textual explanations, pixel-level segmentation, and authenticity labels for model training. Extensive experiments demonstrate the superiority of LogicLens across multiple benchmarks. In a zero-shot evaluation on T-IC13, it surpasses the specialized framework by 41.4% and GPT-4o by 23.4% in macro-average F1 score. Moreover, on the challenging dense-text T-SROIE dataset, it establishes a significant lead over other MLLM-based methods in mF1, CSS, and the macro-average F1. Our dataset, model, and code will be made publicly available.

</details>


### [5] [Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model](https://arxiv.org/abs/2512.21540)
*Yanhao Li,Lu Ma,Jiaran Zhang,Lexiang Tang,Wentao Zhang,Guibo Luo*

Main category: cs.AI

TL;DR: 提出Leash框架，通过自适应长度惩罚和奖励塑造来优化LLM推理效率，在保持性能的同时减少60%推理长度


<details>
  <summary>Details</summary>
Motivation: 现有固定长度惩罚方法难以调优且无法适应LLM推理能力的动态变化，导致准确性和简洁性之间的次优权衡

Method: 将长度控制建模为约束优化问题，采用拉格朗日对偶方法动态调整惩罚系数，通过自适应机制引导模型生成简洁推理

Result: 在Deepseek-R1-Distill-Qwen-1.5B和Qwen3-4B-Thinking-2507上，Leash将平均推理长度减少60%，同时在数学推理、编码和指令跟随等任务上保持竞争力

Conclusion: Leash为开发可控高效LLM提供了实用有效的范式，平衡了推理能力和计算预算

Abstract: Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to suboptimal trade-offs between accuracy and conciseness. To address this challenge, we propose Leash (adaptive LEngth penAlty and reward SHaping), a reinforcement learning framework for efficient reasoning in LLMs. We formulate length control as a constrained optimization problem and employ a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. When generations exceed the target length, the penalty is intensified; when they are shorter, it is relaxed. This adaptive mechanism guides models toward producing concise reasoning without sacrificing task performance. Experiments on Deepseek-R1-Distill-Qwen-1.5B and Qwen3-4B-Thinking-2507 show that Leash reduces the average reasoning length by 60% across diverse tasks - including in-distribution mathematical reasoning and out-of-distribution domains such as coding and instruction following - while maintaining competitive performance. Our work thus presents a practical and effective paradigm for developing controllable and efficient LLMs that balance reasoning capabilities with computational budgets.

</details>


### [6] [NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent](https://arxiv.org/abs/2512.21578)
*Ali Sahami,Sudhanshu Garg,Andrew Wang,Chaitanya Kulkarni,Farhad Farahani,Sean Yun-Shiuan Chuang,Jian Wan,Srinivasan Manoharan,Uma Kona,Nitin Sharma,Linsey Pang,Prakhar Mehrotra,Jessica Clark,Mark Moyou*

Main category: cs.AI

TL;DR: PayPal与NVIDIA合作开发基于NEMO-4-PAYPAL的多智能体系统Commerce Agent，通过NeMo框架对Nemotron小语言模型进行微调优化搜索发现智能体，显著降低了延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 优化PayPal平台上的智能体商务系统性能，特别是解决检索组件占总体响应时间50%以上的关键性能问题，同时降低延迟和成本。

Method: 使用NVIDIA的NeMo框架对Nemotron小语言模型进行微调，采用llama3.1-nemotron-nano-8B-v1架构，通过LoRA技术进行系统化的超参数调优，包括学习率、优化器（Adam、AdamW）、余弦退火调度和LoRA秩等参数。

Result: 微调后的Nemotron SLM有效解决了检索组件的关键性能问题，在保持或提升系统整体性能的同时，显著改善了延迟和成本指标。

Conclusion: 这是NeMo框架在商务特定智能体优化中的首次应用，为生产环境中的电子商务多智能体系统优化提供了一个可扩展的框架，证明了LLM微调策略在检索密集型商务任务中的有效性。

Abstract: We present the development and optimization of PayPal's Commerce Agent, powered by NEMO-4-PAYPAL, a multi-agent system designed to revolutionize agentic commerce on the PayPal platform. Through our strategic partnership with NVIDIA, we leveraged the NeMo Framework for LLM model fine-tuning to enhance agent performance. Specifically, we optimized the Search and Discovery agent by replacing our base model with a fine-tuned Nemotron small language model (SLM).
  We conducted comprehensive experiments using the llama3.1-nemotron-nano-8B-v1 architecture, training LoRA-based models through systematic hyperparameter sweeps across learning rates, optimizers (Adam, AdamW), cosine annealing schedules, and LoRA ranks. Our contributions include: (1) the first application of NVIDIA's NeMo Framework to commerce-specific agent optimization, (2) LLM powered fine-tuning strategy for retrieval-focused commerce tasks, (3) demonstration of significant improvements in latency and cost while maintaining agent quality, and (4) a scalable framework for multi-agent system optimization in production e-commerce environments. Our results demonstrate that the fine-tuned Nemotron SLM effectively resolves the key performance issue in the retrieval component, which represents over 50\% of total agent response time, while maintaining or enhancing overall system performance.

</details>


### [7] [A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning](https://arxiv.org/abs/2512.21583)
*Zelin Zang,Wenyi Gu,Siqi Ma,Dan Yang,Yue Shen,Zhu Zhang,Guohui Fan,Wing-Kuen Ling,Fuji Yang*

Main category: cs.AI

TL;DR: 基于LLaVA的医疗诊断框架，结合视觉语言对齐与逻辑正则化推理，提升多模态医疗AI的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和视觉语言模型在医学领域的快速发展，单纯整合临床文本和医学影像并不能保证可靠的推理。现有的多模态模型经常产生幻觉或不一致的思维链，限制了临床信任。

Method: 提出基于LLaVA的诊断框架，包括：文本和图像的输入编码器、跨模态对齐的投影模块、将诊断任务分解为步骤的推理控制器，以及将逐步前提组装成可验证结论的逻辑树生成器。

Result: 在MedXpertQA和其他基准测试上的评估表明，该方法提高了诊断准确性，在多模态任务上产生更可解释的推理轨迹，同时在纯文本设置下保持竞争力。

Conclusion: 这些结果表明朝着可信赖的多模态医疗AI迈出了有希望的一步。

Abstract: With the rapid growth of large language models (LLMs) and vision-language models (VLMs) in medicine, simply integrating clinical text and medical imaging does not guarantee reliable reasoning. Existing multimodal models often produce hallucinations or inconsistent chains of thought, limiting clinical trust. We propose a diagnostic framework built upon LLaVA that combines vision-language alignment with logic-regularized reasoning. The system includes an input encoder for text and images, a projection module for cross-modal alignment, a reasoning controller that decomposes diagnostic tasks into steps, and a logic tree generator that assembles stepwise premises into verifiable conclusions. Evaluations on MedXpertQA and other benchmarks show that our method improves diagnostic accuracy and yields more interpretable reasoning traces on multimodal tasks, while remaining competitive on text-only settings. These results suggest a promising step toward trustworthy multimodal medical AI.

</details>


### [8] [Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design](https://arxiv.org/abs/2512.21623)
*Takahide Suzuki,Kazuki Nakanishi,Takashi Fujiwara,Hideyuki Shimizu*

Main category: cs.AI

TL;DR: OrchestRA是一个人类在环的多智能体平台，将生物学、化学和药理学统一为自主发现引擎，通过自主执行模拟和结果推理来驱动迭代优化，将药物发现从随机搜索转变为可编程的循证工程学科。


<details>
  <summary>Details</summary>
Motivation: 当前治疗发现面临专业领域碎片化以及计算设计与生理验证之间的执行差距等挑战。虽然生成式AI有潜力，但现有模型通常只是被动助手而非自主执行者。

Method: OrchestRA平台包含一个协调器管理的多智能体系统：生物学家智能体利用大规模知识图谱（>1000万关联）进行深度推理识别高置信度靶点；化学家智能体自主检测结构口袋进行从头设计或药物重定位；药理学家智能体通过严格的生理药代动力学模拟评估候选药物。这些智能体建立动态反馈循环，药代动力学和毒性特征直接触发结构重新优化。

Result: 该平台将自主执行与人类指导无缝集成，建立了动态反馈循环，使药代动力学和毒性特征能够直接触发结构重新优化。

Conclusion: OrchestRA通过整合自主执行与人类指导，使治疗设计民主化，将药物发现从随机搜索转变为可编程的循证工程学科。

Abstract: Therapeutic discovery remains a formidable challenge, impeded by the fragmentation of specialized domains and the execution gap between computational design and physiological validation. Although generative AI offers promise, current models often function as passive assistants rather than as autonomous executors. Here, we introduce OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine. Unlike static code generators, our agents actively execute simulations and reason the results to drive iterative optimization. Governed by an Orchestrator, a Biologist Agent leverages deep reasoning over a massive knowledge graph (>10 million associations) to pinpoint high-confidence targets; a Chemist Agent autonomously detects structural pockets for de novo design or drug repositioning; and a Pharmacologist Agent evaluates candidates via rigorous physiologically based pharmacokinetic (PBPK) simulations. This architecture establishes a dynamic feedback loop where pharmacokinetic and toxicity profiles directly trigger structural reoptimization. By seamlessly integrating autonomous execution with human guidance, OrchestRA democratizes therapeutic design, transforming drug discovery from a stochastic search to a programmable evidence-based engineering discipline.

</details>


### [9] [Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing](https://arxiv.org/abs/2512.21626)
*Hong Xie,Haoran Gu,Yanying Huang,Tao Tan,Defu Lian*

Main category: cs.AI

TL;DR: 该论文提出了一种面向LLM应用、边缘智能等资源分配问题的多臂赌博机变体，其中每个臂具有随机容量，容量单位与奖励函数关联，每个游戏具有优先级权重，容量按优先级分配。论文证明了实例无关和实例相关的遗憾下界，并设计了匹配下界的算法。


<details>
  <summary>Details</summary>
Motivation: 解决LLM应用、边缘智能等场景中的资源分配问题，这些场景中资源需要根据优先级进行分配，传统多臂赌博机模型无法直接适用。

Method: 提出MSB-PRS（多臂随机赌博机-优先级资源共享）模型，设计MSB-PRS-OffOpt算法来寻找最优游戏分配策略，然后基于此设计近似UCB算法。

Result: 证明了实例无关遗憾下界Ω(α₁σ√(KMT))和实例相关遗憾下界Ω(α₁σ²(M/Δ)lnT)，设计的算法遗憾上界分别匹配下界至√(KlnKT)和α₁K²因子。

Conclusion: 该工作为具有优先级资源共享机制的资源分配问题提供了理论框架和高效算法，解决了由优先级分配机制引起的非线性组合效用函数带来的技术挑战。

Abstract: This paper proposes a variant of multiple-play stochastic bandits tailored to resource allocation problems arising from LLM applications, edge intelligence, etc. The model is composed of $M$ arms and $K$ plays. Each arm has a stochastic number of capacities, and each unit of capacity is associated with a reward function. Each play is associated with a priority weight. When multiple plays compete for the arm capacity, the arm capacity is allocated in a larger priority weight first manner. Instance independent and instance dependent regret lower bounds of $Ω( α_1 σ\sqrt{KM T} )$ and $Ω(α_1 σ^2 \frac{M}Δ \ln T)$ are proved, where $α_1$ is the largest priority weight and $σ$ characterizes the reward tail. When model parameters are given, we design an algorithm named \texttt{MSB-PRS-OffOpt} to locate the optimal play allocation policy with a computational complexity of $O(MK^3)$. Utilizing \texttt{MSB-PRS-OffOpt} as a subroutine, an approximate upper confidence bound (UCB) based algorithm is designed, which has instance independent and instance dependent regret upper bounds matching the corresponding lower bound up to factors of $ \sqrt{K \ln KT }$ and $α_1 K^2$ respectively. To this end, we address nontrivial technical challenges arising from optimizing and learning under a special nonlinear combinatorial utility function induced by the prioritized resource sharing mechanism.

</details>


### [10] [Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning](https://arxiv.org/abs/2512.21699)
*Eranga Bandara,Tharaka Hewa,Ross Gore,Sachin Shetty,Ravi Mukkamala,Peter Foytik,Abdul Rahman,Safdar H. Bouk,Xueping Liang,Amin Hass,Sachini Rajapakse,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.AI

TL;DR: 提出了一种基于多模型共识和推理层治理的负责任可解释AI智能体架构，通过异构LLM/VLM智能体独立生成候选输出，再由专用推理智能体进行结构化整合，以提升生产级智能体工作流的鲁棒性、透明度和可信度。


<details>
  <summary>Details</summary>
Motivation: 智能体AI系统虽然功能强大，但自主性增加带来了可解释性、问责制、鲁棒性和治理方面的挑战。现有实现往往强调功能和可扩展性，但缺乏理解决策原理和执行跨智能体责任的有效机制。

Method: 提出负责任可解释AI智能体架构，采用异构LLM和VLM智能体联盟独立生成候选输出，暴露不确定性和分歧，然后由专用推理智能体进行结构化整合，强制执行安全和策略约束，减轻幻觉和偏见。

Result: 在多个真实世界智能体AI工作流中评估该架构，证明共识驱动的推理提高了不同应用领域的鲁棒性、透明度和操作信任度。

Conclusion: 该工作为设计既自主可扩展又天生负责任可解释的智能体AI系统提供了实用指导，通过多模型共识和推理层治理实现了生产级智能体工作流的责任与可解释性。

Abstract: Agentic AI represents a major shift in how autonomous systems reason, plan, and execute multi-step tasks through the coordination of Large Language Models (LLMs), Vision Language Models (VLMs), tools, and external services. While these systems enable powerful new capabilities, increasing autonomy introduces critical challenges related to explainability, accountability, robustness, and governance, especially when agent outputs influence downstream actions or decisions. Existing agentic AI implementations often emphasize functionality and scalability, yet provide limited mechanisms for understanding decision rationale or enforcing responsibility across agent interactions. This paper presents a Responsible(RAI) and Explainable(XAI) AI Agent Architecture for production-grade agentic workflows based on multi-model consensus and reasoning-layer governance. In the proposed design, a consortium of heterogeneous LLM and VLM agents independently generates candidate outputs from a shared input context, explicitly exposing uncertainty, disagreement, and alternative interpretations. A dedicated reasoning agent then performs structured consolidation across these outputs, enforcing safety and policy constraints, mitigating hallucinations and bias, and producing auditable, evidence-backed decisions. Explainability is achieved through explicit cross-model comparison and preserved intermediate outputs, while responsibility is enforced through centralized reasoning-layer control and agent-level constraints. We evaluate the architecture across multiple real-world agentic AI workflows, demonstrating that consensus-driven reasoning improves robustness, transparency, and operational trust across diverse application domains. This work provides practical guidance for designing agentic AI systems that are autonomous and scalable, yet responsible and explainable by construction.

</details>


### [11] [Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets](https://arxiv.org/abs/2512.21775)
*Matyas Bohacek,Ignacio Vilanova Echavarri*

Main category: cs.AI

TL;DR: 提出合规评级方案(CRS)框架评估数据集透明度、问责和安全性，并开发开源Python库实现该框架


<details>
  <summary>Details</summary>
Motivation: 生成式AI快速发展依赖大规模开源数据集，但这些数据集通常采用不透明、不受限制的数据收集方式，且数据集在共享、编辑和复制过程中，其来源、合法性和安全性信息容易丢失，而现有文献多关注GAI模型开发和应用，忽视了数据集创建的伦理和法律考量

Method: 引入合规评级方案(CRS)框架，基于数据溯源技术开发开源Python库，可集成到现有数据集处理和AI训练流程中，既能评估现有数据集的CRS，也能指导负责任的数据抓取和新数据集构建

Result: 开发了一个同时具备反应性和主动性的开源工具，能够评估数据集合规性并指导负责任的数据收集实践

Conclusion: CRS框架和开源库填补了生成式AI数据集伦理和法律评估的空白，通过提高数据集的透明度、问责和安全性，促进更负责任的AI发展

Abstract: Generative Artificial Intelligence (GAI) has experienced exponential growth in recent years, partly facilitated by the abundance of large-scale open-source datasets. These datasets are often built using unrestricted and opaque data collection practices. While most literature focuses on the development and applications of GAI models, the ethical and legal considerations surrounding the creation of these datasets are often neglected. In addition, as datasets are shared, edited, and further reproduced online, information about their origin, legitimacy, and safety often gets lost. To address this gap, we introduce the Compliance Rating Scheme (CRS), a framework designed to evaluate dataset compliance with critical transparency, accountability, and security principles. We also release an open-source Python library built around data provenance technology to implement this framework, allowing for seamless integration into existing dataset-processing and AI training pipelines. The library is simultaneously reactive and proactive, as in addition to evaluating the CRS of existing datasets, it equally informs responsible scraping and construction of new datasets.

</details>
