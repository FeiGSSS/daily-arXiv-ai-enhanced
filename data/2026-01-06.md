<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 提出了一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，为LLMs提供与对话逻辑结构对齐的知识，超越表面语义相似性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs通常通过检索语义相似信息或提升推理能力来增强性能，但如何有效整合检索和推理策略仍是一个挑战。需要超越表面语义相似性，提供与对话逻辑结构对齐的知识。

Method: 采用粗到细的两阶段知识检索方法：1) 识别知识库中与上下文相关的子区域，确保所有句子都与主题相关；2) 在该子区域内细化搜索，提取与推理过程相关的知识。两阶段都使用蒙特卡洛树搜索启发的方法，通过关键词在知识句子中导航。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更贴近人类对话的底层推理逻辑，还显著提升了检索知识的多样性，从而生成更具信息量和创造性的响应。

Conclusion: 提出的推理感知知识检索方法能够有效整合检索和推理策略，为LLMs提供与对话逻辑结构对齐的知识，超越传统的语义相似性检索，提升对话质量和多样性。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [2] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 该研究开发了针对尼日利亚皮钦语的AI抑郁筛查工具，使用微调的大语言模型分析皮钦语音频回答，实现了94.5%的PHQ-9严重程度评分准确率。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查覆盖率低，传统工具如PHQ-9在高收入国家验证，但语言和文化上不适合尼日利亚等中低收入国家，存在语言障碍和文化差异问题。

Method: 收集432份尼日利亚年轻人皮钦语音频回答，进行转录、预处理和标注（语义标签、俚语解释、PHQ-9评分）。微调三种LLM模型（Phi-3-mini-4k-instruct、Gemma-3-4B-it、GPT-4.1），通过定量（准确率、精确度、语义对齐）和定性（清晰度、相关性、文化适宜性）评估性能。

Result: GPT-4.1表现最佳，PHQ-9严重程度评分预测准确率达94.5%，优于其他模型。定性评估中GPT-4.1也产生最文化适宜、清晰且上下文相关的回答。

Conclusion: AI介导的抑郁筛查可为尼日利亚服务不足社区提供解决方案，为在语言多样、资源有限环境中部署对话式心理健康工具奠定基础。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [3] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 本文提出一种多算法方法来解决最后一公里包裹配送中的工作量平衡问题，通过结合距离和工作量考虑来优化包裹分配，确保每位配送员完成相似的工作量。


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近性的包裹分配方法效率低下，导致配送员之间工作量分配不平衡。需要优化系统以提高配送时间并实现工作人员之间的完整工作量平衡。

Method: 提出多算法方法，包括不同版本的k-means、进化方法、基于k-means初始化的递归分配（采用不同问题编码）以及混合进化集成算法。算法同时考虑配送点距离和配送员位置。

Result: 在西班牙Azuqueca de Henares的实际最后一公里包裹配送场景中验证了所提方法的性能，展示了其在实际应用中的有效性。

Conclusion: 该方法能够有效纠正配送员之间的显著工作量不平衡，确保每位工作人员完成相似的工作量，从而提高最后一公里包裹配送系统的运营效率。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [4] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 本文提出基于MinDist度量的规则框架用于13张牌印度拉米纸牌游戏，通过计算手牌与最近有效配置的编辑距离来评估手牌质量，显著提升了胜率。


<details>
  <summary>Details</summary>
Motivation: 13张牌印度拉米纸牌是一个不完全信息的顺序游戏，需要概率推理和组合决策。传统启发式方法在策略设计上存在局限，需要更形式化和可解释的算法框架来提升游戏表现。

Method: 提出基于MinDist度量的规则框架，该度量通过计算手牌与最近有效配置的编辑距离来量化手牌完成度。开发了计算高效的算法，利用动态剪枝和模式缓存精确计算该度量。在双人零和模拟框架中整合对手手牌建模，并使用统计假设检验评估策略。

Result: 实证结果显示，基于MinDist的智能体相比传统启发式方法在胜率上有显著提升，为算法化拉米策略设计提供了形式化和可解释的步骤。

Conclusion: MinDist度量及其计算框架为不完全信息纸牌游戏提供了有效的策略设计方法，显著改善了游戏表现，为算法化游戏策略设计开辟了新途径。

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [5] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 研究探讨生成式AI如何理解乡土建筑中的建筑智慧，以伊朗鸽塔为例，测试三种扩散模型在不同提示阶段的表现，发现AI能重现几何模式但误解材料和气候逻辑。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索生成式AI系统如何解释乡土形式中蕴含的建筑智慧，了解AI在感知、扭曲和重新想象传统设计智能方面的能力边界。

Method: 使用伊朗鸽塔作为案例研究，测试Midjourney v6、DALL-E 3和基于Stable Diffusion XL的DreamStudio三种扩散模型，在参考性、适应性和推测性三个提示阶段进行评估，采用五标准评估框架分析类型学、材料性、环境、真实性和文化特异性。

Result: 结果显示AI能可靠地重现几何模式，但误解材料和气候逻辑；参考图像提高了真实性但限制了创造性，而脱离参考则产生创新但文化模糊的结果；定义了视觉相似性与建筑推理之间的边界。

Conclusion: 研究提出了计算乡土推理框架，用于分析AI如何感知、扭曲和重新想象传统设计智能，揭示了AI在建筑理解方面的局限性和潜力。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [6] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 本文设计了一个基于大语言模型的智能体，能够从原始文本中提取因果反馈模糊认知图，并通过双向交互过程使FCM动态系统获得一定自主性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一种能够从文本中自动提取因果关系的智能系统，使模糊认知图能够自主演化，同时保持与文本源的交互反馈。

Method: 采用三步骤系统指令指导LLM智能体：1)从文本中提取关键名词和名词短语；2)从这些名词短语中提取FCM概念节点；3)推断节点间的部分或模糊因果边。最后混合不同LLM生成的FCM。

Result: 测试显示，该三步骤过程生成的FCM动态系统收敛到与人工生成FCM相同的平衡极限环，尽管节点和边数量不同。混合FCM不仅吸收了主要组件的平衡点，还创建了新的平衡点以更好地近似底层因果动态系统。

Conclusion: LLM智能体能够有效提取文本中的因果结构并生成FCM，混合不同LLM生成的FCM可以产生更丰富的平衡动态，为因果建模提供了新的自动化方法。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [7] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法和大型语言模型，自动演化游戏机制，通过合成完整游戏评估机制质量，生成多样且可玩的游戏。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计通常需要耗费大量时间且依赖专家经验，手动设计过程效率低下。需要自动化方法来探索和生成多样化的游戏机制。

Method: 结合质量多样性算法和大型语言模型探索多样化机制，通过树搜索程序合成完整游戏进行评估，基于技能排序（强者恒胜）作为评估标准。

Result: Mortar能够生成多样且可玩的游戏，产生的机制对游戏中的技能排序得分有更大贡献。通过消融研究和用户研究验证了系统组件的有效性。

Conclusion: Mortar系统成功实现了游戏机制的自主演化，为自动游戏设计提供了有效方法，生成的机制能够提升游戏的质量和可玩性。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [8] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: LLMs作为端到端库存优化求解器存在"幻觉税"性能差距，提出混合智能体框架将语义推理与数学计算解耦，LLM作为智能接口，通过数字孪生测试显示成本降低32.1%


<details>
  <summary>Details</summary>
Motivation: 中小型企业缺乏部署高级优化方法的专业知识，需要探索LLMs是否能帮助弥合这一差距，但发现直接使用LLMs作为端到端求解器存在性能问题

Method: 提出混合智能体框架，严格分离语义推理和数学计算：LLM作为智能接口从自然语言提取参数并解释结果，自动调用严格算法构建优化引擎；引入"人类模仿者"数字孪生进行可扩展的压力测试

Result: 混合框架相比GPT-4o端到端求解器将总库存成本降低32.1%；提供完美真实信息也无法改善GPT-4o性能，确认瓶颈是计算而非信息问题

Conclusion: LLMs不应替代运筹学，而是作为自然语言接口，使非专家能够访问基于严格求解器的策略；混合框架有效解决了LLMs在随机推理方面的局限性

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [9] [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)
*Keqin Xie*

Main category: cs.AI

TL;DR: Mathesis是一种神经符号架构，通过将数学状态编码为高阶超图，使用可微逻辑引擎将约束映射到连续能量景观，将证明搜索转化为能量最小化问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理中存在持续的逻辑失败，缺乏内部公理框架，需要新的架构来解决这一问题。

Method: 提出Mathesis神经符号架构：1) 将数学状态编码为高阶超图；2) 使用符号推理内核(SRK)作为可微逻辑引擎，将约束映射到连续能量景观；3) 通过全局能量函数E(G)实现逻辑一致性；4) 使用梯度信号训练超图变换器大脑；5) 结合蒙特卡洛树搜索和进化证明搜索实现多步推理。

Result: 通过定义全局能量函数，当能量为零时表示逻辑一致性，SRK产生基于梯度的信号来训练模型，将证明搜索转化为能量最小化问题。

Conclusion: Mathesis架构通过神经符号方法解决了LLMs在复杂推理中的逻辑失败问题，将逻辑约束转化为连续优化问题，为数学推理提供了新的框架。

Abstract: Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.

</details>


### [10] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 研究视觉语言模型在视频问答任务中的选择性预测，发现置信度阈值方法在分布内能提供机制性控制，但在分布偏移下可靠性下降


<details>
  <summary>Details</summary>
Motivation: 高风险的视觉语言模型部署需要选择性预测能力，让系统在不确定时选择弃权而非冒险犯错。研究旨在验证置信度弃权方法是否能可靠控制视频问答的错误率，以及在分布偏移下是否仍保持鲁棒性。

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型，通过置信度阈值方法进行选择性预测。在分布内和分布偏移条件下，系统性地调整阈值epsilon来研究风险-覆盖率的权衡关系。

Result: 1. 在分布内，置信度阈值能提供机制性控制，通过调整阈值可以得到平滑的风险-覆盖率权衡曲线，有效降低错误率
2. 在分布偏移下，置信度阈值方法的可靠性显著下降

Conclusion: 置信度阈值方法在分布内能有效控制视觉语言模型在视频问答中的错误率，但在面对分布偏移时缺乏鲁棒性，需要开发更可靠的校准方法以确保高风险部署的安全性。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [11] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM驱动的智能体不仅存在人口统计学偏见，还会在"我们vs他们"的群体线索下表现出群体间偏见。当这种群体边界与智能体-人类划分重合时，人类可能被智能体视为外群体。研究还提出了一种信念中毒攻击，可以抑制智能体对人类有利的规范脚本。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM智能体是否存在群体间偏见，特别是当智能体与人类形成群体边界时，人类是否会被视为外群体而受到不公平对待。同时研究这种偏见可能被恶意利用的攻击面。

Method: 1. 构建基于分配决策的多智能体社会模拟实验，在明确的收益权衡下测试智能体的群体间偏见；2. 设计信念中毒攻击(BPA)，包括初始化时的档案中毒(BPA-PP)和通过优化信念精炼后缀注入存储记忆的BPA-MP；3. 在多种设置下进行广泛实验验证。

Result: 实验发现：1. 智能体在最小群体线索下表现出一致的群体间偏见；2. 当部分对应方被标记为人类时，这种偏见会减弱，但这种减弱依赖于智能体相信真实人类存在的信念；3. 信念中毒攻击能够有效抑制人类规范脚本，重新激活对人类的外群体偏见。

Conclusion: LLM智能体确实存在群体间偏见，且这种偏见可能被恶意攻击利用。研究揭示了智能体框架在档案和记忆边界的安全漏洞，提出了相应的防御策略，旨在促进更安全的智能体设计而非实际利用这些漏洞。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [12] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar,Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt是一个受生物自愈机制启发的智能自愈框架，用于分布式计算连续系统（DCCS），通过语言模型驱动的智能体实现自主故障隔离、诊断、自适应恢复和知识积累。


<details>
  <summary>Details</summary>
Motivation: 现代DCCS系统集成了从物联网设备到云基础设施的异构计算资源，其固有的复杂性、移动性和动态操作条件导致频繁故障，需要可扩展、自适应和自我调节的弹性策略。

Method: 将生物自愈的四个阶段（止血、炎症、增殖、重塑）重构为计算层的四个阶段（遏制、诊断、元认知、知识），使用语言模型驱动的智能体解释异构日志、推断根本原因、优化推理路径并重新配置资源。

Result: 在公共故障数据集上评估显示，ReCiSt能够在数十秒内实现自愈，智能体CPU使用率最低为10%，并展示了克服不确定性的分析深度和实现弹性所需的微智能体数量。

Conclusion: ReCiSt框架成功将生物自愈机制转化为计算弹性策略，通过语言模型驱动的智能体实现了DCCS系统的自主故障恢复和知识积累，为复杂分布式系统提供了有效的自愈解决方案。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [13] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: ACCD框架通过三阶段自适应架构检测社交媒体上的协同虚假行为，使用自适应因果分析、主动学习和自动化验证，在真实数据集上实现87.3%的F1分数，比现有基线提升15.2%，减少68%人工标注需求，处理速度提升2.8倍。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体协同虚假行为检测方法存在三个主要问题：1) 依赖表面相关性分析而非深层因果关系；2) 使用静态参数设置无法适应多样化场景；3) 需要大量人工标注工作，成本高昂且效率低下。需要系统性地解决这些限制。

Method: 提出自适应因果协调检测(ACCD)框架，采用三阶段渐进式架构：1) 自适应收敛交叉映射(CCM)技术深入识别账户间真实因果关系；2) 半监督分类中集成主动学习和不确定性采样，大幅减少人工标注负担；3) 基于历史检测经验的自动化验证模块，实现检测结果的自验证和优化。

Result: 在Twitter IRA数据集、Reddit协调痕迹和多个广泛使用的机器人检测基准上进行评估，ACCD在协同攻击检测中达到87.3%的F1分数，比现有最强基线提升15.2%。系统减少68%的人工标注需求，通过层次聚类优化实现2.8倍处理速度提升。

Conclusion: ACCD为社交媒体平台上的协同行为识别提供了更准确、高效且高度自动化的端到端解决方案，具有重要的实际应用价值和广泛的推广潜力。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [14] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 将语义空间推理从计算语言学扩展到团队运动战术决策，通过将球员视为单词、团队战术视为语义结构，在共享向量空间中评估战术匹配度和对手利用潜力


<details>
  <summary>Details</summary>
Motivation: 传统计算语言学的语义空间推理方法可以类比应用于团队运动的战术决策，将球员视为单词、团队战术视为语义结构，为团队运动提供新的分析框架

Method: 将每个球员表示为多维向量（技术、身体、心理属性），通过上下文加权聚合成团队语义表示；在共享向量空间中编码战术模板，使用向量距离度量评估战术匹配度和对手利用潜力

Result: 开发了Python原型系统，能够生成可解释的动态自适应策略建议，并提供属性级别的细粒度诊断洞察，展示了方法的可行性

Conclusion: 该方法为团队运动提供了通用分析框架，可扩展到篮球、曲棍球、协作机器人等领域，未来方向包括真实数据集成、预测模拟和混合人机战术智能

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [15] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型中的"顿悟时刻"很罕见，不会随训练变得更频繁，也很少提高准确性，表明这些转变是推理不稳定的症状而非内在的自我纠正机制。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为像DeepSeek-R1-Zero这样的模型会在推理过程中经历突然的"顿悟时刻"，导致准确输出，暗示其具有内在的自我纠正能力。但尚不清楚这种推理策略的内在转变是否真正提高了性能。

Method: 研究分析了100多万条推理轨迹、数百个训练检查点、三个推理领域以及多种解码温度和模型架构，检测推理过程中的转变，并人工触发外在转变来验证效果。

Result: 研究发现推理转变很罕见，不会随训练变得更频繁，且很少提高准确性。然而，其效果随模型不确定性而变化：在高熵条件下人工触发外在转变能可靠地提高准确性。

Conclusion: 推理过程中的转变是不稳定推理行为的症状，而非内在的自我纠正机制。人工触发外在转变在高不确定性条件下可以改善性能。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [16] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出了一种难度感知的直接偏好优化框架，通过估计偏好数据的难度并重新加权训练样本，解决多模态大语言模型中偏好优化容易过拟合的问题，从而更有效地抑制幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有多模态DPO方法由于偏好数据难度不平衡容易过拟合，模型倾向于过度关注容易区分的偏好对，这阻碍了细粒度的幻觉抑制并降低了整体性能。

Method: DA-DPO包含两个主要组件：1) 难度估计：利用预训练的视觉-语言模型，结合生成性和对比性目标，通过分布感知投票策略产生鲁棒的难度分数；2) 难度感知训练：基于估计的难度重新加权偏好对，降低简单样本权重，强调困难样本以缓解过拟合。

Result: 大量实验表明，DA-DPO持续改进多模态偏好优化，在标准基准测试中表现出更强的幻觉鲁棒性和更好的泛化能力，同时保持计算效率。

Conclusion: DA-DPO是一种成本效益高的框架，通过难度感知的偏好优化平衡学习过程，无需新数据或额外微调阶段，就能更有效地抑制多模态大语言模型的幻觉。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [17] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM：结合视觉特征和领域知识的LLM框架，用于行人过街行为推理，相比传统方法具有更好的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（统计模型和监督学习）泛化能力有限，在新场景中表现不佳。LLMs提供了从数值模式拟合转向语义、上下文感知行为推理的机会，但现有LLM应用缺乏领域特定适应和视觉上下文。

Method: 提出PedX-LLM框架，集成LLaVA提取的视觉特征、文本数据和交通领域知识，通过LoRA微调LLaMA-2-7B基础模型来推断过街决策。

Result: PedX-LLM达到82.0%的平衡准确率，优于最佳统计和监督学习方法。视觉增强模块带来2.9%性能提升，领域知识集成带来额外4.1%改进。在未见场景的零-shot配置达到66.9%平衡准确率，比基线方法至少高18个百分点；few-shot学习（5个验证样本）进一步提升到72.2%。

Conclusion: PedX-LLM展示了强大的泛化能力，视觉和知识增强的推理使模型能够模拟人类决策逻辑，克服纯数据驱动方法的局限性。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>
