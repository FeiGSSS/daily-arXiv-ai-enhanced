<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Actively Obtaining Environmental Feedback for Autonomous Action Evaluation Without Predefined Measurements](https://arxiv.org/abs/2601.04235)
*Hong Su*

Main category: cs.AI

TL;DR: 提出主动反馈获取模型，让AI智能体主动与环境交互来发现、筛选和验证反馈，无需依赖预定义测量或固定奖励信号。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多依赖预定义测量或固定奖励信号，限制了在开放动态环境中的适用性，因为新动作可能需要先前未知的反馈形式。

Method: 利用动作引起的环境差异来识别未预先指定的目标反馈，引入基于内部目标（如提高准确性、精确度和效率）的自触发机制，自主规划和调整动作。

Result: 实验结果表明，所提出的主动方法显著提高了因子识别的效率和鲁棒性。

Conclusion: 主动反馈获取模型能够在不依赖预定义测量的情况下，让智能体自主发现和验证反馈，适用于开放动态环境。

Abstract: Obtaining reliable feedback from the environment is a fundamental capability for intelligent agents to evaluate the correctness of their actions and to accumulate reusable knowledge. However, most existing approaches rely on predefined measurements or fixed reward signals, which limits their applicability in open-ended and dynamic environments where new actions may require previously unknown forms of feedback. To address these limitations, this paper proposes an Actively Feedback Getting model, in which an AI agent proactively interacts with the environment to discover, screen, and verify feedback without relying on predefined measurements. Rather than assuming explicit feedback definitions, the proposed method exploits action-induced environmental differences to identify target feedback that is not specified in advance, based on the observation that actions inevitably produce measurable changes in the environment. In addition, a self-triggering mechanism, driven by internal objectives such as improved accuracy, precision, and efficiency, is introduced to autonomously plan and adjust actions, thereby enabling faster and more focused feedback acquisition without external commands. Experimental results demonstrate that the proposed active approach significantly improves the efficiency and robustness of factor identification.

</details>


### [2] [SAGE-32B: Agentic Reasoning via Iterative Distillation](https://arxiv.org/abs/2601.04237)
*Basab Jha,Firoj Paudel,Ujjwal Puri,Ethan Henkel,Zhang Yuting,Mateusz Kowalczyk,Mei Huang,Choi Donghyuk,Wang Junhao*

Main category: cs.AI

TL;DR: SAGE-32B是一个专注于智能体推理和长期规划任务的320亿参数语言模型，通过迭代蒸馏和逆向推理方法在智能体任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前聊天模型主要关注通用对话流畅性，但缺乏专门的智能体推理和长期规划能力。需要开发专门针对任务分解、工具使用和错误恢复的智能体模型。

Method: 基于Qwen2.5-32B预训练模型初始化，采用两阶段迭代蒸馏训练过程，并引入逆向推理方法，使用元认知头预测规划过程中的潜在失败。

Result: 在MMLU-Pro、AgentBench和MATH-500等智能体推理基准测试中，SAGE-32B在多工具使用场景中比类似规模的基线模型获得更高的成功率，同时在标准推理评估中保持竞争力。

Conclusion: SAGE-32B展示了专门针对智能体推理和长期规划任务优化的语言模型的有效性，其公开的模型权重为智能体研究社区提供了有价值的资源。

Abstract: We demonstrate SAGE-32B, a 32 billion parameter language model that focuses on agentic reasoning and long range planning tasks. Unlike chat models that aim for general conversation fluency, SAGE-32B is designed to operate in an agentic loop, emphasizing task decomposition, tool usage, and error recovery. The model is initialized from the Qwen2.5-32B pretrained model and fine tuned using Iterative Distillation, a two stage training process that improves reasoning performance through rigorously tested feedback loops. SAGE-32B also introduces an inverse reasoning approach, which uses a meta cognition head to forecast potential failures in the planning process before execution. On agentic reasoning benchmarks including MMLU-Pro, AgentBench, and MATH-500, SAGE-32B achieves higher success rates in multi tool usage scenarios compared to similarly sized baseline models, while remaining competitive on standard reasoning evaluations. Model weights are publicly released at https://huggingface.co/sagea-ai/sage-reasoning-32b

</details>


### [3] [Solving Cyclic Antibandwidth Problem by SAT](https://arxiv.org/abs/2601.04239)
*Hieu Truong Xuan,Khanh To Van*

Main category: cs.AI

TL;DR: 本文提出了首个针对一般图的循环反带宽问题的精确求解方法SAT-CAB，基于SAT求解技术，通过创新的At-Most-One约束编码实现全局最优性保证。


<details>
  <summary>Details</summary>
Motivation: 循环反带宽问题是NP难问题，现有方法仅限于启发式或元启发式算法，精确方法仅适用于受限图类，缺乏针对一般图的精确求解方法。

Method: 提出SAT-CAB方法，基于SAT求解技术，将CABP转化为一系列At-Most-One约束，并引入紧凑的约束表示方法，显著减少公式规模，使现代SAT求解器能有效探索解空间。

Result: 在标准基准实例上的实验表明，SAT-CAB能高效解决实际问题，发现多个先前未知的最优解，首次证明了许多基准实例的全局最优值，性能优于MS-GVNS、HABC-CAB、MACAB等启发式算法以及CPLEX、Gurobi等商业求解器。

Conclusion: SAT-CAB是首个针对一般图CABP的精确方法，推进了该领域的技术水平，为一般图上的精确和混合方法提供了新的基准。

Abstract: The Cyclic Antibandwidth Problem (CABP), a variant of the Antibandwidth Problem, is an NP-hard graph labeling problem with numerous applications. Despite significant research efforts, existing state-of-the-art approaches for CABP are exclusively heuristic or metaheuristic in nature, and exact methods have been limited to restricted graph classes. In this paper, we present the first exact approach for the CABP on general graphs, based on SAT solving, called SAT-CAB. The proposed method is able to systematically explore the solution space and guarantee global optimality, overcoming the limitations of previously reported heuristic algorithms. This approach relies on a novel and efficient SAT encoding of CABP, in which the problem is transformed into a sequence of At-Most-One constraints. In particular, we introduce a compact representation of the At-Most-One constraints inherent to CABP, which significantly reduces the size of the resulting formulas and enables modern SAT solvers to effectively explore the solution space and to certify global optimality. Extensive computational experiments on standard benchmark instances show that the proposed method efficiently solves CABP instances of practical relevance, while identifying several previously unknown optimal solutions. Moreover, global optimal cyclic antibandwidth values are proven for a number of benchmark instances for the first time. Comparative results indicate that SAT-CAB consistently matches or surpasses the best-known solutions obtained by state-of-the-art heuristic algorithms such as MS-GVNS, HABC-CAB, and MACAB, as well as strong commercial Constraint Programming and Mixed Integer Programming solvers like CPLEX and Gurobi, particularly on general graphs, while also providing optimality guarantees. These results advance the state of the art for CABP and provide a new baseline for exact and hybrid methods on general graphs.

</details>


### [4] [Fuzzy Representation of Norms](https://arxiv.org/abs/2601.04249)
*Ziba Assadi,Paola Inverardi*

Main category: cs.AI

TL;DR: 本文提出了一种基于模糊逻辑的SLEEC规则逻辑表示方法，用于在自主系统中嵌入伦理要求


<details>
  <summary>Details</summary>
Motivation: 随着AI驱动的自主系统日益融入日常生活和社会，其伦理和社会影响引发担忧。为建立可信赖的自主系统，需要确保其遵循伦理原则和价值观，这推动了伦理要求在系统设计中的识别与整合研究。

Method: 提出SLEEC（社会、法律、伦理、共情、文化）规则的逻辑表示方法，采用测试分数语义学和模糊逻辑来嵌入伦理要求。模糊逻辑将伦理视为可能性领域，能够解决AI系统可能遇到的伦理困境。

Result: 通过案例研究展示了所提出的方法，验证了基于模糊逻辑的SLEEC规则表示在自主系统中嵌入伦理要求的可行性。

Conclusion: 该研究为自主系统提供了一种综合性的伦理要求嵌入框架，通过模糊逻辑处理伦理困境，有助于构建更可信赖的AI系统。

Abstract: Autonomous systems (AS) powered by AI components are increasingly integrated into the fabric of our daily lives and society, raising concerns about their ethical and social impact. To be considered trustworthy, AS must adhere to ethical principles and values. This has led to significant research on the identification and incorporation of ethical requirements in AS system design. A recent development in this area is the introduction of SLEEC (Social, Legal, Ethical, Empathetic, and Cultural) rules, which provide a comprehensive framework for representing ethical and other normative considerations. This paper proposes a logical representation of SLEEC rules and presents a methodology to embed these ethical requirements using test-score semantics and fuzzy logic. The use of fuzzy logic is motivated by the view of ethics as a domain of possibilities, which allows the resolution of ethical dilemmas that AI systems may encounter. The proposed approach is illustrated through a case study.

</details>


### [5] [Scaling Trends for Multi-Hop Contextual Reasoning in Mid-Scale Language Models](https://arxiv.org/abs/2601.04254)
*Brady Steele,Micah Katz*

Main category: cs.AI

TL;DR: 本文通过控制实验研究大语言模型的多跳上下文推理，展示了任务-方法分离现象：基于规则的模式匹配在结构化信息检索上达到100%成功率，但在跨文档推理任务上只有6.7%；而基于LLM的多智能体系统则呈现相反模式，在推理任务上达到80%成功率。


<details>
  <summary>Details</summary>
Motivation: 研究动机是深入理解大语言模型在多跳上下文推理任务中的表现，特别是探索多智能体系统如何增强模型推理能力，以及不同模型架构（包括MoE架构）在推理任务上的性能差异。

Method: 使用合成评估框架，在四个模型（LLaMA-3 8B、LLaMA-2 13B、Mixtral 8x7B、DeepSeek-V2 16B）上进行120次试验。比较基于规则的模式匹配方法和基于LLM的多智能体系统在不同类型任务上的表现。

Result: 三个关键发现：1）多智能体增强依赖于基础能力，只有具备足够推理能力的模型才能获得显著提升；2）活跃参数预测推理性能，Mixtral的表现与其约12B活跃参数而非47B总参数一致；3）架构质量很重要，LLaMA-3 8B优于LLaMA-2 13B。

Conclusion: 研究结果为多智能体协调和MoE扩展的直觉提供了定量证据，同时强调多智能体效益对基础模型能力的依赖性。研究框架已公开以支持中等规模模型推理的可重复研究。

Abstract: We present a controlled study of multi-hop contextual reasoning in large language models, providing a clean demonstration of the task-method dissociation: rule-based pattern matching achieves 100% success on structured information retrieval but only 6.7% on tasks requiring cross-document reasoning, while LLM-based multi-agent systems show the inverse pattern, achieving up to 80% on reasoning tasks where rule-based methods fail. Using a synthetic evaluation framework with 120 trials across four models (LLaMA-3 8B, LLaMA-2 13B, Mixtral 8x7B, DeepSeek-V2 16B), we report three key findings: (1) Multi-agent amplification depends on base capability: statistically significant gains occur only for models with sufficient reasoning ability (p < 0.001 for LLaMA-3 8B, p = 0.014 for Mixtral), with improvements of up to 46.7 percentage points, while weaker models show no benefit, suggesting amplification rather than compensation; (2) Active parameters predict reasoning performance: Mixtral's performance aligns with its ~12B active parameters rather than 47B total, consistent with the hypothesis that inference-time compute drives reasoning capability in MoE architectures; (3) Architecture quality matters: LLaMA-3 8B outperforms LLaMA-2 13B despite fewer parameters, consistent with known training improvements. Our results provide controlled quantitative evidence for intuitions about multi-agent coordination and MoE scaling, while highlighting the dependence of multi-agent benefits on base model capability. We release our evaluation framework to support reproducible research on reasoning in mid-scale models.

</details>


### [6] [Cross-Language Speaker Attribute Prediction Using MIL and RL](https://arxiv.org/abs/2601.04257)
*Sunny Shu,Seyed Sahand Mohammadi Ziabari,Ali Mohammed Mansoor Alsahag*

Main category: cs.AI

TL;DR: RLMIL-DAT：一种结合强化学习实例选择和对抗域适应的多语言说话人属性预测框架，在少样本和零样本设置下有效应对语言变异、领域不匹配和数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决多语言说话人属性预测中的三个主要挑战：语言变异、领域不匹配以及跨语言数据不平衡问题。传统方法在这些复杂场景下表现不佳，需要更鲁棒的跨语言迁移方法。

Method: 提出RLMIL-DAT框架，是多语言增强的多实例学习框架。结合基于强化学习的实例选择和对抗域适应训练，通过共享编码器鼓励语言不变的语音表示，抑制语言特定线索。

Result: 在五语言Twitter语料库的少样本设置和四十语言VoxCeleb2语料库的零样本设置中，RLMIL-DAT在性别和年龄预测任务上均优于标准多实例学习和原始强化多实例学习框架。性别预测改进最大，年龄预测改进较小但为正。对抗域适应是性能提升的主要贡献者。

Conclusion: 结合实例选择和对抗域适应是跨语言说话人属性预测的有效鲁棒策略，能够实现从高资源语言（如英语）到低资源语言的有效迁移，但年龄预测仍具挑战性，零样本设置下的泛化能力有限。

Abstract: We study multilingual speaker attribute prediction under linguistic variation, domain mismatch, and data imbalance across languages. We propose RLMIL-DAT, a multilingual extension of the reinforced multiple instance learning framework that combines reinforcement learning based instance selection with domain adversarial training to encourage language invariant utterance representations. We evaluate the approach on a five language Twitter corpus in a few shot setting and on a VoxCeleb2 derived corpus covering forty languages in a zero shot setting for gender and age prediction. Across a wide range of model configurations and multiple random seeds, RLMIL-DAT consistently improves Macro F1 compared to standard multiple instance learning and the original reinforced multiple instance learning framework. The largest gains are observed for gender prediction, while age prediction remains more challenging and shows smaller but positive improvements. Ablation experiments indicate that domain adversarial training is the primary contributor to the performance gains, enabling effective transfer from high resource English to lower resource languages by discouraging language specific cues in the shared encoder. In the zero shot setting on the smaller VoxCeleb2 subset, improvements are generally positive but less consistent, reflecting limited statistical power and the difficulty of generalizing to many unseen languages. Overall, the results demonstrate that combining instance selection with adversarial domain adaptation is an effective and robust strategy for cross lingual speaker attribute prediction.

</details>
