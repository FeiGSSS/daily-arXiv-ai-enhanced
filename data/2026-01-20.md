<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 14]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems](https://arxiv.org/abs/2601.10738)
*Percy Jardine*

Main category: cs.AI

TL;DR: 提出约束时间分层架构（CTHA），通过结构化流形投影和仲裁机制解决多时间尺度智能体架构中的协调稳定性问题，显著减少故障级联并提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 多时间尺度智能体架构虽然提升了性能，但破坏了统一智能体系统的协调稳定性，导致层间冲突、误差传播无界和可扩展性受限等问题。

Method: 提出约束时间分层架构（CTHA），包含三个关键约束：1）消息契约约束，通过类型化摘要、计划和策略包形式化层间信息流；2）权威流形约束，根据时间范围限制各层决策空间；3）仲裁器解决约束，保证多层决策的无冲突组合。

Result: CTHA在复杂任务执行中有效，相比无约束分层基线，故障级联减少47%，样本效率提高2.3倍，并展现出优越的可扩展性。

Conclusion: CTHA作为时间分层架构的原则性扩展，有助于深入理解多智能体协调，并为构建鲁棒自主系统的发展指明了方向。

Abstract: Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.

</details>


### [2] [Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration](https://arxiv.org/abs/2601.10744)
*Sen Wang,Bangwei Liu,Zhenkun Gao,Lizhuang Ma,Xuhong Wang,Yuan Xie,Xin Tan*

Main category: cs.AI

TL;DR: LMEE提出了一种统一探索认知与决策行为的终身学习方法，通过构建LMEE-Bench数据集和MemoryExplorer模型，在长时程具身任务中实现主动探索和记忆利用


<details>
  <summary>Details</summary>
Motivation: 现有主流一次性具身任务主要关注任务完成结果，忽视了探索过程和记忆利用的关键环节，而理想的具身智能体需要具备终身学习能力来处理长时程复杂任务

Method: 提出LMEE框架统一探索认知与决策行为，构建LMEE-Bench数据集评估探索过程与结果，开发MemoryExplorer方法通过强化学习微调多模态大语言模型，鼓励主动记忆查询

Result: 通过包含动作预测、边界选择和问答的多任务奖励函数，模型实现了主动探索，在与最先进具身探索模型的对比实验中，在长时程具身任务中取得了显著优势

Conclusion: LMEE框架通过统一探索认知与决策行为，结合主动记忆查询机制，为具身智能体的终身学习提供了有效解决方案，在长时程任务中展现出优越性能

Abstract: An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.

</details>


### [3] [Optimisation of complex product innovation processes based on trend models with three-valued logic](https://arxiv.org/abs/2601.10768)
*Nina Bočková,Barbora Volná,Mirko Dohnal*

Main category: cs.AI

TL;DR: 使用基于启发式的趋势模型研究复杂产品创新过程，通过简单趋势（递增、递减、恒定）作为最小信息强度量化器，避免依赖数值或粗糙集


<details>
  <summary>Details</summary>
Motivation: 研究复杂产品创新过程需要简化的量化方法，避免传统数值或粗糙集方法的复杂性，寻求最小信息强度的分析框架

Method: 基于启发式建立趋势模型，每个启发式通过简单趋势（递增、递减、恒定）表达，定义解决方案为包含可能转换的场景集合，用转换图表示

Result: 构建了转换图表示系统所有可能行为路径，任何未来或过去行为都可以通过图中的路径来描绘

Conclusion: 趋势模型为复杂产品创新过程提供了简化的分析框架，通过最小信息强度的量化方法能够有效描述系统的动态行为

Abstract: This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.

</details>


### [4] [ARC Prize 2025: Technical Report](https://arxiv.org/abs/2601.10904)
*François Chollet,Mike Knoop,Gregory Kamradt,Bryan Landers*

Main category: cs.AI

TL;DR: ARC-AGI-2竞赛显示AI在抽象推理方面仍有限制，2025年主要趋势是精炼循环方法的兴起，但前沿AI性能仍受知识覆盖限制，存在基准污染问题。


<details>
  <summary>Details</summary>
Motivation: 分析ARC-AGI-2竞赛结果，探讨精炼循环方法在AGI进展中的作用，研究知识依赖过拟合问题，并为下一代ARC-AGI-3基准做准备。

Method: 对ARC Prize 2025竞赛（1455个团队，15154个提交）进行调研，分析top-performing方法，特别是精炼循环技术（包括进化程序合成和商业AI系统应用层精炼），同时考察零预训练深度学习方法。

Result: 竞赛最高得分24%（ARC-AGI-2私有评估集），提交论文数量翻倍至90篇，精炼循环成为主导方法，前沿AI实验室开始将ARC-AGI作为行业标准基准，但性能仍受知识覆盖限制。

Conclusion: 当前AI推理能力仍主要依赖知识覆盖而非真正的抽象推理，精炼循环方法显示出潜力但仍有局限，需要ARC-AGI-3引入交互式推理挑战来评估探索、规划、记忆等更全面的智能能力。

Abstract: The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.

</details>


### [5] [What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge](https://arxiv.org/abs/2601.10922)
*Yosub Shin,Michael Buriek,Boris Sobolev,Pavel Bushuyeu,Vikas Kumar,Haoyang Xu,Samuel Watson,Igor Molybog*

Main category: cs.AI

TL;DR: 该研究通过NeurIPS 2025 DCVLR挑战赛探讨多模态推理的数据策展，发现基于难度的样本选择是性能提升的主要驱动力，而数据集大小增加主要减少方差而非提升平均准确率。


<details>
  <summary>Details</summary>
Motivation: 研究多模态推理中的数据策展问题，通过DCVLR挑战赛隔离数据集选择的影响，固定模型和训练协议，专注于探索如何通过数据策展提升多模态推理性能。

Method: 使用主要基于Walton多模态冷启动的紧凑策展数据集，在DCVLR挑战赛中提交方案。通过赛后消融实验，分析基于难度的样本选择、数据集大小、多样性和合成增强等策略对性能的影响。

Result: 提交方案在挑战赛中排名第一。研究发现：基于难度的样本选择是性能提升的主要驱动力；增加数据集大小主要减少运行间方差而非提升平均准确率；常用的多样性和合成增强启发式方法无额外益处且常降低性能。

Conclusion: DCVLR挑战赛代表了饱和状态评估，突出了对齐和难度在多模态推理数据效率中的核心作用。数据策展应更关注样本质量和难度分布，而非单纯扩大数据集规模。

Abstract: We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.

</details>


### [6] [ReCreate: Reasoning and Creating Domain Agents Driven by Experience](https://arxiv.org/abs/2601.11100)
*Zhezheng Hao,Hong Wang,Jian Luo,Jianqing Zhang,Yuyan Zhou,Qiang Lin,Can Wang,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: ReCreate是一个经验驱动的自动创建领域智能体框架，通过分析智能体交互历史来优化和改进智能体设计，显著优于人工设计和现有自动化方法。


<details>
  <summary>Details</summary>
Motivation: 当前大多数实用智能体仍需要人工设计，因为任务差异大且构建成本高。现有自动化方法将智能体生成视为黑盒过程，仅依赖最终性能指标，忽略了成功/失败的关键证据，且计算成本高。

Method: 提出ReCreate框架，采用智能体即优化器范式，包含三个核心组件：1) 经验存储和检索机制用于按需检查；2) 推理-创建协同管道将执行经验映射到脚手架编辑；3) 分层更新将实例级细节抽象为可重用的领域模式。

Result: 在多个不同领域的实验中，ReCreate始终优于人工设计的智能体和现有的自动化智能体生成方法，即使从最小的种子脚手架开始也能取得良好效果。

Conclusion: ReCreate通过系统利用智能体交互历史中的具体信号，成功解决了自动创建和适应领域智能体的挑战，为智能体自动生成提供了更有效、更经济的解决方案。

Abstract: Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.

</details>


### [7] [Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems](https://arxiv.org/abs/2601.11147)
*Zixu Wang,Bingbing Xu,Yige Yuan,Huawei Shen,Xueqi Cheng*

Main category: cs.AI

TL;DR: SCALE框架通过任务级工作流生成和自预测评估，在保持性能的同时大幅降低多智能体系统的令牌消耗


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统工作流生成方法在任务级和查询级各有优劣，但相对成本和效益不明确，且基于执行的评估方法令牌消耗大且不可靠

Method: 提出SCALE框架：通过少量样本校准的自预测优化器进行任务级工作流生成，替代昂贵的全验证执行评估

Result: SCALE在多个数据集上平均性能仅下降0.61%，同时将总体令牌使用量减少高达83%

Conclusion: 查询级工作流生成并非总是必要，任务级工作流结合自预测评估可在保持性能的同时显著降低成本

Abstract: Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \textbf{SCALE}, which means \underline{\textbf{S}}elf prediction of the optimizer with few shot \underline{\textbf{CAL}}ibration for \underline{\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\%.

</details>


### [8] [TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech](https://arxiv.org/abs/2601.11178)
*Girish A. Koushik,Helen Treharne,Diptesh Kanojia*

Main category: cs.AI

TL;DR: TANDEM：一个统一的框架，将视听仇恨检测从二元分类任务转变为结构化推理问题，通过跨模态上下文优化实现精确时间定位和目标识别。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中长格式多模态内容日益增多，有害叙事通过音频、视觉和文本线索的复杂交互构建。现有自动化系统虽然能准确标记仇恨言论，但作为"黑盒"无法提供细粒度、可解释的证据（如精确时间戳和目标身份），难以支持有效的人机协同审核。

Method: 提出TANDEM框架，采用新颖的串联强化学习策略，让视觉-语言和音频-语言模型通过自约束的跨模态上下文相互优化，在不需要密集帧级监督的情况下稳定处理长时间序列推理。

Result: 在三个基准数据集上的实验表明，TANDEM显著优于零样本和上下文增强基线，在HateMM数据集上目标识别F1分数达到0.73（比最先进方法提升30%），同时保持精确的时间定位。二元检测稳健，但在多类别设置中区分冒犯性和仇恨内容仍具挑战性。

Conclusion: 研究表明，即使在复杂的多模态环境中，结构化、可解释的对齐也是可实现的，为下一代透明且可操作的在线安全审核工具提供了蓝图。

Abstract: Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as "black boxes" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.

</details>


### [9] [XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making](https://arxiv.org/abs/2601.11286)
*Weihong Qi,Fan Huang,Rasika Muralidharan,Jisun An,Haewoon Kwak*

Main category: cs.AI

TL;DR: XChoice是一个可解释的框架，用于评估约束决策中AI与人类的对齐程度，通过机制建模而非仅看结果指标，揭示决策因素权重、约束敏感性和权衡取舍。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估主要关注结果一致性（如准确率、F1分数），缺乏对决策机制的深入理解，无法诊断AI与人类在约束决策中的根本差异和潜在偏见。

Method: 构建基于机制的决策模型，拟合人类数据和LLM生成的决策，恢复可解释参数（决策因素重要性、约束敏感性、隐含权衡），通过比较参数向量评估对齐程度。

Result: 在美国时间分配研究中发现模型间和活动间的异质性对齐，黑人和已婚群体存在显著不对齐；通过不变性分析验证鲁棒性，RAG干预可针对性缓解不对齐问题。

Conclusion: XChoice提供基于机制的度量标准，能够诊断不对齐问题并支持超越表面结果匹配的知情改进，为AI与人类对齐评估提供了更深入的分析框架。

Abstract: We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.

</details>


### [10] [AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems](https://arxiv.org/abs/2601.11354)
*Weiyi Wang,Xinchi Chen,Jingjing Gong,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: AstroReason-Bench是一个用于评估太空规划问题中智能体规划能力的基准测试，发现当前智能体在物理约束下的真实世界任务中表现远不如专用求解器。


<details>
  <summary>Details</summary>
Motivation: 现有智能体基准主要关注符号化或弱接地环境，缺乏对物理约束真实世界领域中智能体规划能力的评估，特别是在太空规划这种高风险、多目标、严格物理约束和长时程决策的场景。

Method: 开发AstroReason-Bench基准，整合多种调度机制（包括地面站通信和敏捷地球观测），提供统一的智能体导向交互协议，并在多种最先进的开源和闭源智能体LLM系统上进行评估。

Result: 当前智能体在太空规划问题上表现显著低于专用求解器，揭示了通用规划器在现实约束下的关键局限性。

Conclusion: AstroReason-Bench为未来智能体研究提供了一个具有挑战性和诊断性的测试平台，有助于推动智能体在物理约束真实世界任务中的发展。

Abstract: Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.

</details>


### [11] [Hyperparameter Optimization of Constraint Programming Solvers](https://arxiv.org/abs/2601.11389)
*Hedieh Haddad,Thibault Falque,Pierre Talbot,Pascal Bouvry*

Main category: cs.AI

TL;DR: 提出了一种名为"probe and solve"的两阶段框架，用于约束规划求解器的自动超参数优化，通过贝叶斯优化等方法在时间预算内寻找最优配置，显著提升了求解性能。


<details>
  <summary>Details</summary>
Motivation: 约束规划求解器的性能高度依赖于超参数配置，手动寻找最佳配置需要专业知识且耗时。需要一种自动化的超参数优化方法来提高求解器性能。

Method: 提出probe and solve两阶段框架：1) 探测阶段使用可配置的超参数优化方法（贝叶斯优化和汉明距离搜索）探索不同超参数集；2) 求解阶段使用找到的最佳配置在剩余时间内解决问题。框架集成到CPMpy库中。

Result: 在114个组合问题实例上测试ACE和Choco求解器。使用贝叶斯优化时：ACE在25.4%实例中优于默认配置，57.9%实例表现相当；Choco在38.6%实例中表现更优。贝叶斯优化始终优于汉明距离搜索。

Conclusion: probe and solve算法提供了一种实用、资源感知的约束求解器调优方法，通过模型化探索优于简单局部搜索，能在多样化问题类型上实现稳健的性能提升。

Abstract: The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.
  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.
  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.

</details>


### [12] [Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs](https://arxiv.org/abs/2601.11468)
*Alessandro Padella,Massimiliano de Leoni,Marlon Dumas*

Main category: cs.AI

TL;DR: 本文扩展了基于LLM的预测性流程监控框架，从单一的总时间预测扩展到多KPI预测，在数据稀缺场景下（仅100条轨迹）LLM表现优于基准方法，并展示了其利用先验知识和训练轨迹内部关联的能力。


<details>
  <summary>Details</summary>
Motivation: 预测性流程监控旨在预测进行中流程的结果，现有方法多基于机器学习和深度学习。本文旨在扩展先前基于LLM的预测性流程监控框架，全面评估其通用性、语义利用和推理机制，并扩展到多个关键绩效指标。

Method: 扩展了基于LLM的预测性流程监控框架，从单一的总时间预测扩展到多KPI预测，包括总时间和活动发生预测。通过提示工程利用LLM进行预测，并在数据稀缺设置下进行实验。

Result: 在三个不同事件日志上的实证评估表明，在仅有100条轨迹的数据稀缺设置下，LLM在总时间和活动发生预测方面均超越了基准方法。LLM不仅利用了其内在的先验知识，还利用了训练轨迹之间的内部相关性。

Conclusion: LLM在预测性流程监控中表现出色，特别是在数据稀缺场景下。研究表明LLM并非简单复制现有预测方法，而是进行高阶推理来生成预测，展示了其在流程挖掘领域的潜力。

Abstract: Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.

</details>


### [13] [Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning](https://arxiv.org/abs/2601.11479)
*Yohai Trabelsi,Guojun Xiong,Fentabil Getnet,Stéphane Verguet,Milind Tambe*

Main category: cs.AI

TL;DR: 提出LEG框架，结合大语言模型和扩展贪心算法，在资源有限条件下优化埃塞俄比亚卫生站升级决策，平衡人口覆盖率和专家定性指导


<details>
  <summary>Details</summary>
Motivation: 埃塞俄比亚卫生部升级卫生站以改善基本医疗服务可及性，但资源有限需要优先考虑哪些设施升级，同时需要兼顾专家和利益相关者的多样化偏好

Method: 开发LEG框架：结合具有理论保证的扩展贪心算法进行人口覆盖优化，利用大语言模型进行迭代精炼，融入人机对齐机制，确保解决方案反映专家定性指导

Result: 在埃塞俄比亚三个地区的真实数据上进行实验，证明该框架的有效性，能够为公平、数据驱动的卫生系统规划提供信息

Conclusion: LEG框架成功地将专家知识与优化技术相结合，在保持覆盖保证的同时纳入定性指导，为资源受限环境下的卫生系统规划提供了实用工具

Abstract: Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.

</details>


### [14] [BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics](https://arxiv.org/abs/2601.11492)
*Kaiwen Wang,Kaili Zheng,Rongrong Deng,Qingmin Fan,Milin Zhang,Zongrui Li,Xuesi Zhou,Bo Han,Liren Chen,Chenyi Guo,Ji Wu*

Main category: cs.AI

TL;DR: BoxMind是一个用于拳击战术分析的闭环AI专家系统，通过定义原子击打事件和分层技术战术指标，结合图预测模型和可学习嵌入，将比赛视频转化为可执行的战术建议，在巴黎奥运会上帮助中国队获得历史性成绩。


<details>
  <summary>Details</summary>
Motivation: 格斗类运动如拳击在AI驱动的战术分析方面发展不足，主要由于动作动态复杂且缺乏结构化战术表示。需要将非结构化视频数据转化为战略智能，弥合计算机视觉与竞技体育决策支持之间的差距。

Method: 1. 定义具有精确时间边界、空间和技术属性的原子击打事件；2. 将比赛视频解析为18个分层技术战术指标；3. 提出基于图的预测模型，融合显式技术战术特征与可学习的时间变化潜在嵌入；4. 将比赛结果建模为技术战术指标的可微分函数，将获胜概率梯度转化为可执行的战术调整。

Result: 1. 结果预测模型在BoxerGraph测试集上达到69.8%准确率，在奥运比赛上达到87.5%准确率；2. 系统生成的战略建议与人类专家水平相当；3. 在2024年巴黎奥运会闭环部署中，直接帮助中国国家队获得3金2银的历史性成绩。

Conclusion: BoxMind建立了一个可复制的范式，将非结构化视频数据转化为战略智能，弥合了计算机视觉与竞技体育决策支持之间的差距，为格斗类运动的AI驱动战术分析提供了有效解决方案。

Abstract: Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.

</details>
