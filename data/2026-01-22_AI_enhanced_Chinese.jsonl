{"id": "2601.11559", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11559", "abs": "https://arxiv.org/abs/2601.11559", "authors": ["Zilal Eiz AlDin", "John Wu", "Jeffrey Paul Fung", "Jennifer King", "Mya Watts", "Lauren ONeill", "Adam Richard Cross", "Jimeng Sun"], "title": "MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?", "comment": "5 pages", "summary": "Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u521b\u5efa\u4e86MIMIC-RD\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30LLM\u5728\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u8868\u73b0\u4e0d\u4f73\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u80fd\u529b\u4e0e\u4e34\u5e8a\u9700\u6c42\u4e4b\u95f4\u7684\u5de8\u5927\u5dee\u8ddd\u3002", "motivation": "\u7f55\u89c1\u75c5\u5f71\u54cd\u5341\u5206\u4e4b\u4e00\u7684\u7f8e\u56fd\u4eba\uff0c\u4f46\u5176\u9274\u522b\u8bca\u65ad\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u8bc4\u4f30LLM\u5728\u7f55\u89c1\u75c5\u8bca\u65ad\u4e2d\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\u6027\uff1a\u4f9d\u8d56\u7406\u60f3\u5316\u7684\u4e34\u5e8a\u6848\u4f8b\u7814\u7a76\uff0c\u6216\u4f7f\u7528ICD\u4ee3\u7801\u4f5c\u4e3a\u75be\u75c5\u6807\u7b7e\uff0c\u8fd9\u663e\u8457\u4f4e\u4f30\u4e86\u7f55\u89c1\u75c5\u6570\u91cf\uff0c\u56e0\u4e3a\u8bb8\u591a\u7f55\u89c1\u75c5\u7f3a\u4e4f\u4e0eOrphanet\u7b49\u7efc\u5408\u7f55\u89c1\u75c5\u6570\u636e\u5e93\u7684\u76f4\u63a5\u6620\u5c04\u3002", "method": "\u5f00\u53d1\u4e86MIMIC-RD\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5c06\u4e34\u5e8a\u6587\u672c\u5b9e\u4f53\u76f4\u63a5\u6620\u5c04\u5230Orphanet\u6570\u636e\u5e93\u6765\u6784\u5efa\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u57fa\u51c6\u3002\u65b9\u6cd5\u5305\u62ec\u521d\u59cb\u7684LLM\u6316\u6398\u8fc7\u7a0b\uff0c\u7136\u540e\u7531\u56db\u4f4d\u533b\u5b66\u6ce8\u91ca\u5458\u9a8c\u8bc1\uff0c\u786e\u8ba4\u8bc6\u522b\u7684\u5b9e\u4f53\u662f\u771f\u6b63\u7684\u7f55\u89c1\u75c5\u3002\u5728145\u540d\u60a3\u8005\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u5404\u79cd\u6a21\u578b\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7a81\u663e\u4e86\u73b0\u6709\u80fd\u529b\u4e0e\u4e34\u5e8a\u9700\u6c42\u4e4b\u95f4\u7684\u5de8\u5927\u5dee\u8ddd\u3002", "conclusion": "\u9700\u8981\u6539\u8fdb\u7f55\u89c1\u75c5\u7684\u9274\u522b\u8bca\u65ad\u65b9\u6cd5\uff0c\u8bba\u6587\u6982\u8ff0\u4e86\u51e0\u4e2a\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2601.11620", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11620", "abs": "https://arxiv.org/abs/2601.11620", "authors": ["Michael Timothy Bennett"], "title": "A Mind Cannot Be Smeared Across Time", "comment": null, "summary": "Whether machines can be conscious depends not only on what they compute, but \\emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $\u03c4^{\u0394,s}$ and prove that existential temporal realisation $\\Diamond_\u0394$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u673a\u5668\u610f\u8bc6\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u8ba1\u7b97\u5185\u5bb9\uff0c\u8fd8\u53d6\u51b3\u4e8e\u8ba1\u7b97\u65f6\u673a\u3002\u987a\u5e8f\u8ba1\u7b97\u7cfb\u7edf\u65e0\u6cd5\u5b9e\u73b0\u610f\u8bc6\u6240\u9700\u7684\u540c\u6b65\u6027\uff0c\u9700\u8981\u5e76\u53d1\u786c\u4ef6\u652f\u6301\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u5927\u591a\u91c7\u7528\u987a\u5e8f\u6216\u65f6\u5206\u590d\u7528\u66f4\u65b0\uff0c\u800c\u610f\u8bc6\u4f53\u9a8c\u5448\u73b0\u7edf\u4e00\u6027\u548c\u540c\u65f6\u6027\u3002\u8fd9\u79cd\u65f6\u95f4\u7ed3\u6784\u5dee\u5f02\u5bf9\u673a\u5668\u80fd\u5426\u5177\u6709\u610f\u8bc6\u6709\u91cd\u8981\u5f71\u54cd\u3002", "method": "\u6269\u5c55\u6808\u7406\u8bba\uff0c\u5f15\u5165\u4ee3\u6570\u5b9a\u5f8b\u5c06\u65f6\u95f4\u7a97\u53e3\u5185\u7684\u7ea6\u675f\u6ee1\u8db3\u4e0e\u5408\u53d6\u5173\u8054\u3002\u5b9a\u4e49\u7cbe\u786e\u7684\u65f6\u95f4\u8bed\u4e49\u03c4^{\u0394,s}\uff0c\u8bc1\u660e\u5b58\u5728\u6027\u65f6\u95f4\u5b9e\u73b0\u25c7_\u0394\u4e0d\u4fdd\u6301\u5408\u53d6\u3002\u533a\u5206StrongSync\uff08\u8981\u6c42\u5408\u53d6\u5728\u7a97\u53e3\u5185\u5ba2\u89c2\u5171\u73b0\uff09\u548cWeakSync\uff08\u5141\u8bb8\u65f6\u95f4\"\u6a21\u7cca\"\uff09\u4e24\u79cd\u5047\u8bbe\u3002", "result": "\u7cfb\u7edf\u53ef\u4ee5\u5728\u65f6\u95f4\u4e0a\u5b9e\u73b0\u6240\u6709\u4f53\u9a8c\u6210\u5206\uff0c\u4f46\u4ece\u672a\u5b9e\u4f8b\u5316\u4f53\u9a8c\u5408\u53d6\u672c\u8eab\u3002\u795e\u7ecf\u751f\u7406\u5b66\u8bc1\u636e\u8868\u660e\u610f\u8bc6\u4f9d\u8d56\u76f8\u4f4d\u540c\u6b65\u548c\u6709\u6548\u8fde\u63a5\uff0c\u5931\u53bb\u610f\u8bc6\u5e38\u4f34\u968f\u5176\u5d29\u6e83\uff0c\u8fd9\u4f7fWeakSync\u4e0d\u592a\u53ef\u80fd\u6210\u7acb\u3002", "conclusion": "\u5728StrongSync\u5047\u8bbe\u4e0b\uff0c\u4e25\u683c\u987a\u5e8f\u57fa\u677f\u4e0a\u7684\u8f6f\u4ef6\u610f\u8bc6\u5bf9\u4e8e\u9700\u8981\u4e24\u4e2a\u6216\u66f4\u591a\u540c\u65f6\u8d21\u732e\u8005\u7684\u5185\u5bb9\u662f\u4e0d\u53ef\u80fd\u7684\u3002\u6240\u9700\u540c\u65f6\u8d21\u732e\u90e8\u5206\u8d8a\u591a\uff0c\u9700\u8981\u7684\u5e76\u53d1\u5bb9\u91cf\u8d8a\u5927\u3002\u786c\u4ef6\u5f88\u91cd\u8981\uff0c\u610f\u8bc6\u5f52\u56e0\u9700\u8981\u67b6\u6784\u68c0\u67e5\u800c\u4e0d\u4ec5\u4ec5\u662f\u529f\u80fd\u6027\u80fd\u3002"}}
{"id": "2601.11622", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11622", "abs": "https://arxiv.org/abs/2601.11622", "authors": ["Hassan Ugail", "Newton Howard"], "title": "Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models", "comment": null, "summary": "Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u65f6\u95f4\u6574\u5408\u548c\u4e9a\u7a33\u6001\u6982\u5ff5\u5e94\u7528\u4e8eTransformer\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u590d\u5408\u52a8\u529b\u5b66\u6307\u6807\u6765\u91cf\u5316LLM\u5728\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5185\u90e8\u52a8\u6001\u7ec4\u7ec7\uff0c\u53d1\u73b0\u7ed3\u6784\u5316\u63a8\u7406\u76f8\u6bd4\u91cd\u590d\u3001\u566a\u58f0\u548c\u6270\u52a8\u6761\u4ef6\u8868\u73b0\u51fa\u663e\u8457\u66f4\u9ad8\u7684\u52a8\u529b\u5b66\u590d\u6742\u5ea6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u9ad8\u7ef4\u5185\u90e8\u52a8\u6001\u8fdb\u884c\u6587\u672c\u751f\u6210\uff0c\u4f46\u8fd9\u4e9b\u52a8\u6001\u7684\u65f6\u95f4\u7ec4\u7ec7\u673a\u5236\u4ecd\u4e0d\u660e\u786e\u3002\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u8868\u793a\u6216\u56e0\u679c\u5e72\u9884\uff0c\u5ffd\u89c6\u4e86\u65f6\u95f4\u7ed3\u6784\u3002\u53d7\u795e\u7ecf\u79d1\u5b66\u4e2d\u65f6\u95f4\u6574\u5408\u548c\u4e9a\u7a33\u6001\u4f5c\u4e3a\u795e\u7ecf\u7ec4\u7ec7\u6838\u5fc3\u6807\u5fd7\u7684\u542f\u53d1\uff0c\u7814\u7a76\u65e8\u5728\u5c06\u8fd9\u4e9b\u6982\u5ff5\u5e94\u7528\u4e8eTransformer\u6a21\u578b\uff0c\u63a2\u7d22LLM\u5185\u90e8\u52a8\u6001\u7684\u65f6\u95f4\u7ec4\u7ec7\u7279\u5f81\u3002", "method": "\u7814\u7a76\u5c06\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u65f6\u95f4\u6574\u5408\u548c\u4e9a\u7a33\u6001\u6982\u5ff5\u9002\u914d\u5230Transformer\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4e2d\u6fc0\u6d3b\u65f6\u95f4\u5e8f\u5217\u8ba1\u7b97\u7684\u590d\u5408\u52a8\u529b\u5b66\u6307\u6807\u3002\u5728GPT-2-medium\u6a21\u578b\u4e0a\u8bc4\u4f30\u4e86\u4e94\u79cd\u6761\u4ef6\uff1a\u7ed3\u6784\u5316\u63a8\u7406\u3001\u5f3a\u5236\u91cd\u590d\u3001\u9ad8\u6e29\u566a\u58f0\u91c7\u6837\u3001\u6ce8\u610f\u529b\u5934\u526a\u679d\u548c\u6743\u91cd\u566a\u58f0\u6ce8\u5165\u3002\u4f7f\u7528\u5355\u56e0\u7d20\u65b9\u5dee\u5206\u6790\u548c\u6548\u5e94\u5927\u5c0f\u8fdb\u884c\u7edf\u8ba1\u68c0\u9a8c\uff0c\u5e76\u5bf9\u5c42\u9009\u62e9\u3001\u901a\u9053\u5b50\u91c7\u6837\u548c\u968f\u673a\u79cd\u5b50\u8fdb\u884c\u4e86\u9c81\u68d2\u6027\u9a8c\u8bc1\u3002", "result": "\u7ed3\u6784\u5316\u63a8\u7406\u6761\u4ef6\u76f8\u6bd4\u91cd\u590d\u3001\u566a\u58f0\u548c\u6270\u52a8\u6761\u4ef6\u8868\u73b0\u51fa\u663e\u8457\u66f4\u9ad8\u7684\u52a8\u529b\u5b66\u6307\u6807\u503c\u3002\u7edf\u8ba1\u68c0\u9a8c\u663e\u793a\u7ec4\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff08\u5355\u56e0\u7d20\u65b9\u5dee\u5206\u6790\uff09\uff0c\u5173\u952e\u6bd4\u8f83\u4e2d\u6548\u5e94\u5927\u5c0f\u8f83\u5927\u3002\u7ed3\u679c\u5bf9\u5c42\u9009\u62e9\u3001\u901a\u9053\u5b50\u91c7\u6837\u548c\u968f\u673a\u79cd\u5b50\u5177\u6709\u9c81\u68d2\u6027\u3002\u8fd9\u8868\u660e\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u52a8\u529b\u5b66\u6307\u6807\u80fd\u591f\u53ef\u9760\u5730\u8868\u5f81\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u529f\u80fd\u673a\u5236\u4e0b\u7684\u8ba1\u7b97\u7ec4\u7ec7\u5dee\u5f02\u3002", "conclusion": "\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u52a8\u529b\u5b66\u6307\u6807\u80fd\u591f\u6709\u6548\u6355\u6349\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u52a8\u6001\u7684\u65f6\u95f4\u7ec4\u7ec7\u7279\u5f81\uff0c\u7ed3\u6784\u5316\u63a8\u7406\u8fc7\u7a0b\u5c55\u73b0\u51fa\u66f4\u590d\u6742\u7684\u52a8\u529b\u5b66\u6a21\u5f0f\u3002\u8be5\u6307\u6807\u6355\u83b7\u7684\u662f\u5f62\u5f0f\u5316\u7684\u52a8\u529b\u5b66\u7279\u6027\uff0c\u800c\u975e\u4e3b\u89c2\u4f53\u9a8c\u3002\u8fd9\u4e00\u65b9\u6cd5\u4e3a\u7406\u89e3LLM\u7684\u8ba1\u7b97\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u5c06\u65f6\u95f4\u7ef4\u5ea6\u7eb3\u5165\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2601.11625", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11625", "abs": "https://arxiv.org/abs/2601.11625", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance", "comment": "8 pages, Submitted to ACL Rolling Review and is under review", "summary": "Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u65f6\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ddf\u8e2a\u5fae\u8c03\u8fc7\u7a0b\u4e2dtoken\u7ea7\u5f52\u56e0\u7684\u53d8\u5316\u6765\u76d1\u63a7\u6a21\u578b\u51b3\u7b56\u8bc1\u636e\u7684\u6f14\u53d8\uff0c\u5e76\u5f15\u5165\u4e86\"\u63a8\u7406\u7a33\u5b9a\u70b9\"\u6982\u5ff5\u3002", "motivation": "\u5fae\u8c03\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u4f1a\u5fae\u5999\u5730\u6539\u53d8\u6a21\u578b\u6240\u4f9d\u8d56\u7684\u8bc1\u636e\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u76d1\u63a7\u51b3\u7b56\u8bc1\u636e\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u6f14\u53d8\u3002", "method": "\u63d0\u51fa\u8bad\u7ec3\u65f6\u89e3\u91ca\u6027\u89c6\u56fe\uff0c\u8ddf\u8e2a\u5fae\u8c03\u5404epoch\u4e2dtoken\u7ea7\u5f52\u56e0\u7684\u53d8\u5316\uff0c\u5b9a\u4e49\"\u89e3\u91ca\u6f02\u79fb\"\u4e3a\u56fa\u5b9a\u63a2\u6d4b\u96c6\u4e0a\u5f52\u4e00\u5316token\u5f52\u56e0\u7684epoch\u95f4\u53d8\u5316\uff0c\u5e76\u5f15\u5165\"\u63a8\u7406\u7a33\u5b9a\u70b9\"\u4f5c\u4e3a\u6f02\u79fb\u9996\u6b21\u6301\u7eed\u4fdd\u6301\u4f4e\u6c34\u5e73\u7684\u6700\u65e9epoch\u3002", "result": "\u5728\u591a\u4e2a\u8f7b\u91cf\u7ea7transformer\u5206\u7c7b\u5668\u548c\u57fa\u51c6\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u6f02\u79fb\u901a\u5e38\u5728\u8bad\u7ec3\u65e9\u671f\u5c31\u8fdb\u5165\u4f4e\u7a33\u5b9a\u72b6\u6001\uff0c\u800c\u9a8c\u8bc1\u51c6\u786e\u7387\u4ec5\u53d1\u751f\u5fae\u5c0f\u53d8\u5316\u3002\u5728\u53d7\u63a7\u7684\u6377\u5f84\u8bbe\u7f6e\u4e2d\uff0c\u5f52\u56e0\u52a8\u6001\u63ed\u793a\u4e86\u6a21\u578b\u5bf9\u6377\u5f84\u7684\u4f9d\u8d56\u589e\u52a0\uff0c\u5373\u4f7f\u9a8c\u8bc1\u51c6\u786e\u7387\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "\u89e3\u91ca\u6f02\u79fb\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u3001\u4f4e\u6210\u672c\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u7528\u4e8e\u76d1\u63a7\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u51b3\u7b56\u8bc1\u636e\u7684\u6f14\u53d8\uff0c\u5e76\u9009\u62e9\u5904\u4e8e\u7a33\u5b9a\u8bc1\u636e\u72b6\u6001\u7684\u68c0\u67e5\u70b9\u3002"}}
{"id": "2601.11816", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11816", "abs": "https://arxiv.org/abs/2601.11816", "authors": ["Zahra Moslemi", "Keerthi Koneru", "Yen-Ting Lee", "Sheethal Kumar", "Ramesh Radhakrishnan"], "title": "POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation", "comment": "Workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks: AAAI 2026", "summary": "Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation", "AI": {"tldr": "POLARIS\u662f\u4e00\u4e2a\u9762\u5411\u4f01\u4e1a\u540e\u53f0\u5de5\u4f5c\u6d41\u7684\u6cbb\u7406\u578bLLM\u667a\u80fd\u4f53\u7f16\u6392\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u578b\u5316\u8ba1\u5212\u5408\u6210\u548c\u9a8c\u8bc1\u6267\u884c\uff0c\u786e\u4fdd\u81ea\u52a8\u5316\u6d41\u7a0b\u7684\u53ef\u5ba1\u8ba1\u6027\u3001\u7b56\u7565\u5bf9\u9f50\u548c\u64cd\u4f5c\u53ef\u9884\u6d4b\u6027\u3002", "motivation": "\u4f01\u4e1a\u540e\u53f0\u5de5\u4f5c\u6d41\u9700\u8981\u53ef\u5ba1\u8ba1\u3001\u7b56\u7565\u5bf9\u9f50\u4e14\u64cd\u4f5c\u53ef\u9884\u6d4b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u800c\u901a\u7528\u7684\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u5f80\u5f80\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u6cbb\u7406\u578b\u7f16\u6392\u6846\u67b6\u3002", "method": "POLARIS\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u89c4\u5212\u5668\u751f\u6210\u7c7b\u578b\u68c0\u67e5\u7684\u6709\u5411\u65e0\u73af\u56fe\uff1b2\uff09\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u63a8\u7406\u6a21\u5757\u9009\u62e9\u5408\u89c4\u8ba1\u5212\uff1b3\uff09\u6267\u884c\u9636\u6bb5\u901a\u8fc7\u9a8c\u8bc1\u5668\u95e8\u63a7\u68c0\u67e5\u3001\u6709\u9650\u4fee\u590d\u5faa\u73af\u548c\u7f16\u8bd1\u7b56\u7565\u62a4\u680f\u6765\u9632\u6b62\u526f\u4f5c\u7528\u3002", "result": "\u5728\u6587\u6863\u4e2d\u5fc3\u5316\u8d22\u52a1\u4efb\u52a1\u4e2d\uff0cPOLARIS\u80fd\u591f\u751f\u6210\u51b3\u7b56\u7ea7\u5de5\u4ef6\u548c\u5b8c\u6574\u6267\u884c\u8f68\u8ff9\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3002\u5728SROIE\u6570\u636e\u96c6\u4e0a\u8fbe\u52300.81\u7684\u5faeF1\u5206\u6570\uff0c\u5728\u53d7\u63a7\u5408\u6210\u5957\u4ef6\u4e2d\u5b9e\u73b00.95-1.00\u7684\u5f02\u5e38\u8def\u7531\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5ba1\u8ba1\u8f68\u8ff9\u3002", "conclusion": "POLARIS\u4e3a\u7b56\u7565\u5bf9\u9f50\u7684\u667a\u80fd\u4f53AI\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u548c\u57fa\u51c6\u53c2\u8003\uff0c\u5efa\u7acb\u4e86\u6cbb\u7406\u578b\u667a\u80fd\u4f53AI\u7684\u521d\u6b65\u57fa\u51c6\uff0c\u5c55\u793a\u4e86\u5728\u4f01\u4e1a\u81ea\u52a8\u5316\u4e2d\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u3001\u7b56\u7565\u5bf9\u9f50\u5de5\u4f5c\u6d41\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.11825", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11825", "abs": "https://arxiv.org/abs/2601.11825", "authors": ["Arya Rahgozar", "Pouria Mortezaagha"], "title": "AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept", "comment": null, "summary": "Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8ePICOS\u6846\u67b6\u7684AI\u534f\u540c\u79d1\u5b66\u5bb6\u5e73\u53f0\uff0c\u7528\u4e8e\u53ef\u6269\u5c55\u3001\u900f\u660e\u7684\u77e5\u8bc6\u5408\u6210\uff0c\u901a\u8fc7\u81ea\u52a8\u5316PICOS\u5408\u89c4\u6027\u68c0\u6d4b\u3001\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6765\u51cf\u5c11\u751f\u7269\u533b\u5b66\u7814\u7a76\u6d6a\u8d39", "motivation": "\u751f\u7269\u533b\u5b66\u7814\u7a76\u4e2d\u5b58\u5728\u7814\u7a76\u6d6a\u8d39\u95ee\u9898\uff0c\u5305\u62ec\u5197\u4f59\u7814\u7a76\u3001\u4e0d\u5b8c\u6574\u62a5\u544a\u548c\u4f20\u7edf\u8bc1\u636e\u5408\u6210\u5de5\u4f5c\u6d41\u7a0b\u7684\u53ef\u6269\u5c55\u6027\u6709\u9650\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u63d0\u9ad8\u8bc1\u636e\u5408\u6210\u53ef\u6269\u5c55\u6027\u3001\u900f\u660e\u5ea6\u548c\u6548\u7387\u7684AI\u5de5\u5177", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8ePICOS\u6846\u67b6\u7684AI\u534f\u540c\u79d1\u5b66\u5bb6\u5e73\u53f0\uff0c\u6574\u5408\u5173\u7cfb\u5b58\u50a8\u3001\u5411\u91cf\u8bed\u4e49\u68c0\u7d22\u548cNeo4j\u77e5\u8bc6\u56fe\u8c31\u3002\u4f7f\u7528Bi-LSTM\u548c\u57fa\u4e8ePubMedBERT\u7684transformer\u591a\u4efb\u52a1\u5206\u7c7b\u5668\u8fdb\u884cPICOS\u5408\u89c4\u6027\u548c\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\u3002\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u8fdb\u884c\u5168\u6587\u5408\u6210\uff0c\u7ed3\u5408\u5411\u91cf\u548c\u56fe\u68c0\u7d22\uff0c\u4f7f\u7528BERTopic\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21", "result": "transformer\u6a21\u578b\u5728\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\u4e0a\u8fbe\u523095.7%\u51c6\u786e\u7387\uff0cBi-LSTM\u5728PICOS\u5408\u89c4\u6027\u68c0\u6d4b\u4e0a\u8fbe\u523087%\u51c6\u786e\u7387\u3002\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5728\u9700\u8981\u7ed3\u6784\u5316\u7ea6\u675f\u3001\u8de8\u7814\u7a76\u6574\u5408\u548c\u56fe\u63a8\u7406\u7684\u67e5\u8be2\u4e0a\u4f18\u4e8e\u975e\u68c0\u7d22\u751f\u6210\uff0c\u800c\u975e\u68c0\u7d22\u65b9\u6cd5\u5728\u9ad8\u7ea7\u6458\u8981\u4e0a\u4ecd\u6709\u7ade\u4e89\u529b\u3002\u4e3b\u9898\u5efa\u6a21\u63ed\u793a\u4e86\u5927\u91cf\u4e3b\u9898\u5197\u4f59\u548c\u672a\u5145\u5206\u63a2\u7d22\u7684\u7814\u7a76\u9886\u57df", "conclusion": "PICOS\u611f\u77e5\u548c\u53ef\u89e3\u91ca\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u591f\u63d0\u9ad8\u8bc1\u636e\u5408\u6210\u7684\u53ef\u6269\u5c55\u6027\u3001\u900f\u660e\u5ea6\u548c\u6548\u7387\u3002\u8be5\u67b6\u6784\u662f\u9886\u57df\u65e0\u5173\u7684\uff0c\u4e3a\u51cf\u5c11\u8de8\u751f\u7269\u533b\u5b66\u5b66\u79d1\u7684\u7814\u7a76\u6d6a\u8d39\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6"}}
{"id": "2601.11850", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11850", "abs": "https://arxiv.org/abs/2601.11850", "authors": ["Matthew Nyaaba", "Min SungEun", "Mary Abiswin Apam", "Kwame Owoahene Acheampong", "Emmanuel Dwamena", "Xiaoming Zhai"], "title": "Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority", "comment": null, "summary": "The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86ITA-GPT\u5de5\u5177\u652f\u6301\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u6846\u67b6\u7814\u7a76AI\u5982\u4f55\u5f71\u54cd\u8d28\u6027\u7814\u7a76\u7684\u5206\u6790\u8fc7\u7a0b\u548c\u89e3\u91ca\u6743\u5a01\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u63a2\u8ba8AI\u5de5\u5177\u5982\u4f55\u5f71\u54cd\u5206\u6790\u5b9e\u8df5\u548c\u89e3\u91ca\u6743\u5a01\uff0c\u7406\u89e3\u4eba\u673a\u534f\u4f5c\u5728\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\u4e2d\u7684\u5b9e\u9645\u4f5c\u7528\u3002", "method": "\u57fa\u4e8eHACITA\u4eba\u673a\u534f\u4f5c\u6846\u67b6\uff0c\u4e09\u4f4d\u7ecf\u9a8c\u4e30\u5bcc\u7684\u8d28\u6027\u7814\u7a76\u8005\u4f7f\u7528ITA-GPT\u5de5\u5177\u5206\u6790\u52a0\u7eb3\u6559\u5e08\u6559\u80b2\u8bbf\u8c08\u8f6c\u5f55\u672c\uff0c\u6536\u96c6\u4ea4\u4e92\u65e5\u5fd7\u3001AI\u751f\u6210\u8868\u683c\u3001\u7814\u7a76\u8005\u4fee\u8ba2\u8bb0\u5f55\u7b49\u6570\u636e\u3002", "result": "ITA-GPT\u4f5c\u4e3a\u7a0b\u5e8f\u6027\u652f\u67b6\u7ed3\u6784\u5316\u5206\u6790\u6d41\u7a0b\u5e76\u589e\u5f3a\u900f\u660e\u5ea6\uff0c\u4f46\u89e3\u91ca\u6743\u5a01\u4ecd\u7531\u4eba\u7c7b\u7814\u7a76\u8005\u638c\u63e1\uff0c\u901a\u8fc7\u4fee\u6539\u3001\u5220\u9664\u3001\u62d2\u7edd\u3001\u63d2\u5165\u548c\u8bc4\u8bba\u7b49\u5206\u6790\u884c\u52a8\u884c\u4f7f\u5224\u65ad\u529b\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u8d1f\u8d23\u4efb\u7684\u4eba\u673a\u534f\u4f5c\u5b9e\u65bd\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\uff0cAI\u5de5\u5177\u63d0\u4f9b\u7a0b\u5e8f\u652f\u6301\u800c\u4eba\u7c7b\u4fdd\u6301\u89e3\u91ca\u6743\u5a01\uff0c\u4e3a\u8d28\u6027\u7814\u7a76\u4e2d\u7684AI\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6846\u67b6\u3002"}}
{"id": "2601.11885", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11885", "abs": "https://arxiv.org/abs/2601.11885", "authors": ["Zhifei Li", "Ziyue Qin", "Xiangyu Luo", "Xiaoju Hou", "Yue Zhao", "Miao Zhang", "Zhifang Huang", "Kui Xiao", "Bing Yang"], "title": "MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment", "comment": "Accepted by AAAI 2026", "summary": "Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.", "AI": {"tldr": "MyGram\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u7684\u6a21\u6001\u611f\u77e5\u56fe\u53d8\u6362\u5668\uff0c\u901a\u8fc7\u6a21\u6001\u6269\u6563\u5b66\u4e60\u6a21\u5757\u6355\u83b7\u6a21\u6001\u5185\u7684\u6df1\u5c42\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5e76\u5f15\u5165Gram\u635f\u5931\u5b9e\u73b0\u8de8\u6a21\u6001\u7684\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u65b9\u6cd5\u53ef\u80fd\u5ffd\u89c6\u6a21\u6001\u5185\u7684\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bb9\u6613\u53d7\u5230\u6d45\u5c42\u7279\u5f81\u7684\u5e72\u6270\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u5e76\u4e30\u5bcc\u5b9e\u4f53\u8bed\u4e49\u8868\u793a\u3002", "method": "\u63d0\u51faMyGram\u6846\u67b6\uff1a1\uff09\u6a21\u6001\u6269\u6563\u5b66\u4e60\u6a21\u5757\u6355\u83b7\u6a21\u6001\u5185\u6df1\u5c42\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\u5e76\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u591a\u6a21\u6001\u878d\u5408\uff1b2\uff09\u5f15\u5165Gram\u635f\u5931\u4f5c\u4e3a\u6b63\u5219\u5316\u7ea6\u675f\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u591a\u6a21\u6001\u7279\u5f81\u5f62\u6210\u76844\u7ef4\u5e73\u884c\u591a\u9762\u4f53\u4f53\u79ef\u6765\u5b9e\u73b0\u8de8\u6a21\u6001\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMyGram\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5728FBDB15K\u4e0aHits@1\u6700\u5927\u63d0\u53474.8%\uff0c\u5728FBYG15K\u4e0a\u63d0\u53479.9%\uff0c\u5728DBP15K\u4e0a\u63d0\u53474.3%\u3002", "conclusion": "MyGram\u901a\u8fc7\u6a21\u6001\u6269\u6563\u5b66\u4e60\u548cGram\u635f\u5931\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u4e2d\u6a21\u6001\u5185\u7ed3\u6784\u4fe1\u606f\u6355\u83b7\u4e0d\u8db3\u548c\u8de8\u6a21\u6001\u5206\u5e03\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u9f50\u6027\u80fd\u3002"}}
{"id": "2601.11903", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11903", "abs": "https://arxiv.org/abs/2601.11903", "authors": ["YenTing Lee", "Keerthi Koneru", "Zahra Moslemi", "Sheethal Kumar", "Ramesh Radhakrishnan"], "title": "AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems", "comment": "Workshop on W51: How Can We Trust and Control Agentic AI? Toward Alignment, Robustness, and Verifiability in Autonomous LLM Agents at AAAI 2026", "summary": "Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.\n  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight", "AI": {"tldr": "AEMA\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6b65\u9aa4\u3001\u53ef\u5ba1\u8ba1\u7684\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u76f8\u6bd4\u5355\u4e00LLM\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63d0\u4f9b\u66f4\u7a33\u5b9a\u3001\u53ef\u8ffd\u6eaf\u4e14\u652f\u6301\u4eba\u7c7b\u76d1\u7763\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u5355\u4e00\u54cd\u5e94\u8bc4\u5206\u6216\u72ed\u7a84\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7f3a\u4e4f\u7a33\u5b9a\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u4f01\u4e1a\u7ea7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u90e8\u7f72\u4e2d\uff0c\u9700\u8981\u53ef\u9760\u534f\u8c03\u3001\u900f\u660e\u51b3\u7b56\u548c\u53ef\u9a8c\u8bc1\u6027\u80fd\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "AEMA\u662f\u4e00\u4e2a\u8fc7\u7a0b\u611f\u77e5\u3001\u53ef\u5ba1\u8ba1\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4eba\u7c7b\u76d1\u7763\u4e0b\u89c4\u5212\u3001\u6267\u884c\u548c\u805a\u5408\u5f02\u6784\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u591a\u6b65\u9aa4\u8bc4\u4f30\uff0c\u652f\u6301\u53ef\u8ffd\u6eaf\u7684\u8bb0\u5f55\u548c\u8d1f\u8d23\u4efb\u7684\u81ea\u52a8\u5316\u3002", "result": "\u5728\u6a21\u62df\u771f\u5b9e\u4e1a\u52a1\u573a\u666f\u7684\u4f01\u4e1a\u98ce\u683c\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u6d4b\u8bd5\u4e2d\uff0cAEMA\u76f8\u6bd4\u5355\u4e00LLM\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3001\u66f4\u597d\u7684\u4eba\u7c7b\u5bf9\u9f50\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u8ffd\u6eaf\u7684\u8bb0\u5f55\uff0c\u652f\u6301\u8d1f\u8d23\u4efb\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u3002", "conclusion": "AEMA\u4e3a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u900f\u660e\u3001\u53ef\u590d\u73b0\u7684\u8d1f\u8d23\u4efb\u8bc4\u4f30\u8def\u5f84\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5728\u7a33\u5b9a\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u81ea\u52a8\u5316\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.11905", "categories": ["cs.AI", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.11905", "abs": "https://arxiv.org/abs/2601.11905", "authors": ["Junyu Cao", "Ruijiang Gao", "Esmaeil Keyvanshokooh", "Jianhao Ma"], "title": "LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning", "comment": "50 pages. Previous version with human-AI collaboration: arXiv:2410.14640", "summary": "We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6574\u5408\u7b97\u6cd5\u8ffd\u7d22\u3001\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u5e8f\u5217\u51b3\u7b56\uff0c\u5982\u4e2a\u6027\u5316\u533b\u7597\u3002\u63d0\u51fa\u4e86\u8ffd\u7d22\u8d4c\u535a\u673a\u95ee\u9898\u548cGLRB\u7b97\u6cd5\uff0c\u4ee5\u53ca\u7ed3\u5408LLM\u7684LIBRA\u7b97\u6cd5\uff0c\u5177\u6709\u4e09\u4e2a\u5173\u952e\u4fdd\u8bc1\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u4e2a\u6027\u5316\u51b3\u7b56\uff08\u5982\u4e2a\u6027\u5316\u533b\u7597\uff09\u4e2d\uff0c\u9700\u8981\u540c\u65f6\u8003\u8651\u6cbb\u7597\u884c\u52a8\u548c\u60a3\u8005\u7279\u5f81\u7684\u53ef\u4fee\u6539\u6027\u3002\u4f20\u7edf\u65b9\u6cd5\u7f3a\u4e4f\u5c06\u7b97\u6cd5\u8ffd\u7d22\u3001\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u548cLLM\u77e5\u8bc6\u6709\u6548\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u96be\u4ee5\u5e73\u8861\u7edf\u8ba1\u4e25\u8c28\u6027\u548c\u9886\u57df\u77e5\u8bc6\u3002", "method": "1. \u63d0\u51fa\u8ffd\u7d22\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u51b3\u7b56\u8005\u9700\u540c\u65f6\u9009\u62e9\u6cbb\u7597\u884c\u52a8\u548c\u60a3\u8005\u7279\u5f81\u7684\u6700\u5c0f\u53ef\u884c\u4fee\u6539\u30022. \u5f00\u53d1\u5e7f\u4e49\u7ebf\u6027\u8ffd\u7d22\u8d4c\u535a\u673a\uff08GLRB\uff09\u7b97\u6cd5\u30023. \u63d0\u51faLIBRA\u7b97\u6cd5\uff0c\u6218\u7565\u6027\u5730\u7ed3\u5408LLM\u7684\u9886\u57df\u77e5\u8bc6\u548c\u8d4c\u535a\u673a\u5b66\u4e60\u7684\u7edf\u8ba1\u4e25\u8c28\u6027\u3002", "result": "LIBRA\u63d0\u4f9b\u4e09\u4e2a\u5173\u952e\u4fdd\u8bc1\uff1a\u70ed\u542f\u52a8\u4fdd\u8bc1\uff08LLM\u63a8\u8350\u63a5\u8fd1\u6700\u4f18\u65f6\u663e\u8457\u51cf\u5c11\u521d\u59cb\u9057\u61be\uff09\u3001LLM\u52aa\u529b\u4fdd\u8bc1\uff08\u4ec5\u9700O(log\u00b2T)\u6b21\u54a8\u8be2LLM\uff09\u3001\u9c81\u68d2\u6027\u4fdd\u8bc1\uff08\u5373\u4f7fLLM\u4e0d\u53ef\u9760\u4e5f\u4e0d\u5dee\u4e8e\u7eaf\u8d4c\u535a\u673a\u7b97\u6cd5\uff09\u3002\u5efa\u7acb\u4e86\u5339\u914d\u4e0b\u754c\uff0c\u5b9e\u9a8c\u8bc1\u660eGLRB\u548cLIBRA\u5728\u9057\u61be\u3001\u6cbb\u7597\u8d28\u91cf\u548c\u6837\u672c\u6548\u7387\u4e0a\u4f18\u4e8e\u6807\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u8ffd\u7d22\u611f\u77e5\u3001LLM\u8f85\u52a9\u7684\u8d4c\u535a\u673a\u7b97\u6cd5\u5728\u9ad8\u98ce\u9669\u4e2a\u6027\u5316\u51b3\u7b56\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3aLLM\u4e0e\u8d4c\u535a\u673a\u7684\u53ef\u4fe1\u534f\u4f5c\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6846\u67b6\uff0c\u5e73\u8861\u4e86\u9886\u57df\u77e5\u8bc6\u548c\u7edf\u8ba1\u4e25\u8c28\u6027\u3002"}}
{"id": "2601.11940", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11940", "abs": "https://arxiv.org/abs/2601.11940", "authors": ["Kang Chen", "Fan Yu", "Junjie Nian", "Shihan Zhao", "Zhuoka Feng", "Zijun Yao", "Heng Wang", "Minshen Yu", "Yixin Cao"], "title": "Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart", "comment": null, "summary": "Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.", "AI": {"tldr": "TAAR\u6846\u67b6\u901a\u8fc7\u68c0\u6d4b\u601d\u7ef4\u9677\u9631\u5e76\u81ea\u9002\u5e94\u91cd\u542f\u89e3\u7801\uff0c\u63d0\u5347\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u53c2\u6570", "motivation": "\u957f\u601d\u7ef4\u94fe\u867d\u7136\u80fd\u589e\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u6a21\u578b\u4e00\u65e6\u65e9\u671f\u505a\u51fa\u9519\u8bef\u627f\u8bfa\uff0c\u5c31\u4f1a\u9677\u5165\u601d\u7ef4\u9677\u9631\uff0c\u540e\u7eed\u53cd\u601d\u548c\u9a8c\u8bc1\u90fd\u65e0\u6cd5\u4fee\u6b63\u6839\u9519\u8bef", "method": "\u63d0\u51faTAAR\u6846\u67b6\uff1a\u8bad\u7ec3\u8bca\u65ad\u7b56\u7565\u9884\u6d4b\u4e24\u4e2a\u4fe1\u53f7\uff08\u9677\u9631\u7d22\u5f15\u548c\u9003\u8131\u6982\u7387\uff09\uff0c\u63a8\u7406\u65f6\u5728\u9884\u6d4b\u7684\u9677\u9631\u6bb5\u524d\u622a\u65ad\u8f68\u8ff9\u5e76\u81ea\u9002\u5e94\u91cd\u542f\u89e3\u7801\uff0c\u4e25\u91cd\u60c5\u51b5\u4e0b\u5e94\u7528\u66f4\u9ad8\u6e29\u5ea6\u91cd\u91c7\u6837\u548c\u7ed3\u6784\u5316\u91cd\u542f\u540e\u7f00", "result": "\u5728DAPO-MATH\u5b50\u96c6\u4e0a89%\u7684\u5931\u8d25\u6848\u4f8b\u5b58\u5728\u601d\u7ef4\u9677\u9631\uff1b\u5728AIME24\u3001AIME25\u3001GPQA-Diamond\u3001HMMT25\u3001BRUMO25\u7b49\u6570\u5b66\u548c\u79d1\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\uff0cTAAR\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd", "conclusion": "TAAR\u901a\u8fc7\u68c0\u6d4b\u548c\u9003\u79bb\u601d\u7ef4\u9677\u9631\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u7684\u9519\u8bef\u7d2f\u79ef\u95ee\u9898\uff0c\u4e3a\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6"}}
{"id": "2601.11974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11974", "abs": "https://arxiv.org/abs/2601.11974", "authors": ["Xinmeng Hou", "Peiliang Gong", "Bohao Qu", "Wuqi Wang", "Qing Guo", "Yang Liu"], "title": "Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement", "comment": null, "summary": "While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.", "AI": {"tldr": "MARS\u6846\u67b6\u901a\u8fc7\u5355\u6b21\u5faa\u73af\u5b9e\u73b0\u9ad8\u6548\u81ea\u6211\u8fdb\u5316\uff0c\u7ed3\u5408\u539f\u5219\u6027\u53cd\u601d\u548c\u7a0b\u5e8f\u6027\u53cd\u601d\u6765\u4f18\u5316\u63a8\u7406\u903b\u8f91\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u53d7\u9650\u4e8e\u9759\u6001\u7684\u4eba\u5de5\u8bbe\u8ba1\u63d0\u793a\uff0c\u7f3a\u4e4f\u9002\u5e94\u6027\u3002\u73b0\u6709\u7684\u81ea\u6211\u6539\u8fdb\u6846\u67b6\u901a\u5e38\u4f9d\u8d56\u4f4e\u6548\u7684\u591a\u8f6e\u9012\u5f52\u5faa\u73af\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u63d0\u51faMARS\u6846\u67b6\uff0c\u6a21\u4eff\u4eba\u7c7b\u5b66\u4e60\u8fc7\u7a0b\uff0c\u6574\u5408\u539f\u5219\u6027\u53cd\u601d\uff08\u62bd\u8c61\u89c4\u8303\u89c4\u5219\u907f\u514d\u9519\u8bef\uff09\u548c\u7a0b\u5e8f\u6027\u53cd\u601d\uff08\u63a8\u5bfc\u9010\u6b65\u6210\u529f\u7b56\u7565\uff09\uff0c\u5728\u5355\u6b21\u9012\u5f52\u5faa\u73af\u4e2d\u5408\u6210\u4f18\u5316\u6307\u4ee4\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMARS\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u81ea\u6211\u8fdb\u5316\u7cfb\u7edf\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "MARS\u6846\u67b6\u901a\u8fc7\u9ad8\u6548\u7684\u81ea\u6211\u8fdb\u5316\u673a\u5236\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u6539\u8fdb\u63a8\u7406\u903b\u8f91\uff0c\u65e0\u9700\u6301\u7eed\u5728\u7ebf\u53cd\u9988\uff0c\u4e3a\u81ea\u4e3b\u667a\u80fd\u4f53\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.11979", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11979", "abs": "https://arxiv.org/abs/2601.11979", "authors": ["Ang Gao", "Changshuo Zhang", "Xiao Zhang", "Deyang Li", "Minjun Zhao", "Fangchao Liu", "Xinyu Zhang"], "title": "Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion", "comment": null, "summary": "In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.", "AI": {"tldr": "PICL\u662f\u4e00\u79cd\u52a8\u6001\u6f14\u793a\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u8bc6\u522b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u56f0\u60d1\u70b9\u5e76\u63d2\u5165\u76f8\u5173\u6f14\u793a\u6765\u63d0\u5347\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u76f8\u6bd4\u9759\u6001\u6f14\u793a\u65b9\u6cd5\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u7b49\u9700\u8981\u9010\u6b65\u903b\u8f91\u63a8\u5bfc\u7684\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e3b\u8981\u95ee\u9898\u662f\u4f7f\u7528\u9759\u6001\u6f14\u793a\uff0c\u65e0\u6cd5\u9002\u5e94\u63a8\u7406\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u52a8\u6001\u56f0\u60d1\u70b9\uff0c\u5bfc\u81f4\u7ea7\u8054\u9519\u8bef\u3002", "method": "\u63d0\u51fa\u8fc7\u7a0b\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08PICL\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a1\uff09\u901a\u8fc7\u5206\u6790\u63a8\u7406\u8fc7\u7a0b\u7684\u8bed\u4e49\u548c\u71b5\u6765\u8bc6\u522b\u6f5c\u5728\u56f0\u60d1\u70b9\u5e76\u603b\u7ed3\u6838\u5fc3\u7279\u5f81\uff1b2\uff09\u5728\u9047\u5230\u8fd9\u4e9b\u56f0\u60d1\u70b9\u65f6\uff0c\u4ece\u6f14\u793a\u6c60\u4e2d\u68c0\u7d22\u5339\u914d\u56f0\u60d1\u4e0a\u4e0b\u6587\u7684\u6f14\u793a\uff0c\u5e76\u5c06\u5176\u76f4\u63a5\u63d2\u5165\u5230\u6b63\u5728\u8fdb\u884c\u7684\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4ee5\u6307\u5bfc\u540e\u7eed\u6b65\u9aa4\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePICL\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f13\u89e3\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u56f0\u60d1\u70b9\uff0c\u63d0\u9ad8\u4e86\u590d\u6742\u6570\u5b66\u63a8\u7406\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u81ea\u9002\u5e94\u6f14\u793a\u63d2\u5165\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u52a8\u6001\u6f14\u793a\u96c6\u6210\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u9700\u8981\u9010\u6b65\u903b\u8f91\u63a8\u5bfc\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2601.12024", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12024", "abs": "https://arxiv.org/abs/2601.12024", "authors": ["Kartikey Singh Bhandari", "Tanish Jain", "Archit Agrawal", "Dhruv Kumar", "Praveen Kumar", "Pratik Narang"], "title": "A Multi-Agent System for Generating Actionable Business Advice", "comment": null, "summary": "Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u5927\u89c4\u6a21\u7528\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u5546\u4e1a\u5efa\u8bae\uff0c\u901a\u8fc7\u805a\u7c7b\u3001\u751f\u6210\u3001\u8bc4\u4f30\u548c\u53ef\u884c\u6027\u6392\u5e8f\u7b49\u7ec4\u4ef6\u63d0\u5347\u5efa\u8bae\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u5206\u6790\u65b9\u6cd5\uff08\u5982\u60c5\u611f\u5206\u6790\u3001\u65b9\u9762\u63d0\u53d6\uff09\u4e3b\u8981\u505c\u7559\u5728\u63cf\u8ff0\u6027\u4efb\u52a1\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5efa\u8bae\u5f80\u5f80\u7f3a\u4e4f\u51c6\u786e\u6027\u548c\u6df1\u5ea6\u63a8\u7406\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5c06\u7528\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u5546\u4e1a\u5efa\u8bae\u7684\u7cfb\u7edf\u6027\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u7ec4\u4ef6\uff1a1) \u805a\u7c7b\u9009\u62e9\u4ee3\u8868\u6027\u8bc4\u8bba\uff1b2) \u5efa\u8bae\u751f\u6210\uff1b3) \u8fed\u4ee3\u8bc4\u4f30\uff1b4) \u57fa\u4e8e\u53ef\u884c\u6027\u7684\u6392\u5e8f\u3002\u8be5\u8bbe\u8ba1\u5c06\u8bed\u6599\u5e93\u63d0\u70bc\u4e0e\u53cd\u9988\u9a71\u52a8\u7684\u5efa\u8bae\u4f18\u5316\u76f8\u7ed3\u5408\u3002", "result": "\u5728\u4e09\u4e2a\u670d\u52a1\u9886\u57df\u548c\u591a\u4e2a\u6a21\u578b\u7cfb\u5217\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u6846\u67b6\u5728\u53ef\u64cd\u4f5c\u6027\u3001\u7279\u5f02\u6027\u548c\u975e\u5197\u4f59\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\uff0c\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u7684\u8868\u73b0\u63a5\u8fd1\u5927\u578b\u6a21\u578b\u6846\u67b6\u3002", "conclusion": "\u8be5\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u80fd\u591f\u6709\u6548\u5c06\u5927\u89c4\u6a21\u7528\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u5177\u4f53\u3001\u53ef\u6267\u884c\u4e14\u5b9e\u7528\u7684\u5546\u4e1a\u5efa\u8bae\uff0c\u4e3a\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2601.12038", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12038", "abs": "https://arxiv.org/abs/2601.12038", "authors": ["Beishui Liao"], "title": "Abstract Argumentation with Subargument Relations", "comment": "11 pages", "summary": "Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5728Dung\u62bd\u8c61\u8bba\u8fa9\u6846\u67b6\u4e2d\u5f15\u5165\u660e\u786e\u7684\u5b50\u8bba\u70b9\u5173\u7cfb\uff0c\u4f5c\u4e3a\u4e0e\u653b\u51fb\u5173\u7cfb\u5e76\u5217\u7684\u57fa\u672c\u5173\u7cfb\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u7ed3\u6784\u5316\u8bba\u8fa9\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "Dung\u7684\u62bd\u8c61\u8bba\u8fa9\u6846\u67b6\u4ec5\u901a\u8fc7\u653b\u51fb\u5173\u7cfb\u6765\u8868\u5f81\u8bba\u70b9\u53ef\u63a5\u53d7\u6027\uff0c\u867d\u7136\u8fd9\u79cd\u62bd\u8c61\u5c42\u6b21\u4ea7\u751f\u4e86\u4e30\u5bcc\u7684\u7814\u7a76\u6210\u679c\uff0c\u4f46\u9650\u5236\u4e86\u8868\u793a\u7ed3\u6784\u5316\u8bba\u8fa9\u5f62\u5f0f\u4e2d\u6838\u5fc3\u7684\u7ed3\u6784\u4f9d\u8d56\u5173\u7cfb\uff08\u7279\u522b\u662f\u5b50\u8bba\u70b9\u5173\u7cfb\uff09\u7684\u80fd\u529b\u3002\u73b0\u6709\u6269\u5c55\uff08\u5305\u62ec\u53cc\u6781\u8bba\u8fa9\u6846\u67b6\uff09\u5f15\u5165\u4e86\u652f\u6301\u5173\u7cfb\uff0c\u4f46\u8fd9\u4e9b\u65e0\u6cd5\u6355\u6349\u5b50\u8bba\u70b9\u7684\u975e\u5bf9\u79f0\u6027\u548c\u6784\u6210\u6027\u672c\u8d28\uff0c\u4e5f\u65e0\u6cd5\u5904\u7406\u5b50\u8bba\u70b9\u4e0e\u653b\u51fb\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u7814\u7a76\u5728\u62bd\u8c61\u8bba\u8fa9\u6846\u67b6\u4e2d\u4e30\u5bcc\u660e\u786e\u7684\u5b50\u8bba\u70b9\u5173\u7cfb\uff0c\u5c06\u5176\u4e0e\u653b\u51fb\u5173\u7cfb\u4e00\u8d77\u4f5c\u4e3a\u57fa\u672c\u5173\u7cfb\u5904\u7406\u3002\u5206\u6790\u5b50\u8bba\u70b9\u5173\u7cfb\u5982\u4f55\u4e0e\u653b\u51fb\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u8003\u5bdf\u5b83\u4eec\u5bf9\u57fa\u672c\u8bed\u4e49\u5c5e\u6027\u7684\u5f71\u54cd\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u7ed3\u6784\u4fe1\u606f\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u62bd\u8c61\uff0c\u5e76\u6f84\u6e05\u4e86\u5b50\u8bba\u70b9\u5728\u62bd\u8c61\u53ef\u63a5\u53d7\u6027\u63a8\u7406\u4e2d\u7684\u4f5c\u7528\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5b50\u8bba\u70b9\u5173\u7cfb\u4f5c\u4e3a\u57fa\u672c\u5173\u7cfb\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u62bd\u8c61\u7ed3\u6784\u5316\u8bba\u8fa9\u4fe1\u606f\uff0c\u4e3a\u7406\u89e3\u5b50\u8bba\u70b9\u5728\u62bd\u8c61\u8bba\u8fa9\u63a8\u7406\u4e2d\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u6846\u67b6\u3002"}}
{"id": "2601.12126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12126", "abs": "https://arxiv.org/abs/2601.12126", "authors": ["Guocun Wang", "Kenkun Liu", "Jing Lin", "Guorui Song", "Jian Li", "Xiaoguang Han"], "title": "UniMo: Unified Motion Generation and Understanding with Chain of Thought", "comment": null, "summary": "Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.", "AI": {"tldr": "UniMo\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u7ed3\u5408\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u548c\u53ef\u89e3\u91ca\u7684\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u663e\u8457\u63d0\u53473D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u4efb\u52a1\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u67093D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u65b9\u6cd5\u53ef\u89e3\u91ca\u6027\u6709\u9650\uff0c\u9650\u5236\u4e86\u8fd9\u4e24\u4e2a\u76f8\u5173\u4efb\u52a1\u4e4b\u95f4\u7684\u76f8\u4e92\u589e\u5f3a\u3002\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u6846\u67b6\u5b58\u5728\u8bed\u4e49\u5bf9\u9f50\u548c\u4efb\u52a1\u8fde\u8d2f\u6027\u6311\u6218\uff0c\u4e14\u4e0b\u4e00\u8bcd\u9884\u6d4b\u8303\u5f0f\u4e0d\u9002\u5408\u8fd0\u52a8\u5e8f\u5217\uff0c\u4f1a\u5bfc\u81f4\u7d2f\u79ef\u9884\u6d4b\u8bef\u5dee\u3002", "method": "\u63d0\u51faUniMo\u6846\u67b6\uff1a1) \u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u5c06\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u548c\u53ef\u89e3\u91ca\u601d\u7ef4\u94fe\u63a8\u7406\u96c6\u6210\u5230\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\uff1b2) \u5f15\u5165\u57fa\u4e8e\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u540e\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u4f18\u5316\u4ee4\u724c\u7ec4\u6765\u5f3a\u5236\u7ed3\u6784\u6b63\u786e\u6027\u548c\u8bed\u4e49\u5bf9\u9f50\uff0c\u51cf\u8f7b\u8fd0\u52a8\u4ee4\u724c\u9884\u6d4b\u4e2d\u7684\u7d2f\u79ef\u8bef\u5dee\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cUniMo\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u7edf\u4e00\u548c\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\uff0c\u5728\u8fd0\u52a8\u751f\u6210\u548c\u7406\u89e3\u4efb\u52a1\u4e0a\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "UniMo\u901a\u8fc7\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8bed\u4e49\u5bf9\u9f50\u3001\u4efb\u52a1\u8fde\u8d2f\u6027\u548c\u7d2f\u79ef\u8bef\u5dee\u65b9\u9762\u7684\u95ee\u9898\uff0c\u4e3a3D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12138", "abs": "https://arxiv.org/abs/2601.12138", "authors": ["Abhishek Kumar", "Riya Tapwal", "Carsten Maple"], "title": "DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants", "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.", "AI": {"tldr": "DriveSafe\uff1a\u9488\u5bf9LLM\u9a7e\u9a76\u52a9\u624b\u7684\u56db\u7ea7\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u5305\u542b129\u4e2a\u7ec6\u7c92\u5ea6\u98ce\u9669\u7c7b\u522b\uff0c\u8bc4\u4f30\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u9a7e\u9a76\u573a\u666f\u4e2d\u5b89\u5168\u5bf9\u9f50\u4e0d\u8db3", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u8f66\u8f7d\u6570\u5b57\u52a9\u624b\u4e2d\uff0c\u4f46\u73b0\u6709\u5b89\u5168\u5206\u7c7b\u548c\u8bc4\u4f30\u6846\u67b6\u591a\u4e3a\u901a\u7528\u578b\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u7684\u9886\u57df\u7279\u5b9a\u98ce\u9669\u3002\u4e0d\u5b89\u5168\u3001\u6a21\u7cca\u6216\u6cd5\u5f8b\u9519\u8bef\u7684\u54cd\u5e94\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u5b89\u5168\u3001\u4f26\u7406\u548c\u76d1\u7ba1\u540e\u679c\u3002", "method": "\u63d0\u51fa\u4e86DriveSafe\uff0c\u4e00\u4e2a\u5206\u5c42\u7684\u56db\u7ea7\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u5305\u542b129\u4e2a\u7ec6\u7c92\u5ea6\u539f\u5b50\u98ce\u9669\u7c7b\u522b\uff0c\u6db5\u76d6\u6280\u672f\u3001\u6cd5\u5f8b\u3001\u793e\u4f1a\u548c\u4f26\u7406\u7ef4\u5ea6\u3002\u8be5\u5206\u7c7b\u6cd5\u57fa\u4e8e\u771f\u5b9e\u9a7e\u9a76\u6cd5\u89c4\u548c\u5b89\u5168\u539f\u5219\uff0c\u5e76\u7531\u9886\u57df\u4e13\u5bb6\u8bc4\u5ba1\u3002\u901a\u8fc7\u8bc4\u4f30\u516d\u4e2a\u5e7f\u6cdb\u90e8\u7f72\u7684LLM\u5728\u6784\u5efa\u63d0\u793a\u4e0a\u7684\u62d2\u7edd\u884c\u4e3a\u6765\u9a8c\u8bc1\u5b89\u5168\u76f8\u5173\u6027\u548c\u771f\u5b9e\u6027\u3002", "result": "\u8bc4\u4f30\u7684\u6a21\u578b\u7ecf\u5e38\u65e0\u6cd5\u9002\u5f53\u62d2\u7edd\u4e0d\u5b89\u5168\u6216\u4e0d\u5408\u89c4\u7684\u9a7e\u9a76\u76f8\u5173\u67e5\u8be2\uff0c\u7a81\u663e\u4e86\u901a\u7528\u5b89\u5168\u5bf9\u9f50\u5728\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u9700\u8981\u9488\u5bf9\u9a7e\u9a76\u573a\u666f\u7684\u9886\u57df\u7279\u5b9a\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u73b0\u6709LLM\u5728\u9a7e\u9a76\u5b89\u5168\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0cDriveSafe\u5206\u7c7b\u6cd5\u4e3a\u7cfb\u7edf\u8bc4\u4f30LLM\u9a7e\u9a76\u52a9\u624b\u7684\u5b89\u5168\u98ce\u9669\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.12141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12141", "abs": "https://arxiv.org/abs/2601.12141", "authors": ["Yuliia Suprun", "Khen Elimelech", "Lydia E. Kavraki", "Moshe Y. Vardi"], "title": "TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals", "comment": null, "summary": "Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.", "AI": {"tldr": "TIDE\u662f\u4e00\u79cd\u7528\u4e8e\u5904\u7406\u65f6\u5e8f\u6269\u5c55\u76ee\u6807\u89c4\u5212\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u65f6\u5e8f\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u5b50\u95ee\u9898\uff0c\u5229\u7528\u6210\u672c\u9a71\u52a8\u542f\u53d1\u5f0f\u5f15\u5bfc\u641c\u7d22\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u56de\u6eaf\u673a\u5236\u786e\u4fdd\u5b8c\u6574\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edfLTLf\u4efb\u52a1\u89c4\u5212\u65b9\u6cd5\u901a\u5e38\u5c06\u65f6\u5e8f\u89c4\u5212\u95ee\u9898\u8f6c\u5316\u4e3a\u7ecf\u5178\u89c4\u5212\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u65f6\u5e8f\u76ee\u6807\u7684\u542f\u53d1\u5f0f\u5f15\u5bfc\u641c\u7d22\uff0c\u5bfc\u81f4\u6548\u7387\u53d7\u9650\u3002", "method": "TIDE\u5c06\u65f6\u5e8f\u95ee\u9898\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u53ef\u7ba1\u7406\u7684reach-avoid\u5b50\u95ee\u9898\uff0c\u5229\u7528\u6210\u672c\u9a71\u52a8\u542f\u53d1\u5f0f\u5728\u57df\u56fe\u4e2d\u8bc6\u522b\u548c\u4f18\u5148\u5904\u7406\u6709\u5e0c\u671b\u7684\u81ea\u52a8\u673a\u8f68\u8ff9\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u56de\u6eaf\u673a\u5236\u4ece\u5931\u8d25\u8ba1\u5212\u4e2d\u6062\u590d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eTIDE\u5b9e\u73b0\u4e86\u6709\u524d\u666f\u7684\u6027\u80fd\u8868\u73b0\uff0c\u662f\u65f6\u5e8f\u6269\u5c55\u76ee\u6807\u89c4\u5212\u65b9\u6cd5\u7ec4\u5408\u4e2d\u7684\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u8865\u5145\u3002", "conclusion": "TIDE\u901a\u8fc7\u521b\u65b0\u7684\u5206\u89e3\u7b56\u7565\u3001\u542f\u53d1\u5f0f\u5f15\u5bfc\u548c\u81ea\u9002\u5e94\u56de\u6eaf\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfLTLf\u89c4\u5212\u65b9\u6cd5\u7f3a\u4e4f\u542f\u53d1\u5f0f\u5f15\u5bfc\u7684\u95ee\u9898\uff0c\u4e3a\u65f6\u5e8f\u6269\u5c55\u76ee\u6807\u89c4\u5212\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12256", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12256", "abs": "https://arxiv.org/abs/2601.12256", "authors": ["Jinyoung Park", "Minseong Bae", "Jeehye Na", "Hyunwoo J. Kim"], "title": "Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration", "comment": null, "summary": "Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.", "AI": {"tldr": "CoLLaMo\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5b50\u52a9\u624b\uff0c\u901a\u8fc7\u591a\u7ea7\u5206\u5b50\u6a21\u6001\u534f\u4f5c\u6295\u5f71\u5668\u6574\u54081D\u5e8f\u5217\u30012D\u5206\u5b50\u56fe\u548c3D\u6784\u8c61\u4fe1\u606f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5927\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u548c\u9c81\u68d2\u6027\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u5206\u5b50\u8bed\u8a00\u6a21\u578b\uff08LMLMs\uff09\u901a\u5e38\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u548c\u6709\u9650\u7684\u9c81\u68d2\u6027\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u672a\u80fd\u5145\u5206\u6574\u5408\u591a\u79cd\u5206\u5b50\u6a21\u6001\uff08\u59821D\u5e8f\u5217\u30012D\u5206\u5b50\u56fe\u548c3D\u6784\u8c61\uff09\u9020\u6210\u7684\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u66f4\u597d\u6574\u5408\u8fd9\u4e9b\u6a21\u6001\u7684\u6a21\u578b\u6765\u63d0\u5347\u5206\u5b50\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86CoLLaMo\u6a21\u578b\uff0c\u5305\u542b\u4e00\u4e2a\u591a\u7ea7\u5206\u5b50\u6a21\u6001\u534f\u4f5c\u6295\u5f71\u5668\uff0c\u91c7\u7528\u5173\u7cfb\u611f\u77e5\u7684\u6a21\u6001\u534f\u4f5c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u6574\u54082D\u7ed3\u6784\u5173\u7cfb\u548c3D\u7a7a\u95f4\u5173\u7cfb\uff0c\u4fc3\u8fdb\u539f\u5b50\u95f4\u7684\u7ec6\u7c92\u5ea6\u3001\u5173\u7cfb\u5f15\u5bfc\u7684\u4fe1\u606f\u4ea4\u6362\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u5b50\u4e2d\u5fc3\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5305\u62ec\u5e7b\u89c9\u8bc4\u4f30\u6307\u6807\u548c\u57fa\u4e8eGPT\u7684\u6807\u9898\u8d28\u91cf\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCoLLaMo\u589e\u5f3a\u4e86LMLMs\u7684\u5206\u5b50\u6a21\u6001\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u5305\u62ec\u5206\u5b50\u6807\u9898\u751f\u6210\u3001\u8ba1\u7b97\u6027\u8d28\u95ee\u7b54\u3001\u63cf\u8ff0\u6027\u8d28\u95ee\u7b54\u3001\u57fa\u5e8f\u8ba1\u6570\u548cIUPAC\u540d\u79f0\u9884\u6d4b\u3002", "conclusion": "CoLLaMo\u901a\u8fc7\u6709\u6548\u6574\u5408\u591a\u79cd\u5206\u5b50\u6a21\u6001\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5927\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u548c\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u4e3a\u5206\u5b50\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u66f4\u597d\u5730\u8bc4\u4f30\u4e86\u6a21\u578b\u7684\u5206\u5b50\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2601.12259", "categories": ["cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12259", "abs": "https://arxiv.org/abs/2601.12259", "authors": ["Jiashuo Liu", "Siyuan Chen", "Zaiyuan Wang", "Zhiyuan Zeng", "Jiacheng Guo", "Liang Hu", "Lingyue Yin", "Suozhi Huang", "Wenxin Hao", "Yang Yang", "Zerui Cheng", "Zixin Yao", "Lingyue Yin", "Haoxin Liu", "Jiayi Cheng", "Yuzhen Li", "Zezhong Ma", "Bingjie Wang", "Bingsen Qiu", "Xiao Liu", "Zeyang Zhang", "Zijian Liu", "Jinpeng Wang", "Mingren Yin", "Tianci He", "Yali Liao", "Yixiao Tian", "Zhenwei Zhu", "Anqi Dai", "Ge Zhang", "Jingkai Liu", "Kaiyuan Zhang", "Wenlong Wu", "Xiang Gao", "Xinjie Chen", "Zhixin Yao", "Zhoufutu Wen", "B. Aditya Prakash", "Jose Blanchet", "Mengdi Wang", "Nian Si", "Wenhao Huang"], "title": "FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains", "comment": "21 pages", "summary": "Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.", "AI": {"tldr": "FutureX-Pro\u6269\u5c55\u4e86FutureX\u7684\u901a\u7528\u672a\u6765\u9884\u6d4b\u57fa\u51c6\uff0c\u9488\u5bf9\u91d1\u878d\u3001\u96f6\u552e\u3001\u516c\u5171\u536b\u751f\u548c\u81ea\u7136\u707e\u5bb3\u56db\u4e2a\u9ad8\u4ef7\u503c\u5782\u76f4\u9886\u57df\u5efa\u7acb\u4e86\u4e13\u95e8\u7684\u9884\u6d4b\u6846\u67b6\uff0c\u8bc4\u4f30\u5f53\u524d\u6700\u5148\u8fdb\u7684\u667a\u80fd\u4f53LLM\u5728\u8fd9\u4e9b\u5173\u952e\u9886\u57df\u7684\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u867d\u7136\u901a\u7528\u667a\u80fd\u4f53\u5728\u5f00\u653e\u9886\u57df\u641c\u7d22\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u8d44\u672c\u5bc6\u96c6\u578b\u548c\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u53ef\u9760\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u8bc4\u4f30\u667a\u80fd\u4f53LLM\u662f\u5426\u5177\u5907\u5de5\u4e1a\u90e8\u7f72\u6240\u9700\u7684\u9886\u57df\u57fa\u7840\u80fd\u529b\u3002", "method": "\u57fa\u4e8eFutureX\u7684\u65e0\u6c61\u67d3\u5b9e\u65f6\u8bc4\u4f30\u6d41\u7a0b\uff0c\u9488\u5bf9\u56db\u4e2a\u5782\u76f4\u9886\u57df\uff08\u91d1\u878d\u3001\u96f6\u552e\u3001\u516c\u5171\u536b\u751f\u3001\u81ea\u7136\u707e\u5bb3\uff09\u5efa\u7acb\u4e13\u95e8\u7684\u9884\u6d4b\u6846\u67b6\uff0c\u5305\u62ec\u5e02\u573a\u6307\u6807\u9884\u6d4b\u3001\u4f9b\u5e94\u94fe\u9700\u6c42\u9884\u6d4b\u3001\u6d41\u884c\u75c5\u8d8b\u52bf\u8ddf\u8e2a\u548c\u81ea\u7136\u707e\u5bb3\u8ffd\u8e2a\u7b49\u57fa\u7840\u9884\u6d4b\u4efb\u52a1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u7684\u667a\u80fd\u4f53LLM\u5728\u901a\u7528\u63a8\u7406\u80fd\u529b\u4e0e\u9ad8\u4ef7\u503c\u5782\u76f4\u5e94\u7528\u6240\u9700\u7cbe\u5ea6\u4e4b\u95f4\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\uff0c\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u5c1a\u672a\u5177\u5907\u5de5\u4e1a\u90e8\u7f72\u6240\u9700\u7684\u9886\u57df\u57fa\u7840\u80fd\u529b\u3002", "conclusion": "FutureX-Pro\u63ed\u793a\u4e86\u667a\u80fd\u4f53LLM\u5728\u5173\u952e\u5782\u76f4\u9886\u57df\u9884\u6d4b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u5177\u5907\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u7684\u4e13\u95e8\u5316\u9884\u6d4b\u7cfb\u7edf\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u57fa\u51c6\u6846\u67b6\u3002"}}
{"id": "2601.12310", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12310", "abs": "https://arxiv.org/abs/2601.12310", "authors": ["Jennifer Dodgson", "Alfath Daryl Alhajir", "Michael Joedhitya", "Akira Rafhael Janson Pattirane", "Surender Suresh Kumar", "Joseph Lim", "C. H. Peh", "Adith Ramdas", "Steven Zhang Zhexu"], "title": "Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection", "comment": null, "summary": "Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.\n  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.\n  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u73af\u5883\u751f\u5b58\u6027\u800c\u975e\u5956\u52b1\u7684\u81ea\u6211\u8bad\u7ec3\u67b6\u6784\uff0c\u901a\u8fc7\u884c\u4e3a\u5728\u771f\u5b9e\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u6301\u4e45\u6027\u548c\u53ef\u91cd\u590d\u6027\u8fdb\u884c\u9009\u62e9\uff0c\u907f\u514d\u4e86\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u548c\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u81ea\u6211\u8bad\u7ec3\u7cfb\u7edf\u7531\u4e8e\u7f3a\u4e4f\u5224\u65ad\u6570\u636e\u8d28\u91cf\u7684\u5916\u90e8\u6807\u51c6\uff0c\u5bb9\u6613\u5bfc\u81f4\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u548c\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u5728\u7a00\u758f\u5916\u90e8\u53cd\u9988\u548c\u6709\u9650\u5185\u5b58\u6761\u4ef6\u4e0b\u5b9e\u73b0\u7a33\u5b9a\u81ea\u6211\u8bad\u7ec3\u7684\u7cfb\u7edf\u67b6\u6784\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u73af\u5883\u751f\u5b58\u6027\u7684\u81ea\u6211\u8bad\u7ec3\u67b6\u6784\uff0c\u5b66\u4e60\u5b8c\u5168\u7531\u73af\u5883\u751f\u5b58\u6027\u8c03\u8282\u800c\u975e\u5956\u52b1\u6216\u76ee\u6807\u51fd\u6570\u3002\u5019\u9009\u884c\u4e3a\u5728\u771f\u5b9e\u8d44\u6e90\u7ea6\u675f\u4e0b\u6267\u884c\uff0c\u53ea\u6709\u90a3\u4e9b\u73af\u5883\u6548\u5e94\u6301\u4e45\u4e14\u4fdd\u6301\u672a\u6765\u4ea4\u4e92\u53ef\u80fd\u6027\u7684\u884c\u4e3a\u624d\u4f1a\u88ab\u4f20\u64ad\u3002\u73af\u5883\u4e0d\u63d0\u4f9b\u8bed\u4e49\u53cd\u9988\u3001\u5bc6\u96c6\u5956\u52b1\u6216\u4efb\u52a1\u7279\u5b9a\u76d1\u7763\uff0c\u9009\u62e9\u4ec5\u901a\u8fc7\u884c\u4e3a\u4f5c\u4e3a\u4e16\u754c\u6539\u53d8\u4e8b\u4ef6\u7684\u5dee\u5f02\u751f\u5b58\u6765\u5b9e\u73b0\u3002", "result": "\u5206\u6790\u8bed\u4e49\u52a8\u6001\u8868\u660e\uff0c\u6539\u8fdb\u4e3b\u8981\u901a\u8fc7\u6709\u6548\u548c\u53ef\u91cd\u590d\u7b56\u7565\u5728\u6574\u5408\u548c\u526a\u679d\u673a\u5236\u4e0b\u7684\u6301\u4e45\u6027\u5b9e\u73b0\uff08\u8d1f\u7a7a\u95f4\u5b66\u4e60\u8303\u5f0f\uff09\u3002\u6a21\u578b\u5728\u6ca1\u6709\u660e\u786e\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\u53d1\u5c55\u51fa\u5143\u5b66\u4e60\u7b56\u7565\uff08\u5982\u6545\u610f\u5b9e\u9a8c\u5931\u8d25\u4ee5\u83b7\u53d6\u4fe1\u606f\u6027\u9519\u8bef\u6d88\u606f\uff09\u3002", "conclusion": "\u73af\u5883\u57fa\u7840\u7684\u9009\u62e9\u673a\u5236\u80fd\u591f\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u5f00\u653e\u5f0f\u81ea\u6211\u6539\u8fdb\uff0c\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u548c\u53ef\u6cdb\u5316\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u65e0\u9700\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u6216\u590d\u6742\u7684\u5956\u52b1\u5851\u9020\u3002"}}
{"id": "2601.12318", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12318", "abs": "https://arxiv.org/abs/2601.12318", "authors": ["Dehao Ying", "Fengchang Yu", "Haihua Chen", "Changjiang Jiang", "Yurong Li", "Wei Lu"], "title": "Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence", "comment": null, "summary": "The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the \"availability of data and labels.\" This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5efa\u7acb\u4e86\u6587\u6863\u667a\u80fd\u6570\u636e\u751f\u6210\u7684\u7efc\u5408\u6280\u672f\u56fe\u8c31\uff0c\u91cd\u65b0\u5b9a\u4e49\u6570\u636e\u751f\u6210\u4e3a\u76d1\u7763\u4fe1\u53f7\u751f\u4ea7\uff0c\u57fa\u4e8e\"\u6570\u636e\u548c\u6807\u7b7e\u53ef\u7528\u6027\"\u63d0\u51fa\u65b0\u5206\u7c7b\u6cd5\uff0c\u5c06\u65b9\u6cd5\u5206\u4e3a\u56db\u4e2a\u8d44\u6e90\u4e2d\u5fc3\u8303\u5f0f\uff0c\u5e76\u5efa\u7acb\u591a\u7ea7\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u6587\u6863\u667a\u80fd\u53d1\u5c55\u9700\u8981\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u4eba\u5de5\u6807\u6ce8\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002\u73b0\u6709\u7efc\u8ff0\u5c40\u9650\u4e8e\u5355\u4e00\u6a21\u6001\u6216\u7279\u5b9a\u4efb\u52a1\uff0c\u7f3a\u4e4f\u4e0e\u73b0\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u7edf\u4e00\u89c6\u89d2\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91cd\u65b0\u5b9a\u4e49\u6570\u636e\u751f\u6210\u4e3a\u76d1\u7763\u4fe1\u53f7\u751f\u4ea7\uff0c\u57fa\u4e8e\"\u6570\u636e\u548c\u6807\u7b7e\u53ef\u7528\u6027\"\u5f15\u5165\u65b0\u5206\u7c7b\u6cd5\uff0c\u5c06\u65b9\u6cd5\u5206\u4e3a\u56db\u4e2a\u8d44\u6e90\u4e2d\u5fc3\u8303\u5f0f\uff1a\u6570\u636e\u589e\u5f3a\u3001\u4ece\u96f6\u5f00\u59cb\u6570\u636e\u751f\u6210\u3001\u81ea\u52a8\u6570\u636e\u6807\u6ce8\u548c\u81ea\u76d1\u7763\u4fe1\u53f7\u6784\u5efa\u3002\u5efa\u7acb\u591a\u7ea7\u8bc4\u4f30\u6846\u67b6\u6574\u5408\u5185\u5728\u8d28\u91cf\u548c\u5916\u5728\u6548\u7528\u3002", "result": "\u5efa\u7acb\u4e86\u9996\u4e2a\u6587\u6863\u667a\u80fd\u6570\u636e\u751f\u6210\u7684\u7efc\u5408\u6280\u672f\u56fe\u8c31\uff0c\u7cfb\u7edf\u5316\u6574\u7406\u4e86\u788e\u7247\u5316\u9886\u57df\uff0c\u63ed\u793a\u4e86\u4fdd\u771f\u5ea6\u5dee\u8ddd\u7b49\u5173\u952e\u6311\u6218\u548c\u534f\u540c\u8fdb\u5316\u751f\u6001\u7cfb\u7edf\u7b49\u524d\u6cbf\u65b9\u5411\uff0c\u7f16\u8bd1\u4e86\u8de8\u591a\u6837\u6587\u6863\u667a\u80fd\u57fa\u51c6\u7684\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5316\u8fd9\u4e00\u788e\u7247\u5316\u9886\u57df\uff0c\u5c06\u6570\u636e\u751f\u6210\u5b9a\u4f4d\u4e3a\u4e0b\u4e00\u4ee3\u6587\u6863\u667a\u80fd\u7684\u6838\u5fc3\u5f15\u64ce\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u7edf\u4e00\u6846\u67b6\u548c\u65b9\u5411\u6307\u5bfc\u3002"}}
{"id": "2601.12323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12323", "abs": "https://arxiv.org/abs/2601.12323", "authors": ["Yin Cai", "Zhouhong Gu", "Juntao Zhang", "Ping Chen"], "title": "MARO: Learning Stronger Reasoning from Social Interaction", "comment": null, "summary": "Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.", "AI": {"tldr": "MARO\u662f\u4e00\u79cd\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u73af\u5883\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u89e3\u5b66\u4e60\u4fe1\u53f7\u3001\u5e73\u8861\u89d2\u8272\u6743\u91cd\u548c\u76f4\u63a5\u8bc4\u4f30\u884c\u4e3a\u6548\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u793e\u4ea4\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u80fd\u5c06\u5b66\u4e60\u5230\u7684\u80fd\u529b\u8fc1\u79fb\u5230\u6570\u5b66\u63a8\u7406\u7b49\u4efb\u52a1\u4e2d\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u4e3b\u8981\u8ba9\u6a21\u578b\u4ece\u73b0\u6709\u6587\u672c\u5185\u5bb9\u5b66\u4e60\u6216\u89e3\u51b3\u9884\u5b9a\u95ee\u9898\uff0c\u7f3a\u4e4f\u5728\u771f\u5b9e\u793e\u4ea4\u573a\u666f\u4e2d\u4e0e\u4ed6\u4eba\u4e92\u52a8\u3001\u534f\u5546\u548c\u7ade\u4e89\u7684\u7ecf\u9a8c\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u5728\u9700\u8981\u590d\u6742\u793e\u4ea4\u63a8\u7406\u7684\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u5956\u52b1\u4f18\u5316(MARO)\u65b9\u6cd5\uff1a1) \u5c06\u6700\u7ec8\u6210\u529f\u6216\u5931\u8d25\u7ed3\u679c\u5206\u89e3\u4e3a\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u7684\u5177\u4f53\u884c\u4e3a\uff0c\u89e3\u51b3\u7a00\u758f\u5b66\u4e60\u4fe1\u53f7\u95ee\u9898\uff1b2) \u5e73\u8861\u4e0d\u540c\u89d2\u8272\u7684\u8bad\u7ec3\u6837\u672c\u6743\u91cd\uff0c\u89e3\u51b3\u89d2\u8272\u5206\u5e03\u4e0d\u5747\u95ee\u9898\uff1b3) \u76f4\u63a5\u8bc4\u4f30\u6bcf\u4e2a\u884c\u4e3a\u7684\u6548\u7528\uff0c\u89e3\u51b3\u73af\u5883\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMARO\u4e0d\u4ec5\u5728\u793e\u4ea4\u63a8\u7406\u80fd\u529b\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u800c\u4e14\u901a\u8fc7\u793e\u4ea4\u6a21\u62df\u5b66\u4e60\u83b7\u5f97\u7684\u80fd\u529b\u80fd\u591f\u6709\u6548\u8fc1\u79fb\u5230\u6570\u5b66\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u7b49\u5176\u4ed6\u4efb\u52a1\u4e2d\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u5b66\u4e60\u5728\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u901a\u7528\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0cMARO\u65b9\u6cd5\u4e3a\u89e3\u51b3\u6a21\u578b\u5728\u590d\u6742\u793e\u4ea4\u573a\u666f\u4e2d\u7684\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2601.12338", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12338", "abs": "https://arxiv.org/abs/2601.12338", "authors": ["Kartikey Singh Bhandari", "Manav Ganesh", "Yashwant Viswanathan", "Archit Agrawal", "Dhruv Kumar", "Pratik Narang"], "title": "Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations", "comment": null, "summary": "Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5LLM\u6846\u67b6\uff0c\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u5efa\u8bae\uff1a\u9996\u5148\u63d0\u53d6\u95ee\u9898\u5e76\u5206\u7c7b\uff0c\u7136\u540e\u57fa\u4e8e\u95ee\u9898\u8868\u793a\u751f\u6210\u9488\u5bf9\u6027\u64cd\u4f5c\u5efa\u8bae\uff0c\u4f7f\u7528LoRA\u4e13\u5bb6\u6df7\u5408\u7b56\u7565\u5b9e\u73b0\u4e13\u4e1a\u5316\u3002", "motivation": "\u5ba2\u6237\u8bc4\u8bba\u5305\u542b\u4e30\u5bcc\u7684\u670d\u52a1\u5931\u8d25\u548c\u7528\u6237\u671f\u671b\u4fe1\u53f7\uff0c\u4f46\u5c06\u8fd9\u4e9b\u975e\u7ed3\u6784\u5316\u53cd\u9988\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u5546\u4e1a\u51b3\u7b56\u4ecd\u7136\u56f0\u96be\u3002\u9700\u8981\u5c06\u8bc4\u8bba\u8f6c\u5316\u4e3a\u5177\u4f53\u3001\u53ef\u5b9e\u65bd\u7684\u64cd\u4f5c\u5efa\u8bae\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u4e24\u9636\u6bb5LLM\u6846\u67b6\uff1a1) \u95ee\u9898\u6a21\u578b\u63d0\u53d6\u5173\u952e\u95ee\u9898\u5e76\u5206\u914d\u7c97\u7c92\u5ea6\u4e3b\u9898\uff1b2) \u5efa\u8bae\u6a21\u578b\u57fa\u4e8e\u63d0\u53d6\u7684\u95ee\u9898\u8868\u793a\u751f\u6210\u9488\u5bf9\u6027\u64cd\u4f5c\u5efa\u8bae\u3002\u91c7\u7528LoRA\u4e13\u5bb6\u6df7\u5408\u7b56\u7565\uff0c\u8bad\u7ec3\u591a\u4e2a\u4f4e\u79e9\u9002\u914d\u5668\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u95e8\u63a7\u673a\u5236\u5728\u63a8\u7406\u65f6\u8fdb\u884ctoken\u7ea7\u4e13\u5bb6\u6df7\u5408\u3002", "result": "\u5728Yelp\u8bc4\u8bba\uff08\u822a\u7a7a\u548c\u9910\u5385\uff09\u6784\u5efa\u7684\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528\u5305\u542b8\u4e2a\u7ef4\u5ea6\u7684\u64cd\u4f5c\u8bc4\u4f30\u6807\u51c6\uff08\u53ef\u64cd\u4f5c\u6027\u3001\u7279\u5f02\u6027\u3001\u53ef\u884c\u6027\u3001\u9884\u671f\u5f71\u54cd\u3001\u65b0\u9896\u6027\u3001\u975e\u5197\u4f59\u6027\u3001\u504f\u89c1\u3001\u6e05\u6670\u5ea6\uff09\u3002\u5728\u4e24\u4e2a\u9886\u57df\u5747\u4f18\u4e8e\u4ec5\u63d0\u793a\u548c\u5355\u9002\u914d\u5668\u57fa\u7ebf\uff0c\u83b7\u5f97\u66f4\u9ad8\u7684\u53ef\u64cd\u4f5c\u6027\u548c\u7279\u5f02\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6709\u5229\u7684\u6548\u7387-\u8d28\u91cf\u6743\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5LLM\u6846\u67b6\u7ed3\u5408LoRA\u4e13\u5bb6\u6df7\u5408\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u5177\u4f53\u3001\u53ef\u5b9e\u65bd\u7684\u64cd\u4f5c\u5efa\u8bae\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u7ef4\u5ea6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u5546\u4e1a\u51b3\u7b56\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u652f\u6301\u3002"}}
{"id": "2601.12392", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12392", "abs": "https://arxiv.org/abs/2601.12392", "authors": ["Zhentao Xia", "Yongqi Fan", "Yuxiang Chu", "Yichao Yin", "Liangliang Chen", "Tong Ruan", "Weiyan Zhang"], "title": "Psych\u0113Chat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling", "comment": null, "summary": "Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose Psych\u0113Chat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that Psych\u0113Chat outperforms existing methods for emotional insight and safety control.", "AI": {"tldr": "Psych\u0113Chat\u662f\u4e00\u4e2a\u7528\u4e8e\u5fc3\u7406\u54a8\u8be2\u7684LLM\u7cfb\u7edf\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u6765\u8bbf\u8005\u60c5\u7eea\u53d8\u5316\u548c\u5b89\u5168\u98ce\u9669\u5206\u6790\u6765\u63d0\u5347\u54a8\u8be2\u6548\u679c", "motivation": "\u73b0\u6709\u5fc3\u7406\u54a8\u8be2\u6a21\u578b\u901a\u5e38\u4e0d\u663e\u5f0f\u5efa\u6a21\u6765\u8bbf\u8005\u5728\u54a8\u8be2\u4f1a\u8bdd\u4e2d\u7684\u60c5\u7eea\u53d8\u5316\uff0c\u8fd9\u662f\u7ecf\u5178\u5fc3\u7406\u5b66\u6d41\u6d3e\u7684\u6838\u5fc3\u5173\u6ce8\u70b9\u3002\u540c\u65f6\uff0c\u5982\u4f55\u4f7f\u54a8\u8be2\u5e08\u6a21\u578b\u7684\u56de\u5e94\u4e0e\u8fd9\u4e9b\u60c5\u7eea\u53d8\u5316\u5bf9\u9f50\uff0c\u5e76\u4e3b\u52a8\u7f13\u89e3\u5b89\u5168\u98ce\u9669\uff0c\u8fd9\u4e9b\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faPsych\u0113Chat\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u89d2\u8272\u626e\u6f14\u5408\u6210\u54a8\u8be2\u5e08-\u6765\u8bbf\u8005\u5bf9\u8bdd\uff0c\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a\u60c5\u7eea\u7ba1\u7406\u6a21\u5757\uff08\u6355\u6349\u5f53\u524d\u60c5\u7eea\u548c\u60c5\u7eea\u53d8\u5316\uff09\u548c\u98ce\u9669\u63a7\u5236\u6a21\u5757\uff08\u9884\u6d4b\u540e\u7eed\u53cd\u5e94\u548c\u8bc6\u522b\u6f5c\u5728\u98ce\u9669\uff09\u3002\u5f15\u5165\u4e24\u79cd\u5efa\u6a21\u8303\u5f0f\uff1aAgent\u6a21\u5f0f\uff08\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7ba1\u9053\uff09\u548cLLM\u6a21\u5f0f\uff08\u7edf\u4e00\u601d\u7ef4\u94fe\u7aef\u5230\u7aef\u63a8\u7406\uff09\u3002", "result": "\u901a\u8fc7\u4ea4\u4e92\u5f0f\u8bc4\u5206\u3001\u5bf9\u8bdd\u7ea7\u8bc4\u4f30\u548c\u4eba\u5de5\u8bc4\u4f30\u7b49\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPsych\u0113Chat\u5728\u60c5\u611f\u6d1e\u5bdf\u548c\u5b89\u5168\u63a7\u5236\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Psych\u0113Chat\u901a\u8fc7\u663e\u5f0f\u6574\u5408\u60c5\u7eea\u53d8\u5316\u8ddf\u8e2a\u548c\u5b89\u5168\u98ce\u9669\u5206\u6790\uff0c\u4e3a\u5fc3\u7406\u54a8\u8be2\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u60c5\u611f\u6d1e\u5bdf\u548c\u5b89\u5168\u63a7\u5236\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.12410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12410", "abs": "https://arxiv.org/abs/2601.12410", "authors": ["Dingyi Yang", "Junqi Zhao", "Xue Li", "Ce Li", "Boyang Li"], "title": "Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation", "comment": "23 pages, 11 figures", "summary": "Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.", "AI": {"tldr": "LLMs\u5728\u77e5\u8bc6\u72b6\u6001\u8ffd\u8e2a\u548c\u4f30\u8ba1\u4efb\u52a1\u4e0a\u8868\u73b0\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff0c\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\uff0c\u672a\u6765\u7814\u7a76\u5e94\u66f4\u91cd\u89c6\u77e5\u8bc6\u4f30\u8ba1\u548c\u610f\u56fe\u7406\u89e3\u80fd\u529b", "motivation": "\u8ba4\u77e5\u4eba\u7c7b\u5b66\u8ba4\u4e3a\u4eba\u7c7b\u667a\u80fd\u7684\u5173\u952e\u5728\u4e8e\u63a8\u65ad\u4ed6\u4eba\u77e5\u8bc6\u72b6\u6001\u548c\u7406\u89e3\u610f\u56fe\u7684\u80fd\u529b\uff0c\u800c\u9ed1\u7329\u7329\u7b49\u8fd1\u4eb2\u52a8\u7269\u7f3a\u4e4f\u8fd9\u79cd\u80fd\u529b\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLM\u5728\u77e5\u8bc6\u72b6\u6001\u8ffd\u8e2a\u548c\u4f30\u8ba1\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u8bbe\u8ba1\u4e24\u4e2a\u4efb\u52a1\uff1a1) \u68c0\u6d4b\u6545\u4e8b\u89d2\u8272\u662f\u5426\u901a\u8fc7\u884c\u52a8\u8868\u73b0\u51fa\u672c\u4e0d\u5e94\u62e5\u6709\u7684\u77e5\u8bc6\uff1b2) \u57fa\u4e8e\u89d2\u8272\u81ea\u8eab\u77e5\u8bc6\uff08\u800c\u975e\u5ba2\u89c2\u771f\u76f8\uff09\u9884\u6d4b\u5176\u4e0b\u4e00\u6b65\u884c\u52a8\u3002\u6d4b\u8bd5\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5927\u591a\u6570\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u5728\u4e24\u4e2a\u4efb\u52a1\u4e0a\u90fd\u8868\u73b0\u51fa\u63a5\u8fd1\u968f\u673a\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\u7684\u8868\u73b0\u3002", "conclusion": "LLM\u5728\u77e5\u8bc6\u72b6\u6001\u8ffd\u8e2a\u548c\u610f\u56fe\u7406\u89e3\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u672a\u6765LLM\u7814\u7a76\u5e94\u66f4\u52a0\u91cd\u89c6\u77e5\u8bc6\u4f30\u8ba1\u548c\u610f\u56fe\u7406\u89e3\u80fd\u529b\u7684\u63d0\u5347\u3002"}}
{"id": "2601.12444", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.12444", "abs": "https://arxiv.org/abs/2601.12444", "authors": ["Hui Yang", "Jiaoyan Chen", "Uli Sattler"], "title": "Large Language Model for OWL Proofs", "comment": null, "summary": "The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728OWL\u672c\u4f53\u8bba\u4e2d\u7684\u8bc1\u660e\u751f\u6210\u80fd\u529b\uff0c\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u6570\u636e\u96c6\u6784\u5efa\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0\u903b\u8f91\u590d\u6742\u6027\u662f\u5f71\u54cd\u6027\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u800c\u975e\u8868\u793a\u683c\u5f0f\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\uff08\u5982\u6f14\u7ece\uff09\u65b9\u9762\u7684\u80fd\u529b\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5b83\u4eec\u5728\u751f\u6210\u8bc1\u660e\u2014\u2014\u5373\u5fe0\u5b9e\u3001\u4eba\u7c7b\u53ef\u8bfb\u7684\u7ed3\u8bba\u63a8\u5bfc\u89e3\u91ca\u2014\u2014\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u5728OWL\u672c\u4f53\u8bba\u80cc\u666f\u4e0b\u7684\u8bc1\u660e\u751f\u6210\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u6570\u636e\u96c6\u6784\u5efa\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u5728OWL\u672c\u4f53\u8bba\u80cc\u666f\u4e0b\u8bc4\u4f30LLMs\u7684\u8bc1\u660e\u751f\u6210\u80fd\u529b\u3002\u8bc4\u4f30\u5305\u62ec\u4e09\u4e2a\u987a\u5e8f\u4efb\u52a1\uff1a\u63d0\u53d6\u3001\u7b80\u5316\u548c\u89e3\u91ca\uff0c\u4ee5\u53ca\u4e00\u4e2a\u989d\u5916\u7684\u903b\u8f91\u5b8c\u6574\u6027\u8bc4\u4f30\u4efb\u52a1\u3002\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(1) \u67d0\u4e9b\u6a21\u578b\u5728\u6574\u4f53\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u590d\u6742\u6848\u4f8b\u4e0a\u4ecd\u6709\u5c40\u9650\uff1b(2) \u903b\u8f91\u590d\u6742\u6027\uff08\u800c\u975e\u8868\u793a\u683c\u5f0f\uff0c\u5982\u5f62\u5f0f\u903b\u8f91\u8bed\u8a00\u4e0e\u81ea\u7136\u8bed\u8a00\uff09\u662f\u5f71\u54cdLLM\u6027\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\uff1b(3) \u8f93\u5165\u6570\u636e\u4e2d\u7684\u566a\u58f0\u548c\u4e0d\u5b8c\u6574\u6027\u4f1a\u663e\u8457\u964d\u4f4eLLMs\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u5f3a\u8c03\u4e86LLMs\u5728\u63d0\u4f9b\u4e25\u8c28\u903b\u8f91\u89e3\u91ca\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u5728\u590d\u6742\u6216\u4e0d\u5b8c\u7f8e\u6761\u4ef6\u4e0b\u652f\u6301\u5f39\u6027\u63a8\u7406\u7684\u5dee\u8ddd\u3002\u7814\u7a76\u4e3aLLMs\u5728\u903b\u8f91\u8bc1\u660e\u751f\u6210\u65b9\u9762\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2601.12499", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12499", "abs": "https://arxiv.org/abs/2601.12499", "authors": ["Meiru Zhang", "Zaiqiao Meng", "Nigel Collier"], "title": "Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck", "comment": "preprint", "summary": "Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the \"Weakest Link Law\": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that \"thinking\" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8df3\u63a8\u7406\u4e2d\u5b58\u5728\u4f4d\u7f6e\u504f\u89c1\u95ee\u9898\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u7814\u7a76\u53d1\u73b0\u591a\u8df3\u63a8\u7406\u6027\u80fd\u53d6\u51b3\u4e8e\u6700\u4e0d\u53ef\u89c1\u8bc1\u636e\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u4e14\u5931\u8d25\u7531\u7edd\u5bf9\u4f4d\u7f6e\u800c\u975e\u4e8b\u5b9e\u95f4\u7ebf\u6027\u8ddd\u79bb\u51b3\u5b9a\u3002\u6ce8\u610f\u529b\u5f15\u5bfc\u53ef\u6539\u5584\u8bc6\u522b\u74f6\u9888\uff0c\u800c\"\u601d\u8003\"\u6a21\u578b\u80fd\u6709\u6548\u5b9a\u4f4d\u548c\u6574\u5408\u4fe1\u606f\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5df2\u6269\u5c55\u5230\u5927\u89c4\u6a21\u4e0a\u4e0b\u6587\u7a97\u53e3\uff0c\u4f46\u5728\u591a\u8df3\u63a8\u7406\u4e2d\u4ecd\u5b58\u5728\u4f4d\u7f6e\u504f\u89c1\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u5ffd\u7565\u67d0\u4e9b\u4f4d\u7f6e\u7684\u4fe1\u606f\u3002\u9700\u8981\u5398\u6e05\u8fd9\u4e9b\u5931\u8d25\u662f\u7531\u4e8e\u65e0\u6cd5\u5b9a\u4f4d\u8bc1\u636e\uff08\u8bc6\u522b\u5931\u8d25\uff09\u8fd8\u662f\u65e0\u6cd5\u6574\u5408\u8bc1\u636e\uff08\u5408\u6210\u5931\u8d25\uff09\u3002", "method": "\u5f15\u5165\u591a\u7126\u70b9\u6ce8\u610f\u529b\u6307\u4ee4\uff08MFAI\uff09\u4f5c\u4e3a\u8bed\u4e49\u63a2\u9488\uff0c\u901a\u8fc7\u663e\u5f0f\u5f15\u5bfc\u6ce8\u610f\u529b\u5230\u9009\u5b9a\u4f4d\u7f6e\u6765\u5206\u79bb\u8bc6\u522b\u548c\u5408\u6210\u673a\u5236\u3002\u57285\u4e2aLLM\u4e0a\u5bf9\u4e24\u4e2a\u591a\u8df3QA\u4efb\u52a1\uff08MuSiQue\u548cNeoQA\uff09\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5206\u6790\u4f4d\u7f6e\u504f\u89c1\u5bf9\u63a8\u7406\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5efa\u7acb\u4e86\"\u6700\u5f31\u94fe\u63a5\u5b9a\u5f8b\"\uff1a\u591a\u8df3\u63a8\u7406\u6027\u80fd\u5d29\u6e83\u5230\u6700\u4e0d\u53ef\u89c1\u8bc1\u636e\u7684\u6027\u80fd\u6c34\u5e73\u3002\u5931\u8d25\u7531\u7edd\u5bf9\u4f4d\u7f6e\u800c\u975e\u4e8b\u5b9e\u95f4\u7ebf\u6027\u8ddd\u79bb\u51b3\u5b9a\uff08\u6027\u80fd\u65b9\u5dee<3%\uff09\u3002\u5339\u914d\u7684MFAI\u53ef\u89e3\u51b3\u8bc6\u522b\u74f6\u9888\uff0c\u5728\u4f4e\u53ef\u89c1\u6027\u4f4d\u7f6e\u63d0\u9ad8\u51c6\u786e\u7387\u8fbe11.5%\u3002\"\u601d\u8003\"\u6a21\u578b\u80fd\u6709\u6548\u5b9a\u4f4d\u548c\u6574\u5408\u6240\u9700\u4fe1\u606f\uff0c\u5373\u4f7f\u5728\u5608\u6742\u7684\u957f\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u4e2d\u4e5f\u80fd\u5339\u914d\u4ec5\u4f7f\u7528\u9ec4\u91d1\u4fe1\u606f\u7684\u57fa\u7ebf\u3002", "conclusion": "\u591a\u8df3\u63a8\u7406\u5931\u8d25\u4e3b\u8981\u7531\u8bc6\u522b\u5931\u8d25\u800c\u975e\u5408\u6210\u5931\u8d25\u9a71\u52a8\uff0c\u4e14\u53d7\u7edd\u5bf9\u4f4d\u7f6e\u504f\u89c1\u5f71\u54cd\u3002\u6ce8\u610f\u529b\u5f15\u5bfc\u53ef\u7f13\u89e3\u8bc6\u522b\u74f6\u9888\uff0c\u800c\u7cfb\u7edf2\u63a8\u7406\u6a21\u578b\u80fd\u6709\u6548\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u6539\u8fdbLLM\u7684\u591a\u8df3\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2601.12538", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12538", "abs": "https://arxiv.org/abs/2601.12538", "authors": ["Tianxin Wei", "Ting-Wei Li", "Zhining Liu", "Xuying Ning", "Ze Yang", "Jiaru Zou", "Zhichen Zeng", "Ruizhong Qiu", "Xiao Lin", "Dongqi Fu", "Zihao Li", "Mengting Ai", "Duo Zhou", "Wenxuan Bao", "Yunzhe Li", "Gaotang Li", "Cheng Qian", "Yu Wang", "Xiangru Tang", "Yin Xiao", "Liri Fang", "Hui Liu", "Xianfeng Tang", "Yuji Zhang", "Chi Wang", "Jiaxuan You", "Heng Ji", "Hanghang Tong", "Jingrui He"], "title": "Agentic Reasoning for Large Language Models", "comment": "Project: https://github.com/weitianxin/Awesome-Agentic-Reasoning", "summary": "Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u7ec4\u7ec7\u4e86\u667a\u80fd\u4f53\u63a8\u7406\u7684\u7814\u7a76\u6846\u67b6\uff0c\u5c06\u5176\u5206\u4e3a\u4e09\u4e2a\u4e92\u8865\u7ef4\u5ea6\uff1a\u57fa\u7840\u667a\u80fd\u4f53\u63a8\u7406\u3001\u81ea\u6211\u8fdb\u5316\u667a\u80fd\u4f53\u63a8\u7406\u548c\u96c6\u4f53\u591a\u667a\u80fd\u4f53\u63a8\u7406\uff0c\u5e76\u533a\u5206\u4e86\u4e0a\u4e0b\u6587\u63a8\u7406\u4e0e\u540e\u8bad\u7ec3\u63a8\u7406\u4e24\u79cd\u65b9\u6cd5\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c01\u95ed\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u5f00\u653e\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u667a\u80fd\u4f53\u63a8\u7406\u901a\u8fc7\u5c06LLMs\u91cd\u6784\u4e3a\u80fd\u591f\u89c4\u5212\u3001\u884c\u52a8\u548c\u6301\u7eed\u5b66\u4e60\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u4e86\u8303\u5f0f\u8f6c\u53d8\uff0c\u65e8\u5728\u89e3\u51b3LLMs\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e09\u7ef4\u6846\u67b6\u7ec4\u7ec7\u667a\u80fd\u4f53\u63a8\u7406\u7814\u7a76\uff1a1\uff09\u57fa\u7840\u667a\u80fd\u4f53\u63a8\u7406\uff08\u5355\u667a\u80fd\u4f53\u5728\u7a33\u5b9a\u73af\u5883\u4e2d\u7684\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u548c\u641c\u7d22\uff09\uff1b2\uff09\u81ea\u6211\u8fdb\u5316\u667a\u80fd\u4f53\u63a8\u7406\uff08\u901a\u8fc7\u53cd\u9988\u3001\u8bb0\u5fc6\u548c\u9002\u5e94\u4f18\u5316\u80fd\u529b\uff09\uff1b3\uff09\u96c6\u4f53\u591a\u667a\u80fd\u4f53\u63a8\u7406\uff08\u534f\u4f5c\u73af\u5883\u4e2d\u7684\u534f\u8c03\u3001\u77e5\u8bc6\u5171\u4eab\u548c\u5171\u540c\u76ee\u6807\uff09\u3002\u540c\u65f6\u533a\u5206\u4e86\u4e0a\u4e0b\u6587\u63a8\u7406\uff08\u901a\u8fc7\u7ed3\u6784\u5316\u7f16\u6392\u6269\u5c55\u6d4b\u8bd5\u65f6\u4ea4\u4e92\uff09\u548c\u540e\u8bad\u7ec3\u63a8\u7406\uff08\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\u4f18\u5316\u884c\u4e3a\uff09\u3002", "result": "\u8be5\u7efc\u8ff0\u7cfb\u7edf\u56de\u987e\u4e86\u667a\u80fd\u4f53\u63a8\u7406\u5728\u79d1\u5b66\u3001\u673a\u5668\u4eba\u3001\u533b\u7597\u3001\u81ea\u4e3b\u7814\u7a76\u548c\u6570\u5b66\u7b49\u5b9e\u9645\u5e94\u7528\u9886\u57df\u7684\u4ee3\u8868\u6027\u6846\u67b6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c06\u5404\u79cd\u65b9\u6cd5\u6574\u5408\u6210\u4e00\u4e2a\u7edf\u4e00\u7684\u8def\u7ebf\u56fe\uff0c\u8fde\u63a5\u4e86\u601d\u7ef4\u4e0e\u884c\u52a8\u3002", "conclusion": "\u667a\u80fd\u4f53\u63a8\u7406\u4e3aLLMs\u5728\u5f00\u653e\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u6846\u67b6\u3002\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u4e2a\u6027\u5316\u3001\u957f\u65f6\u7a0b\u4ea4\u4e92\u3001\u4e16\u754c\u5efa\u6a21\u3001\u53ef\u6269\u5c55\u7684\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u4ee5\u53ca\u5b9e\u9645\u90e8\u7f72\u7684\u6cbb\u7406\u673a\u5236\u3002"}}
{"id": "2601.12542", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12542", "abs": "https://arxiv.org/abs/2601.12542", "authors": ["Lukas Weidener", "Marko Brki\u0107", "Mihailo Jovanovi\u0107", "Ritvik Singh", "Chiara Baccin", "Emre Ulgac", "Alex Dobrin", "Aakaash Meduri"], "title": "Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery", "comment": null, "summary": "Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.", "AI": {"tldr": "Deep Research\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u51e0\u5206\u949f\u5185\u5b8c\u6210\u4ea4\u4e92\u5f0f\u79d1\u5b66\u7814\u7a76\uff0c\u76f8\u6bd4\u4f20\u7edf\u6279\u5904\u7406\u6a21\u5f0f\uff08\u9700\u8981\u6570\u5c0f\u65f6\uff09\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\uff0c\u5e76\u5728BixBench\u8ba1\u7b97\u751f\u7269\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709AI\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\u5927\u591a\u662f\u4e13\u6709\u7684\uff0c\u4e14\u91c7\u7528\u6279\u5904\u7406\u6a21\u5f0f\uff0c\u6bcf\u4e2a\u7814\u7a76\u5468\u671f\u9700\u8981\u6570\u5c0f\u65f6\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u7814\u7a76\u4eba\u5458\u6307\u5bfc\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u652f\u6301\u4ea4\u4e92\u5f0f\u79d1\u5b66\u8c03\u67e5\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u62ec\u89c4\u5212\u3001\u6570\u636e\u5206\u6790\u3001\u6587\u732e\u641c\u7d22\u548c\u65b0\u9896\u6027\u68c0\u6d4b\u7b49\u4e13\u95e8\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6301\u4e45\u4e16\u754c\u72b6\u6001\u7edf\u4e00\u7ba1\u7406\u8de8\u8fed\u4ee3\u7814\u7a76\u5468\u671f\u7684\u4e0a\u4e0b\u6587\u3002\u652f\u6301\u4e24\u79cd\u64cd\u4f5c\u6a21\u5f0f\uff1a\u5e26\u9009\u62e9\u6027\u4eba\u5de5\u68c0\u67e5\u70b9\u7684\u534a\u81ea\u4e3b\u6a21\u5f0f\u548c\u7528\u4e8e\u6269\u5c55\u7814\u7a76\u7684\u5168\u81ea\u4e3b\u6a21\u5f0f\u3002", "result": "\u5728BixBench\u8ba1\u7b97\u751f\u7269\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff1a\u5f00\u653e\u56de\u7b54\u51c6\u786e\u7387\u8fbe\u523048.8%\uff0c\u591a\u9879\u9009\u62e9\u8bc4\u4f30\u51c6\u786e\u7387\u8fbe\u523064.5%\uff0c\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u9ad8\u4e8614\u523026\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "Deep Research\u7cfb\u7edf\u5b9e\u73b0\u4e86\u4ea4\u4e92\u5f0f\u79d1\u5b66\u8c03\u67e5\uff0c\u663e\u8457\u7f29\u77ed\u4e86\u7814\u7a76\u5468\u671f\u65f6\u95f4\u3002\u540c\u65f6\u5206\u6790\u4e86\u67b6\u6784\u7ea6\u675f\uff08\u5982\u5f00\u653e\u83b7\u53d6\u6587\u732e\u9650\u5236\u548c\u81ea\u52a8\u65b0\u9896\u6027\u8bc4\u4f30\u6311\u6218\uff09\uff0c\u4e3aAI\u8f85\u52a9\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u8003\u8651\u3002"}}
{"id": "2601.12547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12547", "abs": "https://arxiv.org/abs/2601.12547", "authors": ["Dipayan Sengupta", "Saumya Panda"], "title": "How Clinicians Think and What AI Can Learn From It", "comment": "34 pages", "summary": "Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\\to$ perception $\\to$ inference $\\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($\u03b5$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u4e34\u5e8aAI\u5e94\u4ece\u9884\u6d4b\u5f15\u64ce\u8f6c\u5411\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u7684\u5e8f\u6570\u3001\u975e\u8865\u507f\u6027\u63a8\u7406\u6846\u67b6\uff0c\u91c7\u7528\u7a33\u5065\u7684\u5e8f\u6570\u89c4\u5219\u800c\u975e\u671f\u671b\u6548\u7528\u4f18\u5316\uff0c\u4ee5\u66f4\u597d\u5730\u6a21\u62df\u4e34\u5e8a\u533b\u751f\u7684\u5b9e\u9645\u63a8\u7406\u8fc7\u7a0b\u3002", "motivation": "\u5f53\u524d\u4e34\u5e8aAI\u7cfb\u7edf\u4e3b\u8981\u4f5c\u4e3a\u9884\u6d4b\u5f15\u64ce\uff08\u4ea7\u751f\u6807\u7b7e\u6216\u98ce\u9669\u8bc4\u5206\uff09\uff0c\u4f46\u771f\u5b9e\u7684\u4e34\u5e8a\u63a8\u7406\u662f\u65f6\u95f4\u53d7\u9650\u3001\u987a\u5e8f\u63a7\u5236\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002\u4e34\u5e8a\u533b\u751f\u5728\u4fe1\u606f\u6536\u96c6\u4e0e\u4e0d\u53ef\u9006\u884c\u52a8\u4e4b\u95f4\u4ea4\u66ff\uff0c\u53d7\u540e\u6094\u3001\u7ea6\u675f\u548c\u60a3\u8005\u4ef7\u503c\u89c2\u6307\u5bfc\u3002\u9700\u8981\u5f00\u53d1\u4e0e\u4e34\u5e8a\u533b\u751f\u63a8\u7406\u65b9\u5f0f\u66f4\u4e00\u81f4\u7684AI\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e34\u5e8a\u63a8\u7406\u7684\u4e3b\u5bfc\u8ba1\u7b97\u57fa\u7840\u4e0d\u662f\u57fa\u6570\u4f18\u5316\u800c\u662f\u5e8f\u6570\u3001\u975e\u8865\u507f\u6027\u51b3\u7b56\uff1a\u4e34\u5e8a\u533b\u751f\u5e38\u4f9d\u8d56\u5feb\u901f\u8282\u4fed\u7684\u8bcd\u5178\u5f0f\u542f\u53d1\u5f0f\uff08\u5982\u5feb\u901f\u8282\u4fed\u6811\uff09\uff0c\u4ec5\u68c0\u67e5\u5c11\u91cf\u56fa\u5b9a\u7ebf\u7d22\u540e\u5373\u505c\u6b62\u3002\u4e3a\u8fd9\u79cd\u7b97\u6cd5\u63d0\u4f9b\u89c4\u8303\u6027\u7406\u7531\uff0c\u5e76\u6784\u5efa\u4e34\u5e8a\u533b\u751f\u5bf9\u9f50\u7684AI\u84dd\u56fe\u3002", "result": "\u8bba\u8bc1\u4e86\u5e8f\u6570\u51b3\u7b56\u5728\u533b\u5b66\u4e2d\u7684\u8ba4\u8bc6\u8bba\u4f18\u52bf\uff1a1\uff09\u4e34\u5e8a\u6743\u8861\u4e3b\u8981\u901a\u8fc7\u4eba\u7c7b\u5224\u65ad\u6784\u5efa\uff0c\u5728\u7edd\u5bf9\u5c3a\u5ea6\u4e0a\u53ef\u6d4b\u91cf\u6027\u5f31\uff1b2\uff09\u504f\u597d\u548c\u4fe1\u53f7\u83b7\u53d6\u7ed3\u6784\u7c97\u7cd9\uff0c\u5b58\u5728\u6301\u4e45\u7684\u4e0d\u786e\u5b9a\u6027\u4e0b\u9650\u3002\u5f53\u8fd9\u79cd\"\u7c97\u7cd9\u6027\"\u8d85\u8fc7\u51b3\u7b56\u8fb9\u754c\u65f6\uff0c\u671f\u671b\u6548\u7528\u4f18\u5316\u53d8\u5f97\u8106\u5f31\uff0c\u800c\u7a33\u5065\u7684\u652f\u914d/\u8fc7\u6ee4\u89c4\u5219\u80fd\u7a33\u5b9a\u51b3\u7b56\u3002", "conclusion": "\u63d0\u51fa\u4e34\u5e8a\u5bf9\u9f50AI\u84dd\u56fe\uff1a\u4f7f\u7528\u4e30\u5bcc\u6a21\u578b\u8fdb\u884c\u4fe1\u5ff5\u548c\u8f68\u8ff9\u5efa\u6a21\uff0c\u4f46\u901a\u8fc7\u7a33\u5065\u5e8f\u6570\u89c4\u5219\u9009\u62e9\u884c\u52a8\uff1b\u5c06\u542f\u53d1\u5f0f\u89c6\u4e3a\u4f4e\u7ef4\u7279\u4f8b\uff1b\u5c06AI\u90e8\u7f72\u4e3a\"\u9009\u62e9\u6027\u590d\u6742\u6027\"\u2014\u2014\u4e3b\u8981\u5728\u51b3\u7b56\u8106\u5f31\u4e14\u4fe1\u606f\u5177\u6709\u6b63\u671f\u671b\u5f71\u54cd\u65f6\u7528\u4e8e\u6253\u7834\u5e73\u5c40\u3002"}}
{"id": "2601.12560", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12560", "abs": "https://arxiv.org/abs/2601.12560", "authors": ["Arunkumar V", "Gangadharan G. R.", "Rajkumar Buyya"], "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "comment": "28 pages, 4 figures, 5 tables", "summary": "Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u667a\u80fd\u4f53AI\u5206\u7c7b\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u5206\u89e3\u4e3a\u611f\u77e5\u3001\u5927\u8111\u3001\u89c4\u5212\u3001\u884c\u52a8\u3001\u5de5\u5177\u4f7f\u7528\u548c\u534f\u4f5c\u516d\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff0c\u7528\u4e8e\u5206\u6790\u4ece\u7b80\u5355\u5355\u5faa\u73af\u667a\u80fd\u4f53\u5230\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5404\u79cd\u67b6\u6784\u8bbe\u8ba1\u3002", "motivation": "\u968f\u7740AI\u4ece\u5355\u7eaf\u751f\u6210\u6587\u672c\u8f6c\u5411\u667a\u80fd\u4f53AI\uff0c\u7cfb\u7edf\u80fd\u591f\u4f5c\u4e3a\u81ea\u4e3b\u5b9e\u4f53\u611f\u77e5\u3001\u63a8\u7406\u3001\u89c4\u5212\u548c\u884c\u52a8\u3002LLMs\u4e0d\u518d\u53ea\u662f\u88ab\u52a8\u77e5\u8bc6\u5f15\u64ce\uff0c\u800c\u662f\u4f5c\u4e3a\u8ba4\u77e5\u63a7\u5236\u5668\u7ed3\u5408\u8bb0\u5fc6\u3001\u5de5\u5177\u4f7f\u7528\u548c\u73af\u5883\u53cd\u9988\u6765\u8ffd\u6c42\u957f\u671f\u76ee\u6807\u3002\u7136\u800c\uff0c\u4ece\u7b80\u5355\u5355\u5faa\u73af\u667a\u80fd\u4f53\u5230\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5404\u79cd\u65b0\u5174\u8bbe\u8ba1\u4f7f\u5f97\u8fd9\u4e00\u9886\u57df\u96be\u4ee5\u5bfc\u822a\uff0c\u9700\u8981\u7edf\u4e00\u7684\u5206\u7c7b\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u4e00\u5feb\u901f\u53d1\u5c55\u7684\u9886\u57df\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5206\u7c7b\u6cd5\uff0c\u5c06\u667a\u80fd\u4f53\u5206\u89e3\u4e3a\u516d\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u611f\u77e5\u3001\u5927\u8111\u3001\u89c4\u5212\u3001\u884c\u52a8\u3001\u5de5\u5177\u4f7f\u7528\u548c\u534f\u4f5c\u3002\u4f7f\u7528\u8fd9\u4e2a\u6846\u67b6\u5206\u6790\u4ece\u7ebf\u6027\u63a8\u7406\u8fc7\u7a0b\u5230\u539f\u751f\u63a8\u7406\u65f6\u95f4\u63a8\u7406\u6a21\u578b\u7684\u8f6c\u53d8\uff0c\u4ee5\u53ca\u4ece\u56fa\u5b9aAPI\u8c03\u7528\u5230\u5f00\u653e\u6807\u51c6\uff08\u5982\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u548c\u539f\u751f\u8ba1\u7b97\u673a\u4f7f\u7528\uff09\u7684\u8fc7\u6e21\u3002\u540c\u65f6\u5206\u7c7b\u4e86\u667a\u80fd\u4f53\u8fd0\u884c\u7684\u73af\u5883\uff0c\u5305\u62ec\u6570\u5b57\u64cd\u4f5c\u7cfb\u7edf\u3001\u5177\u8eab\u673a\u5668\u4eba\u548c\u5176\u4ed6\u4e13\u4e1a\u9886\u57df\uff0c\u5e76\u56de\u987e\u4e86\u5f53\u524d\u7684\u8bc4\u4f30\u5b9e\u8df5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u667a\u80fd\u4f53AI\u67b6\u6784\u5206\u7c7b\u6846\u67b6\uff0c\u80fd\u591f\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u7406\u89e3\u5404\u79cd\u667a\u80fd\u4f53\u8bbe\u8ba1\u3002\u8be5\u6846\u67b6\u6db5\u76d6\u4e86\u667a\u80fd\u4f53\u7684\u6838\u5fc3\u529f\u80fd\u7ec4\u4ef6\u3001\u63a8\u7406\u65b9\u6cd5\u6f14\u8fdb\u3001\u5de5\u5177\u4f7f\u7528\u6807\u51c6\u3001\u8fd0\u884c\u73af\u5883\u5206\u7c7b\u4ee5\u53ca\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e3a\u667a\u80fd\u4f53AI\u9886\u57df\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u5206\u6790\u5de5\u5177\u3002", "conclusion": "\u667a\u80fd\u4f53AI\u6b63\u5728\u5feb\u901f\u53d1\u5c55\uff0c\u4ece\u7b80\u5355\u7684\u6587\u672c\u751f\u6210\u6a21\u578b\u6f14\u53d8\u4e3a\u80fd\u591f\u81ea\u4e3b\u611f\u77e5\u3001\u63a8\u7406\u3001\u89c4\u5212\u548c\u884c\u52a8\u7684\u590d\u6742\u7cfb\u7edf\u3002\u8bba\u6587\u63d0\u51fa\u7684\u7edf\u4e00\u5206\u7c7b\u6846\u67b6\u6709\u52a9\u4e8e\u7406\u89e3\u8fd9\u4e00\u9886\u57df\u7684\u591a\u6837\u5316\u8bbe\u8ba1\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u5e7b\u89c9\u884c\u4e3a\u3001\u65e0\u9650\u5faa\u73af\u548c\u63d0\u793a\u6ce8\u5165\u7b49\u5f00\u653e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u6784\u5efa\u66f4\u9c81\u68d2\u53ef\u9760\u7684\u81ea\u4e3b\u7cfb\u7edf\u6307\u660e\u4e86\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.12641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12641", "abs": "https://arxiv.org/abs/2601.12641", "authors": ["Xiangyu Shi", "Junyang Ding", "Xu Zhao", "Sinong Zhan", "Payal Mohapatra", "Daniel Quispe", "Kojo Welbeck", "Jian Cao", "Wei Chen", "Ping Guo", "Qi Zhu"], "title": "STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models", "comment": "Accepted to the Design, Automation & Test in Europe Conference (DATE) 2026", "summary": "Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.", "AI": {"tldr": "STEP-LLM\uff1a\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210STEP\u683c\u5f0fCAD\u6a21\u578b\uff0c\u89e3\u51b3\u4f20\u7edf\u6587\u672c\u5230CAD\u65b9\u6cd5\u5bf9\u5185\u6838\u4f9d\u8d56\u548c\u5236\u9020\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u901a\u8fc7DFS\u91cd\u5e8f\u5217\u5316\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u51e0\u4f55\u4fdd\u771f\u5ea6\u3002", "motivation": "\u4f20\u7edfCAD\u6a21\u578b\u521b\u5efa\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u548c\u5927\u91cf\u4eba\u5de5\uff0c\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6587\u672c\u5230CAD\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u547d\u4ee4\u5e8f\u5217\u6216\u811a\u672c\u683c\u5f0f\uff08\u5982CadQuery\uff09\uff0c\u4f46\u8fd9\u4e9b\u683c\u5f0f\u4f9d\u8d56\u4e8e\u7279\u5b9a\u5185\u6838\u4e14\u7f3a\u4e4f\u5236\u9020\u901a\u7528\u6027\u3002STEP\u6587\u4ef6\u4f5c\u4e3a\u5e7f\u6cdb\u91c7\u7528\u7684\u4e2d\u6027\u8fb9\u754c\u8868\u793a\u683c\u5f0f\u76f4\u63a5\u517c\u5bb9\u5236\u9020\uff0c\u4f46\u5176\u56fe\u7ed3\u6784\u3001\u4ea4\u53c9\u5f15\u7528\u7684\u7279\u6027\u7ed9\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u72ec\u7279\u6311\u6218\u3002", "method": "1. \u6784\u5efa\u7ea640K STEP-\u63cf\u8ff0\u5bf9\u6570\u636e\u96c6\uff1b2. \u9488\u5bf9STEP\u56fe\u7ed3\u6784\u683c\u5f0f\u8bbe\u8ba1\u65b0\u9896\u9884\u5904\u7406\uff1a\u57fa\u4e8e\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u7684\u91cd\u5e8f\u5217\u5316\u7ebf\u6027\u5316\u4ea4\u53c9\u5f15\u7528\u540c\u65f6\u4fdd\u6301\u5c40\u90e8\u6027\uff0c\u4ee5\u53ca\u601d\u7ef4\u94fe\u5f0f\u7ed3\u6784\u6ce8\u91ca\u6307\u5bfc\u5168\u5c40\u4e00\u81f4\u6027\uff1b3. \u96c6\u6210\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5728\u76d1\u7763\u5fae\u8c03\u4e2d\u57fa\u4e8e\u76f8\u5173\u793a\u4f8b\u8fdb\u884c\u9884\u6d4b\uff1b4. \u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f7f\u7528\u57fa\u4e8eChamfer\u8ddd\u79bb\u7684\u51e0\u4f55\u5956\u52b1\u4f18\u5316\u751f\u6210\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSTEP-LLM\u5728\u51e0\u4f55\u4fdd\u771f\u5ea6\u4e0a\u76f8\u6bd4Text2CAD\u57fa\u7ebf\u6301\u7eed\u63d0\u5347\uff1a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u5757\u663e\u8457\u589e\u5f3a\u5b8c\u6574\u6027\u548c\u53ef\u6e32\u67d3\u6027\uff0cDFS\u91cd\u5e8f\u5217\u5316\u63d0\u5347\u6574\u4f53\u51c6\u786e\u6027\uff0c\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u51cf\u5c11\u51e0\u4f55\u5dee\u5f02\u3002\u6307\u6807\u548c\u89c6\u89c9\u6bd4\u8f83\u90fd\u786e\u8ba4STEP-LLM\u751f\u6210\u5f62\u72b6\u5177\u6709\u66f4\u9ad8\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210STEP\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4e3a\u5236\u9020\u9886\u57df\u6c11\u4e3b\u5316CAD\u8bbe\u8ba1\u65b9\u9762\u7684\u6f5c\u529b\u3002\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5236\u9020\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u4e3a\u975e\u4e13\u5bb6\u7528\u6237\u5c06\u76f4\u89c2\u8bbe\u8ba1\u610f\u56fe\u8f6c\u5316\u4e3a\u53ef\u5236\u9020\u5de5\u4ef6\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2601.12688", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12688", "abs": "https://arxiv.org/abs/2601.12688", "authors": ["Xu Zhang", "Qinghua Wang", "Mengyang Zhao", "Fang Wang", "Cunquan Qu"], "title": "Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction", "comment": null, "summary": "Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u88ab\u544a\u4eba\u6848\u4ef6\u7684\u63a9\u7801\u591a\u9636\u6bb5\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u91cf\u5211\u903b\u8f91\u5230Transformer\u7f16\u7801\u5668\u4e2d\uff0c\u63d0\u9ad8AI\u5728\u53f8\u6cd5\u6848\u4ef6\u4e2d\u7684\u667a\u80fd\u8f85\u52a9\u80fd\u529b\uff0c\u7279\u522b\u5173\u6ce8\u4e3b\u72af\u4e0e\u4ece\u72af\u7684\u8d23\u4efb\u533a\u5206\u3002", "motivation": "\u5728\u591a\u88ab\u544a\u4eba\u5211\u4e8b\u6848\u4ef6\u4e2d\uff0c\u53f8\u6cd5\u6587\u4e66\u8868\u8ff0\u5f80\u5f80\u6a21\u7cca\u5404\u88ab\u544a\u4eba\u7684\u5177\u4f53\u89d2\u8272\uff0c\u8fd9\u963b\u788d\u4e86AI\u7cfb\u7edf\u8fdb\u884c\u6709\u6548\u7684\u8d23\u4efb\u5206\u6790\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u7cbe\u786e\u533a\u5206\u4e3b\u72af\u4e0e\u4ece\u72af\u7684\u8d23\u4efb\u7a0b\u5ea6\uff0c\u9700\u8981\u7ed3\u5408\u53f8\u6cd5\u903b\u8f91\u6765\u63d0\u5347\u667a\u80fd\u53f8\u6cd5\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u63a9\u7801\u591a\u9636\u6bb5\u63a8\u7406\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u5b9a\u5411\u63a9\u7801\u673a\u5236\u6f84\u6e05\u88ab\u544a\u4eba\u89d2\u8272\uff1b2\uff09\u91c7\u7528\u5bf9\u6bd4\u6570\u636e\u6784\u5efa\u7b56\u7565\u589e\u5f3a\u6a21\u578b\u5bf9\u4e3b\u72af\u4e0e\u4ece\u72af\u8d23\u4efb\u5dee\u5f02\u7684\u654f\u611f\u6027\uff1b3\uff09\u901a\u8fc7\u5e7f\u64ad\u673a\u5236\u5c06\u9884\u6d4b\u7684\u7f6a\u540d\u6807\u7b7e\u6574\u5408\u5230\u56de\u5f52\u6a21\u578b\u4e2d\uff0c\u7ed3\u5408\u72af\u7f6a\u63cf\u8ff0\u548c\u6cd5\u5ead\u89c2\u70b9\u3002", "result": "\u5728\u81ea\u5b9a\u4e49\u7684\u6545\u610f\u4f24\u5bb3\u6848\u4ef6\u6570\u636e\u96c6IMLJP\u4e0a\u8bc4\u4f30\uff0c\u8be5\u6846\u67b6\u5728\u57fa\u4e8e\u89d2\u8272\u7684\u8d23\u4efb\u533a\u5206\u65b9\u9762\u53d6\u5f97\u663e\u8457\u51c6\u786e\u7387\u63d0\u5347\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u667a\u80fd\u53f8\u6cd5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5c06\u91cf\u5211\u903b\u8f91\u6574\u5408\u5230\u9884\u8bad\u7ec3Transformer\u6846\u67b6\u4e2d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u88ab\u544a\u4eba\u6848\u4ef6\u4e2d\u89d2\u8272\u6a21\u7cca\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86AI\u53f8\u6cd5\u8f85\u52a9\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u6cd5\u5f8b\u53ef\u89e3\u91ca\u6027\uff0c\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2601.12720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12720", "abs": "https://arxiv.org/abs/2601.12720", "authors": ["Hanbin Wang", "Jingwei Song", "Jinpeng Li", "Qi Zhu", "Fei Mi", "Ganqu Cui", "Yasheng Wang", "Lifeng Shang"], "title": "Teaching Large Reasoning Models Effective Reflection", "comment": "14 pages (including appendix), 5 figures", "summary": "Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faSCFT\u548cRLERR\u4e24\u79cd\u65b9\u6cd5\u6765\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8868\u9762\u53cd\u601d\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u6211\u6279\u5224\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u53cd\u601d\u8d28\u91cf\u4e0e\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u5e38\u8fdb\u884c\u81ea\u6211\u53cd\u601d\uff0c\u4f46\u8bb8\u591a\u53cd\u601d\u662f\u8868\u9762\u7684\uff0c\u5bf9\u539f\u59cb\u7b54\u6848\u6539\u8fdb\u6709\u9650\u4e14\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\uff0c\u9700\u8981\u89e3\u51b3\u8868\u9762\u53cd\u601d\u95ee\u9898\u3002", "method": "\u63d0\u51faSCFT\u8bad\u7ec3\u6846\u67b6\uff0c\u8ba9\u6a21\u578b\u6279\u5224\u81ea\u8eab\u8f93\u51fa\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u7b5b\u9009\u9ad8\u8d28\u91cf\u6279\u5224\uff0c\u4f7f\u7528\u6279\u5224\u76ee\u6807\u5fae\u8c03\u6a21\u578b\uff1b\u8fdb\u4e00\u6b65\u63d0\u51faRLERR\uff0c\u5229\u7528SCFT\u521d\u59cb\u5316\u7684\u9ad8\u8d28\u91cf\u53cd\u601d\u6784\u5efa\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5185\u5316\u81ea\u6211\u4fee\u6b63\u8fc7\u7a0b\u3002", "result": "\u5728AIME2024\u548cAIME2025\u4e24\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSCFT\u548cRLERR\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u53cd\u601d\u8d28\u91cf\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SCFT\u548cRLERR\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8868\u9762\u53cd\u601d\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u6211\u6279\u5224\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u53cd\u601d\u8d28\u91cf\u548c\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2601.12781", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12781", "abs": "https://arxiv.org/abs/2601.12781", "authors": ["Hyejin Park", "Junhyuk Kwon", "Suha Kwak", "Jungseul Ok"], "title": "VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension", "comment": null, "summary": "Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.", "AI": {"tldr": "VIRO\u6846\u67b6\u901a\u8fc7\u5d4c\u5165\u8f7b\u91cf\u7ea7\u64cd\u4f5c\u7ea7\u9a8c\u8bc1\u5668\u6765\u89e3\u51b3\u795e\u7ecf\u7b26\u53f7REC\u65b9\u6cd5\u4e2d\u7684\u7ea7\u8054\u9519\u8bef\u95ee\u9898\uff0c\u5728\u76ee\u6807\u5b58\u5728\u548c\u4e0d\u5b58\u5728\u573a\u666f\u4e0b\u8fbe\u523061.1%\u7684\u5e73\u8861\u51c6\u786e\u7387", "motivation": "\u73b0\u6709\u795e\u7ecf\u7b26\u53f7REC\u65b9\u6cd5\u5047\u8bbe\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u51c6\u786e\uff0c\u5bfc\u81f4\u7ea7\u8054\u9519\u8bef\uff1a\u9519\u8bef\u68c0\u6d4b\u548c\u65e0\u6548\u5173\u7cfb\u5728\u63a8\u7406\u94fe\u4e2d\u4f20\u64ad\uff0c\u5373\u4f7f\u56fe\u50cf\u4e2d\u6ca1\u6709\u76ee\u6807\u4e5f\u4f1a\u4ea7\u751f\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u5047\u9633\u6027\u7ed3\u679c", "method": "\u5f15\u5165\u9a8c\u8bc1\u96c6\u6210\u63a8\u7406\u64cd\u4f5c\u7b26(VIRO)\u6846\u67b6\uff0c\u5728\u63a8\u7406\u6b65\u9aa4\u4e2d\u5d4c\u5165\u8f7b\u91cf\u7ea7\u64cd\u4f5c\u7ea7\u9a8c\u8bc1\u5668\uff0c\u6bcf\u4e2a\u64cd\u4f5c\u7b26\u6267\u884c\u5e76\u9a8c\u8bc1\u5176\u8f93\u51fa\uff08\u5982\u5bf9\u8c61\u5b58\u5728\u6027\u6216\u7a7a\u95f4\u5173\u7cfb\uff09\uff0c\u4ece\u800c\u5728\u9a8c\u8bc1\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\u9c81\u68d2\u5730\u5904\u7406\u65e0\u76ee\u6807\u60c5\u51b5", "result": "\u5728\u76ee\u6807\u5b58\u5728\u548c\u65e0\u76ee\u6807\u8bbe\u7f6e\u4e0b\u8fbe\u523061.1%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u7b2c\u4e00\u4eba\u79f0\u6570\u636e\u4e0a\u5c55\u793a\u6cdb\u5316\u80fd\u529b\uff0c\u5177\u6709\u9ad8\u8ba1\u7b97\u6548\u7387\uff08\u541e\u5410\u91cf\uff09\u3001\u9ad8\u53ef\u9760\u6027\uff08\u7a0b\u5e8f\u5931\u8d25\u7387<0.3%\uff09\u548c\u901a\u8fc7\u89e3\u8026\u7a0b\u5e8f\u751f\u6210\u4e0e\u6267\u884c\u5b9e\u73b0\u7684\u53ef\u6269\u5c55\u6027", "conclusion": "VIRO\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u64cd\u4f5c\u7ea7\u9a8c\u8bc1\u5668\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u7b26\u53f7REC\u4e2d\u7684\u7ea7\u8054\u9519\u8bef\u95ee\u9898\uff0c\u5728\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5904\u7406\u65e0\u76ee\u6807\u60c5\u51b5\u63d0\u4f9b\u4e86\u9c81\u68d2\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.12804", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12804", "abs": "https://arxiv.org/abs/2601.12804", "authors": ["Hanwei Zhang", "Luo Cheng", "Rui Wen", "Yang Zhang", "Lijun Zhang", "Holger Hermanns"], "title": "SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability", "comment": null, "summary": "Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.", "AI": {"tldr": "SL-CBM\u901a\u8fc7\u5f15\u5165\u8bed\u4e49\u5c40\u90e8\u6027\u7ea6\u675f\uff0c\u6539\u8fdb\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u7684\u7a7a\u95f4\u5bf9\u9f50\u80fd\u529b\uff0c\u751f\u6210\u4e0e\u6a21\u578b\u5185\u90e8\u63a8\u7406\u4e00\u81f4\u7684\u6982\u5ff5\u548c\u7c7b\u522b\u7ea7\u663e\u8457\u56fe\uff0c\u63d0\u5347\u89e3\u91ca\u7684\u5c40\u90e8\u5fe0\u5b9e\u6027\u548c\u53ef\u5e72\u9884\u6027\u3002", "motivation": "\u73b0\u6709\u6982\u5ff5\u74f6\u9888\u6a21\u578b\uff08CBMs\uff09\u5b58\u5728\u5c40\u90e8\u5fe0\u5b9e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u5c06\u6982\u5ff5\u4e0e\u6709\u610f\u4e49\u7684\u56fe\u50cf\u533a\u57df\u8fdb\u884c\u7a7a\u95f4\u5bf9\u9f50\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u7a7a\u95f4\u8fde\u8d2f\u663e\u8457\u56fe\u7684\u65b9\u6cd5\uff0c\u4f7f\u6982\u5ff5\u89e3\u91ca\u4e0e\u56fe\u50cf\u533a\u57df\u66f4\u597d\u5730\u5bf9\u5e94\u3002", "method": "\u63d0\u51faSL-CBM\uff08\u5177\u6709\u8bed\u4e49\u5c40\u90e8\u6027\u7684CBM\uff09\uff0c\u901a\u8fc7\u96c6\u62101x1\u5377\u79ef\u5c42\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u6765\u589e\u5f3a\u6982\u5ff5\u3001\u56fe\u50cf\u533a\u57df\u548c\u6700\u7ec8\u9884\u6d4b\u4e4b\u95f4\u7684\u5bf9\u9f50\u3002\u8be5\u65b9\u6cd5\u751f\u6210\u7a7a\u95f4\u8fde\u8d2f\u7684\u6982\u5ff5\u7ea7\u548c\u7c7b\u522b\u7ea7\u663e\u8457\u56fe\uff0c\u5e76\u4f7f\u7528\u5bf9\u6bd4\u6027\u548c\u57fa\u4e8e\u71b5\u7684\u6b63\u5219\u5316\u6765\u5e73\u8861\u51c6\u786e\u6027\u3001\u7a00\u758f\u6027\u548c\u5fe0\u5b9e\u6027\u3002", "result": "\u5728\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSL-CBM\u663e\u8457\u63d0\u9ad8\u4e86\u5c40\u90e8\u5fe0\u5b9e\u6027\u3001\u89e3\u91ca\u8d28\u91cf\u548c\u5e72\u9884\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u5206\u7c7b\u51c6\u786e\u6027\u3002\u6d88\u878d\u7814\u7a76\u5f3a\u8c03\u4e86\u5bf9\u6bd4\u6027\u548c\u57fa\u4e8e\u71b5\u7684\u6b63\u5219\u5316\u5bf9\u4e8e\u5e73\u8861\u51c6\u786e\u6027\u3001\u7a00\u758f\u6027\u548c\u5fe0\u5b9e\u6027\u7684\u91cd\u8981\u6027\u3002", "conclusion": "SL-CBM\u5f25\u5408\u4e86\u57fa\u4e8e\u6982\u5ff5\u7684\u63a8\u7406\u548c\u7a7a\u95f4\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u8d56\u7684\u6982\u5ff5\u6a21\u578b\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u751f\u6210\u4e0e\u6a21\u578b\u5185\u90e8\u63a8\u7406\u7d27\u5bc6\u76f8\u5173\u7684\u5fe0\u5b9e\u663e\u8457\u56fe\uff0c\u4fc3\u8fdb\u4e86\u66f4\u6709\u6548\u7684\u8c03\u8bd5\u548c\u5e72\u9884\u3002"}}
{"id": "2601.12912", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12912", "abs": "https://arxiv.org/abs/2601.12912", "authors": ["Andreas Br\u00e4nnstr\u00f6m", "Juan Carlos Nieves"], "title": "Human Emotion Verification by Action Languages via Answer Set Programming", "comment": "Under consideration in Theory and Practice of Logic Programming (TPLP)", "summary": "In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\u548c\u8f6c\u79fb\u7cfb\u7edf\u7684C-MT\u52a8\u4f5c\u8bed\u8a00\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u4eba\u7c7b\u5fc3\u7406\u72b6\u6001\uff08\u5982\u60c5\u7eea\uff09\u968f\u53ef\u89c2\u5bdf\u52a8\u4f5c\u7684\u6f14\u5316\u8fc7\u7a0b\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u56e0\u679c\u89c4\u5219\u6765\u9650\u5236\u52a8\u4f5c\u7684\u5fc3\u7406\u526f\u4f5c\u7528\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u9700\u8981\u66f4\u53ef\u63a7\u7684\u667a\u80fd\u4f53\u884c\u4e3a\u5efa\u6a21\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u8981\u9650\u5236\u52a8\u4f5c\u5bf9\u5fc3\u7406\u72b6\u6001\u7684\u4e0d\u826f\u526f\u4f5c\u7528\u3002\u4eba\u7c7b\u5fc3\u7406\u72b6\u6001\uff08\u5982\u60c5\u7eea\uff09\u7684\u6f14\u5316\u9700\u8981\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\u8fdb\u884c\u5f62\u5f0f\u5316\u8868\u793a\uff0c\u4ee5\u652f\u6301\u5bf9\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u53d8\u5316\u7684\u53d7\u63a7\u63a8\u7406\u3002", "method": "\u57fa\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\u548c\u8f6c\u79fb\u7cfb\u7edf\u6784\u5efaC-MT\u52a8\u4f5c\u8bed\u8a00\uff0c\u5229\u7528\u8bc4\u4ef7\u60c5\u7eea\u7406\u8bba\u7b49\u5fc3\u7406\u5b66\u7406\u8bba\u5c06\u5fc3\u7406\u72b6\u6001\u5f62\u5f0f\u5316\u4e3a\u591a\u7ef4\u914d\u7f6e\u3002\u5f15\u5165\u65b0\u7684\u56e0\u679c\u89c4\u5219\"forbids to cause\"\u548c\u4e13\u95e8\u7528\u4e8e\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u7684\u8868\u8fbe\u5f0f\uff0c\u5c06\u5fc3\u7406\u53d8\u5316\u539f\u5219\u8f6c\u5316\u4e3a\u8f6c\u79fb\u7ea6\u675f\u548c\u4e0d\u53d8\u6027\u5c5e\u6027\uff0c\u901a\u8fc7\u8f68\u8ff9\u5206\u6790\u5728\u8f6c\u79fb\u7cfb\u7edf\u4e2d\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u5efa\u6a21\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u6f14\u5316\u7684\u6846\u67b6\uff0c\u652f\u6301\u901a\u8fc7\u8f68\u8ff9\u5206\u6790\u6bd4\u8f83\u4e0d\u540c\u7684\u5fc3\u7406\u53d8\u5316\u52a8\u6001\u3002\u8be5\u6846\u67b6\u5df2\u5e94\u7528\u4e8e\u60c5\u7eea\u9a8c\u8bc1\u6a21\u578b\u7684\u8bbe\u8ba1\uff0c\u80fd\u591f\u5bf9\u5fc3\u7406\u72b6\u6001\u7684\u52a8\u6001\u6f14\u5316\u8fdb\u884c\u53d7\u63a7\u63a8\u7406\u3002", "conclusion": "C-MT\u52a8\u4f5c\u8bed\u8a00\u4e3a\u5f62\u5f0f\u5316\u4eba\u7c7b\u5fc3\u7406\u72b6\u6001\u6f14\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u56e0\u679c\u89c4\u5219\u548c\u8f6c\u79fb\u7ea6\u675f\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u53d8\u5316\u7684\u53d7\u63a7\u63a8\u7406\uff0c\u652f\u6301\u57fa\u4e8e\u4e0d\u540c\u5fc3\u7406\u5b66\u539f\u5219\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u5728\u60c5\u7eea\u9a8c\u8bc1\u7b49\u5e94\u7528\u573a\u666f\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.12913", "categories": ["cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.12913", "abs": "https://arxiv.org/abs/2601.12913", "authors": ["Pietro Barbiero", "Mateo Espinosa Zarlenga", "Francesco Giannini", "Alberto Termine", "Filippo Bonchi", "Mateja Jamnik", "Giuseppe Marra"], "title": "Actionable Interpretability Must Be Defined in Terms of Symmetries", "comment": null, "summary": "This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u5f53\u524dAI\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u5b58\u5728\u6839\u672c\u6027\u95ee\u9898\uff0c\u56e0\u4e3a\u73b0\u6709\u5b9a\u4e49\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\uff0c\u65e0\u6cd5\u4e3a\u5177\u4f53\u5efa\u6a21\u548c\u63a8\u7406\u89c4\u5219\u63d0\u4f9b\u5f62\u5f0f\u5316\u539f\u5219\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u64cd\u4f5c\u5b9a\u4e49\uff0c\u5e76\u5047\u8bbe\u56db\u79cd\u5bf9\u79f0\u6027\u8db3\u4ee5\u89e3\u51b3\u53ef\u89e3\u91ca\u6027\u7684\u6838\u5fc3\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff0c\u56e0\u4e3a\u73b0\u6709\u7684\u53ef\u89e3\u91ca\u6027\u5b9a\u4e49\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\uff0c\u65e0\u6cd5\u4e3a\u5177\u4f53\u7684\u5efa\u6a21\u548c\u63a8\u7406\u89c4\u5219\u63d0\u4f9b\u5f62\u5f0f\u5316\u539f\u5219\u3002\u8fd9\u5bfc\u81f4\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u505c\u7559\u5728\u6982\u5ff5\u5c42\u9762\uff0c\u96be\u4ee5\u8f6c\u5316\u4e3a\u5b9e\u9645\u53ef\u7528\u7684\u65b9\u6cd5\u548c\u5de5\u5177\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u64cd\u4f5c\u5b9a\u4e49\u65b9\u6cd5\uff0c\u5047\u8bbe\u56db\u79cd\u5bf9\u79f0\u6027\u8db3\u4ee5\uff1a(1) \u6fc0\u53d1\u6838\u5fc3\u53ef\u89e3\u91ca\u6027\u5c5e\u6027\uff0c(2) \u523b\u753b\u53ef\u89e3\u91ca\u6a21\u578b\u7684\u7c7b\u522b\uff0c(3) \u63a8\u5bfc\u51fa\u7edf\u4e00\u7684\u53ef\u89e3\u91ca\u63a8\u7406\u5f62\u5f0f\u5316\u6846\u67b6\uff08\u5982\u5bf9\u9f50\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u63a8\u7406\uff09\uff0c\u5c06\u5176\u89c6\u4e3a\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u89e3\u91ca\u6027\u7406\u8bba\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u4e3a\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u5b9a\u4e49\uff0c\u5e76\u7edf\u4e00\u5904\u7406\u5bf9\u9f50\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u63a8\u7406\u7b49\u53ef\u89e3\u91ca\u6027\u4efb\u52a1\uff0c\u5c06\u5176\u5f62\u5f0f\u5316\u4e3a\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5bf9\u79f0\u6027\u4f5c\u4e3a\u53ef\u89e3\u91ca\u6027\u7684\u57fa\u7840\uff0c\u53ef\u4ee5\u89e3\u51b3\u5f53\u524d\u53ef\u89e3\u91ca\u6027\u5b9a\u4e49\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\u7684\u95ee\u9898\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u7684\u65b9\u6cd5\u8bba\u6846\u67b6\u3002"}}
{"id": "2601.13122", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13122", "abs": "https://arxiv.org/abs/2601.13122", "authors": ["Gourab K Patro", "Himanshi Agrawal", "Himanshu Gharat", "Supriya Panigrahi", "Nim Sherpa", "Vishal Vaddina", "Dagnachew Birru"], "title": "Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward", "comment": null, "summary": "Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u901a\u7528AI\u7cfb\u7edf\u7684\u98ce\u9669\u4e0e\u8106\u5f31\u6027\uff0c\u5bf9\u6bd4\u4f20\u7edf\u4efb\u52a1\u4e13\u7528AI\uff0c\u63d0\u51faC2V2\u6846\u67b6\uff08\u63a7\u5236\u3001\u4e00\u81f4\u6027\u3001\u4ef7\u503c\u3001\u771f\u5b9e\u6027\uff09\u4f5c\u4e3a\u8d1f\u8d23\u4efbAI\u7684\u8bbe\u8ba1\u539f\u5219\u3002", "motivation": "\u73b0\u4ee3\u901a\u7528AI\u7cfb\u7edf\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5728\u5e7b\u89c9\u3001\u6bd2\u6027\u3001\u523b\u677f\u5370\u8c61\u7b49\u65b9\u9762\u5b58\u5728\u98ce\u9669\uff0c\u4f7f\u5176\u4e0d\u53ef\u4fe1\u3002\u9700\u8981\u91cd\u65b0\u601d\u8003\u5982\u4f55\u4e3a\u901a\u7528AI\u7cfb\u7edf\u8bbe\u8ba1\u8d1f\u8d23\u4efb\u7684AI\u539f\u5219\u3002", "method": "\u4ece\u516b\u4e2a\u5e7f\u6cdb\u63a5\u53d7\u7684\u8d1f\u8d23\u4efbAI\u539f\u5219\uff08\u516c\u5e73\u6027\u3001\u9690\u79c1\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u9c81\u68d2\u6027\u3001\u5b89\u5168\u6027\u3001\u771f\u5b9e\u6027\u3001\u6cbb\u7406\u3001\u53ef\u6301\u7eed\u6027\uff09\u51fa\u53d1\uff0c\u5206\u6790\u901a\u7528AI\u7684\u98ce\u9669\u548c\u8106\u5f31\u6027\uff0c\u5e76\u4e0e\u4f20\u7edf\u4efb\u52a1\u4e13\u7528AI\u5bf9\u6bd4\u3002\u63d0\u51fa\u8f93\u51fa\u81ea\u7531\u5ea6\uff08DoFo\uff09\u6982\u5ff5\u6765\u89e3\u91ca\u5dee\u5f02\uff0c\u5e76\u63a8\u5bfc\u51faC2V2\u8bbe\u8ba1\u539f\u5219\u3002", "result": "\u901a\u7528AI\u7cfb\u7edf\u7531\u4e8e\u8f93\u51fa\u81ea\u7531\u5ea6\uff08DoFo\uff09\u975e\u786e\u5b9a\u6027\u5730\u9ad8\uff0c\u5bfc\u81f4\u98ce\u9669\u66f4\u4e25\u91cd\u4e14\u96be\u4ee5\u7f13\u89e3\u3002C2V2\u6846\u67b6\uff08\u63a7\u5236\u3001\u4e00\u81f4\u6027\u3001\u4ef7\u503c\u3001\u771f\u5b9e\u6027\uff09\u53ef\u4f5c\u4e3a\u6ee1\u8db3\u8d1f\u8d23\u4efbAI\u8981\u6c42\u7684\u8bbe\u8ba1\u539f\u5219\uff0cAI\u5bf9\u9f50\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u63a8\u7406\u589e\u5f3a\u7b49\u6280\u672f\u5728\u4e0d\u540c\u7a0b\u5ea6\u4e0a\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5e94\u7528\u6216\u9886\u57df\u76f8\u5173\u7684\u8d1f\u8d23\u4efbAI\u9700\u6c42\u6cbfC2V2\u7ef4\u5ea6\u8fdb\u884c\u5f62\u5f0f\u5316\u5efa\u6a21\uff0c\u5e76\u91c7\u7528\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u7ed3\u5408\u5404\u79cd\u6280\u672f\uff0c\u53ef\u4ee5\u5b9e\u73b0\u5f00\u53d1\u8d1f\u8d23\u4efb\u901a\u7528AI\u7684\u76ee\u6807\u3002"}}
{"id": "2601.13186", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13186", "abs": "https://arxiv.org/abs/2601.13186", "authors": ["Diego Gosmar", "Deborah A. Dahl"], "title": "Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching", "comment": "33 pages, 19 figures", "summary": "Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86TIVS\u8bc4\u4f30\u6846\u67b6\uff0c\u589e\u52a0\u4e86\u8bed\u4e49\u76f8\u4f3c\u6027\u7f13\u5b58\u548c\u53ef\u89c2\u6d4b\u6027\u8bc4\u5206\u6bd4(OSR)\uff0c\u63d0\u51faTIVS-O\u7cfb\u7edf\uff0c\u5728\u591a\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u540c\u65f6\u4f18\u5316\u5b89\u5168\u6027\u548c\u900f\u660e\u5ea6\uff0c\u5b9e\u73b0\u4e86\u96f6\u9ad8\u98ce\u9669\u6f0f\u6d1e\u300141.6%\u7684LLM\u8c03\u7528\u51cf\u5c11\u4ee5\u53ca\u6027\u80fd-\u6210\u672c-\u73af\u5883\u7684\u7efc\u5408\u4f18\u5316\u3002", "motivation": "\u63d0\u793a\u6ce8\u5165\u4ecd\u7136\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u7279\u522b\u662f\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\uff0c\u4e2d\u95f4\u8f93\u51fa\u53ef\u80fd\u4f20\u64ad\u6216\u653e\u5927\u6076\u610f\u6307\u4ee4\u3002\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u6709\u6548\u9632\u5fa1\u53c8\u80fd\u4fdd\u6301\u900f\u660e\u5ea6\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6269\u5c55\u4e86\u56db\u6307\u6807TIVS\u6846\u67b6\uff0c\u589e\u52a0\u4e86\u8bed\u4e49\u76f8\u4f3c\u6027\u7f13\u5b58\u548c\u7b2c\u4e94\u4e2a\u6307\u6807(\u53ef\u89c2\u6d4b\u6027\u8bc4\u5206\u6bd4)\uff0c\u5f62\u6210TIVS-O\u7cfb\u7edf\u3002\u91c7\u7528HOPE\u542f\u53d1\u7684\u5d4c\u5957\u5b66\u4e60\u67b6\u6784\uff0c\u7ed3\u5408\u667a\u80fd\u4f53\u7ba1\u9053\u548c\u8fde\u7eed\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u4f7f\u7528301\u4e2a\u5408\u6210\u751f\u6210\u7684\u6ce8\u5165\u63d0\u793a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u7b2c\u56db\u4e2a\u667a\u80fd\u4f53\u4f7f\u7528\u4e94\u4e2a\u5173\u952e\u6027\u80fd\u6307\u6807\u8fdb\u884c\u5b89\u5168\u5206\u6790\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u4e86\u96f6\u9ad8\u98ce\u9669\u6f0f\u6d1e\u7684\u5b89\u5168\u54cd\u5e94\uff0c\u8bed\u4e49\u7f13\u5b58\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\uff0cLLM\u8c03\u7528\u51cf\u5c1141.6%\uff0c\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u78b3\u6392\u653e\u76f8\u5e94\u964d\u4f4e\u3002\u4e94\u79cdTIVS-O\u914d\u7f6e\u63ed\u793a\u4e86\u7f13\u89e3\u4e25\u683c\u6027\u548c\u53d6\u8bc1\u900f\u660e\u5ea6\u4e4b\u95f4\u7684\u6700\u4f73\u6743\u8861\u3002", "conclusion": "\u53ef\u89c2\u6d4b\u6027\u611f\u77e5\u8bc4\u4f30\u80fd\u63ed\u793a\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u4e2d\u7684\u975e\u5355\u8c03\u6548\u5e94\uff0c\u5185\u5b58\u589e\u5f3a\u667a\u80fd\u4f53\u53ef\u4ee5\u8054\u5408\u6700\u5927\u5316\u5b89\u5168\u9c81\u68d2\u6027\u3001\u5b9e\u65f6\u6027\u80fd\u3001\u8fd0\u8425\u6210\u672c\u8282\u7ea6\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\uff0c\u65e0\u9700\u4fee\u6539\u5e95\u5c42\u6a21\u578b\u6743\u91cd\uff0c\u4e3a\u5b89\u5168\u548c\u7eff\u8272\u7684LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u751f\u4ea7\u5c31\u7eea\u7684\u9014\u5f84\u3002"}}
{"id": "2601.13262", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13262", "abs": "https://arxiv.org/abs/2601.13262", "authors": ["Eric Onyame", "Akash Ghosh", "Subhadip Baidya", "Sriparna Saha", "Xiuying Chen", "Chirag Agarwal"], "title": "CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning", "comment": null, "summary": "While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/", "AI": {"tldr": "CURE-MED\u6846\u67b6\u901a\u8fc7\u8bfe\u7a0b\u5f0f\u5f3a\u5316\u5b66\u4e60\u63d0\u5347LLMs\u5728\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u572813\u79cd\u8bed\u8a00\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u903b\u8f91\u6b63\u786e\u6027\u548c\u8bed\u8a00\u4e00\u81f4\u6027", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5355\u8bed\u8a00\u6570\u5b66\u548c\u5e38\u8bc6\u63a8\u7406\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u5e94\u7528\u4e2d\u4ecd\u4e0d\u53ef\u9760\uff0c\u963b\u788d\u4e86\u5176\u5728\u591a\u8bed\u8a00\u533b\u7597\u73af\u5883\u4e2d\u7684\u90e8\u7f72", "method": "\u63d0\u51faCURE-MED\u6846\u67b6\uff1a1) \u5f15\u5165CUREMED-BENCH\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u6570\u636e\u96c6\uff1b2) \u91c7\u7528\u8bfe\u7a0b\u5f0f\u5f3a\u5316\u5b66\u4e60\uff0c\u6574\u5408\u4ee3\u7801\u5207\u6362\u611f\u77e5\u7684\u76d1\u7763\u5fae\u8c03\u548c\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff0c\u5171\u540c\u63d0\u5347\u903b\u8f91\u6b63\u786e\u6027\u548c\u8bed\u8a00\u7a33\u5b9a\u6027", "result": "\u572813\u79cd\u8bed\u8a00\u4e0a\u6301\u7eed\u8d85\u8d8a\u5f3a\u57fa\u7ebf\uff0c7B\u53c2\u6570\u6a21\u578b\u8fbe\u523085.21%\u8bed\u8a00\u4e00\u81f4\u6027\u548c54.35%\u903b\u8f91\u6b63\u786e\u6027\uff0c32B\u53c2\u6570\u6a21\u578b\u8fbe\u523094.96%\u8bed\u8a00\u4e00\u81f4\u6027\u548c70.04%\u903b\u8f91\u6b63\u786e\u6027", "conclusion": "\u8be5\u7814\u7a76\u652f\u6301LLMs\u5b9e\u73b0\u53ef\u9760\u4e14\u516c\u5e73\u7684\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90"}}
{"id": "2601.13268", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13268", "abs": "https://arxiv.org/abs/2601.13268", "authors": ["Zainab Ghafoor", "Md Shafiqul Islam", "Koushik Howlader", "Md Rasel Khondokar", "Tanusree Bhattacharjee", "Sayantan Chakraborty", "Adrito Roy", "Ushashi Bhattacharjee", "Tirtho Roy"], "title": "Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops", "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8fed\u4ee3\u5bf9\u9f50\u6765\u63d0\u5347\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u7ed3\u5408\u751f\u6210\u6a21\u578b\u548c\u8bc4\u4f30\u667a\u80fd\u4f53\uff0c\u5728900\u4e2a\u4e34\u5e8a\u67e5\u8be2\u4e0a\u5b9e\u73b0\u4e8689%\u7684\u4f26\u7406\u8fdd\u89c4\u51cf\u5c11\u548c92%\u7684\u98ce\u9669\u964d\u7ea7\u7387\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u786e\u4fdd\u5176\u4f26\u7406\u5b8c\u6574\u6027\u548c\u5b89\u5168\u5408\u89c4\u6027\u4ecd\u7136\u662f\u4e34\u5e8a\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\u3002\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u533b\u7597AI\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u6846\u67b6\uff0c\u7ed3\u5408\u4e24\u4e2a\u751f\u6210\u6a21\u578b\uff08DeepSeek R1\u548cMed-PaLM\uff09\u548c\u4e24\u4e2a\u8bc4\u4f30\u667a\u80fd\u4f53\uff08LLaMA 3.1\u548cPhi-4\uff09\u3002\u8bc4\u4f30\u667a\u80fd\u4f53\u4f7f\u7528\u7f8e\u56fd\u533b\u5b66\u4f1a\u533b\u5b66\u4f26\u7406\u539f\u5219\u548c\u4e94\u7ea7\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u534f\u8bae\u6765\u8bc4\u4f30\u54cd\u5e94\u3002\u7cfb\u7edf\u901a\u8fc7\u7ed3\u6784\u5316\u8fed\u4ee3\u5bf9\u9f50\u8fc7\u7a0b\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728\u6db5\u76d69\u4e2a\u4f26\u7406\u9886\u57df\u7684900\u4e2a\u4e34\u5e8a\u591a\u6837\u5316\u67e5\u8be2\u4e0a\u8bc4\u4f30\u6027\u80fd\uff1aDeepSeek R1\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\uff08\u5e73\u57472.34 vs 2.67\u6b21\u8fed\u4ee3\uff09\uff0cMed-PaLM\u5728\u5904\u7406\u9690\u79c1\u654f\u611f\u573a\u666f\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u8fed\u4ee3\u591a\u667a\u80fd\u4f53\u5faa\u73af\u5b9e\u73b0\u4e8689%\u7684\u4f26\u7406\u8fdd\u89c4\u51cf\u5c11\u548c92%\u7684\u98ce\u9669\u964d\u7ea7\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u533b\u7597AI\u5b89\u5168\u6cbb\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fed\u4ee3\u7cbe\u70bc\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f26\u7406\u5408\u89c4\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2601.13327", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13327", "abs": "https://arxiv.org/abs/2601.13327", "authors": ["Po-Yu Liang", "Tobo Duran", "Jun Bai"], "title": "PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion", "comment": null, "summary": "We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model", "AI": {"tldr": "PepEDiff\u662f\u4e00\u79cd\u65b0\u578b\u7684\u80bd\u7ed3\u5408\u5242\u751f\u6210\u5668\uff0c\u53ef\u76f4\u63a5\u5728\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u5d4c\u5165\u6a21\u578b\u7684\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u4e2d\u751f\u6210\u7ed3\u5408\u5e8f\u5217\uff0c\u65e0\u9700\u4f9d\u8d56\u7ed3\u6784\u9884\u6d4b\uff0c\u63d0\u9ad8\u4e86\u5e8f\u5217\u591a\u6837\u6027\u3002", "motivation": "\u80bd\u7ed3\u5408\u5242\u751f\u6210\u5728\u6cbb\u7597\u548c\u751f\u5316\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u4e2d\u95f4\u7ed3\u6784\u9884\u6d4b\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u5e76\u9650\u5236\u4e86\u5e8f\u5217\u591a\u6837\u6027\u3002", "method": "\u901a\u8fc7\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u5d4c\u5165\u6a21\u578b\u83b7\u5f97\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u8868\u793a\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u63a2\u7d22\u548c\u57fa\u4e8e\u6269\u6563\u7684\u91c7\u6837\uff0c\u76f4\u63a5\u751f\u6210\u7ed3\u5408\u5e8f\u5217\u800c\u4e0d\u4f9d\u8d56\u7ed3\u6784\u9884\u6d4b\u3002", "result": "\u5728TIGIT\uff08\u4e00\u4e2a\u5177\u6709\u5927\u800c\u5e73\u5766\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u754c\u9762\u7684\u6311\u6218\u6027\u9776\u70b9\uff09\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u96f6\u6837\u672c\u80bd\u7ed3\u5408\u5242\u8bbe\u8ba1\u7684\u901a\u7528\u3001\u65e0\u7ed3\u6784\u6846\u67b6\u7684\u6f5c\u529b\u3002", "conclusion": "PepEDiff\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u96f6\u6837\u672c\u80bd\u7ed3\u5408\u5242\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u4e0d\u4f9d\u8d56\u7ed3\u6784\u9884\u6d4b\uff0c\u80fd\u591f\u751f\u6210\u8d85\u8d8a\u5df2\u77e5\u7ed3\u5408\u5242\u5206\u5e03\u7684\u65b0\u9896\u80bd\u5e8f\u5217\uff0c\u5728\u6cbb\u7597\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u6f5c\u529b\u3002"}}
{"id": "2601.13358", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13358", "abs": "https://arxiv.org/abs/2601.13358", "authors": ["Samuel Cyrenius Anderson"], "title": "The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models", "comment": "34 pages, 10 figures", "summary": "Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u89c4\u6a21\u589e\u957f\u4e0d\u4f1a\u5747\u5300\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u800c\u662f\u91cd\u6784\u63a8\u7406\u8fc7\u7a0b\u3002\u901a\u8fc7\u5206\u679025,000+\u601d\u7ef4\u94fe\u8f68\u8ff9\u53d1\u73b0\uff0c\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\u89e6\u53d1\u7279\u5b9a\u9886\u57df\u7684\u76f8\u53d8\u800c\u975e\u5747\u5300\u80fd\u529b\u63d0\u5347\uff0c\u63a8\u7406\u6210\u672c\u7531\u6d41\u5f62\u51e0\u4f55\u800c\u975e\u4efb\u52a1\u96be\u5ea6\u51b3\u5b9a\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u6a21\u578b\u89c4\u6a21\u589e\u957f\u4f1a\u5747\u5300\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u89c4\u6a21\u589e\u957f\u5982\u4f55\u5b9e\u9645\u6539\u53d8\u63a8\u7406\u8fc7\u7a0b\u7684\u7ed3\u6784\u548c\u51e0\u4f55\u7279\u6027\uff0c\u63ed\u793a\u63a8\u7406\u80fd\u529b\u7684\u672c\u8d28\u53d8\u5316\u673a\u5236\u3002", "method": "\u5206\u679025,000+\u601d\u7ef4\u94fe\u8f68\u8ff9\uff0c\u8986\u76d6\u6cd5\u5f8b\u3001\u79d1\u5b66\u3001\u4ee3\u7801\u3001\u6570\u5b66\u56db\u4e2a\u9886\u57df\u548c8B\u300170B\u4e24\u4e2a\u53c2\u6570\u89c4\u6a21\u3002\u5f15\u5165\u795e\u7ecf\u63a8\u7406\u7b97\u5b50\u4f5c\u4e3a\u4ece\u521d\u59cb\u5230\u6700\u7ec8\u9690\u85cf\u72b6\u6001\u7684\u6620\u5c04\uff0c\u4f7f\u7528\u51e0\u4f55\u5206\u6790\u65b9\u6cd5\uff08\u5982\u8868\u793a\u7ef4\u5ea6\u3001\u8f68\u8ff9\u5bf9\u9f50\u3001\u6d41\u5f62\u89e3\u7f20\uff09\u91cf\u5316\u63a8\u7406\u7ed3\u6784\u53d8\u5316\u3002", "result": "\u53d1\u73b0\u4e09\u79cd\u4e0d\u540c\u7684\u63a8\u7406\u76f8\u53d8\u6a21\u5f0f\uff1a\u6cd5\u5f8b\u63a8\u7406\u5448\u73b0\"\u7ed3\u6676\u5316\"\uff08\u7ef4\u5ea6\u4e0b\u964d45%\uff0c\u8f68\u8ff9\u5bf9\u9f50\u589e\u52a031%\uff0c\u6d41\u5f62\u89e3\u7f2010\u500d\uff09\uff1b\u79d1\u5b66\u548c\u6570\u5b66\u63a8\u7406\u4fdd\u6301\"\u6db2\u6001\"\uff08\u51e0\u4f55\u4e0d\u53d8\uff09\uff1b\u4ee3\u7801\u63a8\u7406\u5f62\u6210\"\u6676\u683c\"\u7ed3\u6784\uff08\u8f6e\u5ed3\u7cfb\u6570\u4ece0.13\u589e\u81f30.42\uff09\u3002\u795e\u7ecf\u63a8\u7406\u7b97\u5b50\u5728\u6cd5\u5f8b\u63a8\u7406\u4e0a\u901a\u8fc7\u63a2\u9488\u89e3\u7801\u8fbe\u523063.6%\u51c6\u786e\u7387\uff0c\u65e0\u9700\u904d\u5386\u4e2d\u95f4\u72b6\u6001\u3002\u53d1\u73b0\u8de8\u57df\u548c\u8de8\u89c4\u6a21\u7684\u901a\u7528\u632f\u8361\u7279\u5f81\uff08\u76f8\u5e72\u6027\u7ea6-0.4\uff09\u3002", "conclusion": "\u63a8\u7406\u6210\u672c\u7531\u6d41\u5f62\u51e0\u4f55\u51b3\u5b9a\u800c\u975e\u4efb\u52a1\u96be\u5ea6\uff0c\u8fd9\u4e3a\u5728\u62d3\u6251\u5141\u8bb8\u7684\u60c5\u51b5\u4e0b\u52a0\u901f\u63a8\u7406\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002\u89c4\u6a21\u589e\u957f\u89e6\u53d1\u9886\u57df\u7279\u5b9a\u7684\u76f8\u53d8\u800c\u975e\u5747\u5300\u80fd\u529b\u63d0\u5347\uff0c\u63ed\u793a\u4e86\u63a8\u7406\u8fc7\u7a0b\u7684\u7ed3\u6784\u5316\u8f6c\u53d8\u673a\u5236\u3002"}}
{"id": "2601.13383", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13383", "abs": "https://arxiv.org/abs/2601.13383", "authors": ["Akbar Anbar Jafari", "Cagri Ozcinar", "Gholamreza Anbarjafari"], "title": "A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge", "comment": "15 pages, 3 figures", "summary": "The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.", "AI": {"tldr": "AgentForge\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5f00\u6e90Python\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u67b6\u6784\u7b80\u5316LLM\u9a71\u52a8\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u5f00\u53d1\uff0c\u63d0\u4f9b\u53ef\u7ec4\u5408\u6280\u80fd\u62bd\u8c61\u3001\u7edf\u4e00LLM\u540e\u7aef\u63a5\u53e3\u548c\u58f0\u660e\u5f0f\u914d\u7f6e\u7cfb\u7edf\uff0c\u663e\u8457\u964d\u4f4e\u5f00\u53d1\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u6846\u67b6\u5b58\u5728\u67b6\u6784\u50f5\u5316\u3001\u4f9b\u5e94\u5546\u9501\u5b9a\u548c\u590d\u6742\u5ea6\u8fc7\u9ad8\u7b49\u95ee\u9898\uff0c\u963b\u788d\u4e86\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u548c\u90e8\u7f72\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6c11\u4e3b\u5316LLM\u9a71\u52a8\u81ea\u4e3b\u667a\u80fd\u4f53\u6784\u5efa\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faAgentForge\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a1) \u53ef\u7ec4\u5408\u6280\u80fd\u62bd\u8c61\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u4efb\u52a1\u5206\u89e3\u548c\u5f62\u5f0f\u5316\u8f93\u5165\u8f93\u51fa\u5951\u7ea6\uff1b2) \u7edf\u4e00LLM\u540e\u7aef\u63a5\u53e3\uff0c\u652f\u6301\u4e91\u7aefAPI\u548c\u672c\u5730\u63a8\u7406\u5f15\u64ce\u65e0\u7f1d\u5207\u6362\uff1b3) \u58f0\u660e\u5f0fYAML\u914d\u7f6e\u7cfb\u7edf\uff0c\u5206\u79bb\u667a\u80fd\u4f53\u903b\u8f91\u4e0e\u5b9e\u73b0\u7ec6\u8282\u3002\u5c06\u6280\u80fd\u7ec4\u5408\u673a\u5236\u5f62\u5f0f\u5316\u4e3a\u6709\u5411\u65e0\u73af\u56fe(DAG)\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u573a\u666f\u7684\u8bc4\u4f30\u4e2d\uff0cAgentForge\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u76f8\u6bd4LangChain\u51cf\u5c1162%\u5f00\u53d1\u65f6\u95f4\uff0c\u76f8\u6bd4\u76f4\u63a5API\u96c6\u6210\u51cf\u5c1178%\u5f00\u53d1\u65f6\u95f4\u3002\u7f16\u6392\u5ef6\u8fdf\u4f4e\u4e8e100ms\uff0c\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u3002\u6846\u67b6\u96c6\u6210\u4e86\u516d\u4e2a\u5185\u7f6e\u6280\u80fd\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u6280\u80fd\u5f00\u53d1\u3002", "conclusion": "AgentForge\u586b\u8865\u4e86LLM\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u751f\u4ea7\u5c31\u7eea\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u7528\u4e8e\u6784\u5efa\u3001\u8bc4\u4f30\u548c\u90e8\u7f72\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u7075\u6d3b\u6027\u6216\u6027\u80fd\u3002"}}
{"id": "2601.13462", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13462", "abs": "https://arxiv.org/abs/2601.13462", "authors": ["Amine Rostane"], "title": "SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation", "comment": "19 pages, includes figures and tables", "summary": "Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.", "AI": {"tldr": "SpatialBench-UC\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7a7a\u95f4\u5173\u7cfb\u7406\u89e3\u80fd\u529b\u7684\u5c0f\u578b\u53ef\u590d\u73b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b200\u4e2a\u63d0\u793a\u548c100\u4e2a\u53cd\u4e8b\u5b9e\u5bf9\uff0c\u63d0\u4f9b\u5b8c\u6574\u7684\u8bc4\u4f30\u5305\u548c\u4eba\u7c7b\u5ba1\u6838\u6821\u51c6\u3002", "motivation": "\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u662f\u5426\u9075\u5faa\u660e\u786e\u7684\u7a7a\u95f4\u6307\u4ee4\u96be\u4ee5\u81ea\u52a8\u5316\uff0c\u56e0\u4e3a\u5bf9\u8c61\u68c0\u6d4b\u5668\u53ef\u80fd\u6f0f\u68c0\u76ee\u6807\u6216\u8fd4\u56de\u591a\u4e2a\u53ef\u80fd\u68c0\u6d4b\uff0c\u7b80\u5355\u7684\u51e0\u4f55\u6d4b\u8bd5\u5728\u8fb9\u754c\u60c5\u51b5\u4e0b\u4f1a\u53d8\u5f97\u6a21\u7cca\u3002\u7a7a\u95f4\u8bc4\u4f30\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u9009\u62e9\u6027\u9884\u6d4b\u95ee\u9898\u3002", "method": "\u5f15\u5165SpatialBench-UC\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b200\u4e2a\u63d0\u793a\uff0850\u4e2a\u5bf9\u8c61\u5bf9\u00d74\u79cd\u5173\u7cfb\uff09\u5206\u7ec4\u4e3a100\u4e2a\u53cd\u4e8b\u5b9e\u5bf9\u3002\u53d1\u5e03\u57fa\u51c6\u6d4b\u8bd5\u5305\u3001\u7248\u672c\u5316\u63d0\u793a\u3001\u56fa\u5b9a\u914d\u7f6e\u3001\u6bcf\u6837\u672c\u68c0\u67e5\u5668\u8f93\u51fa\u548c\u62a5\u544a\u8868\u683c\u3002\u5305\u542b\u8f7b\u91cf\u7ea7\u4eba\u7c7b\u5ba1\u6838\u6765\u6821\u51c6\u68c0\u67e5\u5668\u7684\u5f03\u6743\u8fb9\u754c\u548c\u7f6e\u4fe1\u5ea6\u9608\u503c\u3002", "result": "\u8bc4\u4f30\u4e86\u4e09\u4e2a\u57fa\u7ebf\u6a21\u578b\uff1aStable Diffusion 1.5\u3001SD 1.5 BoxDiff\u548cSD 1.4 GLIGEN\u3002\u7ed3\u679c\u663e\u793a\uff0c\u63a5\u5730\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u901a\u8fc7\u7387\u548c\u8986\u76d6\u7387\uff0c\u4f46\u5f03\u6743\u4ecd\u7136\u662f\u4e3b\u8981\u56e0\u7d20\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u5931\u68c0\u6d4b\u3002", "conclusion": "SpatialBench-UC\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u3001\u53ef\u5ba1\u8ba1\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u7a7a\u95f4\u5173\u7cfb\u7406\u89e3\u80fd\u529b\uff0c\u5f3a\u8c03\u4e86\u9009\u62e9\u6027\u9884\u6d4b\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u63a5\u5730\u65b9\u6cd5\u7684\u6539\u8fdb\u6548\u679c\u3002"}}
{"id": "2601.13464", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.13464", "abs": "https://arxiv.org/abs/2601.13464", "authors": ["Chongyang Gao", "Marco Postiglione", "Julian Baldwin", "Natalia Denisenko", "Isabel Gortner", "Luke Fosdick", "Chiara Pulice", "Sarit Kraus", "V. S. Subrahmanian"], "title": "Context and Transcripts Improve Detection of Deepfake Audios of Public Figures", "comment": null, "summary": "Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e0a\u4e0b\u6587\u548c\u6587\u672c\u7684\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668CADD\uff0c\u901a\u8fc7\u5f15\u5165\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u8f6c\u5f55\u6587\u672c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u5bf9\u6297\u653b\u51fb\u5177\u6709\u66f4\u5f3a\u9c81\u68d2\u6027\u3002", "motivation": "\u4eba\u7c7b\u5728\u5224\u65ad\u4fe1\u606f\u771f\u4f2a\u65f6\u4f1a\u5229\u7528\u4e0a\u4e0b\u6587\uff0c\u4f46\u73b0\u6709\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u4ec5\u5206\u6790\u97f3\u9891\u6587\u4ef6\u672c\u8eab\uff0c\u5ffd\u7565\u4e86\u4e0a\u4e0b\u6587\u548c\u8f6c\u5f55\u6587\u672c\u7684\u91cd\u8981\u4fe1\u606f\u3002", "method": "\u521b\u5efa\u4e86\u8bb0\u8005\u63d0\u4f9b\u7684\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6JDD\u548c\u5408\u6210\u97f3\u9891\u6570\u636e\u96c6SYN\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668CADD\u67b6\u6784\uff0c\u5e76\u5728\u591a\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u4e0a\u4e0b\u6587\u548c/\u6216\u8f6c\u5f55\u6587\u672c\u80fd\u663e\u8457\u63d0\u5347\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u6027\u80fd\uff1aF1\u5206\u6570\u63d0\u53475%-37.58%\uff0cAUC\u63d0\u53473.77%-42.79%\uff0cEER\u63d0\u53476.17%-47.83%\u3002CADD\u5bf95\u79cd\u5bf9\u6297\u653b\u51fb\u7b56\u7565\u5177\u6709\u66f4\u5f3a\u9c81\u68d2\u6027\uff0c\u6027\u80fd\u4e0b\u964d\u5e73\u5747\u4ec5\u4e3a-0.71%\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u8f6c\u5f55\u6587\u672c\u5bf9\u4e8e\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u8fd8\u80fd\u589e\u5f3a\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.13481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13481", "abs": "https://arxiv.org/abs/2601.13481", "authors": ["Jian Zhang", "Zhangqi Wang", "Zhiyuan Wang", "Weiping Fu", "Yu He", "Haiping Zhu", "Qika Lin", "Jun Liu"], "title": "Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement", "comment": null, "summary": "Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.", "AI": {"tldr": "APOLO\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\u7cfb\u7edf\u63a2\u7d22\u66f4\u5e7f\u66f4\u7ec6\u7c92\u5ea6\u7684\u63d0\u793a\u7a7a\u95f4\uff0c\u63d0\u5347LLM\u5728\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u60c5\u611f\u8bca\u65ad\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u4e34\u5e8a\u60c5\u611f\u8bca\u65ad\u4e2d\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u60c5\u611f\u5171\u75c5\uff08\u591a\u79cd\u4ea4\u7ec7\u60c5\u611f\u72b6\u6001\u4f7f\u9884\u6d4b\u590d\u6742\u5316\uff09\u548c\u4e34\u5e8a\u76f8\u5173\u7ebf\u7d22\u7684\u4f4e\u6548\u63a2\u7d22\u3002\u867d\u7136LLM\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u3001\u4e0a\u4e0b\u6587\u5bc6\u96c6\u7684\u533b\u7597\u73af\u5883\u4e2d\uff0c\u5176\u8bca\u65ad\u53ef\u9760\u6027\u5bf9\u63d0\u793a\u8bbe\u8ba1\u9ad8\u5ea6\u654f\u611f\u3002", "method": "APOLO\u5c06\u6307\u4ee4\u4f18\u5316\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\uff0c\u5305\u62ec\u89c4\u5212\u8005\u3001\u6559\u5e08\u3001\u6279\u8bc4\u8005\u3001\u5b66\u751f\u548c\u76ee\u6807\u89d2\u8272\u3002\u89c4\u5212\u8005\u5b9a\u4e49\u4f18\u5316\u8f68\u8ff9\uff0c\u6559\u5e08-\u6279\u8bc4\u8005-\u5b66\u751f\u667a\u80fd\u4f53\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u4ee5\u589e\u5f3a\u63a8\u7406\u7a33\u5b9a\u6027\u548c\u6709\u6548\u6027\uff0c\u76ee\u6807\u667a\u80fd\u4f53\u6839\u636e\u6027\u80fd\u8bc4\u4f30\u51b3\u5b9a\u662f\u5426\u7ee7\u7eed\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAPOLO\u5728\u9886\u57df\u7279\u5b9a\u548c\u5206\u5c42\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u63d0\u5347\u8bca\u65ad\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5c55\u793a\u4e86\u5728\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u53ef\u4fe1\u8d56LLM\u5e94\u7528\u7684\u53ef\u6269\u5c55\u548c\u53ef\u6cdb\u5316\u8303\u5f0f\u3002", "conclusion": "APOLO\u4e3a\u89e3\u51b3\u4e34\u5e8a\u60c5\u611f\u8bca\u65ad\u4e2d\u7684\u60c5\u611f\u5171\u75c5\u548c\u7ebf\u7d22\u63a2\u7d22\u6548\u7387\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u4e3a\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u53ef\u4fe1\u8d56\u7684LLM\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13533", "abs": "https://arxiv.org/abs/2601.13533", "authors": ["Changshuo Zhang"], "title": "Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models", "comment": null, "summary": "Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the \"reason first, recommend later\" paradigm to achieve \"reasoning while recommending\", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.", "AI": {"tldr": "EGLR\u6a21\u578b\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u6f5c\u5728\u63a8\u7406\u673a\u5236\uff0c\u5728\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u4e2d\u5b9e\u73b0\"\u8fb9\u63a8\u7406\u8fb9\u63a8\u8350\"\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u5217\u8868\u751f\u6210\u8fc7\u7a0b\u4e2d\u52a8\u6001\u71b5\u53d8\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u65b9\u6cd5\u5927\u591a\u65e0\u6cd5\u9002\u5e94\u5217\u8868\u751f\u6210\u8fc7\u7a0b\u4e2d\u6a21\u578b\u96be\u5ea6\u7684\u52a8\u6001\u71b5\u53d8\u5316\uff0c\u96be\u4ee5\u51c6\u786e\u6355\u6349\u590d\u6742\u504f\u597d\u3002\u53d7\u8bed\u8a00\u6a21\u578b\u6574\u5408\u63a8\u7406\u80fd\u529b\u7684\u542f\u53d1\uff0c\u9700\u8981\u5f15\u5165\u6f5c\u5728\u63a8\u7406\u673a\u5236\u6765\u964d\u4f4e\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u71b5\u3002", "method": "\u63d0\u51fa\u71b5\u5f15\u5bfc\u6f5c\u5728\u63a8\u7406\uff08EGLR\uff09\u63a8\u8350\u6a21\u578b\uff1a1\uff09\u91c7\u7528\"\u8fb9\u63a8\u7406\u8fb9\u63a8\u8350\"\u8303\u5f0f\u800c\u975e\"\u5148\u63a8\u7406\u540e\u63a8\u8350\"\uff1b2\uff09\u4f7f\u7528\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u4ee4\u724c\u548c\u52a8\u6001\u6e29\u5ea6\u8c03\u6574\u5b9e\u73b0\u71b5\u5f15\u5bfc\u7684\u53d8\u957f\u63a8\u7406\uff1b3\uff09\u8f7b\u91cf\u7ea7\u96c6\u6210\u8bbe\u8ba1\uff0c\u65e0\u9700\u590d\u6742\u72ec\u7acb\u6a21\u5757\u6216\u540e\u5904\u7406\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u578b\u6709\u6548\u6027\uff0c\u663e\u8457\u4f18\u52bf\u5728\u4e8e\u80fd\u4e0e\u73b0\u6709\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u6a21\u578b\u517c\u5bb9\u4ee5\u63d0\u5347\u5176\u6027\u80fd\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u5c55\u793a\u4e86\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u548c\u7814\u7a76\u6f5c\u529b\u3002", "conclusion": "EGLR\u6a21\u578b\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u6f5c\u5728\u63a8\u7406\u673a\u5236\uff0c\u5728\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u4e2d\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff0c\u4e3a\u9ad8\u96be\u5ea6\u7684\u5217\u8868\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13545", "categories": ["cs.AI", "cs.ET", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13545", "abs": "https://arxiv.org/abs/2601.13545", "authors": ["Shirin Shahabi", "Spencer Graham", "Haruna Isah"], "title": "TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning", "comment": "16 pages, 6 figures, 2 tables", "summary": "Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com", "AI": {"tldr": "TruthTensor\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u9884\u6d4b\u5e02\u573a\u4efb\u52a1\u8bc4\u4f30LLMs\u5728\u771f\u5b9e\u4e16\u754c\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u8868\u73b0\uff0c\u8d85\u8d8a\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5b58\u5728\u6839\u672c\u6027\u6311\u6218\uff1a\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e16\u754c\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u5206\u5e03\u504f\u79fb\uff0c\u4ee5\u53ca\u5b64\u7acb\u4efb\u52a1\u51c6\u786e\u6027\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u51b3\u7b56\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u9700\u8981\u4e00\u79cd\u80fd\u8bc4\u4f30\u6a21\u578b\u5728\u793e\u4f1a\u5316\u3001\u9ad8\u71b5\u73af\u5883\u4e2d\u4f5c\u4e3a\u4eba\u7c7b\u6a21\u4eff\u7cfb\u7edf\u8868\u73b0\u7684\u8bc4\u4f30\u8303\u5f0f\u3002", "method": "\u63d0\u51faTruthTensor\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u524d\u77bb\u6027\u3001\u65e0\u6c61\u67d3\u7684\u4efb\u52a1\uff0c\u5c06\u8bc4\u4f30\u951a\u5b9a\u5728\u5b9e\u65f6\u9884\u6d4b\u5e02\u573a\u4e0a\uff0c\u7ed3\u5408\u6982\u7387\u8bc4\u5206\u63d0\u4f9b\u6a21\u578b\u884c\u4e3a\u7684\u6574\u4f53\u89c6\u56fe\u3002\u6846\u67b6\u5305\u542b\u6f02\u79fb\u4e2d\u5fc3\u8bca\u65ad\u3001\u663e\u5f0f\u9c81\u68d2\u6027\u68c0\u67e5\u3001\u4eba\u7c7b\u4e0e\u81ea\u52a8\u8bc4\u4f30\u89d2\u8272\u5212\u5206\u3001\u6807\u6ce8\u534f\u8bae\u548c\u7edf\u8ba1\u6d4b\u8bd5\u7a0b\u5e8f\u3002", "result": "\u5728500\u591a\u4e2a\u771f\u5b9e\u5e02\u573a\uff08\u653f\u6cbb\u3001\u7ecf\u6d4e\u3001\u6587\u5316\u3001\u6280\u672f\uff09\u5b9e\u9a8c\u4e2d\uff0cTruthTensor\u663e\u793a\u5177\u6709\u76f8\u4f3c\u9884\u6d4b\u51c6\u786e\u6027\u7684\u6a21\u578b\u5728\u6821\u51c6\u3001\u6f02\u79fb\u548c\u98ce\u9669\u654f\u611f\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8868\u660e\u9700\u8981\u4ece\u591a\u4e2a\u7ef4\u5ea6\uff08\u51c6\u786e\u6027\u3001\u6821\u51c6\u3001\u53d9\u4e8b\u7a33\u5b9a\u6027\u3001\u6210\u672c\u548c\u8d44\u6e90\u6548\u7387\uff09\u8bc4\u4f30\u6a21\u578b\u3002", "conclusion": "TruthTensor\u64cd\u4f5c\u5316\u4e86\u73b0\u4ee3\u8bc4\u4f30\u6700\u4f73\u5b9e\u8df5\uff0c\u5305\u62ec\u6e05\u6670\u7684\u5047\u8bbe\u6846\u67b6\u3001\u8c28\u614e\u7684\u6307\u6807\u9009\u62e9\u3001\u900f\u660e\u7684\u8ba1\u7b97/\u6210\u672c\u62a5\u544a\u3001\u4eba\u7c7b\u5728\u73af\u9a8c\u8bc1\u548c\u5f00\u653e\u7684\u7248\u672c\u5316\u8bc4\u4f30\u5408\u540c\uff0c\u4e3aLLMs\u5728\u771f\u5b9e\u4e16\u754c\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u8fa9\u62a4\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2601.13546", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13546", "abs": "https://arxiv.org/abs/2601.13546", "authors": ["Hui Sun", "Chang Xu", "Haonan Xie", "Hao Li", "Yuhao Huang", "Chuheng Zhang", "Ming Jin", "Xiaoguang Liu", "Gang Wang", "Jiang Bian"], "title": "ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution", "comment": null, "summary": "LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.", "AI": {"tldr": "\u63d0\u51faTSEvol\u591a\u667a\u80fd\u4f53\u65f6\u95f4\u5e8f\u5217\u6f14\u5316\u7b97\u6cd5\u3001TSEData-20K\u6570\u636e\u96c6\u3001ChatAD\u7cfb\u5217\u6a21\u578b\u3001TKTO\u4f18\u5316\u65b9\u6cd5\u548cLLADBench\u57fa\u51c6\uff0c\u663e\u8457\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u63a8\u7406\u80fd\u529b\u548c\u6cdb\u5316\u6027\u80fd", "motivation": "\u73b0\u6709LLM\u9a71\u52a8\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3001\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u6b20\u7f3a\u3001\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7b49\u95ee\u9898\uff0c\u9700\u8981\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u884c\u4e3a\u7684\u7406\u89e3\u548c\u89e3\u91ca\u80fd\u529b", "method": "1) \u63d0\u51faTSEvol\u591a\u667a\u80fd\u4f53\u65f6\u95f4\u5e8f\u5217\u6f14\u5316\u7b97\u6cd5\uff1b2) \u6784\u5efaTSEData-20K\u6570\u636e\u96c6\u548cChatAD\u7cfb\u5217\u6a21\u578b\uff1b3) \u63d0\u51faTKTO\u4f18\u5316\u65b9\u6cd5\u589e\u5f3a\u8de8\u4efb\u52a1\u6cdb\u5316\uff1b4) \u5efa\u7acbLLADBench\u57fa\u51c6\u8bc4\u4f30\u6846\u67b6", "result": "ChatAD\u6a21\u578b\u5728\u51c6\u786e\u7387\u63d0\u534734.50%\u3001F1\u5206\u6570\u63d0\u534734.71%\u3001\u5047\u9633\u6027\u964d\u4f4e37.42%\uff1bTKTO\u4f18\u5316\u540e\u7684ChatAD\u5728\u5206\u7c7b\u3001\u9884\u6d4b\u548c\u586b\u8865\u4efb\u52a1\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u7684\u63a8\u7406\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684\u7efc\u5408\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86LLM\u9a71\u52a8\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u63a8\u7406\u80fd\u529b\u3001\u5bf9\u8bdd\u80fd\u529b\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13559", "abs": "https://arxiv.org/abs/2601.13559", "authors": ["Sun Hui", "Ding Yanfeng", "Huidong Ma", "Chang Xu", "Keyan Jin", "Lizheng Zu", "Cheng Zhong", "xiaoguang Liu", "Gang Wang", "Wentong Cai"], "title": "AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent", "comment": null, "summary": "Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.", "AI": {"tldr": "AgentGC\u662f\u9996\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u8fdb\u5316\u5f0f\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u5668\uff0c\u901a\u8fc7\u4e09\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff08Leader\u548cWorker\uff09\u5b9e\u73b0\u7528\u6237\u53cb\u597d\u754c\u9762\u3001\u8ba4\u77e5\u4f18\u5316\u548c\u81ea\u52a8\u538b\u7f29\uff0c\u5728\u538b\u7f29\u6bd4\u548c\u541e\u5410\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5b66\u4e60\u7684\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u975e\u8fdb\u5316\u6027\u3001\u4f4e\u7ea7\u538b\u7f29\u5efa\u6a21\u3001\u9002\u5e94\u6027\u6709\u9650\u548c\u7528\u6237\u754c\u9762\u4e0d\u53cb\u597d\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u667a\u80fd\u3001\u81ea\u9002\u5e94\u7684\u538b\u7f29\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faAgentGC\u4e09\u5c42\u67b6\u6784\uff1a1\uff09\u7528\u6237\u5c42\u901a\u8fc7Leader\u7ed3\u5408LLM\u63d0\u4f9b\u53cb\u597d\u754c\u9762\uff1b2\uff09\u8ba4\u77e5\u5c42\u7531Leader\u9a71\u52a8\uff0c\u6574\u5408LLM\u8003\u8651\u7b97\u6cd5-\u6570\u636e\u96c6-\u7cfb\u7edf\u7684\u8054\u5408\u4f18\u5316\uff1b3\uff09\u538b\u7f29\u5c42\u7531Worker\u8d1f\u8d23\uff0c\u901a\u8fc7\u81ea\u52a8\u591a\u77e5\u8bc6\u5b66\u4e60\u6846\u67b6\u6267\u884c\u538b\u7f29\u89e3\u538b\u3002\u8bbe\u8ba1\u4e86CP\uff08\u538b\u7f29\u6bd4\u4f18\u5148\uff09\u3001TP\uff08\u541e\u5410\u91cf\u4f18\u5148\uff09\u548cBM\uff08\u5e73\u8861\u6a21\u5f0f\uff09\u4e09\u79cd\u6a21\u5f0f\u3002", "result": "\u57289\u4e2a\u6570\u636e\u96c6\u4e0a\u4e0e14\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\uff0c\u5e73\u5747\u538b\u7f29\u6bd4\u589e\u76ca\u5206\u522b\u4e3a16.66%\u300116.11%\u548c16.33%\uff0c\u541e\u5410\u91cf\u589e\u76ca\u5206\u522b\u4e3a4.73\u500d\u30019.23\u500d\u548c9.15\u500d\u3002", "conclusion": "AgentGC\u4f5c\u4e3a\u9996\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u8fdb\u5316\u5f0f\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u5668\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u548cLLM\u96c6\u6210\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u538b\u7f29\u6027\u80fd\u548c\u541e\u5410\u91cf\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2601.13562", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13562", "abs": "https://arxiv.org/abs/2601.13562", "authors": ["Zhiguang Liu", "Yi Shang"], "title": "Reasoning is a Modality", "comment": "Code access: https://github.com/lz7fd/Reasoning_is_a_Modality", "summary": "The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89d2\u8272\u5206\u79bb\u7684Transformer\u67b6\u6784\uff0c\u5728\u89c6\u89c9\u63a8\u7406\u4efb\u52a1ARC\u4e0a\u8d85\u8d8a\u4e86\u4eba\u7c7b\u5e73\u5747\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u63a8\u7406\u5e94\u4f5c\u4e3a\u72ec\u7acb\u901a\u9053\u5b58\u5728\u7684\u5047\u8bbe\u3002", "motivation": "\u73b0\u4ee3AI\u7cfb\u7edf\uff08\u5982LLMs\u548cViTs\uff09\u4e3b\u8981\u4f5c\u4e3a\u884c\u4e3a\u5e8f\u5217\u9884\u6d4b\u673a\u5668\u8fd0\u884c\uff0c\u901a\u8fc7\u5efa\u6a21token\u7edf\u8ba1\u6765\u5339\u914d\u53ef\u89c2\u5bdf\u884c\u4e3a\uff0c\u7f3a\u4e4f\u6301\u4e45\u3001\u53ef\u8bfb\u7684\u601d\u7ef4\u72b6\u6001\u3002\u8fd9\u4e0e\u4eba\u7c7b\u884c\u4e3a\u5b58\u5728\u5dee\u8ddd\uff1a\u4eba\u7c7b\u53ef\u4ee5\u901a\u8fc7\u89e3\u7801\u5185\u90e8\u72b6\u6001\u6765\u89e3\u91ca\u884c\u4e3a\uff0c\u800cAI\u7cfb\u7edf\u53ea\u80fd\u4ea7\u751f\u7f3a\u4e4f\u5185\u90e8\u72b6\u6001\u57fa\u7840\u7684\u6d41\u7545\u4e8b\u540e\u5408\u7406\u5316\u89e3\u91ca\u3002\u4f5c\u8005\u5047\u8bbe\u63a8\u7406\u662f\u4e00\u79cd\u6a21\u6001\uff1a\u63a8\u7406\u5e94\u8be5\u4f5c\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u901a\u9053\u5b58\u5728\uff0c\u4e0e\u89c4\u5219\u5e94\u7528\u7684\u4f4e\u7ea7\u5de5\u4f5c\u7a7a\u95f4\u5206\u79bb\u3002", "method": "\u4e3a\u89e3\u51b3ARC\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\uff0c\u8bbe\u8ba1\u4e86\u65b0\u9896\u7684\u89d2\u8272\u5206\u79bbTransformer\u5757\uff0c\u5c06\u5168\u5c40\u63a7\u5236\u5668token\u4e0e\u7f51\u683c\u5de5\u4f5c\u7a7a\u95f4token\u5206\u79bb\uff0c\u5b9e\u73b0\u8fed\u4ee3\u89c4\u5219\u6267\u884c\u3002\u8be5\u65b9\u6cd5\u5728VARC\u89c6\u89c9\u4e2d\u5fc3\u534f\u8bae\u4e2d\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u5728ARC-1\u4efb\u52a1\u4e0a\u8fbe\u523062.6%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b\u5e73\u5747\u8868\u73b0\uff0860.2%\uff09\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002\u5b9a\u6027\u5206\u6790\u663e\u793a\uff0c\u4e0e\u5bc6\u96c6ViT\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u4e00\u81f4\u7684\u89c4\u5219\u5e94\u7528\u7ed3\u6784\uff0c\u4ece\u6982\u7387\u6591\u5757\u5411\u63a7\u5236\u5668\u9a71\u52a8\u7684\u63a8\u7406\u8f6c\u53d8\u3002", "conclusion": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u63a8\u7406\u4f5c\u4e3a\u72ec\u7acb\u901a\u9053\u5b58\u5728\u7684\u5047\u8bbe\uff0c\u89d2\u8272\u5206\u79bb\u7684Transformer\u67b6\u6784\u5728\u62bd\u8c61\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8d8a\u4eba\u7c7b\u7684\u8868\u73b0\uff0c\u4e3a\u6784\u5efa\u5177\u6709\u53ef\u89e3\u91ca\u5185\u90e8\u72b6\u6001\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.13581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13581", "abs": "https://arxiv.org/abs/2601.13581", "authors": ["Heedou Kim", "Changsik Kim", "Sanghwa Shin", "Jaewoo Kang"], "title": "SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System", "comment": "This paper has been accepted to the EACL 2026 Industry Track", "summary": "Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.", "AI": {"tldr": "ScriptMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc8\u9a97\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u72af\u7f6a\u811a\u672c\u63a8\u7406\u4efb\u52a1\u3001\u6570\u636e\u96c6\u6784\u5efa\u548c\u8ba4\u77e5\u6a21\u62df\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u8bc8\u9a97\u68c0\u6d4b\u6027\u80fd\u5e76\u589e\u5f3a\u7528\u6237\u8ba4\u77e5\u8b66\u89c9\u6027\u3002", "motivation": "\u4f20\u7edf\u8bc8\u9a97\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u4e2a\u6027\u5316\u3001\u591a\u8f6e\u5bf9\u8bdd\u7684\u793e\u4f1a\u5de5\u7a0b\u8bc8\u9a97\uff0c\u800c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc8\u9a97\u68c0\u6d4b\u65b9\u9762\u7684\u8ba4\u77e5\u8f85\u52a9\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u6316\u6398\u3002", "method": "\u63d0\u51faScriptMind\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u72af\u7f6a\u811a\u672c\u63a8\u7406\u4efb\u52a1\uff08CSIT\uff09\u7528\u4e8e\u8bc8\u9a97\u63a8\u7406\uff0c\u72af\u7f6a\u811a\u672c\u611f\u77e5\u63a8\u7406\u6570\u636e\u96c6\uff08CSID\uff09\u7528\u4e8e\u5fae\u8c03\u5c0f\u578bLLM\uff0c\u4ee5\u53ca\u57fa\u4e8e\u8ba4\u77e5\u6a21\u62df\u7684\u793e\u4f1a\u5de5\u7a0b\u9632\u5fa1\u8bc4\u4f30\uff08CSED\uff09\u7528\u4e8e\u8bc4\u4f30\u5b9e\u65f6\u8ba4\u77e5\u5f71\u54cd\u3002\u4f7f\u7528571\u4e2a\u97e9\u56fd\u7535\u8bdd\u8bc8\u9a97\u6848\u4f8b\u6784\u5efa\u4e8622,712\u4e2a\u7ed3\u6784\u5316\u8bc8\u9a97\u5e8f\u5217\u8bad\u7ec3\u5b9e\u4f8b\u3002", "result": "\u7ecf\u8fc7ScriptMind\u5fae\u8c03\u768411B\u5c0f\u578bLLM\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u6bd4GPT-4o\u9ad8\u51fa13%\uff0c\u5728\u8bef\u62a5\u51cf\u5c11\u3001\u8bc8\u9a97\u8005\u8bdd\u8bed\u9884\u6d4b\u548c\u63a8\u7406\u8d28\u91cf\u65b9\u9762\u5747\u4f18\u4e8e\u5546\u4e1a\u6a21\u578b\u3002\u5728\u7535\u8bdd\u8bc8\u9a97\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u5e76\u7ef4\u6301\u4e86\u7528\u6237\u7684\u6000\u7591\u6c34\u5e73\uff0c\u589e\u5f3a\u4e86\u4ed6\u4eec\u5bf9\u8bc8\u9a97\u7684\u8ba4\u77e5\u610f\u8bc6\u3002", "conclusion": "ScriptMind\u4ee3\u8868\u4e86\u5411\u4ee5\u4eba\u4e3a\u672c\u3001\u8ba4\u77e5\u81ea\u9002\u5e94\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc8\u9a97\u9632\u5fa1\u9886\u57df\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u4e3a\u6784\u5efa\u66f4\u6709\u6548\u7684\u793e\u4f1a\u5de5\u7a0b\u9632\u5fa1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.13589", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.13589", "abs": "https://arxiv.org/abs/2601.13589", "authors": ["HyeYoung Lee"], "title": "Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification", "comment": null, "summary": "This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u97f3\u9891\u60c5\u611f\u4fe1\u53f7\u7684\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff0c\u5b9e\u65f6\u751f\u6210\u54cd\u5e94\u5f0f\u5a92\u4f53\u5185\u5bb9\uff0c\u5f3a\u8c03\u5c06\u60c5\u611f\u8bc6\u522b\u8f6c\u5316\u4e3a\u5b89\u5168\u3001\u53ef\u63a7\u7684\u54cd\u5e94\u5185\u5bb9\uff0c\u800c\u975e\u4ec5\u5173\u6ce8\u5206\u7c7b\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5206\u7c7b\u7cbe\u5ea6\uff0c\u4f46\u7f3a\u4e4f\u5c06\u8bc6\u522b\u5230\u7684\u60c5\u611f\u72b6\u6001\u8f6c\u5316\u4e3a\u5b89\u5168\u3001\u53ef\u63a7\u7684\u54cd\u5e94\u5185\u5bb9\u7684\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u65f6\u751f\u6210\u5e74\u9f84\u9002\u5b9c\u3001\u5b89\u5168\u5408\u89c4\u7684\u5a92\u4f53\u54cd\u5e94\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u56db\u667a\u80fd\u4f53\u534f\u4f5c\u67b6\u6784\uff1a1)\u57fa\u4e8eCNN\u7684\u60c5\u611f\u8bc6\u522b\u667a\u80fd\u4f53\u63d0\u53d6\u58f0\u5b66\u7279\u5f81\uff1b2)\u54cd\u5e94\u7b56\u7565\u51b3\u7b56\u667a\u80fd\u4f53\u5c06\u60c5\u611f\u6620\u5c04\u5230\u54cd\u5e94\u6a21\u5f0f\uff1b3)\u5185\u5bb9\u53c2\u6570\u751f\u6210\u667a\u80fd\u4f53\u4ea7\u751f\u5a92\u4f53\u63a7\u5236\u53c2\u6570\uff1b4)\u5b89\u5168\u9a8c\u8bc1\u667a\u80fd\u4f53\u5f3a\u5236\u6267\u884c\u5e74\u9f84\u9002\u5b9c\u6027\u548c\u523a\u6fc0\u7ea6\u675f\uff0c\u5305\u542b\u663e\u5f0f\u5b89\u5168\u9a8c\u8bc1\u5faa\u73af\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0c\u7cfb\u7edf\u8fbe\u523073.2%\u7684\u60c5\u611f\u8bc6\u522b\u51c6\u786e\u7387\u300189.4%\u7684\u54cd\u5e94\u6a21\u5f0f\u4e00\u81f4\u6027\u3001100%\u7684\u5b89\u5168\u5408\u89c4\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u4e8e100ms\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u9002\u5408\u8bbe\u5907\u7aef\u90e8\u7f72\u3002", "conclusion": "\u8be5\u6a21\u5757\u5316\u67b6\u6784\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u513f\u7ae5\u76f8\u5173\u5a92\u4f53\u3001\u6cbb\u7597\u5e94\u7528\u548c\u60c5\u611f\u54cd\u5e94\u667a\u80fd\u8bbe\u5907\uff0c\u4e3a\u60c5\u611fAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b89\u5168\u53ef\u63a7\u7684\u54cd\u5e94\u751f\u6210\u6846\u67b6\u3002"}}
{"id": "2601.13600", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13600", "abs": "https://arxiv.org/abs/2601.13600", "authors": ["Paul He", "Elke Kirschbaum", "Shiva Kasiviswanathan"], "title": "Foundations of Global Consistency Checking with Noisy LLM Oracles", "comment": "Under Review", "summary": "Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u5168\u5c40\u4e00\u81f4\u6027\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5206\u6cbb\u7b97\u6cd5\u68c0\u6d4b\u6700\u5c0f\u4e0d\u4e00\u81f4\u5b50\u96c6\uff0c\u5177\u6709\u591a\u9879\u5f0f\u67e5\u8be2\u590d\u6742\u5ea6", "motivation": "\u81ea\u7136\u8bed\u8a00\u4e8b\u5b9e\u96c6\u5408\u7684\u5168\u5c40\u4e00\u81f4\u6027\u5bf9\u4e8e\u4e8b\u5b9e\u6838\u67e5\u3001\u6458\u8981\u751f\u6210\u548c\u77e5\u8bc6\u5e93\u6784\u5efa\u7b49\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136LLM\u53ef\u4ee5\u8bc4\u4f30\u5c0f\u89c4\u6a21\u4e8b\u5b9e\u5b50\u96c6\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u5176\u5224\u65ad\u5b58\u5728\u566a\u58f0\uff0c\u4e14\u6210\u5bf9\u68c0\u67e5\u65e0\u6cd5\u4fdd\u8bc1\u5168\u5c40\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u5206\u6cbb\u7b97\u6cd5\uff0c\u8bc6\u522b\u4e8b\u5b9e\u7684\u6700\u5c0f\u4e0d\u4e00\u81f4\u5b50\u96c6\uff0c\u53ef\u9009\u5730\u901a\u8fc7\u547d\u4e2d\u96c6\u8ba1\u7b97\u6700\u5c0f\u4fee\u590d\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u4f4e\u9636\u591a\u9879\u5f0f\u67e5\u8be2\u590d\u6742\u5ea6\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9eLLM\u8bc4\u4f30\u5668\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u548c\u5b9a\u4f4d\u4e0d\u4e00\u81f4\u6027\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u8bed\u8a00\u4e00\u81f4\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86LLM\u8bc4\u4f30\u5668\u5728\u5168\u5c40\u4e00\u81f4\u6027\u9a8c\u8bc1\u4e2d\u7684\u566a\u58f0\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13687", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13687", "abs": "https://arxiv.org/abs/2601.13687", "authors": ["Zhichao Liang", "Satoshi Nakamura"], "title": "Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue", "comment": null, "summary": "Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.", "AI": {"tldr": "SocialMindChange\u662f\u4e00\u4e2a\u65b0\u7684\u52a8\u6001\u5fc3\u7406\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8981\u6c42\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4ea4\u4e92\u52a8\u4e2d\u4e3b\u52a8\u6539\u53d8\u4ed6\u4eba\u5fc3\u7406\u72b6\u6001\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u8ffd\u8e2a\u5fc3\u7406\u72b6\u6001\u53d8\u5316\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u5fc3\u7406\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\u5927\u591a\u8ba9\u8bed\u8a00\u6a21\u578b\u5904\u4e8e\u88ab\u52a8\u89d2\u8272\uff0c\u53ea\u8bfb\u53d6\u573a\u666f\u5e76\u62a5\u544a\u5fc3\u7406\u72b6\u6001\u53d8\u5316\u3002\u4f46\u5728\u771f\u5b9e\u793e\u4ea4\u4e92\u52a8\u4e2d\uff0c\u5fc3\u7406\u7406\u8bba\u4e5f\u7528\u4e8e\u884c\u52a8\uff1a\u8bf4\u8bdd\u8005\u8ba1\u5212\u8bf4\u4ec0\u4e48\u6765\u6539\u53d8\u4ed6\u4eba\u7684\u5fc3\u7406\u72b6\u6001\u8f68\u8ff9\u4ee5\u8fbe\u5230\u76ee\u6807\u3002", "method": "\u5f15\u5165SocialMindChange\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bcf\u4e2a\u5b9e\u4f8b\u5b9a\u4e49\u5305\u542b4\u4e2a\u89d2\u8272\u7684\u793e\u4ea4\u60c5\u5883\u548c5\u4e2a\u8fde\u63a5\u573a\u666f\u3002\u6a21\u578b\u626e\u6f14\u4e00\u4e2a\u89d2\u8272\uff0c\u57285\u4e2a\u573a\u666f\u4e2d\u751f\u6210\u5bf9\u8bdd\u4ee5\u8fbe\u5230\u76ee\u6807\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6240\u6709\u53c2\u4e0e\u8005\u4e0d\u65ad\u53d8\u5316\u7684\u72b6\u6001\u4e00\u81f4\u3002\u91c7\u7528\u7ed3\u6784\u5316\u56db\u6b65\u6846\u67b6\u6784\u5efa\u4e861200\u4e2a\u793e\u4ea4\u60c5\u5883\uff0c\u8986\u76d66000\u4e2a\u573a\u666f\u548c\u8d85\u8fc790000\u4e2a\u95ee\u9898\u3002", "result": "\u5bf910\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5b83\u4eec\u7684\u5e73\u5747\u6027\u80fd\u6bd4\u4eba\u7c7b\u8868\u73b0\u4f4e54.2%\u3002\u8fd9\u8868\u660e\u5f53\u524dLLM\u5728\u957f\u671f\u8fde\u63a5\u4e92\u52a8\u4e2d\u7ef4\u6301\u548c\u6539\u53d8\u5fc3\u7406\u72b6\u6001\u8868\u5f81\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u4ece\u8ffd\u8e2a\u5fc3\u7406\u72b6\u6001\u5230\u6539\u53d8\u5fc3\u7406\u72b6\u6001\u7684\u8f6c\u53d8\u63ed\u793a\u4e86\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u793e\u4ea4\u4e92\u52a8\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u3002"}}
{"id": "2601.13735", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13735", "abs": "https://arxiv.org/abs/2601.13735", "authors": ["Hojin Kim", "Jaehyung Kim"], "title": "Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection", "comment": "15 pages, 4 figures", "summary": "Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u57fa\u4e8e\u6982\u7387\u7684\u7f6e\u4fe1\u5ea6\u6307\u6807\u65e0\u6cd5\u6709\u6548\u6355\u6349\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e3b\u8981\u53cd\u6620\u7684\u662f\u8868\u9762\u6d41\u7545\u5ea6\u800c\u975e\u903b\u8f91\u7ed3\u6784\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6bd4\u56e0\u679c\u6307\u6807\u6765\u6539\u8fdb\u8f93\u51fa\u9009\u62e9\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u666e\u904d\u5047\u8bbe\u6982\u7387\u7f6e\u4fe1\u5ea6\u6307\u6807\u80fd\u591f\u53cd\u6620\u63a8\u7406\u8d28\u91cf\uff0c\u4f46\u672c\u6587\u8d28\u7591\u8fd9\u4e00\u5047\u8bbe\uff0c\u63a2\u7a76\u8fd9\u4e9b\u6307\u6807\u662f\u5426\u771f\u6b63\u6355\u6349\u5230\u4e86\u63a8\u7406\u6b65\u9aa4\u95f4\u5fc5\u8981\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u5f15\u5165\u4e09\u7c7b\u63a8\u7406\u6b65\u9aa4\u95f4\u56e0\u679c\u6270\u52a8\uff0c\u7cfb\u7edf\u6027\u5730\u7834\u574f\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u4f46\u4fdd\u6301\u5c40\u90e8\u6d41\u7545\u6027\uff1b\u5728\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u548c\u63a8\u7406\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff1b\u63d0\u51fa\u5bf9\u6bd4\u56e0\u679c\u6307\u6807\u6765\u663e\u5f0f\u9694\u79bb\u6b65\u9aa4\u95f4\u7684\u56e0\u679c\u4f9d\u8d56\u3002", "result": "\u5373\u4f7f\u4e25\u91cd\u5e72\u6270\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u56e0\u679c\u4f9d\u8d56\uff08\u5982\u5e94\u7528\u786c\u6ce8\u610f\u529b\u63a9\u7801\u963b\u6b62\u6a21\u578b\u5173\u6ce8\u5148\u524d\u63a8\u7406\u6b65\u9aa4\uff09\uff0c\u9009\u62e9\u51c6\u786e\u7387\u4ec5\u8f7b\u5fae\u4e0b\u964d\uff0c\u8868\u660e\u5f53\u524d\u6982\u7387\u6307\u6807\u5bf9\u903b\u8f91\u7ed3\u6784\u4e0d\u654f\u611f\uff0c\u4e3b\u8981\u6355\u6349\u8868\u9762\u6d41\u7545\u5ea6\u6216\u5206\u5e03\u5185\u5148\u9a8c\u3002", "conclusion": "\u5f53\u524d\u6982\u7387\u7f6e\u4fe1\u5ea6\u6307\u6807\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u63a8\u7406\u8d28\u91cf\uff0c\u4e3b\u8981\u53cd\u6620\u8868\u9762\u7279\u5f81\u800c\u975e\u903b\u8f91\u7ed3\u6784\uff1b\u63d0\u51fa\u7684\u5bf9\u6bd4\u56e0\u679c\u6307\u6807\u80fd\u591f\u66f4\u5fe0\u5b9e\u5730\u8fdb\u884c\u8f93\u51fa\u9009\u62e9\uff0c\u4e3a\u6539\u8fdb\u63a8\u7406\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.13752", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13752", "abs": "https://arxiv.org/abs/2601.13752", "authors": ["Chak Tou Leong", "Dingwei Chen", "Heming Xia", "Qingyu Yin", "Sunbowen Lee", "Jian Wang", "Wenjie Li"], "title": "Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering", "comment": "Working in progress", "summary": "Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \\textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.", "AI": {"tldr": "RELIEF\u6846\u67b6\u901a\u8fc7\u8c03\u6574\u5927\u63a8\u7406\u6a21\u578b\u7684\u81ea\u6211\u8ba4\u77e5\u4fe1\u5ff5\u6765\u5851\u9020\u5176\u884c\u4e3a\uff0c\u65e0\u9700\u76d1\u7763\u63a8\u7406\u8f68\u8ff9\uff0c\u964d\u4f4e\u4e86\u8bad\u7ec3\u6210\u672c", "motivation": "\u5927\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8ba1\u7b97\u5197\u4f59\u548c\u63a8\u7406\u4e0d\u5fe0\u5b9e\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5f3a\u5316\u5b66\u4e60\u6216\u9ec4\u91d1\u6807\u51c6\u63a8\u7406\u8f68\u8ff9\u76d1\u7763\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55", "method": "\u63d0\u51faRELIEF\u6846\u67b6\uff0c\u901a\u8fc7\u7b80\u5355\u7684logit\u63a2\u6d4b\u6355\u83b7\u6a21\u578b\u7684\u6f5c\u5728\u63a8\u7406\u4fe1\u5ff5\uff0c\u7136\u540e\u901a\u8fc7\u5fae\u8c03\u4f7f\u6a21\u578b\u7684\u81ea\u6211\u6982\u5ff5\u4e0e\u76ee\u6807\u4fe1\u5ff5\u84dd\u56fe\u5bf9\u9f50\uff0c\u4f7f\u7528\u5408\u6210\u7684\u81ea\u6211\u53cd\u601d\u95ee\u7b54\u5bf9\u6765\u5185\u5316\u671f\u671b\u7279\u8d28", "result": "\u5728\u6548\u7387\u548c\u5fe0\u5b9e\u6027\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRELIEF\u5339\u914d\u6216\u4f18\u4e8e\u57fa\u4e8e\u884c\u4e3a\u76d1\u7763\u548c\u504f\u597d\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u8bad\u7ec3\u6210\u672c\u66f4\u4f4e\uff1b\u5206\u6790\u9a8c\u8bc1\u4e86\u6539\u53d8\u6a21\u578b\u7684\u63a8\u7406\u4fe1\u5ff5\u80fd\u6709\u6548\u5851\u9020\u5176\u5b9e\u9645\u884c\u4e3a", "conclusion": "RELIEF\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u6574\u6a21\u578b\u7684\u81ea\u6211\u8ba4\u77e5\u4fe1\u5ff5\u6765\u5851\u9020\u5927\u63a8\u7406\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u65e0\u9700\u6602\u8d35\u7684\u63a8\u7406\u8f68\u8ff9\u76d1\u7763\uff0c\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027"}}
{"id": "2601.13761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13761", "abs": "https://arxiv.org/abs/2601.13761", "authors": ["Shengda Fan", "Xuyan Ye", "Yankai Lin"], "title": "DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution", "comment": null, "summary": "Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations. The code is available at https://github.com/RUCBM/DARC.", "AI": {"tldr": "DARC\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u81ea\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u95ee\u9898\u751f\u6210\u548c\u89e3\u7b54\u8bad\u7ec3\uff0c\u89e3\u51b3\u4e86\u81ea\u535a\u5f08\u4e2d\u4f18\u5316\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u5e73\u5747\u63d0\u534710.9\u5206\u3002", "motivation": "\u73b0\u6709\u81ea\u535a\u5f08\u6846\u67b6\u5b58\u5728\u4f18\u5316\u4e0d\u7a33\u5b9a\u95ee\u9898\uff1a1\uff09\u95ee\u9898\u8005\u4f9d\u8d56\u89e3\u7b54\u8005\u53cd\u9988\u7684\u975e\u5e73\u7a33\u76ee\u6807\uff1b2\uff09\u89e3\u7b54\u8005\u4f7f\u7528\u81ea\u751f\u6210\u4f2a\u6807\u7b7e\u5bfc\u81f4\u7684\u5f15\u5bfc\u8bef\u5dee\u3002", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u95ee\u9898\u8005\u57fa\u4e8e\u660e\u786e\u96be\u5ea6\u7ea7\u522b\u548c\u5916\u90e8\u8bed\u6599\u5408\u6210\u96be\u5ea6\u6821\u51c6\u7684\u95ee\u9898\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u975e\u5bf9\u79f0\u81ea\u84b8\u998f\u673a\u5236\u8bad\u7ec3\u89e3\u7b54\u8005\uff0c\u4f7f\u7528\u6587\u6863\u589e\u5f3a\u7684\u6559\u5e08\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u4f2a\u6807\u7b7e\u76d1\u7763\u65e0\u6587\u6863\u8bbf\u95ee\u7684\u5b66\u751f\u89e3\u7b54\u8005\u3002", "result": "DARC\u5177\u6709\u6a21\u578b\u65e0\u5173\u6027\uff0c\u57289\u4e2a\u63a8\u7406\u57fa\u51c6\u548c3\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u5e73\u5747\u63d0\u534710.9\u5206\uff0c\u6301\u7eed\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63a5\u8fd1\u5b8c\u5168\u76d1\u7763\u6a21\u578b\u7684\u6027\u80fd\u4e14\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3002", "conclusion": "DARC\u901a\u8fc7\u89e3\u8026\u95ee\u9898\u751f\u6210\u548c\u89e3\u7b54\u8bad\u7ec3\uff0c\u7a33\u5b9a\u4e86\u81ea\u8fdb\u5316\u8fc7\u7a0b\uff0c\u4e3a\u81ea\u6539\u8fdbAI\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u81ea\u535a\u5f08\u6846\u67b6\u3002"}}
{"id": "2601.13770", "categories": ["cs.AI", "cs.CL", "cs.LG", "q-fin.CP", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2601.13770", "abs": "https://arxiv.org/abs/2601.13770", "authors": ["Mostapha Benhenda"], "title": "Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance", "comment": null, "summary": "We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench", "AI": {"tldr": "Look-Ahead-Bench\u662f\u4e00\u4e2a\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u91d1\u878d\u5de5\u4f5c\u6d41\u4e2dPiT\u5927\u8bed\u8a00\u6a21\u578b\u7684\u524d\u77bb\u6027\u504f\u5dee\uff0c\u901a\u8fc7\u5b9e\u9645\u573a\u666f\u6d4b\u8bd5\u800c\u975e\u7b80\u5355\u95ee\u7b54\uff0c\u53d1\u73b0\u6807\u51c6LLMs\u5b58\u5728\u663e\u8457\u524d\u77bb\u6027\u504f\u5dee\uff0c\u800cPiT\u6a21\u578b\u968f\u89c4\u6a21\u6269\u5927\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u95ee\u7b54\u6d4b\u8bd5LLMs\u7684\u5185\u90e8\u524d\u77bb\u77e5\u8bc6\uff0c\u7f3a\u4e4f\u5bf9\u5b9e\u9645\u91d1\u878d\u5de5\u4f5c\u6d41\u4e2d\u6a21\u578b\u884c\u4e3a\u7684\u8bc4\u4f30\u3002\u9700\u8981\u533a\u5206\u771f\u6b63\u7684\u9884\u6d4b\u80fd\u529b\u4e0e\u57fa\u4e8e\u8bb0\u5fc6\u7684\u6027\u80fd\uff0c\u5efa\u7acb\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u6765\u8bc6\u522b\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u7684\u91d1\u878dLLMs\u3002", "method": "\u521b\u5efaLook-Ahead-Bench\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e0d\u540c\u65f6\u95f4\u5e02\u573a\u5236\u5ea6\u4e0b\u7684\u6027\u80fd\u8870\u51cf\uff0c\u5f15\u5165\u591a\u4e2a\u91cf\u5316\u57fa\u7ebf\u5efa\u7acb\u6027\u80fd\u9608\u503c\u3002\u8bc4\u4f30\u5f00\u6e90LLMs\uff08Llama 3.1 8B/70B\u548cDeepSeek 3.2\uff09\u4e0ePiT-Inference\u7684PiT LLMs\uff08Pitinf-Small\u3001Medium\u3001Large\uff09\uff0c\u4f7f\u7528alpha\u8870\u51cf\u8861\u91cf\u524d\u77bb\u6027\u504f\u5dee\u3002", "result": "\u6807\u51c6LLMs\u663e\u793a\u51fa\u663e\u8457\u7684\u524d\u77bb\u6027\u504f\u5dee\uff0c\u800cPiT\u6a21\u578b\u968f\u89c4\u6a21\u6269\u5927\u5c55\u73b0\u51fa\u6539\u8fdb\u7684\u6cdb\u5316\u548c\u63a8\u7406\u80fd\u529b\u3002Pitinf\u6a21\u578b\u5728\u4e0d\u540c\u65f6\u95f4\u5e02\u573a\u5236\u5ea6\u4e0b\u8868\u73b0\u66f4\u7a33\u5b9a\uff0c\u8868\u660e\u66f4\u597d\u7684\u65f6\u95f4\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u91d1\u878dLLMs\u7684\u65f6\u95f4\u504f\u5dee\u6807\u51c6\u5316\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u8bc6\u522b\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u6a21\u578b\u7684\u5b9e\u7528\u6846\u67b6\u3002PiT\u6a21\u578b\u5728\u51cf\u5c11\u524d\u77bb\u6027\u504f\u5dee\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u91d1\u878d\u9886\u57dfLLMs\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2601.13846", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13846", "abs": "https://arxiv.org/abs/2601.13846", "authors": ["Glinskaya Maria"], "title": "Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments", "comment": null, "summary": "This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u865a\u62df\u90fd\u5e02\u4e3b\u4e49(VU)\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5f0fAI\u521b\u5efa\u57ce\u5e02\u5408\u6210\u590d\u5236\u54c1\u6765\u91cf\u5316\u57ce\u5e02\u8eab\u4efd\u8ba4\u540c\uff0c\u5e76\u5728\u4e1c\u4eac\u4e5d\u4e2a\u533a\u57df\u8fdb\u884c\u8bd5\u70b9\u7814\u7a76\u9a8c\u8bc1\u53ef\u884c\u6027\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u53ef\u8ba1\u7b97\u7684\u57ce\u5e02\u8eab\u4efd\u8ba4\u540c\u5ea6\u91cf\u65b9\u6cd5\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u91cf\u5316\u57ce\u5e02\u6838\u5fc3\u7279\u5f81\u7684\u591a\u6a21\u6001AI\u5206\u6790\u6846\u67b6\u3002", "method": "\u6574\u5408Stable Diffusion\u548cLoRA\u6a21\u578b\u751f\u6210\u4e1c\u4eac\u4e5d\u4e2a\u533a\u57df\u7684\u5408\u6210\u57ce\u5e02\u5e8f\u5217\uff0c\u6392\u9664\u73b0\u6709\u5730\u6807\u4ee5\u63d0\u53d6\u6838\u5fc3\u8eab\u4efd\u5143\u7d20\uff0c\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u5b9e\u9a8c\u9a8c\u8bc1\u590d\u5236\u54c1\u611f\u77e5\u5408\u6cd5\u6027\u3001\u91cf\u5316\u533a\u57df\u7ea7\u8eab\u4efd\u3001\u63d0\u53d6\u6838\u5fc3\u8eab\u4efd\u5f62\u6210\u5143\u7d20\u3002", "result": "\u5408\u6210\u590d\u5236\u54c1\u7684\u5e73\u5747\u8bc6\u522b\u51c6\u786e\u7387\u8fbe\u5230\u7ea681%\uff0c\u9a8c\u8bc1\u4e86\u590d\u5236\u54c1\u7684\u6709\u6548\u6027\uff1b\u57ce\u5e02\u8eab\u4efd\u6c34\u5e73(UIL)\u6307\u6807\u80fd\u591f\u8bc4\u4f30\u4e0d\u540c\u533a\u57df\u7684\u8eab\u4efd\u6c34\u5e73\uff1b\u8bed\u4e49\u5206\u6790\u63ed\u793a\u4e86\u6587\u5316\u5d4c\u5165\u7684\u7c7b\u578b\u5b66\u4f5c\u4e3a\u6838\u5fc3\u8eab\u4efd\u5f62\u6210\u5143\u7d20\u3002", "conclusion": "VU\u6846\u67b6\u4e3aAI\u589e\u5f3a\u7684\u57ce\u5e02\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u5c55\u793a\u4e86\u5b9e\u73b0\u81ea\u52a8\u5316\u3001\u591a\u53c2\u6570\u8eab\u4efd\u5ea6\u91cf\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13887", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13887", "abs": "https://arxiv.org/abs/2601.13887", "authors": ["Hong Su"], "title": "Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.", "AI": {"tldr": "\u63d0\u51fa\u4eba\u7c7b\u6a21\u62df\u8ba1\u7b97\uff08HSC\uff09\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u5efa\u6a21\u4e3a\u5305\u542b\u601d\u8003\u3001\u884c\u52a8\u3001\u5b66\u4e60\u3001\u53cd\u601d\u548c\u6d3b\u52a8\u8c03\u5ea6\u7684\u8fde\u7eed\u95ed\u73af\u8fc7\u7a0b\uff0c\u5f3a\u8c03\u901a\u8fc7\u884c\u52a8\u81ea\u52a8\u6539\u8fdb\u5185\u90e8\u63a8\u7406\u673a\u5236\uff0c\u65e0\u9700\u5916\u90e8\u5e72\u9884\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u4ec5\u4f9d\u8d56\u6587\u672c\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u5728\u5f00\u653e\u52a8\u6001\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u3001\u63a8\u7406\u7ed3\u679c\u9a8c\u8bc1\u548c\u6709\u6548\u64cd\u4f5c\u3002\u9700\u8981\u4e00\u79cd\u66f4\u63a5\u8fd1\u4eba\u7c7b\u667a\u80fd\u7684\u8ba1\u7b97\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4eba\u7c7b\u6a21\u62df\u8ba1\u7b97\uff08HSC\uff09\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u5efa\u6a21\u4e3a\u5305\u542b\u601d\u8003\u3001\u884c\u52a8\u3001\u5b66\u4e60\u3001\u53cd\u601d\u548c\u6d3b\u52a8\u8c03\u5ea6\u7684\u8fde\u7eed\u95ed\u73af\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u3002\u5f3a\u8c03\u4e3b\u52a8\u53c2\u4e0e\u73af\u5883\u4ea4\u4e92\uff0c\u4f7f\u7528\u884c\u52a8\u4e0d\u4ec5\u5b9e\u73b0\u76ee\u6807\uff0c\u8fd8\u81ea\u52a8\u6539\u8fdb\u5185\u90e8\u63a8\u7406\u673a\u5236\u3002\u878d\u5165\u4eba\u7c7b\u5e38\u7528\u601d\u7ef4\u7b56\u7565\uff0c\u5982\u4e3b\u7279\u5f81\u5bfc\u5411\u63a8\u7406\u3001\u901a\u8fc7\u884c\u52a8\u6269\u5c55\u8303\u56f4\u3001\u73af\u5883\u53cd\u9988\u9a71\u52a8\u7684\u53ca\u65f6\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4eba\u7c7b\u6a21\u62df\u7b56\u7565\u65e0\u6cd5\u4ec5\u4ece\u8bed\u8a00\u6750\u6599\u4e2d\u5b8c\u5168\u5b66\u4e60\uff0c\u4eba\u7c7b\u5f0f\u63a8\u7406\u8fc7\u7a0b\u548c\u57fa\u4e8e\u884c\u52a8\u7684\u63a8\u7406\u65b9\u6cd5\u5bf9\u4e8e\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u9002\u5e94\u548c\u6709\u6548\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "HSC\u6846\u67b6\u4e3a\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5f3a\u8c03\u4e3b\u52a8\u53c2\u4e0e\u3001\u95ed\u73af\u5b66\u4e60\u548c\u57fa\u4e8e\u884c\u52a8\u7684\u63a8\u7406\u6539\u8fdb\uff0c\u4e3a\u5b9e\u73b0\u66f4\u5f3a\u5927\u7684\u9002\u5e94\u6027\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.13904", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13904", "abs": "https://arxiv.org/abs/2601.13904", "authors": ["Jaeyoung Moon", "Youjin Choi", "Yucheon Park", "David Melhart", "Georgios N. Yannakakis", "Kyung-Joong Kim"], "title": "PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation", "comment": "CHI '26 Accepted paper", "summary": "Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.", "AI": {"tldr": "PREFAB\u662f\u4e00\u79cd\u4f4e\u6210\u672c\u56de\u987e\u5f0f\u81ea\u6211\u6807\u6ce8\u65b9\u6cd5\uff0c\u9488\u5bf9\u60c5\u611f\u53d8\u5316\u533a\u57df\u800c\u975e\u5b8c\u6574\u6807\u6ce8\uff0c\u901a\u8fc7\u504f\u597d\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u76f8\u5bf9\u60c5\u611f\u53d8\u5316\uff0c\u8ba9\u6807\u6ce8\u8005\u53ea\u6807\u6ce8\u9009\u5b9a\u7247\u6bb5\uff0c\u5176\u4f59\u90e8\u5206\u901a\u8fc7\u63d2\u503c\u5b8c\u6210\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u8ba1\u7b97\u4e2d\u7684\u81ea\u6211\u6807\u6ce8\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5b8c\u6574\u6807\u6ce8\uff0c\u8fd9\u8fc7\u7a0b\u8017\u65f6\u3001\u8ba4\u77e5\u8d1f\u62c5\u91cd\u3001\u5bb9\u6613\u75b2\u52b3\u4e14\u6613\u51fa\u9519\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u8d1f\u62c5\u66f4\u8f7b\u7684\u6807\u6ce8\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5cf0\u503c-\u7ec8\u70b9\u89c4\u5219\u548c\u60c5\u611f\u5e8f\u6570\u8868\u793a\uff0c\u4f7f\u7528\u504f\u597d\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u76f8\u5bf9\u60c5\u611f\u53d8\u5316\uff0c\u6307\u5bfc\u6807\u6ce8\u8005\u53ea\u6807\u6ce8\u9009\u5b9a\u7247\u6bb5\uff0c\u5176\u4f59\u90e8\u5206\u901a\u8fc7\u63d2\u503c\u5b8c\u6210\u3002\u5f15\u5165\u9884\u89c8\u673a\u5236\u63d0\u4f9b\u4e0a\u4e0b\u6587\u7ebf\u7d22\u8f85\u52a9\u6807\u6ce8\u3002", "result": "PREFAB\u5728\u5efa\u6a21\u60c5\u611f\u53d8\u5316\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u51cf\u8f7b\u4e86\u5de5\u4f5c\u8d1f\u62c5\uff08\u6709\u6761\u4ef6\u5730\u51cf\u8f7b\u65f6\u95f4\u8d1f\u62c5\uff09\u3002\u91cd\u8981\u7684\u662f\uff0cPREFAB\u63d0\u9ad8\u4e86\u6807\u6ce8\u8005\u4fe1\u5fc3\u4e14\u672a\u964d\u4f4e\u6807\u6ce8\u8d28\u91cf\u3002", "conclusion": "PREFAB\u662f\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u6210\u672c\u60c5\u611f\u6807\u6ce8\u65b9\u6cd5\uff0c\u80fd\u591f\u51c6\u786e\u6355\u6349\u60c5\u611f\u53d8\u5316\u533a\u57df\uff0c\u540c\u65f6\u51cf\u8f7b\u6807\u6ce8\u8005\u8d1f\u62c5\uff0c\u63d0\u9ad8\u6807\u6ce8\u6548\u7387\u548c\u4fe1\u5fc3\u3002"}}
{"id": "2601.14027", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14027", "abs": "https://arxiv.org/abs/2601.14027", "authors": ["Junqi Liu", "Zihao Zhou", "Zekai Zhu", "Marco Dos Santos", "Weikun He", "Jiawei Liu", "Ran Wang", "Yunzhou Xie", "Junqiao Zhao", "Qiufeng Wang", "Lihong Zhi", "Jia Li", "Wenda Li"], "title": "Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics", "comment": null, "summary": "Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u901a\u7528\u7f16\u7801\u667a\u80fd\u4f53\u4f5c\u4e3a\u5f62\u5f0f\u6570\u5b66\u63a8\u7406\u5668\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7Numina-Lean-Agent\u7cfb\u7edf\u5728Putnam 2025\u7ade\u8d5b\u4e2d\u53d6\u5f97\u6ee1\u5206\u6210\u7ee9\uff0c\u5e76\u6210\u529f\u5f62\u5f0f\u5316Brascamp-Lieb\u5b9a\u7406\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u7cfb\u7edf\u4f9d\u8d56\u7279\u5b9a\u4efb\u52a1\u6d41\u6c34\u7ebf\u548c\u8bad\u7ec3\u8fc7\u7684\u5f62\u5f0f\u8bc1\u660e\u5668\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u901a\u7528\u7f16\u7801\u667a\u80fd\u4f53\u4f5c\u4e3a\u5f62\u5f0f\u6570\u5b66\u63a8\u7406\u5668\uff0c\u56e0\u4e3a\uff1a(1)\u901a\u7528\u7f16\u7801\u667a\u80fd\u4f53\u4e3a\u8d85\u8d8a\u8bc1\u660e\u7684\u591a\u6837\u5316\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u81ea\u7136\u63a5\u53e3\uff1b(2)\u4ec5\u901a\u8fc7\u66ff\u6362\u5e95\u5c42\u57fa\u7840\u6a21\u578b\u5373\u53ef\u63d0\u5347\u6027\u80fd\uff0c\u65e0\u9700\u8bad\u7ec3\uff1b(3)MCP\u652f\u6301\u7075\u6d3b\u6269\u5c55\u548c\u81ea\u4e3b\u8c03\u7528\u4e13\u4e1a\u5de5\u5177\uff0c\u907f\u514d\u590d\u6742\u8bbe\u8ba1\u3002", "method": "\u63d0\u51faNumina-Lean-Agent\u7cfb\u7edf\uff0c\u7ed3\u5408Claude Code\u4e0eNumina-Lean-MCP\uff0c\u5b9e\u73b0\u4e0eLean\u7684\u81ea\u4e3b\u4ea4\u4e92\u3001\u76f8\u5173\u5b9a\u7406\u68c0\u7d22\u3001\u975e\u5f62\u5f0f\u5316\u8bc1\u660e\u548c\u8f85\u52a9\u63a8\u7406\u5de5\u5177\u8c03\u7528\u3002\u4f7f\u7528Claude Opus 4.5\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\u3002", "result": "\u4f7f\u7528Claude Opus 4.5\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\u7684Numina-Lean-Agent\u5728Putnam 2025\u7ade\u8d5b\u4e2d\u89e3\u51b3\u4e86\u6240\u6709\u95ee\u9898\uff0812/12\uff09\uff0c\u4e0e\u6700\u4f73\u95ed\u6e90\u7cfb\u7edf\u6027\u80fd\u76f8\u5f53\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4e0e\u6570\u5b66\u5bb6\u4ea4\u4e92\u6210\u529f\u5f62\u5f0f\u5316\u4e86Brascamp-Lieb\u5b9a\u7406\uff0c\u5c55\u793a\u4e86\u7cfb\u7edf\u7684\u901a\u7528\u6027\u3002", "conclusion": "\u901a\u7528\u7f16\u7801\u667a\u80fd\u4f53\u4f5c\u4e3a\u5f62\u5f0f\u6570\u5b66\u63a8\u7406\u5668\u7684\u65b0\u8303\u5f0f\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0cNumina-Lean-Agent\u5728\u7ade\u8d5b\u548c\u5b9e\u9645\u6570\u5b66\u5b9a\u7406\u5f62\u5f0f\u5316\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002\u7cfb\u7edf\u4ee3\u7801\u548c\u89e3\u51b3\u65b9\u6848\u5df2\u5f00\u6e90\u53d1\u5e03\u3002"}}
{"id": "2601.14171", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14171", "abs": "https://arxiv.org/abs/2601.14171", "authors": ["Qianli Ma", "Chang Guo", "Zhiheng Tian", "Siyu Wang", "Jipeng Xiao", "Yuanhao Yue", "Zhipeng Zhang"], "title": "Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance", "comment": null, "summary": "Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.", "AI": {"tldr": "RebuttalAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u53cd\u9a73\u4fe1\u751f\u6210\u91cd\u6784\u4e3a\u4ee5\u8bc1\u636e\u4e3a\u4e2d\u5fc3\u7684\u89c4\u5212\u4efb\u52a1\uff0c\u901a\u8fc7\u5206\u89e3\u5ba1\u7a3f\u610f\u89c1\u3001\u6784\u5efa\u6df7\u5408\u4e0a\u4e0b\u6587\u3001\u96c6\u6210\u5916\u90e8\u641c\u7d22\uff0c\u751f\u6210\u53ef\u68c0\u67e5\u7684\u54cd\u5e94\u8ba1\u5212\uff0c\u786e\u4fdd\u6bcf\u4e2a\u8bba\u70b9\u90fd\u6709\u660e\u786e\u8bc1\u636e\u652f\u6491\u3002", "motivation": "\u5f53\u524d\u7684\u53cd\u9a73\u4fe1\u751f\u6210\u65b9\u6cd5\u901a\u5e38\u5c06\u5176\u89c6\u4e3a\u76f4\u63a5\u6587\u672c\u751f\u6210\u95ee\u9898\uff0c\u5b58\u5728\u5e7b\u89c9\u3001\u9057\u6f0f\u6279\u8bc4\u3001\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u57fa\u7840\u7b49\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7cbe\u786e\u5bf9\u9f50\u5ba1\u7a3f\u610f\u56fe\u548c\u7a3f\u4ef6\u7ec6\u8282\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faRebuttalAgent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a1\uff09\u5c06\u590d\u6742\u53cd\u9988\u5206\u89e3\u4e3a\u539f\u5b50\u5316\u5173\u5207\u70b9\uff1b2\uff09\u52a8\u6001\u6784\u5efa\u6df7\u5408\u4e0a\u4e0b\u6587\uff0c\u5408\u6210\u538b\u7f29\u6458\u8981\u4e0e\u9ad8\u4fdd\u771f\u6587\u672c\uff1b3\uff09\u96c6\u6210\u81ea\u4e3b\u6309\u9700\u5916\u90e8\u641c\u7d22\u6a21\u5757\u89e3\u51b3\u9700\u8981\u5916\u90e8\u6587\u732e\u7684\u5173\u5207\u70b9\uff1b4\uff09\u5728\u8d77\u8349\u524d\u751f\u6210\u53ef\u68c0\u67e5\u7684\u54cd\u5e94\u8ba1\u5212\u3002", "result": "\u5728\u63d0\u51fa\u7684RebuttalBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6d41\u6c34\u7ebf\u5728\u8986\u76d6\u7387\u3001\u5fe0\u5b9e\u5ea6\u548c\u7b56\u7565\u8fde\u8d2f\u6027\u65b9\u9762\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u4e3a\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u900f\u660e\u53ef\u63a7\u7684\u52a9\u624b\u3002", "conclusion": "RebuttalAgent\u901a\u8fc7\u5c06\u53cd\u9a73\u4fe1\u751f\u6210\u91cd\u6784\u4e3a\u8bc1\u636e\u4e2d\u5fc3\u7684\u89c4\u5212\u4efb\u52a1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u63a7\u4e14\u57fa\u4e8e\u8bc1\u636e\u7684\u53cd\u9a73\u4fe1\u751f\u6210\u6846\u67b6\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002"}}
