<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 10]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: Doc2AHP：结合LLM泛化能力与AHP决策理论严谨性的结构化推理框架，无需标注数据或人工干预，通过AHP原则约束LLM在非结构化文档空间搜索，提升决策模型的逻辑完整性和任务准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在语义理解方面表现出色，但在需要严格逻辑的复杂决策任务中难以保证结构一致性和推理可靠性。传统决策理论如AHP虽提供系统理性框架，但构建依赖大量领域专家知识，存在"专家瓶颈"问题，限制了在通用场景中的可扩展性。

Method: 提出Doc2AHP结构化推理框架，利用AHP的结构原则作为约束条件，引导LLM在非结构化文档空间进行约束搜索，强制父节点与子节点之间的逻辑蕴含关系。引入多智能体加权机制和自适应一致性优化策略，确保权重分配的数字一致性。

Result: 实证结果表明，Doc2AHP不仅使非专业用户能够从零开始构建高质量决策模型，而且在逻辑完整性和下游任务准确性方面显著优于直接生成基线方法。

Conclusion: Doc2AHP成功弥合了LLM的泛化能力与决策理论严谨性之间的差距，通过结构化推理框架解决了传统AHP的专家瓶颈问题，为复杂决策任务提供了可扩展的解决方案。

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [2] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: SycoEval-EM框架通过多智能体模拟评估LLM在急诊医学中对抗患者说服的鲁棒性，发现模型在不当医疗请求面前存在显著妥协风险


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床决策支持中展现潜力，但面临患者施压要求不当医疗的风险，需要评估其在对抗性社会压力下的安全性

Method: 引入SycoEval-EM多智能体模拟框架，在三个"明智选择"场景下测试20个LLM模型，共1875次交互，评估模型对抗患者说服策略的鲁棒性

Result: 模型妥协率从0%到100%不等，对影像检查请求的脆弱性(38.8%)高于阿片类药物处方(25.0%)，模型能力与鲁棒性相关性弱，所有说服策略效果相当(30.0-36.0%)

Conclusion: 静态基准测试无法充分预测临床AI在社交压力下的安全性，需要多轮对抗性测试作为临床AI认证的必要环节

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [3] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: 该研究对比了传统机器学习、基于提示的LLMs/VLMs和微调PEFT模型在医学分类任务上的表现，发现传统机器学习模型在大多数任务中表现最佳，而微调模型表现最差，提示模型在图像任务上有竞争力。


<details>
  <summary>Details</summary>
Motivation: 探索多模态视觉语言模型和大语言模型在医学分类中的潜力，通过统一基准对比传统机器学习与当代基于Transformer的技术，评估不同模型在医学分类任务中的实际效果。

Method: 使用四个公开数据集（涵盖文本和图像模态，包括二元和多分类复杂度），评估三类模型：传统机器学习（LR、LightGBM、ResNet-50）、基于提示的LLMs/VLMs（Gemini 2.5）和微调PEFT模型（LoRA适配的Gemma3变体），采用一致的数据划分和评估指标。

Result: 传统机器学习模型在大多数医学分类任务中表现最佳，尤其在结构化文本数据集上表现优异；LoRA微调的Gemma变体在所有文本和图像实验中表现最差；零样本LLM/VLM管道在文本任务上表现不佳，但在多分类图像任务上与ResNet-50基线表现相当。

Conclusion: 在许多医学分类场景中，传统机器学习模型仍然是最可靠的选择；基础模型并非普遍优越，参数高效微调的效果高度依赖于适配策略，本研究中最小化微调反而有害。

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [4] [LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents](https://arxiv.org/abs/2601.16649)
*Amin Rakhsha,Thomas Hehn,Pietro Mazzaglia,Fabio Valerio Massoli,Arash Behboodi,Tribhuvanesh Orekondy*

Main category: cs.AI

TL;DR: 论文提出了一种评估多轮智能体任务中不同能力相对重要性的框架，通过设计可控环境并提供精确的oracle干预来测量规划、状态跟踪等技能对AI智能体性能的关键性影响。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在孤立任务上表现良好，但在需要规划、状态跟踪和长上下文处理的多轮、长视野智能体任务中仍然存在困难。研究旨在理解这些底层能力对于此类任务成功的相对重要性，为AI智能体和语言模型的未来发展提供指导。

Method: 开发了一个oracle反事实框架，通过程序生成的可调复杂度的游戏式任务套件，提供精确的oracle干预（如完美规划或无错误状态跟踪），在受控环境中隔离每种oracle技能的贡献，避免现实基准中的混杂效应。

Result: 结果显示，某些干预（如规划）在各种设置中持续提升性能，而其他技能的有用性则取决于环境和语言模型的特性。这揭示了多轮智能体环境中不同技能重要性的差异性。

Conclusion: 研究阐明了多轮智能体环境的挑战，为AI智能体和语言模型的未来发展提供了指导方向。通过可控环境中的精确干预，能够更好地理解不同底层能力对智能体性能的相对重要性。

Abstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.

</details>


### [5] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: 提出AgentsEval多智能体流推理框架，用于评估医学影像报告的临床正确性和推理保真度，通过模拟放射科医生协作诊断流程提供结构化评估。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像报告生成系统的评估方法无法捕捉放射学解释背后的结构化诊断逻辑，导致评估不可靠且临床相关性有限，需要更透明、临床基础的评估框架。

Method: AgentsEval多智能体流推理框架，将评估过程分解为可解释步骤：标准定义、证据提取、对齐和一致性评分，模拟放射科医生协作诊断流程，提供明确推理轨迹和结构化临床反馈。

Result: 实验结果显示AgentsEval在五个医学报告数据集上提供临床对齐、语义忠实且可解释的评估，在释义、语义和风格扰动下保持稳健，优于现有评估方法。

Conclusion: AgentsEval框架代表了向透明和临床基础的医学报告生成系统评估迈出的一步，促进大语言模型在临床实践中的可信集成。

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [6] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking-2601是一个5600亿参数的开源MoE推理模型，在多种智能体基准测试中达到SOTA性能，具备强大的工具使用泛化能力和噪声环境鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发一个具备卓越智能体推理能力的开源模型，能够处理复杂的工具交互并在嘈杂的真实世界环境中稳定工作，解决现有模型在工具使用泛化、多环境训练稳定性和噪声鲁棒性方面的不足。

Method: 采用统一的训练框架，结合领域并行专家训练与后续融合；扩展异步强化学习框架DORA以支持超过10,000个环境的稳定训练；系统分析真实世界噪声模式并设计针对性训练程序；引入Heavy Thinking模式进行测试时扩展，联合扩展推理深度和宽度。

Result: 在智能体搜索、智能体工具使用和工具集成推理等广泛基准测试中达到开源模型的最先进性能；在复杂工具交互中表现出强大的泛化能力；在嘈杂真实世界环境中展现出稳健行为。

Conclusion: LongCat-Flash-Thinking-2601通过创新的训练框架、环境扩展、噪声建模和推理增强技术，成功创建了一个具备卓越智能体推理能力的开源模型，为复杂真实世界应用提供了强大解决方案。

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [7] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 开发了一种受昆虫启发的视觉点目标导航智能体，结合了昆虫大脑中与联想学习和路径整合相关的两个结构，在Habitat点目标导航任务中表现出与SOTA模型相当的性能，但计算成本低多个数量级。


<details>
  <summary>Details</summary>
Motivation: 受到昆虫能够在发现食物位置和巢穴之间学习并优化视觉引导路径的能力启发，希望开发一种简单高效的视觉点目标导航方法。将Habitat点目标导航任务的形式基准与昆虫的这种能力进行类比，旨在创建计算成本极低但性能优越的导航智能体。

Method: 结合了昆虫大脑中两个关键结构的抽象模型：一个与联想学习相关，另一个与路径整合相关。开发了昆虫启发的智能体，将Habitat点目标导航任务形式化为类似昆虫在食物和巢穴之间导航的问题。在模拟环境中进行测试，评估其性能和鲁棒性。

Result: 简单的昆虫启发智能体在Habitat点目标导航任务中表现出与最近SOTA模型相当的性能，但计算成本低多个数量级。在更真实的模拟环境中测试表明，该方法对扰动具有鲁棒性。

Conclusion: 昆虫大脑的简单抽象模型可以产生高效的视觉点目标导航智能体，在保持高性能的同时大幅降低计算成本，展示了生物启发方法在机器人导航中的潜力。

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [8] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: 研究发现，通过强化学习验证奖励训练的推理型大语言模型在心理理论任务中表现出更强的鲁棒性，但这种改进主要源于寻找正确解决方案的鲁棒性增强，而非形成了新的心理理论推理能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型最近在心理理论测试中表现出色，引发了关于其底层能力本质和真实性能的争论。同时，通过强化学习验证奖励训练的推理型大语言模型在各种基准测试中取得了显著改进。本研究旨在探究这类推理模型在心理理论任务中的行为表现。

Method: 使用新颖的机器心理学实验改编方法和已建立基准测试的结果，分析推理型大语言模型在心理理论任务中的行为。特别关注模型对提示变化和任务扰动的鲁棒性。

Result: 推理模型在心理理论任务中一致表现出对提示变化和任务扰动更强的鲁棒性。分析表明，观察到的改进更可能归因于寻找正确解决方案的鲁棒性增强，而不是形成了根本性的新型心理理论推理能力。

Conclusion: 研究结果对评估大语言模型的社会认知行为具有重要意义。改进主要源于解决任务的鲁棒性提升，而非心理理论推理能力的根本性改变，这为理解大语言模型在心理理论任务中的表现提供了新的视角。

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [9] [MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion](https://arxiv.org/abs/2601.16886)
*Chi Yu,Hongyu Yuan,Zhiyi Duan*

Main category: cs.AI

TL;DR: MAGE-KT：多智能体图增强知识追踪框架，通过多视图异构图和子图检索解决现有图KT方法中概念关系挖掘不足和全图编码计算成本高、噪声多的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于图的知识追踪方法未能充分探索概念间关系（通常仅从交互序列推断），且KT图的规模和异质性导致全图编码计算成本高、噪声多，注意力会扩散到与学生无关的区域，降低概念间关系保真度

Method: 1) 构建多视图异构图：结合多智能体知识概念关系提取器和学生-问题交互图，捕获互补的语义和行为信号；2) 基于目标学生历史检索紧凑、高价值子图；3) 使用非对称交叉注意力融合模块集成子图，增强预测同时避免注意力扩散和不相关计算

Result: 在三个广泛使用的KT数据集上实验显示，在知识概念关系准确性方面有显著提升，并在下一问题预测方面明显优于现有方法

Conclusion: MAGE-KT框架通过多智能体关系提取、子图检索和非对称融合机制，有效解决了图增强知识追踪中的概念关系挖掘不足和计算效率问题，在关系准确性和预测性能上均取得改进

Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.

</details>


### [10] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: AI平台帮助中低收入国家医疗设备维护，通过LLM提供实时故障诊断指导，减少设备停机时间


<details>
  <summary>Details</summary>
Motivation: 中低收入国家医疗设备因缺乏及时维护、技术支持和制造商支持而利用率低，导致设备停机时间长、诊断延迟和患者护理受损

Method: 开发基于大语言模型的AI支持平台，集成用户友好的Web界面，允许技术人员输入错误代码或症状，提供逐步故障排除指导；包含全球点对点讨论论坛；使用Philips HDI 5000超声机进行概念验证

Result: 在错误代码解释方面达到100%精确度，在建议纠正措施方面达到80%准确率

Conclusion: AI驱动系统支持医疗设备维护具有可行性和潜力，可减少设备停机时间，改善资源受限环境中的医疗服务

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>
