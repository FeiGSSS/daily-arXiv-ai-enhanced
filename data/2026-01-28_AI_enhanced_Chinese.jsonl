{"id": "2601.17009", "categories": ["cs.AI", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.17009", "abs": "https://arxiv.org/abs/2601.17009", "authors": ["Yanhua Zhao"], "title": "Online parameter estimation for the Crazyflie quadcopter through an EM algorithm", "comment": "20 pages, 37 figures", "summary": "Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u968f\u673a\u566a\u58f0\u5bf9\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u4f7f\u7528\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\uff0c\u5e76\u5e94\u7528\u7ebf\u6027\u4e8c\u6b21\u9ad8\u65af\u63a7\u5236\u5668\u548c\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1\u3002", "motivation": "\u65e0\u4eba\u673a\u5728\u591a\u4e2a\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5730\u9707\u7b49\u707e\u5bb3\u4f1a\u7834\u574f\u57fa\u7840\u8bbe\u65bd\uff0c\u4f7f\u6551\u63f4\u4eba\u5458\u96be\u4ee5\u5230\u8fbe\u67d0\u4e9b\u533a\u57df\u3002\u65e0\u4eba\u673a\u53ef\u4ee5\u514b\u670d\u8fd9\u4e9b\u969c\u788d\uff0c\u4f46\u7cfb\u7edf\u6613\u53d7\u968f\u673a\u566a\u58f0\u5f71\u54cd\uff0c\u9700\u8981\u7814\u7a76\u566a\u58f0\u5bf9\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u5f71\u54cd\u5e76\u5f00\u53d1\u6709\u6548\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "1. \u5728\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u7cfb\u7edf\u4e2d\u6dfb\u52a0\u968f\u673a\u566a\u58f0\uff1b2. \u4f7f\u7528\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u57fa\u4e8e\u4f20\u611f\u5668\u566a\u58f0\u89c2\u6d4b\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\uff1b3. \u57fa\u4e8e\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7cfb\u7edf\u5b9e\u73b0\u7ebf\u6027\u4e8c\u6b21\u9ad8\u65af\u63a7\u5236\u5668\uff1b4. \u5e94\u7528\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u8fdb\u884c\u65e0\u4eba\u673a\u53c2\u6570\u4f30\u8ba1\uff1b5. \u6bd4\u8f83\u79bb\u7ebf\u53c2\u6570\u4f30\u8ba1\u548c\u5728\u7ebf\u53c2\u6570\u4f30\u8ba1\u7684\u7ed3\u679c\u3002", "result": "\u5728\u7ebf\u53c2\u6570\u4f30\u8ba1\u7684\u6536\u655b\u503c\u8303\u56f4\u7565\u5927\u4e8e\u79bb\u7ebf\u53c2\u6570\u4f30\u8ba1\u3002\u8fd9\u8868\u660e\u5728\u7ebf\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\u5728\u5e94\u5bf9\u7cfb\u7edf\u53d8\u5316\u65f6\u5177\u6709\u66f4\u597d\u7684\u9002\u5e94\u6027\uff0c\u4f46\u540c\u65f6\u4e5f\u8868\u73b0\u51fa\u66f4\u5927\u7684\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u968f\u673a\u566a\u58f0\u5bf9\u65e0\u4eba\u673a\u7cfb\u7edf\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4f46\u901a\u8fc7\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u3001\u7ebf\u6027\u4e8c\u6b21\u9ad8\u65af\u63a7\u5236\u5668\u548c\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u7684\u7ec4\u5408\u53ef\u4ee5\u6709\u6548\u5904\u7406\u566a\u58f0\u95ee\u9898\u3002\u5728\u7ebf\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\u867d\u7136\u6536\u655b\u8303\u56f4\u8f83\u5927\uff0c\u4f46\u66f4\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u573a\u666f\uff0c\u4e3a\u65e0\u4eba\u673a\u5728\u590d\u6742\u73af\u5883\u4e0b\u7684\u7a33\u5b9a\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17168", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.17168", "abs": "https://arxiv.org/abs/2601.17168", "authors": ["Judy Zhu", "Dhari Gandhi", "Himanshu Joshi", "Ahmad Rezaie Mianroodi", "Sedef Akinli Kocak", "Dhanesh Ramachandran"], "title": "Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability", "comment": null, "summary": "Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u5c40\u9650\uff0c\u63d0\u51fa\u4e86\u4e13\u95e8\u9488\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u7684\u65b0\u53ef\u89e3\u91ca\u6027\u6280\u672f\u65b9\u5411\uff0c\u4ee5\u786e\u4fdd\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u5b89\u5168\u53ef\u9760\u90e8\u7f72\u3002", "motivation": "\u667a\u80fd\u4f53\u7cfb\u7edf\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u67b6\u6784\u548c\u90e8\u7f72\u4e0a\u5b58\u5728\u6839\u672c\u5dee\u5f02\uff0c\u5f15\u5165\u4e86\u72ec\u7279\u7684\u5b89\u5168\u6311\u6218\uff08\u5982\u76ee\u6807\u9519\u4f4d\u3001\u51b3\u7b56\u9519\u8bef\u7d2f\u79ef\u3001\u591a\u667a\u80fd\u4f53\u534f\u8c03\u98ce\u9669\u7b49\uff09\uff0c\u9700\u8981\u5d4c\u5165\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u8bbe\u8ba1\uff0c\u4f46\u73b0\u6709\u4e3b\u8981\u9488\u5bf9\u9759\u6001\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\u5728\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u8bc4\u4f30\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\uff0c\u8bc6\u522b\u5176\u5728\u63d0\u4f9b\u667a\u80fd\u4f53\u51b3\u7b56\u6d1e\u5bdf\u65b9\u9762\u7684\u80fd\u529b\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e13\u95e8\u9488\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u7684\u65b0\u53ef\u89e3\u91ca\u6027\u6280\u672f\u53d1\u5c55\u65b9\u5411\u3002", "result": "\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u6280\u672f\u5728\u5e94\u7528\u4e8e\u667a\u80fd\u4f53\u7cfb\u7edf\u65f6\u8868\u73b0\u51fa\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65f6\u95f4\u52a8\u6001\u6027\u3001\u51b3\u7b56\u7d2f\u79ef\u6027\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u884c\u4e3a\uff0c\u9700\u8981\u65b0\u7684\u5206\u6790\u65b9\u6cd5\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u5728\u667a\u80fd\u4f53\u751f\u547d\u5468\u671f\u7684\u5404\u4e2a\u9636\u6bb5\uff08\u76ee\u6807\u5f62\u6210\u3001\u73af\u5883\u4ea4\u4e92\u3001\u7ed3\u679c\u8bc4\u4f30\uff09\u5d4c\u5165\u76d1\u7763\u673a\u5236\uff0c\u8fd9\u5bf9\u4e8e\u786e\u4fdd\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u5b89\u5168\u548c\u8d1f\u8d23\u4efb\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.17310", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17310", "abs": "https://arxiv.org/abs/2601.17310", "authors": ["Yu Akagi", "Tomohisa Seki", "Hiromasa Ito", "Toru Takiguchi", "Kazuhiko Ohe", "Yoshimasa Kawazoe"], "title": "High-Fidelity Longitudinal Patient Simulation Using Real-World Data", "comment": null, "summary": "Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.", "AI": {"tldr": "\u5229\u7528\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u8bb0\u5f55\u6784\u5efa\u751f\u6210\u5f0f\u6a21\u62df\u5668\uff0c\u80fd\u591f\u57fa\u4e8e\u60a3\u8005\u5386\u53f2\u751f\u6210\u9ad8\u4fdd\u771f\u7684\u672a\u6765\u4e34\u5e8a\u8f68\u8ff9", "motivation": "\u6a21\u62df\u5728\u4e34\u5e8a\u533b\u5b66\u4e2d\u5177\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u53ef\u7528\u4e8e\u4e2a\u6027\u5316\u6cbb\u7597\u89c4\u5212\u548c\u865a\u62df\u4e34\u5e8a\u8bd5\u9a8c\uff0c\u4f46\u6a21\u62df\u60a3\u8005\u8f68\u8ff9\u56e0\u590d\u6742\u7684\u751f\u7269\u548c\u793e\u4f1a\u6587\u5316\u5f71\u54cd\u800c\u5177\u6709\u6311\u6218\u6027", "method": "\u5f00\u53d1\u751f\u6210\u5f0f\u6a21\u62df\u5668\u6a21\u578b\uff0c\u4ee5\u60a3\u8005\u5386\u53f2\u4e3a\u8f93\u5165\uff0c\u5408\u6210\u7ec6\u7c92\u5ea6\u7684\u73b0\u5b9e\u672a\u6765\u8f68\u8ff9\uff1b\u5728\u8d85\u8fc72\u4ebf\u6761\u4e34\u5e8a\u8bb0\u5f55\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3", "result": "\u6a21\u578b\u751f\u6210\u9ad8\u4fdd\u771f\u672a\u6765\u65f6\u95f4\u7ebf\uff0c\u4e0e\u771f\u5b9e\u60a3\u8005\u672a\u6765\u6570\u636e\u4e2d\u7684\u4e8b\u4ef6\u53d1\u751f\u7387\u3001\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u7ed3\u679c\u548c\u65f6\u95f4\u52a8\u6001\u7d27\u5bc6\u5339\u914d\uff1b\u51c6\u786e\u4f30\u8ba1\u672a\u6765\u4e8b\u4ef6\u6982\u7387\uff0c\u89c2\u5bdf\u4e0e\u9884\u671f\u6bd4\u7387\u5728\u4e0d\u540c\u7ed3\u679c\u548c\u65f6\u95f4\u8303\u56f4\u5185\u59cb\u7ec8\u63a5\u8fd11.0", "conclusion": "\u63ed\u793a\u4e86\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u672a\u5f00\u53d1\u4ef7\u503c\uff0c\u5e76\u5f15\u5165\u4e86\u4e34\u5e8a\u62a4\u7406\u8ba1\u7b97\u673a\u6a21\u62df\u7684\u53ef\u6269\u5c55\u6846\u67b6"}}
{"id": "2601.17311", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17311", "abs": "https://arxiv.org/abs/2601.17311", "authors": ["Bang Liu", "Linglong Kong", "Jian Pei"], "title": "Phase Transition for Budgeted Multi-Agent Synergy", "comment": "55 pages, 12 figures", "summary": "Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $\u03b2$; communication is captured by a message-length fidelity curve $\u03b3(m)$; dependence is captured by an effective shared-error correlation $\u03c1$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $\u03b1_\u03c1$ (combining $\u03b3(m)$, $\u03c1$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>\u03b2$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6700\u5c0f\u5316\u53ef\u6821\u51c6\u7406\u8bba\uff0c\u7528\u4e8e\u9884\u6d4b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u56fa\u5b9a\u63a8\u7406\u9884\u7b97\u4e0b\u7684\u4e09\u79cd\u884c\u4e3a\u6a21\u5f0f\uff1a\u63d0\u5347\u3001\u9971\u548c\u548c\u5d29\u6e83\uff0c\u8be5\u7406\u8bba\u57fa\u4e8e\u4e09\u4e2a\u5173\u952e\u7ea6\u675f\uff1a\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u3001\u6709\u635f\u901a\u4fe1\u548c\u76f8\u4f3c\u667a\u80fd\u4f53\u95f4\u7684\u5171\u4eab\u6545\u969c\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7406\u8bba\u4e0a\u80fd\u63d0\u9ad8\u53ef\u9760\u6027\uff0c\u4f46\u5728\u56fa\u5b9a\u63a8\u7406\u9884\u7b97\u4e0b\uff0c\u5b83\u4eec\u5e38\u5e38\u53ea\u80fd\u63d0\u4f9b\u6709\u9650\u5e2e\u52a9\u3001\u8fbe\u5230\u9971\u548c\u751a\u81f3\u5d29\u6e83\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u89e3\u91ca\u8fd9\u4e9b\u73b0\u8c61\uff0c\u7279\u522b\u662f\u8003\u8651\u5230\u73b0\u4ee3\u667a\u80fd\u4f53\u5806\u6808\u7684\u4e09\u4e2a\u5173\u952e\u7ea6\u675f\uff1a\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u3001\u6709\u635f\u7684\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\uff0c\u4ee5\u53ca\u76f8\u4f3c\u667a\u80fd\u4f53\u95f4\u7684\u5171\u4eab\u6545\u969c\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6700\u5c0f\u5316\u53ef\u6821\u51c6\u7406\u8bba\uff0c\u5c06\u6bcf\u4e2a\u53f6\u667a\u80fd\u4f53\u7528\u8ba1\u7b97-\u6027\u80fd\u7f29\u653e\u6307\u6570\u03b2\u8868\u793a\uff0c\u901a\u4fe1\u7528\u6d88\u606f\u957f\u5ea6\u4fdd\u771f\u5ea6\u66f2\u7ebf\u03b3(m)\u8868\u793a\uff0c\u76f8\u5173\u6027\u7528\u6709\u6548\u5171\u4eab\u8bef\u5dee\u76f8\u5173\u6027\u03c1\u8868\u793a\uff0c\u4e0a\u4e0b\u6587\u7a97\u53e3W\u65bd\u52a0\u4e86\u786c\u6027\u6247\u5165\u9650\u5236\u3002\u5bf9\u4e8e\u5177\u6709\u591a\u6570\u805a\u5408\u7684\u4e8c\u5143\u6210\u529f/\u5931\u8d25\u4efb\u52a1\uff0c\u8bc1\u660e\u4e86\u6df1\u5ea6b\u53c9\u6811\u5728\u76f8\u5173\u8f93\u5165\u548c\u6709\u635f\u901a\u4fe1\u4e0b\u7684\u5c16\u9510\u76f8\u53d8\uff0c\u5355\u4e2a\u6807\u91cf\u03b1\u03c1\uff08\u7ed3\u5408\u03b3(m)\u3001\u03c1\u548c\u6247\u5165b\uff09\u51b3\u5b9a\u4e86\u5f31\u4fe1\u53f7\u662f\u88ab\u653e\u5927\u5230\u975e\u5e73\u51e1\u56fa\u5b9a\u70b9\u8fd8\u662f\u88ab\u6d17\u724c\u4e3a\u968f\u673a\u7ed3\u679c\u3002", "result": "\u7406\u8bba\u63a8\u5bfc\u51fa\u7ec4\u7ec7\u6307\u6570s\uff0c\u5e76\u8bc1\u660e\u5f53s>\u03b2\u65f6\u4f1a\u51fa\u73b0\u9884\u7b97\u534f\u540c\u6548\u5e94\uff08\u5373\u76f8\u540c\u603b\u9884\u7b97\u4e0b\u4f18\u4e8e\u6700\u4f73\u5355\u4e2a\u667a\u80fd\u4f53\uff09\uff0c\u7ed9\u51fa\u4e86\u5c01\u95ed\u5f62\u5f0f\u7684\u8ba1\u7b97\u5206\u914d\u89c4\u5219\u548c\u660e\u786e\u7684\u9884\u7b97\u9608\u503c\u3002\u8fdb\u4e00\u6b65\u901a\u8fc7\u6df7\u5408\u6df1\u5ea6\u8868\u5f81\u9971\u548c\u73b0\u8c61\uff0c\u63d0\u4f9b\u4e86\u5728\u589e\u957f\u548c\u9971\u548c\u9636\u6bb5\u90fd\u4fdd\u6301\u51c6\u786e\u7684\u4fdd\u5b88\u88c1\u526a\u9884\u6d4b\u5668\u3002\u8fde\u7eed\u6027\u80fd\u9884\u70ed\u7ed9\u51fa\u4e86\u661f\u5f62\u3001\u94fe\u5f0f\u548c\u6811\u5f62\u7ec4\u7ec7\u7684\u5c01\u95ed\u5f62\u5f0f\u98ce\u9669\uff0c\u4f7f\u76f8\u5173\u6027\u548c\u901a\u4fe1\u5f15\u8d77\u7684\u5730\u677f\u6548\u5e94\u53d8\u5f97\u660e\u786e\u3002", "conclusion": "\u8be5\u7406\u8bba\u6846\u67b6\u6210\u529f\u9884\u6d4b\u4e86\u53d7\u63a7\u5408\u6210\u6a21\u62df\u4e2d\u7684\u76f8\u53d8\u8fb9\u754c\uff0c\u5e76\u89e3\u91ca\u4e86\u6700\u8fd1\u5927\u89c4\u6a21\u5339\u914d\u9884\u7b97\u7814\u7a76\u4e2d\u62a5\u544a\u7684LLM\u667a\u80fd\u4f53\u7cfb\u7edf\u7f29\u653e\u7684\u4e3b\u8981\u74f6\u9888\u3002\u8be5\u7406\u8bba\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6838\u5fc3\u6743\u8861\u7684\u660e\u786e\u5206\u6790\uff0c\u5e2e\u52a9\u7406\u89e3\u5728\u6709\u9650\u9884\u7b97\u4e0b\u5982\u4f55\u4f18\u5316\u667a\u80fd\u4f53\u7ec4\u7ec7\u7ed3\u6784\u548c\u901a\u4fe1\u7b56\u7565\u3002"}}
{"id": "2601.17332", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17332", "abs": "https://arxiv.org/abs/2601.17332", "authors": ["Yicheng Tao", "Hongteng Xu"], "title": "TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow", "comment": null, "summary": "The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \\textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \\textit{statement formalization}, \\textit{proof generation}, \\textit{premise selection}, \\textit{proof correction} and \\textit{proof sketching}. By implementing a \\textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\\%, surpassing the 8.6\\% baseline, at an average cost of only \\textbf{\\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \\textbf{1.6$\\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \\href{https://github.com/timechess/TheoremForge}{here}.", "AI": {"tldr": "TheoremForge\u662f\u4e00\u4e2a\u4f4e\u6210\u672c\u7684\u5f62\u5f0f\u5316\u6570\u5b66\u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u901a\u8fc7\u5206\u89e3\u5f62\u5f0f\u5316\u8fc7\u7a0b\u4e3a\u4e94\u4e2a\u5b50\u4efb\u52a1\u5e76\u91c7\u7528\u89e3\u8026\u63d0\u53d6\u7b56\u7565\uff0c\u6709\u6548\u5229\u7528\u5931\u8d25\u8f68\u8ff9\u4e2d\u7684\u8bad\u7ec3\u4fe1\u53f7\uff0c\u663e\u8457\u964d\u4f4e\u6570\u636e\u5408\u6210\u6210\u672c\u3002", "motivation": "\u5f62\u5f0f\u5316\u6570\u5b66\u4e2d\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u9ad8\u6210\u672c\u963b\u788d\u4e86\u5927\u89c4\u6a21\u6570\u636e\u5408\u6210\uff0c\u52a0\u5267\u4e86\u5f00\u6e90\u8bed\u6599\u5e93\u7684\u7a00\u7f3a\u6027\u95ee\u9898\u3002\u9700\u8981\u5f00\u53d1\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u6765\u6784\u5efa\u8bad\u7ec3\u672a\u6765\u4e13\u5bb6\u6a21\u578b\u6240\u9700\u7684\u6570\u636e\u98de\u8f6e\u3002", "method": "\u5c06\u5f62\u5f0f\u5316\u8fc7\u7a0b\u5206\u89e3\u4e3a\u4e94\u4e2a\u5b50\u4efb\u52a1\uff1a\u9648\u8ff0\u5f62\u5f0f\u5316\u3001\u8bc1\u660e\u751f\u6210\u3001\u524d\u63d0\u9009\u62e9\u3001\u8bc1\u660e\u4fee\u6b63\u548c\u8bc1\u660e\u8349\u56fe\u3002\u91c7\u7528\u89e3\u8026\u63d0\u53d6\u7b56\u7565\uff0c\u4ece\u5168\u5c40\u5931\u8d25\u7684\u8f68\u8ff9\u4e2d\u6062\u590d\u6709\u6548\u7684\u8bad\u7ec3\u4fe1\u53f7\uff0c\u5145\u5206\u5229\u7528\u6d6a\u8d39\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u57282000\u4e2a\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTheoremForge\u5b9e\u73b0\u4e8612.6%\u7684\u9a8c\u8bc1\u7387\uff0c\u8d85\u8fc78.6%\u7684\u57fa\u7ebf\uff0c\u6bcf\u4e2a\u6210\u529f\u8f68\u8ff9\u7684\u5e73\u5747\u6210\u672c\u4ec5\u4e3a0.481\u7f8e\u5143\uff08\u4f7f\u7528Gemini-3-Flash\uff09\u3002\u89e3\u8026\u7b56\u7565\u4f7f\u8bc1\u660e\u751f\u6210\u7684\u6570\u636e\u4ea7\u91cf\u76f8\u6bd4\u6807\u51c6\u8fc7\u6ee4\u63d0\u9ad8\u4e861.6\u500d\u3002", "conclusion": "TheoremForge\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u6784\u5efa\u6570\u636e\u98de\u8f6e\u6765\u8bad\u7ec3\u672a\u6765\u7684\u4e13\u5bb6\u6a21\u578b\uff0c\u4e3a\u89e3\u51b3\u5f62\u5f0f\u5316\u6570\u5b66\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u63d0\u4f9b\u4e86\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17335", "abs": "https://arxiv.org/abs/2601.17335", "authors": ["Angshul Majumdar"], "title": "The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability", "comment": null, "summary": "We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and G\u00f6del--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc1\u660eAGI\uff08\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff09\u65e0\u6cd5\u83b7\u5f97\u72ec\u7acb\u4e8e\u4efb\u52a1\u5206\u5e03\u7684\u7edf\u4e00\u5b9a\u4e49\uff0c\u7f3a\u4e4f\u666e\u904d\u9c81\u68d2\u6027\uff0c\u5b58\u5728\u6709\u9650\u8fc1\u79fb\u80fd\u529b\uff0c\u4e14\u65e0\u6cd5\u901a\u8fc7\u53ef\u8ba1\u7b97\u7a0b\u5e8f\uff08\u5305\u62ec\u81ea\u6211\u9a8c\u8bc1\uff09\u8fdb\u884c\u5b8c\u5907\u8ba4\u8bc1\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u8ba8AGI\u662f\u5426\u5177\u6709\u652f\u6301\u5b58\u5728\u6027\u3001\u9c81\u68d2\u6027\u6216\u81ea\u6211\u9a8c\u8bc1\u7edd\u5bf9\u4e3b\u5f20\u7684\u8fde\u8d2f\u7406\u8bba\u5b9a\u4e49\u3002\u5f53\u524d\u5bf9AGI\u7684\u8ba8\u8bba\u5e38\u57fa\u4e8e\u6a21\u7cca\u6982\u5ff5\uff0c\u7f3a\u4e4f\u4e25\u683c\u7684\u6570\u5b66\u6846\u67b6\u6765\u8bc4\u4f30\u5176\u7406\u8bba\u53ef\u80fd\u6027\u3002", "method": "\u91c7\u7528\u516c\u7406\u5316\u65b9\u6cd5\uff0c\u5c06AGI\u5f62\u5f0f\u5316\u4e3a\u4e00\u4e2a\u5206\u5e03\u6027\u3001\u8d44\u6e90\u53d7\u9650\u7684\u8bed\u4e49\u8c13\u8bcd\uff0c\u7d22\u5f15\u5305\u62ec\u4efb\u52a1\u65cf\u3001\u4efb\u52a1\u5206\u5e03\u3001\u6027\u80fd\u51fd\u6570\u548c\u663e\u5f0f\u8d44\u6e90\u9884\u7b97\u3002\u5728\u6b64\u6846\u67b6\u4e0b\uff0c\u8fd0\u7528\u6570\u5b66\u8bc1\u660e\u65b9\u6cd5\uff08\u5305\u62ecRice\u98ce\u683c\u548c\u54e5\u5fb7\u5c14-\u5854\u65af\u57fa\u8bba\u8bc1\uff09\u63a8\u5bfc\u7406\u8bba\u7ed3\u679c\u3002", "result": "1. \u901a\u7528\u6027\u662f\u5173\u7cfb\u6027\u7684\uff0c\u4e0d\u5b58\u5728\u72ec\u7acb\u4e8e\u5206\u5e03\u7684\u7edf\u4e00AGI\u6982\u5ff5\uff1b2. \u4efb\u52a1\u5206\u5e03\u7684\u5fae\u5c0f\u6270\u52a8\u53ef\u901a\u8fc7\"\u60ac\u5d16\u96c6\"\u4f7fAGI\u5c5e\u6027\u5931\u6548\uff0c\u6392\u9664\u666e\u904d\u9c81\u68d2\u6027\uff1b3. \u6709\u9650\u8d44\u6e90\u4e0b\u65e0\u6cd5\u5b9e\u73b0\u8de8\u4efb\u52a1\u65cf\u7684\u65e0\u754c\u6cdb\u5316\uff1b4. AGI\u4f5c\u4e3a\u975e\u5e73\u51e1\u8bed\u4e49\u5c5e\u6027\uff0c\u65e0\u6cd5\u901a\u8fc7\u4efb\u4f55\u53ef\u8ba1\u7b97\u7a0b\u5e8f\uff08\u5305\u62ec\u81ea\u6211\u9a8c\u8bc1\uff09\u8fdb\u884c\u5b8c\u5907\u8ba4\u8bc1\u3002", "conclusion": "\u5f3a\u5206\u5e03\u72ec\u7acb\u7684AGI\u4e3b\u5f20\u5728\u6ca1\u6709\u663e\u5f0f\u5f62\u5f0f\u5316\u7d22\u5f15\u7684\u60c5\u51b5\u4e0b\u662f\u672a\u5b9a\u4e49\u7684\uff0cAI\u7684\u5b9e\u8bc1\u8fdb\u5c55\u5e76\u4e0d\u6697\u793a\u81ea\u6211\u8ba4\u8bc1\u901a\u7528\u667a\u80fd\u7684\u53ef\u5b9e\u73b0\u6027\uff0c\u4f9d\u8d56\u5185\u90e8\u81ea\u6211\u8ba4\u8bc1\u7684\u9012\u5f52\u81ea\u6211\u6539\u8fdb\u65b9\u6848\u5b58\u5728\u6839\u672c\u7f3a\u9677\u3002"}}
{"id": "2601.17343", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17343", "abs": "https://arxiv.org/abs/2601.17343", "authors": ["Wei Liu", "Haomei Xu", "Hongkai Liu", "Zhiying Deng", "Ruixuan Li", "Heng Huang", "Yee Whye Teh", "Wee Sun Lee"], "title": "Are We Evaluating the Edit Locality of LLM Model Editing Properly?", "comment": null, "summary": "Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.", "AI": {"tldr": "\u73b0\u6709\u6a21\u578b\u7f16\u8f91\u7279\u5f02\u6027\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898", "motivation": "\u6a21\u578b\u7f16\u8f91\u9700\u8981\u5e73\u8861\u7f16\u8f91\u6548\u679c\u548c\u7279\u5f02\u6027\uff08\u4fdd\u7559\u975e\u76ee\u6807\u77e5\u8bc6\uff09\uff0c\u4f46\u73b0\u6709\u7279\u5f02\u6027\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u6027\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u4e0d\u540c\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02", "method": "\u63d0\u51fa\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u6d88\u9664\u5f00\u653eLLM\u4e0e\u786e\u5b9a\u6027\u7b54\u6848\u5047\u8bbe\u7684\u51b2\u7a81\uff0c\u907f\u514d\u67e5\u8be2\u65e0\u5173\u7684\u6d41\u7545\u6027\u504f\u5dee\uff0c\u5e76\u80fd\u5728\u63a5\u8fd1\u8fde\u7eed\u7684\u7a7a\u95f4\u4e2d\u5e73\u6ed1\u8c03\u6574\u8bc4\u4f30\u4e25\u683c\u5ea6", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u534f\u8bae\u751f\u6210\u7684\u6307\u6807\u5bf9\u7279\u5f02\u6027\u6b63\u5219\u5316\u5f3a\u5ea6\u7684\u53d8\u5316\u66f4\u654f\u611f\uff0c\u4e0e\u6b63\u5219\u5316\u5f3a\u5ea6\u5f3a\u76f8\u5173\uff0c\u80fd\u66f4\u7cbe\u7ec6\u5730\u533a\u5206\u4e0d\u540c\u65b9\u6cd5\u7684\u77e5\u8bc6\u4fdd\u7559\u80fd\u529b", "conclusion": "\u73b0\u6709\u7279\u5f02\u6027\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u6982\u5ff5\u548c\u5b9e\u8bc1\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u65b0\u8bc4\u4f30\u534f\u8bae\u80fd\u66f4\u51c6\u786e\u3001\u654f\u611f\u5730\u8bc4\u4f30\u6a21\u578b\u7f16\u8f91\u7684\u7279\u5f02\u6027\u6027\u80fd"}}
{"id": "2601.17346", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17346", "abs": "https://arxiv.org/abs/2601.17346", "authors": ["Haoxin Xu", "Changyong Qi", "Tong Liu", "Bohao Zhang", "Anna He", "Bingqian Jiang", "Longwei Zheng", "Xiaoqing Gu"], "title": "Multi-Agent Learning Path Planning via LLMs", "comment": null, "summary": "The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684MALPP\u6846\u67b6\uff0c\u5229\u7528LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u4e3a\u9ad8\u7b49\u6559\u80b2\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u8def\u5f84\u89c4\u5212\u3002", "motivation": "\u5f53\u524d\u667a\u80fd\u5bfc\u5b66\u7cfb\u7edf\u4e2d\u7684\u5b66\u4e60\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u7f3a\u4e4f\u900f\u660e\u5ea6\u3001\u9002\u5e94\u6027\u548c\u4ee5\u5b66\u4e60\u8005\u4e3a\u4e2d\u5fc3\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u4ee5\u5145\u5206\u53d1\u6325LLM\u5728\u6559\u80b2\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faMALPP\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u57fa\u4e8e\u89d2\u8272\u548c\u89c4\u5219\u7684LLM\u667a\u80fd\u4f53\uff1a\u5b66\u4e60\u8005\u5206\u6790\u667a\u80fd\u4f53\u3001\u8def\u5f84\u89c4\u5212\u667a\u80fd\u4f53\u548c\u53cd\u601d\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u548c\u9884\u5b9a\u4e49\u89c4\u5219\u534f\u4f5c\u5206\u6790\u5b66\u4e60\u6863\u6848\u3001\u751f\u6210\u5b9a\u5236\u5b66\u4e60\u8def\u5f84\u5e76\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728MOOCCubeX\u6570\u636e\u96c6\u4e0a\u4f7f\u75287\u79cdLLM\u8fdb\u884c\u5b9e\u9a8c\uff0cMALPP\u5728\u8def\u5f84\u8d28\u91cf\u3001\u77e5\u8bc6\u5e8f\u5217\u4e00\u81f4\u6027\u548c\u8ba4\u77e5\u8d1f\u8377\u5bf9\u9f50\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u534f\u4f5c\u673a\u5236\u548c\u7406\u8bba\u7ea6\u675f\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u53ef\u4fe1\u3001\u53ef\u89e3\u91ca\u7684\u6559\u80b2AI\u53d1\u5c55\u505a\u51fa\u8d21\u732e\uff0c\u5c55\u793a\u4e86\u57fa\u4e8eLLM\u7684\u4ee5\u5b66\u4e60\u8005\u4e3a\u4e2d\u5fc3\u7684\u81ea\u9002\u5e94\u6559\u5b66\u7684\u53ef\u6269\u5c55\u65b9\u6cd5\u3002"}}
{"id": "2601.17348", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17348", "abs": "https://arxiv.org/abs/2601.17348", "authors": ["Srikant Panda", "Sourabh Singh Yadav", "Palkesh Malviya"], "title": "Auditing Disability Representation in Vision-Language Models", "comment": null, "summary": "Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.", "AI": {"tldr": "\u7814\u7a76\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6b8b\u75be\u4eba\u63cf\u8ff0\u4e2d\u7684\u89e3\u91ca\u504f\u79fb\u95ee\u9898\uff0c\u53d1\u73b0\u5f15\u5165\u6b8b\u75be\u4e0a\u4e0b\u6587\u4f1a\u964d\u4f4e\u89e3\u91ca\u4fdd\u771f\u5ea6\uff0c\u5bfc\u81f4\u63a8\u6d4b\u6027\u63a8\u65ad\u3001\u53d9\u4e8b\u9610\u8ff0\u3001\u60c5\u611f\u964d\u7ea7\u548c\u7f3a\u9677\u5bfc\u5411\u6846\u67b6\u7b49\u95ee\u9898\uff0c\u8fd9\u4e9b\u6548\u5e94\u5728\u79cd\u65cf\u548c\u6027\u522b\u7ef4\u5ea6\u4e0a\u8fdb\u4e00\u6b65\u653e\u5927\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u793e\u4f1a\u654f\u611f\u9886\u57df\uff0c\u4f46\u5176\u5728\u6b8b\u75be\u65b9\u9762\u7684\u884c\u4e3a\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u6a21\u578b\u7ecf\u5e38\u4ece\u57fa\u4e8e\u8bc1\u636e\u7684\u4e8b\u5b9e\u63cf\u8ff0\u8f6c\u5411\u89e3\u91ca\u504f\u79fb\uff0c\u5f15\u5165\u8d85\u51fa\u53ef\u89c2\u5bdf\u89c6\u89c9\u8bc1\u636e\u7684\u4e0d\u652f\u6301\u63a8\u65ad\u3002", "method": "\u57fa\u4e8e\u4e2d\u6027\u63d0\u793a(NP)\u548c\u6b8b\u75be\u60c5\u5883\u5316\u63d0\u793a(DP)\u7684\u914d\u5bf9\u57fa\u51c6\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8bc4\u4f3015\u4e2a\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u548c\u95ed\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u6db5\u76d69\u4e2a\u6b8b\u75be\u7c7b\u522b\u3002\u8bc4\u4f30\u6846\u67b6\u5c06\u89e3\u91ca\u4fdd\u771f\u5ea6\u4f5c\u4e3a\u6838\u5fc3\u76ee\u6807\uff0c\u7ed3\u5408\u6807\u51c6\u6587\u672c\u6307\u6807\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u534f\u8bae\uff0c\u7531\u6709\u6b8b\u75be\u751f\u6d3b\u7ecf\u9a8c\u7684\u6807\u6ce8\u8005\u9a8c\u8bc1\u3002", "result": "\u5f15\u5165\u6b8b\u75be\u4e0a\u4e0b\u6587\u4f1a\u6301\u7eed\u964d\u4f4e\u89e3\u91ca\u4fdd\u771f\u5ea6\uff0c\u5bfc\u81f4\u89e3\u91ca\u504f\u79fb\uff0c\u8868\u73b0\u4e3a\u63a8\u6d4b\u6027\u63a8\u65ad\u3001\u53d9\u4e8b\u9610\u8ff0\u3001\u60c5\u611f\u964d\u7ea7\u548c\u7f3a\u9677\u5bfc\u5411\u6846\u67b6\u3002\u8fd9\u4e9b\u6548\u5e94\u5728\u79cd\u65cf\u548c\u6027\u522b\u7ef4\u5ea6\u4e0a\u8fdb\u4e00\u6b65\u653e\u5927\u3002", "conclusion": "\u6709\u9488\u5bf9\u6027\u7684\u63d0\u793a\u548c\u504f\u597d\u5fae\u8c03\u80fd\u6709\u6548\u63d0\u9ad8\u89e3\u91ca\u4fdd\u771f\u5ea6\uff0c\u5e76\u5927\u5e45\u51cf\u5c11\u89e3\u91ca\u504f\u79fb\u3002"}}
{"id": "2601.17426", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.17426", "abs": "https://arxiv.org/abs/2601.17426", "authors": ["Zhengqing Zang", "Yuqi Ding", "Yanmei Gu", "Changkai Song", "Zhengkai Yang", "Guoping Du", "Junbo Zhao", "Haobo Wang"], "title": "A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models", "comment": null, "summary": "Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u50cf\u4eba\u7c7b\u903b\u8f91\u4e00\u6837\u4ece\u76f4\u89c9\u63a8\u7406\u8f6c\u5411\u5f62\u5f0f\u7cfb\u7edf\uff0c\u4f7f\u7528\u5b58\u5728\u5bfc\u5165\u4f5c\u4e3a\u63a2\u9488\u8bc4\u4f30\u4e09\u6bb5\u8bba\u63a8\u7406\uff0c\u53d1\u73b0\u6a21\u578b\u89c4\u6a21\u3001\u601d\u7ef4\u94fe\u548c\u57fa\u7840\u6a21\u578b\u662f\u5f71\u54cd\u8fd9\u79cd\u8f6c\u53d8\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u53d7\u4eba\u7c7b\u903b\u8f91\u4ece\u76f4\u89c9\u63a8\u7406\u5411\u4e25\u683c\u5f62\u5f0f\u7cfb\u7edf\u6f14\u53d8\u7684\u542f\u53d1\uff0c\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u8868\u73b0\u51fa\u7c7b\u4f3c\u7684\u903b\u8f91\u6846\u67b6\u6f14\u53d8\u3002\u5229\u7528\u5b58\u5728\u5bfc\u5165\u4f5c\u4e3a\u63a2\u9488\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u4f20\u7edf\u903b\u8f91\u548c\u73b0\u4ee3\u903b\u8f91\u4e0b\u7684\u4e09\u6bb5\u8bba\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5b58\u5728\u5bfc\u5165\u4f5c\u4e3a\u63a2\u9488\u8bc4\u4f30\u4e09\u6bb5\u8bba\u63a8\u7406\uff0c\u5728\u65b0\u5efa\u7684\u4e09\u6bb5\u8bba\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5SOTA\u5927\u8bed\u8a00\u6a21\u578b\u3002\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u5206\u6790\u6a21\u578b\u89c4\u6a21\u7f29\u653e\u3001\u601d\u7ef4\u94fe\u63a8\u7406\u548c\u57fa\u7840\u6a21\u578b\u5bf9\u903b\u8f91\u6846\u67b6\u8f6c\u53d8\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u7ed3\u679c\uff1a(1) \u6a21\u578b\u89c4\u6a21\u7f29\u653e\u4fc3\u8fdb\u5411\u73b0\u4ee3\u903b\u8f91\u7684\u8f6c\u53d8\uff1b(2) \u601d\u7ef4\u94fe\u63a8\u7406\u662f\u8d85\u8d8a\u53c2\u6570\u7f29\u653e\u7684\u9ad8\u6548\u52a0\u901f\u5668\uff1b(3) \u57fa\u7840\u6a21\u578b\u51b3\u5b9a\u8fd9\u79cd\u8f6c\u53d8\u7684\u5bb9\u6613\u7a0b\u5ea6\u548c\u7a33\u5b9a\u6027\u3002\u6b64\u5916\u8fd8\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\u5f53\u524dLLM\u5728\u4e09\u6bb5\u8bba\u63a8\u7406\u4e0a\u7684\u7279\u6027\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u786e\u5b9e\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u903b\u8f91\u7684\u6f14\u53d8\u6a21\u5f0f\uff0c\u6a21\u578b\u89c4\u6a21\u3001\u601d\u7ef4\u94fe\u63a8\u7406\u548c\u57fa\u7840\u6a21\u578b\u662f\u5f71\u54cd\u903b\u8f91\u6846\u67b6\u8f6c\u53d8\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e3a\u7406\u89e3LLM\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2601.17481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17481", "abs": "https://arxiv.org/abs/2601.17481", "authors": ["Emily Broadhurst", "Tawab Safi", "Joseph Edell", "Vashisht Ganesh", "Karime Maamari"], "title": "Lattice: Generative Guardrails for Conversational Agents", "comment": null, "summary": "Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.", "AI": {"tldr": "Lattice\u662f\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u548c\u6301\u7eed\u6539\u8fdb\u5bf9\u8bddAI\u62a4\u680f\u7684\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u5b9e\u73b0\uff1a\u521d\u59cb\u6784\u5efa\u548c\u6301\u7eed\u4f18\u5316\uff0c\u5728ProsocialDialog\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5bf9\u8bddAI\u62a4\u680f\u7cfb\u7edf\u4f7f\u7528\u9759\u6001\u89c4\u5219\uff0c\u65e0\u6cd5\u9002\u5e94\u65b0\u5a01\u80c1\u6216\u90e8\u7f72\u73af\u5883\u7684\u53d8\u5316\uff0c\u9700\u8981\u80fd\u591f\u81ea\u6211\u6784\u5efa\u548c\u6301\u7eed\u6539\u8fdb\u7684\u81ea\u9002\u5e94\u62a4\u680f\u6846\u67b6\u3002", "method": "Lattice\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u6784\u5efa\u9636\u6bb5\u901a\u8fc7\u8fed\u4ee3\u6a21\u62df\u548c\u4f18\u5316\u4ece\u6807\u6ce8\u793a\u4f8b\u6784\u5efa\u521d\u59cb\u62a4\u680f\uff1b2) \u6301\u7eed\u6539\u8fdb\u9636\u6bb5\u901a\u8fc7\u98ce\u9669\u8bc4\u4f30\u3001\u5bf9\u6297\u6d4b\u8bd5\u548c\u6574\u5408\u81ea\u4e3b\u9002\u5e94\u5df2\u90e8\u7f72\u7684\u62a4\u680f\u3002", "result": "\u5728ProsocialDialog\u6570\u636e\u96c6\u4e0a\uff0cLattice\u5728\u4fdd\u7559\u6570\u636e\u4e0a\u8fbe\u523091% F1\u5206\u6570\uff0c\u6bd4\u5173\u952e\u8bcd\u57fa\u7ebf\u9ad843\u4e2a\u767e\u5206\u70b9\uff0c\u6bd4LlamaGuard\u9ad825\u4e2a\u767e\u5206\u70b9\uff0c\u6bd4NeMo\u9ad84\u4e2a\u767e\u5206\u70b9\u3002\u6301\u7eed\u6539\u8fdb\u9636\u6bb5\u901a\u8fc7\u95ed\u73af\u4f18\u5316\u5728\u8de8\u57df\u6570\u636e\u4e0a\u5b9e\u73b0\u4e867\u4e2a\u767e\u5206\u70b9\u7684F1\u63d0\u5347\u3002", "conclusion": "Lattice\u6846\u67b6\u8868\u660e\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u53ef\u4ee5\u81ea\u6211\u6784\u5efa\u6709\u6548\u7684\u62a4\u680f\uff0c\u4e3a\u5bf9\u8bddAI\u7cfb\u7edf\u63d0\u4f9b\u81ea\u9002\u5e94\u5b89\u5168\u9632\u62a4\u80fd\u529b\u3002"}}
{"id": "2601.17542", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.17542", "abs": "https://arxiv.org/abs/2601.17542", "authors": ["Vinoth Punniyamoorthy", "Nitin Saksena", "Srivenkateswara Reddy Sankiti", "Nachiappan Chockalingam", "Aswathnarayan Muthukrishnan Kirubakaran", "Shiva Kumar Reddy Carimireddy", "Durgaraman Maruthavanan"], "title": "Cognitive Platform Engineering for Autonomous Cloud Operations", "comment": null, "summary": "Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u8ba4\u77e5\u5e73\u53f0\u5de5\u7a0b\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u56db\u5c42\u53c2\u8003\u67b6\u6784\u6574\u5408\u6570\u636e\u6536\u96c6\u3001\u667a\u80fd\u63a8\u7406\u3001\u7b56\u7565\u9a71\u52a8\u7f16\u6392\u548c\u4eba\u5de5\u4ea4\u4e92\uff0c\u5b9e\u73b0\u4e91\u539f\u751f\u7cfb\u7edf\u7684\u81ea\u4e3b\u8fd0\u7ef4\u548c\u81ea\u8c03\u6574\u80fd\u529b\u3002", "motivation": "\u4f20\u7edfDevOps\u81ea\u52a8\u5316\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u4e91\u539f\u751f\u7cfb\u7edf\u7684\u89c4\u6a21\u548c\u52a8\u6001\u6027\uff0c\u5bfc\u81f4\u8fd0\u7ef4\u53cd\u5e94\u6ede\u540e\u3001\u4fee\u590d\u5ef6\u8fdf\u548c\u8fc7\u5ea6\u4f9d\u8d56\u4eba\u5de5\u7ecf\u9a8c\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u5e73\u53f0\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u8ba4\u77e5\u5e73\u53f0\u5de5\u7a0b\u8303\u5f0f\uff0c\u8bbe\u8ba1\u56db\u5c42\u53c2\u8003\u67b6\u6784\uff1a\u6570\u636e\u6536\u96c6\u5c42\u3001\u667a\u80fd\u63a8\u7406\u5c42\u3001\u7b56\u7565\u9a71\u52a8\u7f16\u6392\u5c42\u548c\u4eba\u5de5\u4f53\u9a8c\u5c42\uff0c\u6784\u5efa\u6301\u7eed\u53cd\u9988\u5faa\u73af\u3002\u539f\u578b\u57fa\u4e8eKubernetes\u3001Terraform\u3001Open Policy Agent\u548cML\u5f02\u5e38\u68c0\u6d4b\u5b9e\u73b0\u3002", "result": "\u539f\u578b\u5b9e\u73b0\u663e\u793a\u5728\u5e73\u5747\u89e3\u51b3\u65f6\u95f4\u3001\u8d44\u6e90\u6548\u7387\u548c\u5408\u89c4\u6027\u65b9\u9762\u5747\u6709\u6539\u5584\uff0c\u8bc1\u660e\u5c06\u667a\u80fd\u5d4c\u5165\u5e73\u53f0\u8fd0\u7ef4\u80fd\u591f\u521b\u5efa\u5f39\u6027\u3001\u81ea\u8c03\u6574\u4e14\u610f\u56fe\u5bf9\u9f50\u7684\u4e91\u73af\u5883\u3002", "conclusion": "\u8ba4\u77e5\u5e73\u53f0\u5de5\u7a0b\u4f7f\u4e91\u73af\u5883\u5177\u5907\u5f39\u6027\u3001\u81ea\u8c03\u6574\u548c\u610f\u56fe\u5bf9\u9f50\u80fd\u529b\uff0c\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u5f3a\u5316\u5b66\u4e60\u3001\u53ef\u89e3\u91ca\u6cbb\u7406\u548c\u53ef\u6301\u7eed\u81ea\u7ba1\u7406\u4e91\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2601.17564", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17564", "abs": "https://arxiv.org/abs/2601.17564", "authors": ["Aadam", "Monu Verma", "Mohamed Abdel-Mottaleb"], "title": "JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research", "comment": null, "summary": "The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.", "AI": {"tldr": "JaxARC\u662f\u4e00\u4e2a\u57fa\u4e8eJAX\u5b9e\u73b0\u7684\u9ad8\u6027\u80fd\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u7528\u4e8eARC\u63a8\u7406\u4efb\u52a1\uff0c\u76f8\u6bd4Gymnasium\u5b9e\u73b0\u4e8638-5439\u500d\u7684\u52a0\u901f\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5e76\u884c\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709\u7684Gymnasium-based RL\u73af\u5883\u5728ARC\u4efb\u52a1\u4e0a\u5b58\u5728\u8ba1\u7b97\u74f6\u9888\uff0c\u9650\u5236\u4e86\u5b9e\u9a8c\u89c4\u6a21\uff0c\u9700\u8981\u9ad8\u6027\u80fd\u73af\u5883\u6765\u652f\u6301\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u3002", "method": "\u91c7\u7528JAX\u5b9e\u73b0\u529f\u80fd\u5316\u3001\u65e0\u72b6\u6001\u67b6\u6784\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5e76\u884c\u5316\uff0c\u63d0\u4f9b\u591a\u79cdARC\u6570\u636e\u96c6\u3001\u7075\u6d3b\u7684\u52a8\u4f5c\u7a7a\u95f4\u3001\u53ef\u7ec4\u5408\u7684\u5305\u88c5\u5668\u548c\u914d\u7f6e\u9a71\u52a8\u7684\u53ef\u91cd\u590d\u6027\u3002", "result": "\u5728\u5339\u914d\u7684\u6279\u91cf\u5927\u5c0f\u4e0b\uff0c\u76f8\u6bd4Gymnasium\u5b9e\u73b0\u4e8638-5439\u500d\u7684\u52a0\u901f\uff0c\u5cf0\u503c\u541e\u5410\u91cf\u8fbe\u52307.9\u4ebf\u6b65/\u79d2\uff0c\u4f7f\u4e4b\u524d\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c\u7684\u5927\u89c4\u6a21RL\u7814\u7a76\u6210\u4e3a\u53ef\u80fd\u3002", "conclusion": "JaxARC\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u9ad8\u6027\u80fdRL\u73af\u5883\uff0c\u89e3\u51b3\u4e86ARC\u4efb\u52a1\u4e2d\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u8ba1\u7b97\u5e73\u53f0\u3002"}}
{"id": "2601.17642", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17642", "abs": "https://arxiv.org/abs/2601.17642", "authors": ["Zhihao Zhang", "Liting Huang", "Guanghao Wu", "Preslav Nakov", "Heng Ji", "Usman Naseem"], "title": "Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context", "comment": "Preprint", "summary": "Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \\emph{over-refusal} of benign queries or \\emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \\textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \\textbf{Over-Refusal} and \\textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\\% of \"Hard\" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit \"safety-pessimism\" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \\textcolor{red}{Warning: Some contents may include toxic or undesired contents.}", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Health-ORSC-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u5bf9\u9f50\u4e2d\u7684\u8fc7\u5ea6\u62d2\u7edd\u548c\u5b89\u5168\u5b8c\u6210\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u4e3b\u8981\u4f9d\u8d56\u4e8c\u5143\u62d2\u7edd\u8fb9\u754c\uff0c\u5bfc\u81f4\u5bf9\u826f\u6027\u67e5\u8be2\u7684\u8fc7\u5ea6\u62d2\u7edd\u6216\u5bf9\u6709\u5bb3\u67e5\u8be2\u7684\u4e0d\u5b89\u5168\u9075\u4ece\u3002\u73b0\u6709\u57fa\u51c6\u53ea\u80fd\u6d4b\u91cf\u6781\u7aef\u60c5\u51b5\uff0c\u65e0\u6cd5\u8bc4\u4f30\u6a21\u578b\u5728\u53cc\u7528\u9014\u6216\u8fb9\u754c\u67e5\u8be2\u4e2d\u63d0\u4f9b\u5b89\u5168\u9ad8\u5c42\u6307\u5bfc\u800c\u4e0d\u8de8\u8d8a\u53ef\u64cd\u4f5c\u5371\u5bb3\u7684\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86Health-ORSC-Bench\u57fa\u51c6\uff0c\u5305\u542b31,920\u4e2a\u826f\u6027\u8fb9\u754c\u63d0\u793a\uff0c\u6db5\u76d6\u4e03\u4e2a\u5065\u5eb7\u7c7b\u522b\uff08\u5982\u81ea\u6b8b\u3001\u533b\u7597\u9519\u8bef\u4fe1\u606f\uff09\u3002\u91c7\u7528\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u7ed3\u5408\u4eba\u5de5\u9a8c\u8bc1\uff0c\u5728\u4e0d\u540c\u610f\u56fe\u6a21\u7cca\u5ea6\u6c34\u5e73\u4e0b\u6d4b\u8bd5\u6a21\u578b\u3002\u8bc4\u4f30\u4e8630\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u62ecGPT-5\u548cClaude-4\u3002", "result": "\u5b89\u5168\u4f18\u5316\u7684\u6a21\u578b\u7ecf\u5e38\u62d2\u7edd\u9ad8\u8fbe80%\u7684\"\u56f0\u96be\"\u826f\u6027\u63d0\u793a\uff0c\u800c\u9886\u57df\u7279\u5b9a\u6a21\u578b\u5f80\u5f80\u4e3a\u4e86\u5b9e\u7528\u6027\u727a\u7272\u5b89\u5168\u6027\u3002\u6a21\u578b\u5bb6\u65cf\u548c\u89c4\u6a21\u663e\u8457\u5f71\u54cd\u6821\u51c6\uff1a\u5927\u578b\u524d\u6cbf\u6a21\u578b\u8868\u73b0\u51fa\"\u5b89\u5168\u60b2\u89c2\u4e3b\u4e49\"\u548c\u66f4\u9ad8\u7684\u8fc7\u5ea6\u62d2\u7edd\uff0c\u800c\u8f83\u5c0f\u6216MoE\u67b6\u6784\u6a21\u578b\u8868\u73b0\u4e0d\u540c\u3002\u5f53\u524d\u6a21\u578b\u96be\u4ee5\u5e73\u8861\u62d2\u7edd\u548c\u9075\u4ece\u3002", "conclusion": "Health-ORSC-Bench\u4e3a\u6821\u51c6\u4e0b\u4e00\u4ee3\u533b\u7597AI\u52a9\u624b\u63d0\u4f9b\u4e86\u4e25\u683c\u6807\u51c6\uff0c\u4f7f\u5176\u80fd\u591f\u5b9e\u73b0\u7ec6\u81f4\u3001\u5b89\u5168\u548c\u6709\u5e2e\u52a9\u7684\u5b8c\u6210\u3002\u8be5\u57fa\u51c6\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u5b89\u5168\u5bf9\u9f50\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u533b\u7597AI\u7684\u5b89\u5168\u4f18\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2601.17717", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17717", "abs": "https://arxiv.org/abs/2601.17717", "authors": ["Kaituo Zhang", "Mingzhi Hu", "Hoang Anh Duy Le", "Fariha Kabir Torsha", "Zhimeng Jiang", "Minh Khai Bui", "Chia-Yuan Chang", "Yu-Neng Chuang", "Zhen Xiong", "Ying Lin", "Guanchu Wang", "Na Zou"], "title": "The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data", "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \\textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86LLM\u6570\u636e\u5ba1\u8ba1\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u591a\u6a21\u6001\u5408\u6210\u6570\u636e\u7684\u8d28\u91cf\u548c\u53ef\u4fe1\u5ea6\uff0c\u53d1\u73b0\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "LLM\u5df2\u6210\u4e3a\u751f\u6210\u591a\u6a21\u6001\u6570\u636e\u7684\u6709\u529b\u5de5\u5177\uff0c\u80fd\u5c06\u7a00\u7f3a\u6570\u636e\u8f6c\u5316\u4e3a\u53ef\u63a7\u8d44\u4ea7\uff0c\u4f46\u786e\u4fdd\u5408\u6210\u6570\u636e\u7684\u9ad8\u8d28\u91cf\u4ecd\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u751f\u6210\u65b9\u6cd5\uff0c\u5bf9\u6570\u636e\u8d28\u91cf\u672c\u8eab\u5173\u6ce8\u6709\u9650\uff0c\u4e14\u591a\u4e3a\u5355\u6a21\u6001\u7814\u7a76\uff0c\u7f3a\u4e4f\u8de8\u6a21\u6001\u7684\u7edf\u4e00\u89c6\u89d2\u3002", "method": "\u63d0\u51faLLM\u6570\u636e\u5ba1\u8ba1\u6846\u67b6\uff1a1)\u63cf\u8ff0LLM\u5982\u4f55\u751f\u6210\u516d\u79cd\u4e0d\u540c\u6a21\u6001\u7684\u6570\u636e\uff1b2)\u4ece\u8d28\u91cf\u548c\u53ef\u4fe1\u5ea6\u4e24\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u5206\u7c7b\u5408\u6210\u6570\u636e\u7684\u5185\u5728\u8bc4\u4f30\u6307\u6807\uff1b3)\u5c06\u8bc4\u4f30\u7126\u70b9\u4ece\u4f9d\u8d56\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u5916\u5728\u8bc4\u4f30\u8f6c\u5411\u6570\u636e\u672c\u8eab\u56fa\u6709\u5c5e\u6027\uff1b4)\u5206\u6790\u5404\u6a21\u6001\u4ee3\u8868\u6027\u751f\u6210\u65b9\u6cd5\u7684\u5b9e\u9a8c\u8bc4\u4f30\uff1b5)\u57fa\u4e8e\u53d1\u73b0\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\uff1b6)\u6982\u8ff0\u5408\u6210\u6570\u636e\u5728\u4e0d\u540c\u6a21\u6001\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u8be5\u8bc4\u4f30\u7cfb\u7edf\u5206\u6790\u53d1\u73b0\uff0c\u5f53\u524d\u5404\u6a21\u6001\u4ee3\u8868\u6027\u751f\u6210\u65b9\u6cd5\u7684\u5b9e\u9a8c\u8bc4\u4f30\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u8bc6\u522b\u51fa\u8bc4\u4f30\u5b9e\u8df5\u4e2d\u7684\u5b9e\u8d28\u6027\u4e0d\u8db3\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u6539\u8fdb\u6570\u636e\u751f\u6210\u8bc4\u4f30\u7684\u5177\u4f53\u5efa\u8bae\uff0c\u5e76\u6982\u8ff0\u4e86\u5408\u6210\u6570\u636e\u5728\u4e0d\u540c\u6a21\u6001\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u65b9\u6cd5\uff0c\u4e3aLLM\u751f\u6210\u6570\u636e\u7684\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\u3002"}}
{"id": "2601.17722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17722", "abs": "https://arxiv.org/abs/2601.17722", "authors": ["Ying Mo", "Yu Bai", "Dapeng Sun", "Yuqian Shi", "Yukai Miao", "Li Chen", "Dan Li"], "title": "EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents", "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.", "AI": {"tldr": "EntWorld\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u4f01\u4e1a\u7ea7\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1,756\u4e2a\u4efb\u52a1\uff0c\u8986\u76d6CRM\u3001ITIL\u3001ERP\u7b49\u516d\u4e2a\u4f01\u4e1a\u9886\u57df\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u9488\u5bf9\u6d88\u8d39\u7ea7\u573a\u666f\uff08\u5982\u7535\u5546\u3001\u65c5\u884c\u9884\u8ba2\uff09\uff0c\u65e0\u6cd5\u6355\u6349\u4f01\u4e1a\u5de5\u4f5c\u6d41\u7a0b\u7684\u590d\u6742\u6027\u548c\u4e25\u8c28\u6027\u3002\u4f01\u4e1a\u7cfb\u7edf\u5177\u6709\u9ad8\u5bc6\u5ea6\u7528\u6237\u754c\u9762\u3001\u4e25\u683c\u4e1a\u52a1\u903b\u8f91\u7ea6\u675f\u548c\u7cbe\u786e\u72b6\u6001\u4e00\u81f4\u6027\u8981\u6c42\u7b49\u7279\u70b9\uff0c\u5f53\u524d\u901a\u7528\u667a\u80fd\u4f53\u5728\u8fd9\u4e9b\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6a21\u5f0f\u7684\u4efb\u52a1\u751f\u6210\u6846\u67b6\uff0c\u76f4\u63a5\u4ece\u5e95\u5c42\u6570\u636e\u5e93\u6a21\u5f0f\u9006\u5411\u5de5\u7a0b\u4e1a\u52a1\u903b\u8f91\uff0c\u5408\u6210\u771f\u5b9e\u7684\u957f\u5468\u671f\u5de5\u4f5c\u6d41\u7a0b\u3002\u63d0\u51fa\u57fa\u4e8eSQL\u7684\u786e\u5b9a\u6027\u9a8c\u8bc1\u673a\u5236\uff0c\u7528\u4e25\u683c\u7684\u72b6\u6001\u8f6c\u6362\u9a8c\u8bc1\u66ff\u4ee3\u6a21\u7cca\u7684\u89c6\u89c9\u5339\u914d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff08\u5982GPT-4.1\uff09\u5728EntWorld\u4e0a\u7684\u6210\u529f\u7387\u4ec5\u4e3a47.61%\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u8868\u73b0\uff0c\u7a81\u663e\u4e86\u5f53\u524d\u667a\u80fd\u4f53\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u663e\u8457\u80fd\u529b\u5dee\u8ddd\u3002", "conclusion": "EntWorld\u63ed\u793a\u4e86\u5f53\u524d\u901a\u7528\u667a\u80fd\u4f53\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u9886\u57df\u7279\u5b9a\u667a\u80fd\u4f53\u7684\u5fc5\u8981\u6027\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u4e0b\u4e00\u4ee3\u4f01\u4e1a\u7ea7\u6570\u5b57\u667a\u80fd\u4f53\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2601.17767", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.17767", "abs": "https://arxiv.org/abs/2601.17767", "authors": ["Rajan Das Gupta", "Xiaobin Wu", "Xun Liu", "Jiaqi He"], "title": "HyCARD-Net: A Synergistic Hybrid Intelligence Framework for Cardiovascular Disease Diagnosis", "comment": "Accepted and published in the 2025 4th International Conference on Image Processing, Computer Vision and Machine Learning (ICICML)", "summary": "Cardiovascular disease (CVD) remains the foremost cause of mortality worldwide, underscoring the urgent need for intelligent and data-driven diagnostic tools. Traditional predictive models often struggle to generalize across heterogeneous datasets and complex physiological patterns. To address this, we propose a hybrid ensemble framework that integrates deep learning architectures, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), with classical machine learning algorithms, including K-Nearest Neighbor (KNN) and Extreme Gradient Boosting (XGB), using an ensemble voting mechanism. This approach combines the representational power of deep networks with the interpretability and efficiency of traditional models. Experiments on two publicly available Kaggle datasets demonstrate that the proposed model achieves superior performance, reaching 82.30 percent accuracy on Dataset I and 97.10 percent on Dataset II, with consistent gains in precision, recall, and F1-score. These findings underscore the robustness and clinical potential of hybrid AI frameworks for predicting cardiovascular disease and facilitating early intervention. Furthermore, this study directly supports the United Nations Sustainable Development Goal 3 (Good Health and Well-being) by promoting early diagnosis, prevention, and management of non-communicable diseases through innovative, data-driven healthcare solutions.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u96c6\u6210\u6846\u67b6\uff0c\u7ed3\u5408CNN\u3001LSTM\u6df1\u5ea6\u5b66\u4e60\u4e0eKNN\u3001XGB\u4f20\u7edf\u673a\u5668\u5b66\u4e60\uff0c\u901a\u8fc7\u6295\u7968\u673a\u5236\u63d0\u5347\u5fc3\u8840\u7ba1\u75be\u75c5\u9884\u6d4b\u6027\u80fd", "motivation": "\u5fc3\u8840\u7ba1\u75be\u75c5\u662f\u5168\u7403\u4e3b\u8981\u6b7b\u56e0\uff0c\u4f20\u7edf\u9884\u6d4b\u6a21\u578b\u96be\u4ee5\u6cdb\u5316\u5230\u5f02\u6784\u6570\u636e\u96c6\u548c\u590d\u6742\u751f\u7406\u6a21\u5f0f\uff0c\u9700\u8981\u667a\u80fd\u6570\u636e\u9a71\u52a8\u7684\u8bca\u65ad\u5de5\u5177", "method": "\u96c6\u6210CNN\u3001LSTM\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u4e0eKNN\u3001XGB\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u91c7\u7528\u6295\u7968\u673a\u5236\u6784\u5efa\u6df7\u5408\u96c6\u6210\u6846\u67b6", "result": "\u5728\u4e24\u4e2aKaggle\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u523082.30%\u548c97.10%\u7684\u51c6\u786e\u7387\uff0c\u5728\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u5747\u6709\u7a33\u5b9a\u63d0\u5347", "conclusion": "\u6df7\u5408AI\u6846\u67b6\u5728\u5fc3\u8840\u7ba1\u75be\u75c5\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u548c\u4e34\u5e8a\u6f5c\u529b\uff0c\u652f\u6301\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u68073\uff0c\u4fc3\u8fdb\u65e9\u671f\u8bca\u65ad\u548c\u5e72\u9884"}}
{"id": "2601.17814", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17814", "abs": "https://arxiv.org/abs/2601.17814", "authors": ["Haoxuan Ma", "Guannan Lai", "Han-Jia Ye"], "title": "MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing", "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.", "AI": {"tldr": "MMR-Bench\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u8def\u7531\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5f02\u6784\u6027\u548c\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u667a\u80fd\u8def\u7531\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u9009\u62e9\u6700\u4f18\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u67b6\u6784\u3001\u5bf9\u9f50\u7b56\u7565\u548c\u6548\u7387\u65b9\u9762\u5b58\u5728\u5f02\u8d28\u6027\uff0c\u6ca1\u6709\u5355\u4e00\u6a21\u578b\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u90fd\u8868\u73b0\u6700\u4f18\u3002\u5b9e\u9645\u90e8\u7f72\u4e2d\uff0c\u5de5\u4f5c\u8d1f\u8f7d\u4ece\u8f7b\u91cf\u7ea7OCR\u5230\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u4e0d\u7b49\uff0c\u4f7f\u7528\u5355\u4e00\u6a21\u578b\u8981\u4e48\u5728\u7b80\u5355\u5b9e\u4f8b\u4e0a\u8fc7\u5ea6\u914d\u7f6e\u8ba1\u7b97\u8d44\u6e90\uff0c\u8981\u4e48\u5728\u56f0\u96be\u5b9e\u4f8b\u4e0a\u727a\u7272\u51c6\u786e\u6027\u3002\u9700\u8981\u89e3\u51b3\u4ece\u7eaf\u6587\u672cLLM\u8def\u7531\u6269\u5c55\u5230\u591a\u6a21\u6001MLLM\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faMMR-Bench\u7edf\u4e00\u57fa\u51c6\u6d4b\u8bd5\uff1a1\uff09\u63d0\u4f9b\u5177\u6709\u6a21\u6001\u611f\u77e5\u8f93\u5165\u548c\u53ef\u53d8\u8ba1\u7b97\u9884\u7b97\u7684\u53d7\u63a7\u73af\u5883\uff1b2\uff09\u5305\u542bOCR\u3001\u901a\u7528VQA\u548c\u591a\u6a21\u6001\u6570\u5b66\u63a8\u7406\u7b49\u5e7f\u6cdb\u7684\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u5957\u4ef6\uff1b3\uff09\u63d0\u4f9b\u5f3a\u5355\u6a21\u578b\u53c2\u8003\u3001\u7406\u8bba\u4e0a\u9650\u548c\u4ee3\u8868\u6027\u8def\u7531\u7b56\u7565\u3002\u901a\u8fc7\u8be5\u57fa\u51c6\u6d4b\u8bd5\u7814\u7a76\u591a\u6a21\u6001\u4fe1\u53f7\u5bf9\u8def\u7531\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u878d\u5165\u591a\u6a21\u6001\u4fe1\u53f7\u80fd\u63d0\u5347\u8def\u7531\u8d28\u91cf\uff0c\u6539\u5584\u6210\u672c-\u51c6\u786e\u6027\u8fb9\u754c\u3002\u8def\u7531\u7cfb\u7edf\u80fd\u4ee5\u6700\u5f3a\u5355\u6a21\u578b\u7ea633%\u7684\u6210\u672c\u8d85\u8d8a\u5176\u51c6\u786e\u6027\u3002\u5728\u6a21\u578b\u548c\u4efb\u52a1\u5b50\u96c6\u4e0a\u8bad\u7ec3\u7684\u7b56\u7565\u80fd\u591f\u96f6\u6837\u672c\u6cdb\u5316\u5230\u65b0\u6570\u636e\u96c6\u548c\u7eaf\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e0\u9700\u91cd\u65b0\u8c03\u4f18\u3002", "conclusion": "MMR-Bench\u4e3a\u7814\u7a76\u81ea\u9002\u5e94\u591a\u6a21\u6001\u6a21\u578b\u9009\u62e9\u548c\u9ad8\u6548MLLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u667a\u80fd\u8def\u7531\u5728\u591a\u6a21\u6001\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5728\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2601.17826", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17826", "abs": "https://arxiv.org/abs/2601.17826", "authors": ["Siyuan Yang", "Xihan Bian", "Jiayin Tang"], "title": "RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance", "comment": null, "summary": "The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.", "AI": {"tldr": "RegGuard\u662f\u4e00\u4e2a\u5de5\u4e1a\u7ea7AI\u52a9\u624b\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u89e3\u8bfb\u5f02\u6784\u76d1\u7ba1\u6587\u672c\u5e76\u5c06\u5176\u4e0e\u516c\u53f8\u5185\u90e8\u653f\u7b56\u5bf9\u9f50\uff0c\u901a\u8fc7HiSACC\u548cReLACE\u7ec4\u4ef6\u63d0\u5347\u68c0\u7d22\u548c\u751f\u6210\u8d28\u91cf\uff0c\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u663e\u8457\u6539\u5584\u56de\u7b54\u8d28\u91cf\u5e76\u964d\u4f4e\u5e7b\u89c9\u98ce\u9669\u3002", "motivation": "\u76d1\u7ba1\u66f4\u65b0\u65e5\u76ca\u9891\u7e41\u548c\u590d\u6742\uff0c\u7ed9\u8de8\u56fd\u5236\u836f\u516c\u53f8\u5e26\u6765\u6c89\u91cd\u8d1f\u62c5\u3002\u5408\u89c4\u56e2\u961f\u9700\u8981\u8de8\u53f8\u6cd5\u7ba1\u8f96\u533a\u3001\u683c\u5f0f\u548c\u673a\u6784\u624b\u52a8\u89e3\u8bfb\u4e0d\u65ad\u53d8\u5316\u7684\u89c4\u5219\uff0c\u6210\u672c\u9ad8\u4e14\u5bb9\u6613\u51fa\u9519\u3002", "method": "\u7cfb\u7edf\u901a\u8fc7\u5b89\u5168\u7ba1\u9053\u6444\u53d6\u5f02\u6784\u6587\u6863\u6e90\uff0c\u91c7\u7528\u4e24\u4e2a\u521b\u65b0\u7ec4\u4ef6\uff1aHiSACC\uff08\u5206\u5c42\u8bed\u4e49\u805a\u5408\u4e0a\u4e0b\u6587\u5206\u5757\uff09\u5c06\u957f\u6587\u6863\u8bed\u4e49\u5206\u5272\u4e3a\u8fde\u8d2f\u5355\u5143\uff0c\u4fdd\u6301\u975e\u8fde\u7eed\u90e8\u5206\u7684\u4e00\u81f4\u6027\uff1bReLACE\uff08\u76d1\u7ba1\u5217\u8868\u81ea\u9002\u5e94\u4ea4\u53c9\u7f16\u7801\u5668\u91cd\u6392\u5e8f\uff09\u57fa\u4e8e\u5f00\u6e90\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u4ea4\u53c9\u7f16\u7801\u5668\uff0c\u8054\u5408\u5efa\u6a21\u7528\u6237\u67e5\u8be2\u548c\u68c0\u7d22\u5019\u9009\u4ee5\u6539\u8fdb\u6392\u540d\u76f8\u5173\u6027\u3002", "result": "\u4f01\u4e1a\u73af\u5883\u8bc4\u4f30\u663e\u793a\uff0cRegGuard\u5728\u76f8\u5173\u6027\u3001\u57fa\u7840\u6027\u548c\u4e0a\u4e0b\u6587\u805a\u7126\u65b9\u9762\u663e\u8457\u6539\u5584\u56de\u7b54\u8d28\u91cf\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u5e7b\u89c9\u98ce\u9669\u3002\u7cfb\u7edf\u67b6\u6784\u5177\u5907\u53ef\u5ba1\u8ba1\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u5305\u62ec\u6765\u6e90\u8ddf\u8e2a\u3001\u8bbf\u95ee\u63a7\u5236\u548c\u589e\u91cf\u7d22\u5f15\u3002", "conclusion": "RegGuard\u7cfb\u7edf\u80fd\u591f\u9ad8\u6548\u54cd\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u6587\u6863\u6e90\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u6709\u4e25\u683c\u5408\u89c4\u9700\u6c42\u7684\u9886\u57df\uff0c\u4e3a\u76d1\u7ba1\u5408\u89c4\u63d0\u4f9b\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.17828", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17828", "abs": "https://arxiv.org/abs/2601.17828", "authors": ["Tanvi Verma", "Yang Zhou", "Rick Siow Mong Goh", "Yong Liu"], "title": "Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards", "comment": null, "summary": "We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.", "AI": {"tldr": "IGFT\u662f\u4e00\u79cd\u65e0\u9700\u4eba\u7c7b\u5bf9\u8bdd\u6570\u636e\u3001\u901a\u8fc7\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u8bad\u7ec3\u533b\u7597\u5bf9\u8bddAI\u7684\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u6a21\u62df\u60a3\u8005\u5bf9\u8bdd\u4e2d\u5b66\u4e60\u6709\u6548\u7684\u75c5\u53f2\u91c7\u96c6\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u533b\u7597\u5bf9\u8bddAI\u8bad\u7ec3\u4f9d\u8d56\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\u5bf9\u8bdd\u6570\u636e\u6216\u9759\u6001\u6570\u636e\u96c6\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u9884\u6536\u96c6\u4eba\u7c7b\u5bf9\u8bdd\u3001\u80fd\u591f\u901a\u8fc7\u81ea\u4e3b\u63a2\u7d22\u5b66\u4e60\u6709\u6548\u95ee\u8bca\u7b56\u7565\u7684\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u5728\u7ebf\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u4e0e\u4fe1\u606f\u8bba\u5956\u52b1\uff0c\u4f7f\u7528\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u51fd\u6570\u8ffd\u8e2a\u4e34\u5e8a\u5b9e\u4f53\uff08\u75c7\u72b6\u3001\u65f6\u95f4\u6a21\u5f0f\u3001\u75c5\u53f2\uff09\u7684\u63ed\u793a\u60c5\u51b5\uff0c\u7ed3\u5408GPT-4o-mini\u7684\u8d28\u91cf\u8bc4\u4f30\u8ba1\u7b97\u95ee\u9898\u5956\u52b1\uff0c\u901a\u8fc7LoRA\u5fae\u8c03Llama-3.1-8B-Instruct\u548cDeepSeek-R1-Distill-Qwen-7B\u6a21\u578b\u3002", "result": "DeepSeek-R1-Distill-Qwen-7B\uff08IGFT\uff09\u5728Avey\u6570\u636e\u4e0aF1\u5206\u6570\u8fbe\u52300.408\uff08\u6bd4\u57fa\u7840\u6a21\u578b\u63d0\u534710.9%\uff09\uff0c\u5728MIMIC\u6570\u636e\u4e0a\u8fbe\u52300.289\uff08\u63d0\u534712.9%\uff09\uff1bLlama-3.1-8B-Instruct\uff08IGFT\uff09\u5206\u522b\u8fbe\u52300.384\u548c0.336\uff0c\u5747\u4f18\u4e8eOpenAI\u6a21\u578b\u548c\u533b\u7597\u9886\u57df\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "IGFT\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bad\u7ec3\u533b\u7597\u5bf9\u8bddAI\u8fdb\u884c\u60a3\u8005\u8bbf\u8c08\u548c\u75c5\u53f2\u91c7\u96c6\uff0c\u65e0\u9700\u4f9d\u8d56\u9884\u6536\u96c6\u7684\u4eba\u7c7b\u5bf9\u8bdd\u6570\u636e\uff0c\u5728\u4fe1\u606f\u589e\u76ca\u5956\u52b1\u7684\u9a71\u52a8\u4e0b\uff0c\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u63d0\u51fa\u6709\u9488\u5bf9\u6027\u7684\u4e34\u5e8a\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.17897", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17897", "abs": "https://arxiv.org/abs/2601.17897", "authors": ["Jiayu Liu", "Yinhe Long", "Zhenya Huang", "Enhong Chen"], "title": "UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis", "comment": null, "summary": "A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.", "AI": {"tldr": "UniCog\u6846\u67b6\u901a\u8fc7\u6f5c\u5728\u601d\u7ef4\u7a7a\u95f4\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u53d1\u73b0LLM\u8ba4\u77e5\u9075\u5faa\u5e15\u7d2f\u6258\u539f\u5219\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u6f5c\u5728\u6fc0\u6d3b\u7684\u5019\u9009\u4f18\u5148\u7ea7\u7b56\u7565\u63d0\u5347\u63a8\u7406\u6027\u80fd", "motivation": "\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u89e3\u91caLLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8ba4\u77e5\u80fd\u529b\u5982\u4f55\u88ab\u8c03\u7528\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u65b0\u7684\u6846\u67b6\u6765\u5206\u6790LLM\u7684\u8ba4\u77e5\u8fc7\u7a0b", "method": "\u63d0\u51faUniCog\u7edf\u4e00\u6846\u67b6\uff0c\u4f5c\u4e3a\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\uff0c\u5c06\u5bc6\u96c6\u6a21\u578b\u6fc0\u6d3b\u7f16\u7801\u4e3a\u7a00\u758f\u3001\u89e3\u8026\u7684\u6f5c\u5728\u7ef4\u5ea6\uff0c\u5206\u6790\u516d\u4e2a\u5148\u8fdbLLM\u7684\u8ba4\u77e5\u8fc7\u7a0b", "result": "\u53d1\u73b0LLM\u8ba4\u77e5\u9075\u5faa\u5e15\u7d2f\u6258\u539f\u5219\uff1a\u5171\u4eab\u63a8\u7406\u6838\u5fc3\u8f85\u4ee5\u80fd\u529b\u7279\u5b9a\u7279\u5f81\uff1b\u63a8\u7406\u5931\u8d25\u5e38\u8868\u73b0\u4e3a\u6f5c\u5728\u6fc0\u6d3b\u5f02\u5e38\u5f3a\u5ea6\uff1b\u6f5c\u5728\u4fe1\u606f\u5019\u9009\u4f18\u5148\u7ea7\u7b56\u7565\u53ef\u5c06\u63a8\u7406\u6027\u80fd\u63d0\u5347\u8fbe7.5%", "conclusion": "UniCog\u4e3aLLM\u5206\u6790\u5f00\u8f9f\u4e86\u65b0\u8303\u5f0f\uff0c\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8ba4\u77e5\u7684\u63a8\u7406\u52a8\u6001\u89c6\u89d2\uff0c\u901a\u8fc7\u6f5c\u5728\u6fc0\u6d3b\u5206\u6790\u53ef\u63d0\u5347\u6a21\u578b\u63a8\u7406\u6027\u80fd"}}
{"id": "2601.17920", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17920", "abs": "https://arxiv.org/abs/2601.17920", "authors": ["Xuanzhou Chen", "Audrey Wang", "Stanley Yin", "Hanyang Jiang", "Dong Zhang"], "title": "Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges", "comment": null, "summary": "Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\uff08SDL\uff09\u4e2d\u7684\u4eba\u5de5\u667a\u80fd\u95ee\u9898\uff0c\u5c06SDL\u81ea\u4e3b\u6027\u6784\u5efa\u4e3a\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u95ee\u9898\uff0c\u56de\u987e\u4e86\u95ed\u73af\u5b9e\u9a8c\u7684\u4e3b\u8981\u65b9\u6cd5\u5bb6\u65cf\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u80fd\u529b\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u603b\u7ed3\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u7ecf\u9a8c\u6559\u8bad\u548c\u5f00\u653e\u6311\u6218\u3002", "motivation": "\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\uff08SDL\uff09\u901a\u8fc7\u8fde\u63a5\u5b9e\u9a8c\u8bbe\u8ba1\u3001\u81ea\u52a8\u5316\u6267\u884c\u548c\u6570\u636e\u9a71\u52a8\u51b3\u7b56\uff0c\u4e3a\u5728\u6602\u8d35\u64cd\u4f5c\u3001\u566a\u58f0\u5ef6\u8fdf\u53cd\u9988\u3001\u4e25\u683c\u53ef\u884c\u6027\u5b89\u5168\u7ea6\u675f\u548c\u975e\u5e73\u7a33\u6027\u6761\u4ef6\u4e0b\u7684\u667a\u80fd\u4f53AI\u63d0\u4f9b\u4e86\u4e25\u683c\u6d4b\u8bd5\u5e73\u53f0\u3002\u672c\u6587\u4ee5\u8f6f\u7269\u8d28\u4e3a\u4ee3\u8868\u573a\u666f\uff0c\u91cd\u70b9\u5173\u6ce8\u5b9e\u9645\u5b9e\u9a8c\u5ba4\u4e2d\u51fa\u73b0\u7684\u4eba\u5de5\u667a\u80fd\u95ee\u9898\u3002", "method": "\u5c06SDL\u81ea\u4e3b\u6027\u6784\u5efa\u4e3a\u5177\u6709\u660e\u786e\u89c2\u5bdf\u3001\u884c\u52a8\u3001\u6210\u672c\u548c\u7ea6\u675f\u7684\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u95ee\u9898\uff1b\u56de\u987e\u4e86\u95ed\u73af\u5b9e\u9a8c\u7684\u4e3b\u8981\u65b9\u6cd5\u5bb6\u65cf\uff0c\u5305\u62ec\u7528\u4e8e\u6837\u672c\u9ad8\u6548\u5b9e\u9a8c\u9009\u62e9\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u4e3b\u52a8\u5b66\u4e60\u3001\u7528\u4e8e\u957f\u89c6\u91ce\u534f\u8bae\u4f18\u5316\u7684\u89c4\u5212\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u4ee5\u53ca\u534f\u8c03\u5f02\u6784\u4eea\u5668\u548c\u8f6f\u4ef6\u7684\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\uff1b\u63d0\u51fa\u4e86\u57fa\u4e8e\u80fd\u529b\u7684\u5206\u7c7b\u6cd5\uff0c\u6309\u51b3\u7b56\u89c6\u91ce\u3001\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u3001\u884c\u52a8\u53c2\u6570\u5316\u3001\u7ea6\u675f\u5904\u7406\u3001\u6545\u969c\u6062\u590d\u548c\u4eba\u7c7b\u53c2\u4e0e\u7ec4\u7ec7\u7cfb\u7edf\uff1b\u5408\u6210\u4e86\u57fa\u51c6\u4efb\u52a1\u6a21\u677f\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5efa\u7acb\u4e86SDL\u4e0eAI\u539f\u5219\u7684\u8fde\u63a5\u6846\u67b6\uff1b\u63d0\u51fa\u4e86\u7cfb\u7edf\u5316\u7684\u5206\u7c7b\u6cd5\u548c\u8bc4\u4f30\u4f53\u7cfb\uff1b\u5f3a\u8c03\u4e86\u53ef\u9a8c\u8bc1\u548c\u6eaf\u6e90\u611f\u77e5\u7684\u7b56\u7565\u4ee5\u652f\u6301\u8c03\u8bd5\u3001\u53ef\u91cd\u590d\u6027\u548c\u5b89\u5168\u64cd\u4f5c\uff1b\u603b\u7ed3\u4e86\u5b9e\u9645\u90e8\u7f72SDL\u7684\u7ecf\u9a8c\u6559\u8bad\u3002", "conclusion": "\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u4e3aAI\u63d0\u4f9b\u4e86\u5177\u6709\u6311\u6218\u6027\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u53d1\u5c55\u591a\u6a21\u6001\u8868\u793a\u3001\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u3001\u5b89\u5168\u63a2\u7d22\u548c\u5171\u4eab\u57fa\u51c6\u57fa\u7840\u8bbe\u65bd\u7b49\u5f00\u653e\u6311\u6218\u3002\u672c\u6587\u4e3aSDL\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u6846\u67b6\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u7684\u6807\u51c6\u5316\u548c\u53ef\u6bd4\u6027\u7814\u7a76\u3002"}}
{"id": "2601.17923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.17923", "abs": "https://arxiv.org/abs/2601.17923", "authors": ["Ali Najar"], "title": "Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation", "comment": "5 pages", "summary": "Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6280\u80fd\u56fe\u7684\u5206\u5c42\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff0c\u8ba9\u667a\u80fd\u4f53\u5728\u590d\u6742\u5b9e\u65f6\u63a7\u5236\u73af\u5883\u4e2d\uff08\u9ed1\u6697\u4e4b\u9b42III\uff09\u80fd\u591f\u6301\u7eed\u5b66\u4e60\u800c\u4e0d\u9700\u8981\u4ece\u5934\u8bad\u7ec3\u6216\u8986\u76d6\u5df2\u5b66\u884c\u4e3a\u3002", "motivation": "\u7ec8\u8eab\u5b66\u4e60\u667a\u80fd\u4f53\u5e94\u8be5\u80fd\u591f\u968f\u65f6\u95f4\u6269\u5c55\u80fd\u529b\uff0c\u800c\u4e0d\u9700\u8981\u4ece\u5934\u5f00\u59cb\u91cd\u65b0\u8bad\u7ec3\u6216\u8986\u76d6\u5148\u524d\u5b66\u4e60\u7684\u884c\u4e3a\u3002\u5728\u590d\u6742\u5b9e\u65f6\u63a7\u5236\u73af\u5883\u4e2d\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5c06\u6218\u6597\u8868\u793a\u4e3a\u6709\u5411\u6280\u80fd\u56fe\uff0c\u91c7\u7528\u5206\u5c42\u8bfe\u7a0b\u8bad\u7ec3\u5176\u7ec4\u4ef6\u3002\u5c06\u63a7\u5236\u5206\u89e3\u4e3a\u4e94\u4e2a\u53ef\u91cd\u7528\u6280\u80fd\uff1a\u76f8\u673a\u63a7\u5236\u3001\u76ee\u6807\u9501\u5b9a\u3001\u79fb\u52a8\u3001\u95ea\u907f\u548c\u6cbb\u7597-\u653b\u51fb\u51b3\u7b56\u7b56\u7565\uff0c\u6bcf\u4e2a\u6280\u80fd\u9488\u5bf9\u7279\u5b9a\u804c\u8d23\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u6280\u80fd\u5206\u89e3\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u5355\u4e2a\u7b56\u7565\u7684\u8d1f\u62c5\uff0c\u5e76\u652f\u6301\u9009\u62e9\u6027\u540e\u8bad\u7ec3\u3002\u5f53\u73af\u5883\u4ece\u7b2c\u4e00\u9636\u6bb5\u5207\u6362\u5230\u7b2c\u4e8c\u9636\u6bb5\u65f6\uff0c\u53ea\u9700\u8c03\u6574\u90e8\u5206\u6280\u80fd\uff0c\u800c\u4e0a\u6e38\u6280\u80fd\u4fdd\u6301\u53ef\u8fc1\u79fb\u6027\u3002\u4ec5\u5bf9\u4e24\u4e2a\u6280\u80fd\u8fdb\u884c\u9488\u5bf9\u6027\u5fae\u8c03\u5c31\u80fd\u5728\u6709\u9650\u4ea4\u4e92\u9884\u7b97\u4e0b\u5feb\u901f\u6062\u590d\u6027\u80fd\u3002", "conclusion": "\u6280\u80fd\u56fe\u8bfe\u7a0b\u4e0e\u9009\u62e9\u6027\u5fae\u8c03\u76f8\u7ed3\u5408\uff0c\u4e3a\u590d\u6742\u5b9e\u65f6\u73af\u5883\u4e2d\u8fdb\u5316\u3001\u6301\u7eed\u5b66\u4e60\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2601.18027", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18027", "abs": "https://arxiv.org/abs/2601.18027", "authors": ["Chiyuan Fu", "Lyuhao Chen", "Yunze Xiao", "Weihao Xuan", "Carlos Busso", "Mona Diab"], "title": "Sentipolis: Emotion-Aware Agents for Social Simulations", "comment": null, "summary": "LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.", "AI": {"tldr": "Sentipolis\u662f\u4e00\u4e2a\u60c5\u611f\u72b6\u6001\u5316\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7PAD\u60c5\u611f\u8868\u793a\u3001\u53cc\u901f\u60c5\u611f\u52a8\u6001\u548c\u60c5\u611f-\u8bb0\u5fc6\u8026\u5408\u89e3\u51b3LLM\u667a\u80fd\u4f53\u5728\u793e\u4ea4\u6a21\u62df\u4e2d\u7684\u60c5\u611f\u9057\u5fd8\u548c\u957f\u671f\u8fde\u7eed\u6027\u4e0d\u8db3\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u5728\u793e\u4ea4\u6a21\u62df\u4e2d\u5e38\u5c06\u60c5\u611f\u89c6\u4e3a\u77ed\u6682\u7ebf\u7d22\uff0c\u5bfc\u81f4\u60c5\u611f\u9057\u5fd8\u548c\u957f\u671f\u60c5\u611f\u8fde\u7eed\u6027\u8584\u5f31\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u5316\u7684\u60c5\u611f\u72b6\u6001\u7ba1\u7406\u6846\u67b6\u3002", "method": "\u63d0\u51faSentipolis\u6846\u67b6\uff0c\u5305\u542b\uff1a1) \u8fde\u7eedPleasure-Arousal-Dominance\u60c5\u611f\u8868\u793a\uff1b2) \u53cc\u901f\u60c5\u611f\u52a8\u6001\u673a\u5236\uff1b3) \u60c5\u611f-\u8bb0\u5fc6\u8026\u5408\u7cfb\u7edf\u3002", "result": "\u5728\u6570\u5343\u6b21\u4ea4\u4e92\u4e2d\uff0cSentipolis\u63d0\u5347\u4e86\u60c5\u611f\u57fa\u7840\u884c\u4e3a\u3001\u6c9f\u901a\u80fd\u529b\u548c\u60c5\u611f\u8fde\u7eed\u6027\u3002\u6548\u679c\u6a21\u578b\u4f9d\u8d56\uff1a\u9ad8\u5bb9\u91cf\u6a21\u578b\u53ef\u4fe1\u5ea6\u63d0\u5347\uff0c\u5c0f\u6a21\u578b\u53ef\u80fd\u4e0b\u964d\uff1b\u60c5\u611f\u610f\u8bc6\u53ef\u80fd\u8f7b\u5fae\u964d\u4f4e\u793e\u4f1a\u89c4\u8303\u9075\u5b88\u5ea6\u3002", "conclusion": "Sentipolis\u901a\u8fc7\u60c5\u611f\u72b6\u6001\u5316\u667a\u80fd\u4f53\u6539\u5584\u4e86\u793e\u4ea4\u6a21\u62df\u7684\u60c5\u611f\u8fde\u7eed\u6027\uff0c\u63ed\u793a\u4e86\u60c5\u611f\u9a71\u52a8\u884c\u4e3a\u4e0e\u793e\u4f1a\u89c4\u8303\u9075\u5b88\u4e4b\u95f4\u7684\u4eba\u7c7b\u5316\u5f20\u529b\uff0c\u652f\u6301\u7814\u7a76\u7d2f\u79ef\u793e\u4ea4\u52a8\u6001\u5982\u8054\u76df\u5f62\u6210\u548c\u5173\u7cfb\u6e10\u53d8\u3002"}}
{"id": "2601.18061", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.18061", "abs": "https://arxiv.org/abs/2601.18061", "authors": ["Kiana Jafari", "Paul Ulrich Nikolaus Rust", "Duncan Eddy", "Robbie Fraser", "Nina Vasan", "Darja Djordjevic", "Akanksha Dadlani", "Max Lamparth", "Eugenia Kim", "Mykel Kochenderfer"], "title": "Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing", "comment": "17 pages, 7 pages of appendix, 21 tables", "summary": "Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $\u03b1= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u4e13\u5bb6\u5bf9AI\u751f\u6210\u56de\u590d\u7684\u8bc4\u4f30\u5b58\u5728\u7cfb\u7edf\u6027\u5206\u6b67\uff0c\u5c24\u5176\u662f\u5728\u81ea\u6740\u81ea\u4f24\u7b49\u5b89\u5168\u5173\u952e\u95ee\u9898\u4e0a\uff0c\u4e13\u5bb6\u95f4\u4e00\u81f4\u6027\u8fdc\u4f4e\u4e8e\u53ef\u63a5\u53d7\u6c34\u5e73\uff0c\u8fd9\u79cd\u5206\u6b67\u6e90\u4e8e\u4e0d\u540c\u7684\u4e34\u5e8a\u6846\u67b6\u800c\u975e\u6d4b\u91cf\u8bef\u5dee\u3002", "motivation": "\u9a8c\u8bc1\"\u4eba\u7c7b\u53cd\u9988\u5b66\u4e60\"\u7684\u57fa\u672c\u5047\u8bbe\uff1a\u4e13\u5bb6\u5224\u65ad\u7ecf\u8fc7\u9002\u5f53\u805a\u5408\u540e\u80fd\u4ea7\u751f\u6709\u6548\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u771f\u5b9e\u6807\u7b7e\u3002\u5728\u5fc3\u7406\u5065\u5eb7\u8fd9\u4e00\u5b89\u5168\u98ce\u9669\u9ad8\u7684\u9886\u57df\uff0c\u4e13\u5bb6\u5171\u8bc6\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u4e09\u4f4d\u8ba4\u8bc1\u7cbe\u795e\u79d1\u533b\u751f\u4f7f\u7528\u6821\u51c6\u7684\u8bc4\u5206\u6807\u51c6\u72ec\u7acb\u8bc4\u4f30LLM\u751f\u6210\u7684\u56de\u590d\uff0c\u8ba1\u7b97\u7ec4\u5185\u76f8\u5173\u7cfb\u6570(ICC)\u548cKrippendorff's \u03b1\u7b49\u53ef\u9760\u6027\u6307\u6807\uff0c\u5e76\u8fdb\u884c\u5b9a\u6027\u8bbf\u8c08\u4e86\u89e3\u5206\u6b67\u539f\u56e0\u3002", "result": "\u4e13\u5bb6\u95f4\u53ef\u9760\u6027\u6781\u4f4e(ICC 0.087-0.295)\uff0c\u4f4e\u4e8e\u53ef\u63a5\u53d7\u9608\u503c\uff1b\u81ea\u6740\u81ea\u4f24\u7c7b\u56de\u590d\u5206\u6b67\u6700\u5927\uff1b\u4e00\u4e2a\u56e0\u7d20\u751a\u81f3\u51fa\u73b0\u8d1f\u53ef\u9760\u6027(\u03b1=-0.203)\uff1b\u5206\u6b67\u6e90\u4e8e\u4e09\u79cd\u4e0d\u540c\u7684\u4e34\u5e8a\u6846\u67b6\uff1a\u5b89\u5168\u4f18\u5148\u3001\u53c2\u4e0e\u4e3a\u4e2d\u5fc3\u548c\u6587\u5316\u654f\u611f\u3002", "conclusion": "\u4e13\u5bb6\u5206\u6b67\u662f\u539f\u5219\u6027\u7684\u793e\u4f1a\u6280\u672f\u73b0\u8c61\uff0c\u800c\u975e\u6d4b\u91cf\u8bef\u5dee\uff1b\u805a\u5408\u6807\u7b7e\u53ea\u662f\u7b97\u672f\u59a5\u534f\uff0c\u62b9\u6740\u4e86\u4e13\u4e1a\u54f2\u5b66\uff1b\u5efa\u8bae\u4ece\u57fa\u4e8e\u5171\u8bc6\u7684\u805a\u5408\u8f6c\u5411\u80fd\u591f\u4fdd\u7559\u548c\u5b66\u4e60\u4e13\u5bb6\u5206\u6b67\u7684\u5bf9\u9f50\u65b9\u6cd5\u3002"}}
{"id": "2601.18067", "categories": ["cs.AI", "cs.NE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.18067", "abs": "https://arxiv.org/abs/2601.18067", "authors": ["Wei-Po Hsin", "Ren-Hao Deng", "Yao-Ting Hsieh", "En-Ming Huang", "Shih-Hao Hung"], "title": "EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization", "comment": "17 pages, 6 figures, 8 tables", "summary": "Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.", "AI": {"tldr": "EvolVE\u6846\u67b6\u901a\u8fc7\u591a\u79cd\u8fdb\u5316\u7b56\u7565\uff08MCTS\u548cIGR\uff09\u548c\u7ed3\u6784\u5316\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\uff0c\u5728Verilog\u786c\u4ef6\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\uff0c\u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u4f18\u5316\u65b9\u9762\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "Verilog\u786c\u4ef6\u8bbe\u8ba1\u5468\u671f\u52b3\u52a8\u5bc6\u96c6\u4e14\u9700\u8981\u5927\u91cf\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u6709\u9650\u548c\u987a\u5e8f\u63a8\u7406\u7279\u6027\uff0c\u96be\u4ee5\u6355\u6349\u786c\u4ef6\u7cfb\u7edf\u7684\u4e25\u683c\u5f62\u5f0f\u903b\u8f91\u548c\u5e76\u53d1\u7279\u6027\u3002", "method": "\u63d0\u51faEvolVE\u6846\u67b6\uff0c\u5206\u6790\u591a\u79cd\u8fdb\u5316\u7b56\u7565\uff1a\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u7528\u4e8e\u6700\u5927\u5316\u529f\u80fd\u6b63\u786e\u6027\uff0c\u60f3\u6cd5\u5f15\u5bfc\u7cbe\u70bc\uff08IGR\uff09\u7528\u4e8e\u4f18\u5316\uff1b\u91c7\u7528\u7ed3\u6784\u5316\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\uff08STG\uff09\u52a0\u901f\u8fdb\u5316\u8fc7\u7a0b\uff1b\u5f15\u5165IC-RTL\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u9488\u5bf9\u884c\u4e1a\u89c4\u6a21\u95ee\u9898\u3002", "result": "\u5728VerilogEval v2\u4e0a\u8fbe\u523098.1%\uff0c\u5728RTLLM v2\u4e0a\u8fbe\u523092%\uff1b\u5728\u884c\u4e1a\u89c4\u6a21\u7684IC-RTL\u5957\u4ef6\u4e0a\uff0c\u8d85\u8d8a\u7ade\u8d5b\u53c2\u4e0e\u8005\u53c2\u8003\u5b9e\u73b0\uff0c\u5728\u54c8\u592b\u66fc\u7f16\u7801\u4e2d\u5c06PPA\uff08\u529f\u8017\u3001\u6027\u80fd\u3001\u9762\u79ef\uff09\u4e58\u79ef\u964d\u4f4e66%\uff0c\u6240\u6709\u95ee\u9898\u7684\u51e0\u4f55\u5e73\u5747\u503c\u964d\u4f4e17%\u3002", "conclusion": "EvolVE\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u8fdb\u5316\u7b56\u7565\u548c\u7ed3\u6784\u5316\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u786c\u4ef6\u8bbe\u8ba1\u81ea\u52a8\u5316\u7684\u6311\u6218\uff0c\u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u4f18\u5316\u65b9\u9762\u5747\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2601.18119", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18119", "abs": "https://arxiv.org/abs/2601.18119", "authors": ["Jing Ye", "Yiwen Duan", "Yonghong Yu", "Victor Ma", "Yang Gao", "Xing Chen"], "title": "Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?", "comment": null, "summary": "SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.\n  OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.\n  Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.", "AI": {"tldr": "OurBench\u662f\u9996\u4e2a\u4f01\u4e1a\u7ea7SQL\u63a8\u7406\u4e0e\u8c03\u8bd5\u57fa\u51c6\uff0c\u5305\u542b469\u4e2a\u8bed\u6cd5\u9519\u8bef\u67e5\u8be2\u548c516\u4e2a\u8bed\u4e49\u9519\u8bef\u67e5\u8be2\uff0c\u901a\u8fc7\u81ea\u52a8\u6ce8\u5165\u771f\u5b9e\u9519\u8bef\u6784\u5efa\uff0c\u8bc4\u4f30\u663e\u793a\u73b0\u6709LLM\u5728\u590d\u6742SQL\u8c03\u8bd5\u4e0a\u8868\u73b0\u4e0d\u4f73\uff08\u6700\u4f73\u6a21\u578b\u51c6\u786e\u7387\u4ec536%\uff09\u3002", "motivation": "\u4f01\u4e1a\u6570\u636e\u5de5\u7a0b\u4e2dSQL\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5373\u4f7f\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u53d1\u8005\u548c\u5148\u8fdbLLM\u4e5f\u96be\u4ee5\u4e00\u6b21\u6027\u751f\u6210\u5b8c\u5168\u6b63\u786e\u7684SQL\u4ee3\u7801\uff0c\u901a\u5e38\u9700\u8981\u591a\u6b21\u8c03\u8bd5\u8fed\u4ee3\uff0c\u7f3a\u4e4f\u4e13\u95e8\u7684\u4f01\u4e1a\u7ea7SQL\u8c03\u8bd5\u57fa\u51c6\u3002", "method": "\u91c7\u7528\u81ea\u52a8\u5316\u6784\u5efa\u6d41\u7a0b\uff1a1) \u4f7f\u7528\u9006\u5411\u5de5\u7a0b\u5728\u5927\u89c4\u6a21SQL\u4ee3\u7801\u4e2d\u7cfb\u7edf\u6ce8\u5165\u771f\u5b9e\u9519\u8bef\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u591a\u6837\u5316\u57fa\u51c6\u751f\u6210\uff1b2) \u8bbe\u8ba1\u9762\u5411\u4f01\u4e1a\u73af\u5883\u7684\u514d\u6267\u884c\u8bc4\u4f30\u6846\u67b6\uff0c\u63d0\u4f9b\u5feb\u901f\u3001\u51c6\u786e\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u8bc4\u4f30\u3002", "result": "OurBench\u5305\u542b469\u4e2a\u5e26\u660e\u786e\u9519\u8bef\u4fe1\u606f\u7684\u8bed\u6cd5\u9519\u8bef\u67e5\u8be2\u548c516\u4e2a\u8bed\u4e49\u9519\u8bef\u67e5\u8be2\uff0c\u67e5\u8be2\u5e73\u5747\u8d85\u8fc7140\u884c\u4e14\u5177\u6709\u6df1\u5e7f\u7684\u62bd\u8c61\u8bed\u6cd5\u6811\u3002\u8bc4\u4f30\u8fd130\u4e2aLLM\u663e\u793a\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff1a\u6700\u4f73\u6a21\u578bClaude-4-Sonnet\u5728\u8bed\u6cd5\u9519\u8bef\u4e0a\u4ec536.46%\u51c6\u786e\u7387\uff0c\u8bed\u4e49\u9519\u8bef\u4e0a32.17%\uff0c\u5927\u591a\u6570\u6a21\u578b\u4f4e\u4e8e20%\u3002", "conclusion": "\u4f01\u4e1a\u7ea7SQL\u8c03\u8bd5\u5bf9\u73b0\u6709LLM\u4ecd\u5177\u6311\u6218\u6027\uff0c\u7814\u7a76\u63a2\u7d22\u4e86\u56db\u79cd\u89e3\u51b3\u65b9\u6848\u7b56\u7565\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u6311\u6218\uff0c\u5e76\u4e3aLLM\u5728\u4f01\u4e1aSQL\u8c03\u8bd5\u4e2d\u7684\u5e94\u7528\u6307\u660e\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2601.18123", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18123", "abs": "https://arxiv.org/abs/2601.18123", "authors": ["Muhammad Ibrahim Khan", "Bivin Pradeep", "James Brusey"], "title": "Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters", "comment": "Accepted at AAAI 2026", "summary": "Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u622a\u6b62\u65f6\u95f4\u611f\u77e5\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5bb6\u7528\u6d78\u5165\u5f0f\u70ed\u6c34\u5668\u80fd\u8017\uff0c\u5728\u6307\u5b9a\u65f6\u95f4\u8fbe\u5230\u76ee\u6807\u6e29\u5ea6\u7684\u540c\u65f6\u6700\u5c0f\u5316\u80fd\u91cf\u6d88\u8017\u3002", "motivation": "\u4f20\u7edf\u5bb6\u7528\u6d78\u5165\u5f0f\u70ed\u6c34\u5668\u5728\u51ac\u5b63\u901a\u5e38\u8fde\u7eed\u8fd0\u884c\uff0c\u53ea\u8ffd\u6c42\u5feb\u901f\u52a0\u70ed\u800c\u5ffd\u89c6\u6548\u7387\uff0c\u5ffd\u7565\u4e86\u53ef\u9884\u6d4b\u7684\u9700\u6c42\u7a97\u53e3\u548c\u73af\u5883\u70ed\u635f\u5931\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5728\u6307\u5b9a\u622a\u6b62\u65f6\u95f4\u8fbe\u5230\u76ee\u6807\u6e29\u5ea6\u7684\u540c\u65f6\u6700\u5c0f\u5316\u80fd\u8017\u7684\u667a\u80fd\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86Gymnasium\u4eff\u771f\u73af\u5883\uff0c\u6a21\u62df\u5177\u6709\u4e00\u9636\u70ed\u635f\u5931\u7684\u6d78\u5165\u5f0f\u70ed\u6c34\u5668\uff0c\u6bcf120\u79d2\u6267\u884c0W\u62166000W\u7684\u79bb\u6563\u5f00\u5173\u52a8\u4f5c\u3002\u6bd4\u8f83\u4e86\u4e09\u79cd\u65b9\u6cd5\uff1a\u65f6\u95f4\u6700\u4f18\u7684bang-bang\u57fa\u7ebf\u63a7\u5236\u3001\u96f6\u6837\u672c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u89c4\u5212\u5668\u3001\u4ee5\u53ca\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u57282\u5c0f\u65f6\uff0860\u6b65\uff09\u65f6\u95f4\u8303\u56f4\u5185\uff0cPPO\u7b56\u7565\u4ec5\u6d88\u80173.23\u5343\u74e6\u65f6\u80fd\u91cf\uff0c\u76f8\u6bd4bang-bang\u63a7\u5236\u76844.37-10.45\u5343\u74e6\u65f6\u548cMCTS\u76844.18-6.46\u5343\u74e6\u65f6\u8868\u73b0\u6700\u4f18\u3002\u5728\u5178\u578b\u573a\u666f\u4e2d\uff0850kg\u6c34\u8d28\u91cf\uff0c20\u00b0C\u73af\u5883\u6e29\u5ea6\uff0c60\u00b0C\u76ee\u6807\u6e29\u5ea6\uff09\uff0cPPO\u6bd4bang-bang\u8282\u80fd54%\uff0c\u6bd4MCTS\u8282\u80fd33%\u3002", "conclusion": "\u5b66\u4e60\u578b\u622a\u6b62\u65f6\u95f4\u611f\u77e5\u63a7\u5236\u80fd\u5728\u76f8\u540c\u7269\u7406\u6761\u4ef6\u4e0b\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff0c\u89c4\u5212\u5668\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u63d0\u4f9b\u90e8\u5206\u8282\u80fd\u6548\u679c\uff0c\u800c\u8bad\u7ec3\u540e\u7684\u5b66\u4e60\u7b56\u7565\u5728\u63a8\u7406\u65f6\u6210\u672c\u51e0\u4e4e\u4e3a\u96f6\uff0c\u4e3a\u667a\u80fd\u70ed\u6c34\u5668\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18130", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18130", "abs": "https://arxiv.org/abs/2601.18130", "authors": ["Jize Wang", "Han Wu", "Zhiyuan You", "Yiming Song", "Yijun Wang", "Zifei Shan", "Yining Li", "Songyang Zhang", "Xinyi Le", "Cailian Chen", "Xinping Guan", "Dacheng Tao"], "title": "RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents", "comment": null, "summary": "Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.", "AI": {"tldr": "RouteMoA\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u6df7\u5408\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u7531\u673a\u5236\u89e3\u51b3\u4f20\u7edfMoA\u65b9\u6cd5\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u8bc4\u5206\u5668\u9884\u7b5b\u9009\u6a21\u578b\uff0c\u7ed3\u5408\u6df7\u5408\u8bc4\u4f30\u5668\u8fdb\u884c\u540e\u9a8c\u4fee\u6b63\uff0c\u5b9e\u73b0\u6210\u672c\u964d\u4f4e89.8%\u548c\u5ef6\u8fdf\u51cf\u5c1163.6%\u3002", "motivation": "\u4f20\u7edf\u6df7\u5408\u667a\u80fd\u4f53(MoA)\u65b9\u6cd5\u901a\u8fc7\u5206\u5c42\u534f\u4f5c\u63d0\u5347LLM\u6027\u80fd\uff0c\u4f46\u5176\u5bc6\u96c6\u62d3\u6251\u7ed3\u6784\u5bfc\u81f4\u6210\u672c\u9ad8\u3001\u5ef6\u8fdf\u5927\u3002\u73b0\u6709\u65b9\u6cd5\u867d\u7136\u4f7f\u7528LLM\u8bc4\u5224\u5668\u8fc7\u6ee4\u54cd\u5e94\uff0c\u4f46\u4ecd\u9700\u6240\u6709\u6a21\u578b\u5148\u8fdb\u884c\u63a8\u7406\u518d\u8bc4\u5224\uff0c\u65e0\u6cd5\u6709\u6548\u964d\u4f4e\u6210\u672c\u3002\u540c\u65f6\u7f3a\u4e4f\u6a21\u578b\u9009\u62e9\u6807\u51c6\uff0c\u5728\u5927\u89c4\u6a21\u6a21\u578b\u6c60\u4e2d\u9762\u4e34\u6210\u672c\u8fc7\u9ad8\u548c\u4e0a\u4e0b\u6587\u9650\u5236\u95ee\u9898\u3002", "method": "RouteMoA\u91c7\u7528\u52a8\u6001\u8def\u7531\u6846\u67b6\uff1a1) \u8f7b\u91cf\u7ea7\u8bc4\u5206\u5668\u6839\u636e\u67e5\u8be2\u9884\u6d4b\u7c97\u7565\u6027\u80fd\uff0c\u9884\u7b5b\u9009\u9ad8\u6f5c\u529b\u5019\u9009\u6a21\u578b\u5b50\u96c6\uff0c\u907f\u514d\u5b8c\u6574\u63a8\u7406\uff1b2) \u6df7\u5408\u8bc4\u4f30\u5668\u901a\u8fc7\u8f7b\u91cf\u7ea7\u81ea\u8bc4\u4f30\u548c\u4ea4\u53c9\u8bc4\u4f30\u5bf9\u73b0\u6709\u6a21\u578b\u8f93\u51fa\u8fdb\u884c\u540e\u9a8c\u4fee\u6b63\uff1b3) \u6a21\u578b\u6392\u540d\u673a\u5236\u7efc\u5408\u8003\u8651\u6027\u80fd\u3001\u6210\u672c\u548c\u5ef6\u8fdf\u8fdb\u884c\u6a21\u578b\u9009\u62e9\u3002", "result": "RouteMoA\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6a21\u578b\u6c60\u89c4\u6a21\u4e0b\u5747\u4f18\u4e8e\u4f20\u7edfMoA\u65b9\u6cd5\uff0c\u5728\u5927\u89c4\u6a21\u6a21\u578b\u6c60\u4e2d\u5b9e\u73b0\u6210\u672c\u964d\u4f4e89.8%\uff0c\u5ef6\u8fdf\u51cf\u5c1163.6%\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "RouteMoA\u901a\u8fc7\u52a8\u6001\u8def\u7531\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u6df7\u5408\u667a\u80fd\u4f53\u65b9\u6cd5\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5927\u89c4\u6a21\u6a21\u578b\u534f\u4f5c\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18132", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18132", "abs": "https://arxiv.org/abs/2601.18132", "authors": ["Xi Chen", "Hongru Zhou", "Huahui Yi", "Shiyu Feng", "Hanyu Zhou", "Tiancheng He", "Mingke You", "Li Wang", "Qiankun Li", "Kun Wang", "Weili Fu", "Kang Li", "Jian Li"], "title": "RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening", "comment": "28 page, 3 figures", "summary": "Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.", "AI": {"tldr": "RareAlert\u662f\u4e00\u4e2a\u57fa\u4e8e\u591aLLM\u63a8\u7406\u6821\u51c6\u7684\u7f55\u89c1\u75c5\u65e9\u671f\u7b5b\u67e5\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u540810\u4e2aLLM\u7684\u63a8\u7406\u4fe1\u53f7\uff0c\u8bad\u7ec3\u51fa\u53ef\u672c\u5730\u90e8\u7f72\u7684\u5355\u4e00\u6a21\u578b\uff0c\u5728158,666\u4f8b\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u5b9e\u73b0\u4e860.917\u7684AUC\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u6240\u6709\u8bc4\u4f30\u7684LLM\u3002", "motivation": "\u7f55\u89c1\u75c5\u7684\u6f0f\u8bca\u548c\u5ef6\u8fdf\u8bca\u65ad\u662f\u533b\u7597\u9886\u57df\u7684\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u521d\u7ea7\u4fdd\u5065\u5206\u8bca\u6d41\u7a0b\u5728\u521d\u6b21\u4e34\u5e8a\u5c31\u8bca\u65f6\u65e0\u6cd5\u53ef\u9760\u8bc6\u522b\u7f55\u89c1\u75c5\u60a3\u8005\uff0c\u9700\u8981\u4e00\u79cd\u901a\u7528\u7b5b\u67e5\u7cfb\u7edf\u6765\u51cf\u5c11\u8bca\u65ad\u5ef6\u8fdf\u3002", "method": "\u5f00\u53d1\u4e86RareAlert\u7cfb\u7edf\uff0c\u6574\u540810\u4e2aLLM\u751f\u6210\u7684\u63a8\u7406\u4fe1\u53f7\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u6821\u51c6\u548c\u52a0\u6743\uff0c\u5e76\u5c06\u5bf9\u9f50\u7684\u63a8\u7406\u84b8\u998f\u5230\u5355\u4e2a\u53ef\u672c\u5730\u90e8\u7f72\u7684\u6a21\u578b\u4e2d\u3002\u4f7f\u7528RareBench\u6570\u636e\u96c6\uff08158,666\u4f8b\u75c5\u4f8b\uff0c\u8986\u76d633\u4e2aOrphanet\u75be\u75c5\u7c7b\u522b\u548c7,000\u591a\u79cd\u7f55\u89c1\u75c5\uff09\u8fdb\u884c\u5f00\u53d1\u548c\u8bc4\u4f30\u3002", "result": "RareAlert\u5728\u72ec\u7acb\u6d4b\u8bd5\u96c6\u4e0a\u5b9e\u73b0\u4e860.917\u7684AUC\uff0c\u4f18\u4e8e\u6700\u4f73\u673a\u5668\u5b66\u4e60\u96c6\u6210\u6a21\u578b\u548c\u6240\u6709\u8bc4\u4f30\u7684LLM\uff08\u5305\u62ecGPT-5\u3001DeepSeek-R1\u3001Claude-3.7-Sonnet\u7b49\uff09\u3002\u8bc1\u660e\u4e86LLM\u533b\u5b66\u63a8\u7406\u7684\u591a\u6837\u6027\u4ee5\u53ca\u5728\u9ad8\u4e0d\u786e\u5b9a\u6027\u4e34\u5e8a\u4efb\u52a1\u4e2d\u5bf9\u9f50\u8fd9\u79cd\u63a8\u7406\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7f55\u89c1\u75c5\u8bc6\u522b\u53ef\u4ee5\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u5e94\u7528\u4e8e\u666e\u901a\u60a3\u8005\u7fa4\u4f53\u7684\u901a\u7528\u4e0d\u786e\u5b9a\u6027\u89e3\u51b3\u8fc7\u7a0b\u3002\u901a\u8fc7\u5c06\u6821\u51c6\u63a8\u7406\u6574\u5408\u5230\u5355\u4e00\u6a21\u578b\u4e2d\uff0cRareAlert\u5b9e\u73b0\u4e86\u51c6\u786e\u3001\u4fdd\u62a4\u9690\u79c1\u4e14\u53ef\u6269\u5c55\u7684\u7f55\u89c1\u75c5\u98ce\u9669\u7b5b\u67e5\uff0c\u9002\u5408\u5927\u89c4\u6a21\u672c\u5730\u90e8\u7f72\u3002"}}
{"id": "2601.18137", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18137", "abs": "https://arxiv.org/abs/2601.18137", "authors": ["Yinger Zhang", "Shutong Jiang", "Renhao Li", "Jianhong Tu", "Yang Su", "Lianghao Deng", "Xudong Guo", "Chenxu Lv", "Junyang Lin"], "title": "DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints", "comment": null, "summary": "While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.", "AI": {"tldr": "DeepPlanning\u662f\u4e00\u4e2a\u9488\u5bf9\u5b9e\u9645\u957f\u65f6\u7a0b\u667a\u80fd\u4f53\u89c4\u5212\u7684\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u591a\u65e5\u65c5\u884c\u89c4\u5212\u548c\u591a\u4ea7\u54c1\u8d2d\u7269\u4efb\u52a1\uff0c\u8981\u6c42\u4e3b\u52a8\u4fe1\u606f\u83b7\u53d6\u3001\u5c40\u90e8\u7ea6\u675f\u63a8\u7406\u548c\u5168\u5c40\u7ea6\u675f\u4f18\u5316", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u8bc4\u4f30\u867d\u7136\u8f6c\u5411\u957f\u65f6\u7a0b\u4efb\u52a1\uff0c\u4f46\u5927\u591a\u6570\u57fa\u51c6\u6d4b\u8bd5\u4ecd\u5f3a\u8c03\u5c40\u90e8\u3001\u6b65\u9aa4\u7ea7\u63a8\u7406\uff0c\u800c\u975e\u9700\u8981\u771f\u6b63\u89c4\u5212\u80fd\u529b\u7684\u5168\u5c40\u7ea6\u675f\u4f18\u5316\uff08\u5982\u65f6\u95f4\u548c\u8d22\u52a1\u9884\u7b97\uff09\u3002\u540c\u65f6\uff0c\u73b0\u6709LLM\u89c4\u5212\u57fa\u51c6\u672a\u80fd\u5145\u5206\u4f53\u73b0\u73b0\u5b9e\u4e16\u754c\u4e2d\u5178\u578b\u7684\u4e3b\u52a8\u4fe1\u606f\u6536\u96c6\u548c\u7ec6\u7c92\u5ea6\u5c40\u90e8\u7ea6\u675f", "method": "\u5f15\u5165DeepPlanning\u57fa\u51c6\uff0c\u5305\u542b\u591a\u65e5\u65c5\u884c\u89c4\u5212\u548c\u591a\u4ea7\u54c1\u8d2d\u7269\u4e24\u7c7b\u4efb\u52a1\uff0c\u8fd9\u4e9b\u4efb\u52a1\u8981\u6c42\u667a\u80fd\u4f53\u8fdb\u884c\u4e3b\u52a8\u4fe1\u606f\u83b7\u53d6\u3001\u5c40\u90e8\u7ea6\u675f\u63a8\u7406\u548c\u5168\u5c40\u7ea6\u675f\u4f18\u5316", "result": "\u8bc4\u4f30\u663e\u793a\u5373\u4f7f\u662f\u524d\u6cbf\u7684\u667a\u80fd\u4f53LLM\u5728\u8fd9\u4e9b\u95ee\u9898\u4e0a\u4e5f\u8868\u73b0\u4e0d\u4f73\uff0c\u7a81\u663e\u4e86\u53ef\u9760\u7684\u663e\u5f0f\u63a8\u7406\u6a21\u5f0f\u548c\u5e76\u884c\u5de5\u5177\u4f7f\u7528\u5bf9\u4e8e\u5b9e\u73b0\u66f4\u597d\u7684\u6548\u679c-\u6548\u7387\u6743\u8861\u7684\u91cd\u8981\u6027", "conclusion": "DeepPlanning\u57fa\u51c6\u63ed\u793a\u4e86\u5f53\u524d\u667a\u80fd\u4f53LLM\u5728\u957f\u89c4\u5212\u65f6\u7a0b\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u9519\u8bef\u5206\u6790\u6307\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\uff0c\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76"}}
{"id": "2601.18175", "categories": ["cs.AI", "cs.LG", "eess.SY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18175", "abs": "https://arxiv.org/abs/2601.18175", "authors": ["Daniel Russo"], "title": "Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success", "comment": null, "summary": "A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $\u03c7^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.", "AI": {"tldr": "\u6210\u529f\u6761\u4ef6\u5316\uff08success conditioning\uff09\u662f\u4e00\u79cd\u901a\u8fc7\u6536\u96c6\u8f68\u8ff9\u3001\u8bc6\u522b\u6210\u529f\u8f68\u8ff9\u5e76\u6a21\u4eff\u5176\u884c\u52a8\u6765\u6539\u8fdb\u7b56\u7565\u7684\u5e7f\u6cdb\u4f7f\u7528\u6280\u672f\u3002\u672c\u6587\u8bc1\u660e\u8be5\u65b9\u6cd5\u5b9e\u9645\u4e0a\u7cbe\u786e\u89e3\u51b3\u4e86\u4e00\u4e2a\u4fe1\u4efb\u57df\u4f18\u5316\u95ee\u9898\uff0c\u5728\u6570\u636e\u81ea\u52a8\u786e\u5b9a\u7684\u03c7\u00b2\u6563\u5ea6\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u7b56\u7565\u6539\u8fdb\u3002", "motivation": "\u6210\u529f\u6761\u4ef6\u5316\u6280\u672f\u4ee5\u591a\u79cd\u540d\u79f0\u51fa\u73b0\uff08\u5982\u62d2\u7edd\u91c7\u6837+SFT\u3001\u76ee\u6807\u6761\u4ef6RL\u3001\u51b3\u7b56\u53d8\u6362\u5668\u7b49\uff09\uff0c\u4f46\u5176\u89e3\u51b3\u7684\u4f18\u5316\u95ee\u9898\u672c\u8d28\u4e00\u76f4\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u8be5\u65b9\u6cd5\u7684\u6570\u5b66\u57fa\u7840\uff0c\u9610\u660e\u5176\u4f5c\u4e3a\u4fdd\u5b88\u6539\u8fdb\u7b97\u5b50\u7684\u7406\u8bba\u6027\u8d28\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u6210\u529f\u6761\u4ef6\u5316\u7cbe\u786e\u89e3\u51b3\u4e86\u4e00\u4e2a\u4fe1\u4efb\u57df\u4f18\u5316\u95ee\u9898\uff1a\u5728\u03c7\u00b2\u6563\u5ea6\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u7b56\u7565\u6539\u8fdb\uff0c\u7ea6\u675f\u534a\u5f84\u7531\u6570\u636e\u81ea\u52a8\u786e\u5b9a\u3002\u5efa\u7acb\u4e86\u76f8\u5bf9\u7b56\u7565\u6539\u8fdb\u3001\u7b56\u7565\u53d8\u5316\u5e45\u5ea6\u548c\u52a8\u4f5c\u5f71\u54cd\u4e09\u8005\u76f8\u7b49\u7684\u6052\u7b49\u5f0f\u3002", "result": "\u6210\u529f\u6761\u4ef6\u5316\u88ab\u8bc1\u660e\u662f\u4e00\u4e2a\u4fdd\u5b88\u6539\u8fdb\u7b97\u5b50\uff0c\u4e0d\u4f1a\u964d\u4f4e\u6027\u80fd\u6216\u5f15\u53d1\u5371\u9669\u7684\u5206\u5e03\u504f\u79fb\u3002\u5f53\u5931\u8d25\u65f6\uff0c\u5b83\u4f1a\u901a\u8fc7\u51e0\u4e4e\u4e0d\u6539\u53d8\u7b56\u7565\u6765\u53ef\u89c2\u5bdf\u5730\u5931\u8d25\u3002\u7406\u8bba\u8fd8\u5e94\u7528\u4e8e\u5e38\u89c1\u7684\u56de\u62a5\u9608\u503c\u5316\u5b9e\u8df5\uff0c\u663e\u793a\u5176\u80fd\u653e\u5927\u6539\u8fdb\u4f46\u53ef\u80fd\u504f\u79bb\u771f\u5b9e\u76ee\u6807\u3002", "conclusion": "\u6210\u529f\u6761\u4ef6\u5316\u5177\u6709\u575a\u5b9e\u7684\u6570\u5b66\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\u7279\u5b9a\u7684\u4fe1\u4efb\u57df\u4f18\u5316\u95ee\u9898\u3002\u5b83\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b89\u5168\u3001\u4fdd\u5b88\u7684\u7b56\u7565\u6539\u8fdb\u65b9\u6cd5\uff0c\u5176\u5931\u8d25\u6a21\u5f0f\u53ef\u89c2\u5bdf\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2601.18217", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18217", "abs": "https://arxiv.org/abs/2601.18217", "authors": ["Zhihan Liu", "Lin Guan", "Yixin Nie", "Kai Zhang", "Zhuoqun Hao", "Lin Chen", "Asli Celikyilmaz", "Zhaoran Wang", "Na Zhang"], "title": "Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents", "comment": null, "summary": "Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.", "AI": {"tldr": "\u7814\u7a76LLM\u667a\u80fd\u4f53\u5728\u672a\u77e5\u6d4b\u8bd5\u9886\u57df\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u73af\u5883\u72b6\u6001\u4fe1\u606f\u4e30\u5bcc\u5ea6\u548c\u89c4\u5212\u590d\u6742\u5ea6\u662f\u5f71\u54cd\u8de8\u57df\u6cdb\u5316\u7684\u5173\u952e\u56e0\u7d20\uff0c\u800c\u975e\u9886\u57df\u771f\u5b9e\u6027\u6216\u6587\u672c\u76f8\u4f3c\u6027\u3002", "motivation": "\u901a\u7528LLM\u667a\u80fd\u4f53\u901a\u5e38\u5728\u72ed\u7a84\u73af\u5883\u96c6\u4e0a\u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u4f46\u90e8\u7f72\u5230\u66f4\u5e7f\u6cdb\u7684\u672a\u77e5\u9886\u57df\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5f53\u6700\u7ec8\u6d4b\u8bd5\u9886\u57df\u672a\u77e5\u65f6\uff0c\u667a\u80fd\u4f53\u540e\u8bad\u7ec3\u9762\u4e34\u7684\u6311\u6218\uff0c\u5206\u6790\u54ea\u4e9bRL\u73af\u5883\u5c5e\u6027\u548c\u5efa\u6a21\u9009\u62e9\u5bf9\u8de8\u57df\u6027\u80fd\u5f71\u54cd\u6700\u5927\u3002", "method": "\u9996\u5148\u8bc6\u522b\u4e0e\u8de8\u57df\u6cdb\u5316\u5f3a\u76f8\u5173\u7684\u4e24\u4e2a\u73af\u5883\u8f74\uff1a\u72b6\u6001\u4fe1\u606f\u4e30\u5bcc\u5ea6\uff08agent\u9700\u8981\u5904\u7406\u7684\u4fe1\u606f\u91cf\uff09\u548c\u89c4\u5212\u590d\u6742\u5ea6\uff08\u901a\u8fc7\u57fa\u7840\u7b56\u7565\u4e0b\u7684\u76ee\u6807\u53ef\u8fbe\u6027\u548c\u8f68\u8ff9\u957f\u5ea6\u4f30\u8ba1\uff09\u3002\u63d0\u51fa\u968f\u673a\u5316\u6280\u672f\uff1a\u5728\u72b6\u6001\u4e2d\u6dfb\u52a0\u5c11\u91cf\u5206\u6563\u6ce8\u610f\u529b\u7684\u76ee\u6807\u65e0\u5173\u7279\u5f81\u6765\u589e\u52a0\u4e30\u5bcc\u5ea6\u800c\u4e0d\u6539\u53d8\u4efb\u52a1\u3002\u540c\u65f6\u7814\u7a76\u5efa\u6a21\u9009\u62e9\uff1aSFT\u9884\u70ed\u6216\u4e2d\u671f\u8bad\u7ec3\u7684\u5f71\u54cd\uff0c\u4ee5\u53caRL\u671f\u95f4\u5f00\u542f\u9010\u6b65\u601d\u8003\u7684\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u72b6\u6001\u4fe1\u606f\u4e30\u5bcc\u5ea6\u548c\u89c4\u5212\u590d\u6742\u5ea6\u662f\u8de8\u57df\u6cdb\u5316\u7684\u4e3b\u8981\u51b3\u5b9a\u56e0\u7d20\uff0c\u800c\u9886\u57df\u771f\u5b9e\u6027\u548c\u6587\u672c\u76f8\u4f3c\u6027\u4e0d\u662f\u5173\u952e\u56e0\u7d20\u3002\u589e\u52a0\u72b6\u6001\u4fe1\u606f\u4e30\u5bcc\u5ea6\u80fd\u6709\u6548\u63d0\u9ad8\u8de8\u57df\u9c81\u68d2\u6027\u3002SFT\u9884\u70ed\u6216\u4e2d\u671f\u8bad\u7ec3\u867d\u80fd\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4f46\u4f1a\u524a\u5f31\u5bf9\u672a\u5305\u542b\u5728\u4e2d\u671f\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u3002RL\u671f\u95f4\u7684\u9010\u6b65\u601d\u8003\u867d\u4e0d\u603b\u662f\u63d0\u9ad8\u57df\u5185\u6027\u80fd\uff0c\u4f46\u5bf9\u4fdd\u6301\u6cdb\u5316\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8de8\u57df\u6cdb\u5316\u4e3b\u8981\u53d7\u73af\u5883\u72b6\u6001\u4fe1\u606f\u4e30\u5bcc\u5ea6\u548c\u89c4\u5212\u590d\u6742\u5ea6\u5f71\u54cd\uff0c\u800c\u975e\u9886\u57df\u771f\u5b9e\u6027\u3002\u901a\u8fc7\u6dfb\u52a0\u76ee\u6807\u65e0\u5173\u7279\u5f81\u589e\u52a0\u72b6\u6001\u4e30\u5bcc\u5ea6\u662f\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u7684\u6709\u6548\u65b9\u6cd5\u3002\u5728\u8bad\u7ec3\u7b56\u7565\u4e0a\uff0c\u9700\u8981\u5728\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\u548c\u4fdd\u6301\u6cdb\u5316\u80fd\u529b\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u9010\u6b65\u601d\u8003\u662f\u4fdd\u6301\u6cdb\u5316\u80fd\u529b\u7684\u91cd\u8981\u673a\u5236\u3002"}}
{"id": "2601.18226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18226", "abs": "https://arxiv.org/abs/2601.18226", "authors": ["Haotian Li", "Shijun Yang", "Weizhen Qi", "Silei Zhao", "Rui Hua", "Mingzhu Song", "Xiaojian Yang", "Chao Peng"], "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks", "comment": null, "summary": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.", "AI": {"tldr": "\u63d0\u51faIn-Situ Self-Evolving\u8303\u5f0f\uff0c\u901a\u8fc7Yunjue Agent\u7cfb\u7edf\u5728\u5f00\u653e\u73af\u5883\u4e2d\u81ea\u6211\u6f14\u5316\u5de5\u5177\u96c6\uff0c\u5229\u7528\u4efb\u52a1\u4ea4\u4e92\u53cd\u9988\u6301\u7eed\u6269\u5c55\u80fd\u529b\u8fb9\u754c\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u76d1\u7763\u3002", "motivation": "\u4f20\u7edf\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u5f00\u653e\u73af\u5883\u4e2d\u9762\u4e34\u6311\u6218\uff1a\u4efb\u52a1\u5206\u5e03\u6301\u7eed\u6f02\u79fb\u3001\u5916\u90e8\u76d1\u7763\u7a00\u7f3a\uff0c\u4f9d\u8d56\u9759\u6001\u5de5\u5177\u96c6\u6216\u79bb\u7ebf\u8bad\u7ec3\u5bfc\u81f4\u80fd\u529b\u8fb9\u754c\u50f5\u5316\u4e14\u672a\u77e5\u3002", "method": "\u63d0\u51faIn-Situ Self-Evolving\u8303\u5f0f\uff0c\u5c06\u5e8f\u5217\u4efb\u52a1\u4ea4\u4e92\u89c6\u4e3a\u8fde\u7eed\u7ecf\u9a8c\u6d41\uff0c\u5c06\u77ed\u671f\u6267\u884c\u53cd\u9988\u63d0\u70bc\u4e3a\u957f\u671f\u53ef\u91cd\u7528\u80fd\u529b\u3002\u5177\u4f53\u5b9e\u73b0Yunjue Agent\u7cfb\u7edf\uff0c\u901a\u8fc7\u5de5\u5177\u6f14\u5316\u4f5c\u4e3a\u80fd\u529b\u6269\u5c55\u5173\u952e\u8def\u5f84\uff0c\u91c7\u7528Parallel Batch Evolution\u7b56\u7565\u4f18\u5316\u6f14\u5316\u6548\u7387\u3002", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u7684\u96f6\u8d77\u70b9\u8bbe\u7f6e\u4e0b\uff0c\u76f8\u6bd4\u4e13\u6709\u57fa\u7ebf\u83b7\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002\u8865\u5145\u7684\u6696\u542f\u52a8\u8bc4\u4f30\u8bc1\u5b9e\u79ef\u7d2f\u7684\u901a\u7528\u77e5\u8bc6\u53ef\u65e0\u7f1d\u8fc1\u79fb\u5230\u65b0\u9886\u57df\u3002\u63d0\u51fa\u4e86\u76d1\u6d4b\u6f14\u5316\u6536\u655b\u7684\u65b0\u6307\u6807\u3002", "conclusion": "In-Situ Self-Evolving\u8303\u5f0f\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u5f00\u653e\u73af\u5883\u4e2d\u6301\u7eed\u81ea\u6211\u6f14\u5316\uff0c\u5de5\u5177\u6f14\u5316\u4f5c\u4e3a\u53ef\u9a8c\u8bc1\u7684\u4e8c\u5143\u53cd\u9988\u4fe1\u53f7\u4e3a\u80fd\u529b\u6269\u5c55\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\u3002\u5f00\u6e90\u4ee3\u7801\u5e93\u3001\u7cfb\u7edf\u8f68\u8ff9\u548c\u6f14\u5316\u5de5\u5177\u4ee5\u4fc3\u8fdb\u5f39\u6027\u81ea\u6f14\u5316\u667a\u80fd\u7814\u7a76\u3002"}}
{"id": "2601.18282", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18282", "abs": "https://arxiv.org/abs/2601.18282", "authors": ["Lei Wei", "Jinpeng Ou", "Xiao Peng", "Bin Wang"], "title": "Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal \"think\" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.", "AI": {"tldr": "\u63d0\u51faThink-Augmented Function Calling (TAFC)\u6846\u67b6\uff0c\u901a\u8fc7\u51fd\u6570\u548c\u53c2\u6570\u7ea7\u522b\u7684\u663e\u5f0f\u63a8\u7406\u589e\u5f3aLLM\u51fd\u6570\u8c03\u7528\u51c6\u786e\u6027\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u67b6\u6784", "motivation": "\u5f53\u524dLLM\u5728\u51fd\u6570\u8c03\u7528\u4e2d\u7f3a\u4e4f\u53c2\u6570\u751f\u6210\u7684\u663e\u5f0f\u63a8\u7406\u900f\u660e\u5ea6\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5177\u6709\u76f8\u4e92\u4f9d\u8d56\u53c2\u6570\u7684\u590d\u6742\u51fd\u6570\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u601d\u7ef4\u94fe\u63d0\u793a\u5728\u667a\u80fd\u4f53\u7ea7\u522b\u64cd\u4f5c\uff0c\u65e0\u6cd5\u4e3a\u5355\u4e2a\u51fd\u6570\u53c2\u6570\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u7684\u63a8\u7406\u6307\u5bfc\u3002", "method": "\u63d0\u51faTAFC\u6846\u67b6\uff1a1) \u5f15\u5165\u901a\u7528\u7684\"think\"\u53c2\u6570\u589e\u5f3a\uff0c\u8ba9\u6a21\u578b\u9610\u8ff0\u51b3\u7b56\u8fc7\u7a0b\uff1b2) \u52a8\u6001\u4f18\u5316\u53c2\u6570\u63cf\u8ff0\u4ee5\u63d0\u9ad8\u63a8\u7406\u8d28\u91cf\uff1b3) \u5bf9\u590d\u6742\u53c2\u6570\u57fa\u4e8e\u590d\u6742\u5ea6\u8bc4\u5206\u81ea\u52a8\u89e6\u53d1\u7ec6\u7c92\u5ea6\u63a8\u7406\uff1b4) \u63d0\u51fa\u63a8\u7406\u5f15\u5bfc\u4f18\u5316\u4ee5\u5bf9\u9f50\u4eba\u7c7b\u671f\u671b\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u4fee\u6539\u73b0\u6709LLM\u67b6\u6784\uff0c\u4fdd\u6301\u5b8c\u5168API\u517c\u5bb9\u6027\u3002", "result": "\u5728ToolBench\u4e0a\u5bf9\u4e13\u6709\u548c\u5f00\u6e90\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\uff0cTAFC\u5728\u591a\u53c2\u6570\u51fd\u6570\u7684\u53c2\u6570\u751f\u6210\u51c6\u786e\u6027\u548c\u63a8\u7406\u8fde\u8d2f\u6027\u65b9\u9762\u6709\u663e\u8457\u6539\u8fdb\uff0c\u540c\u65f6\u4e3a\u8c03\u8bd5AI\u667a\u80fd\u4f53\u884c\u4e3a\u63d0\u4f9b\u4e86\u589e\u5f3a\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "TAFC\u901a\u8fc7\u663e\u5f0f\u63a8\u7406\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86LLM\u51fd\u6570\u8c03\u7528\u4e2d\u53c2\u6570\u751f\u6210\u7684\u900f\u660e\u5ea6\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u590d\u6742\u51fd\u6570\u8c03\u7528\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u73b0\u6709\u7cfb\u7edf\u7684\u517c\u5bb9\u6027\u3002"}}
{"id": "2601.18308", "categories": ["cs.AI", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.18308", "abs": "https://arxiv.org/abs/2601.18308", "authors": ["Geunsik Lim"], "title": "A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience", "comment": "19 pages", "summary": "As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.", "AI": {"tldr": "Climate RADAR\u662f\u4e00\u4e2a\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u707e\u5bb3\u9884\u8b66\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u591a\u6e90\u6570\u636e\u548c\u4e2a\u6027\u5316\u884c\u52a8\u5efa\u8bae\uff0c\u5c06\u4f20\u7edf\u9884\u8b66\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u884c\u52a8\uff0c\u63d0\u9ad8\u9632\u62a4\u63aa\u65bd\u6267\u884c\u7387\u548c\u54cd\u5e94\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\u867d\u7136\u80fd\u5feb\u901f\u4f20\u64ad\u8b66\u62a5\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u89e6\u53d1\u53ca\u65f6\u7684\u9632\u62a4\u884c\u52a8\uff0c\u5bfc\u81f4\u53ef\u9884\u9632\u7684\u635f\u5931\u548c\u4e0d\u516c\u5e73\u73b0\u8c61\u3002\u968f\u7740\u6c14\u5019\u76f8\u5173\u707e\u5bb3\u52a0\u5267\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u9884\u8b66\u673a\u5236\u3002", "method": "\u5f00\u53d1Climate RADAR\u7cfb\u7edf\uff0c\u6574\u5408\u6c14\u8c61\u3001\u6c34\u6587\u3001\u8106\u5f31\u6027\u548c\u793e\u4f1a\u6570\u636e\u5f62\u6210\u7efc\u5408\u98ce\u9669\u6307\u6570\uff0c\u4f7f\u7528\u5e26\u6709\u62a4\u680f\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u516c\u6c11\u3001\u5fd7\u613f\u8005\u548c\u5e02\u653f\u90e8\u95e8\u63d0\u4f9b\u4e2a\u6027\u5316\u884c\u52a8\u5efa\u8bae\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u3001\u7528\u6237\u7814\u7a76\u548c\u5e02\u653f\u8bd5\u70b9\u8bc4\u4f30\u663e\u793a\uff0c\u7cfb\u7edf\u63d0\u9ad8\u4e86\u9632\u62a4\u884c\u52a8\u6267\u884c\u7387\u3001\u51cf\u5c11\u4e86\u54cd\u5e94\u5ef6\u8fdf\u3001\u589e\u5f3a\u4e86\u53ef\u7528\u6027\u548c\u4fe1\u4efb\u5ea6\u3002", "conclusion": "Climate RADAR\u901a\u8fc7\u7ed3\u5408\u9884\u6d4b\u5206\u6790\u3001\u884c\u4e3a\u79d1\u5b66\u548c\u8d1f\u8d23\u4efbAI\uff0c\u63a8\u8fdb\u4e86\u4ee5\u4eba\u4e3a\u672c\u3001\u900f\u660e\u548c\u516c\u5e73\u7684\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\uff0c\u4e3a\u7b26\u5408\u8981\u6c42\u7684\u707e\u5bb3\u97e7\u6027\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2601.18353", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.18353", "abs": "https://arxiv.org/abs/2601.18353", "authors": ["Tuhin Chakrabarty", "Paramveer S. Dhillon"], "title": "Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books", "comment": "Proceedings of CHI 2026 Conference (To Appear)", "summary": "Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes \"good writing.\" These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u6a21\u4eff\u4f5c\u5bb6\u98ce\u683c\u65b9\u9762\u5df2\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\uff0c\u7279\u522b\u662f\u5728\u7ecf\u8fc7\u5fae\u8c03\u540e\uff0c\u4e13\u5bb6\u8bc4\u59d4\u4e5f\u66f4\u503e\u5411\u4e8eAI\u4f5c\u54c1\uff0c\u8fd9\u5f15\u53d1\u4e86\u521b\u610f\u5199\u4f5c\u9886\u57df\u7684\u8eab\u4efd\u5371\u673a", "motivation": "\u6311\u6218\u4f20\u7edf\u89c2\u5ff5\u2014\u2014\u521b\u610f\u5199\u4f5c\u957f\u671f\u4ee5\u6765\u88ab\u8ba4\u4e3a\u662f\u4eba\u7c7b\u72ec\u6709\u7684\u80fd\u529b\uff0c\u9700\u8981\u673a\u5668\u65e0\u6cd5\u590d\u5236\u7684\u72ec\u7279\u58f0\u97f3\u548c\u98ce\u683c\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u751f\u6210\u5f0fAI\u662f\u5426\u80fd\u591f\u771f\u6b63\u6a21\u4eff\u8457\u540d\u4f5c\u5bb6\u7684\u5199\u4f5c\u98ce\u683c\uff0c\u4ee5\u53ca\u8fd9\u5bf9\u521b\u610f\u5199\u4f5c\u9886\u57df\u610f\u5473\u7740\u4ec0\u4e48", "method": "\u884c\u4e3a\u5b9e\u9a8c\u8bbe\u8ba1\uff1a28\u4f4dMFA\u521b\u610f\u5199\u4f5c\u4e13\u5bb6\u4e0e3\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ade\u4e89\u6a21\u4eff50\u4f4d\u5907\u53d7\u597d\u8bc4\u7684\u4f5c\u5bb6\u98ce\u683c\u3002\u91c7\u7528\u76f2\u5ba1\u6210\u5bf9\u6bd4\u8f83\uff0c\u753128\u4f4d\u4e13\u5bb6\u8bc4\u59d4\u548c131\u4f4d\u666e\u901a\u8bc4\u59d4\u8fdb\u884c\u8bc4\u4f30\u3002\u6d4b\u8bd5\u4e24\u79cd\u6761\u4ef6\uff1a\u4e0a\u4e0b\u6587\u63d0\u793a\u548c\u57fa\u4e8e\u4f5c\u8005\u5b8c\u6574\u4f5c\u54c1\u5fae\u8c03", "result": "\u5728\u4e0a\u4e0b\u6587\u63d0\u793a\u6761\u4ef6\u4e0b\uff0c\u4e13\u5bb6\u8bc4\u59d482.7%\u66f4\u503e\u5411\u4e8e\u4eba\u7c7b\u5199\u4f5c\uff1b\u4f46\u7ecf\u8fc7\u5fae\u8c03\u540e\uff0c\u8fd9\u4e00\u504f\u597d\u9006\u8f6c\u4e3a62%\u503e\u5411\u4e8eAI\u5199\u4f5c\u3002\u666e\u901a\u8bc4\u59d4\u5219\u59cb\u7ec8\u66f4\u503e\u5411\u4e8eAI\u4f5c\u54c1\u3002\u4e13\u5bb6\u4f5c\u5bb6\u8bbf\u8c08\u663e\u793a\uff0c\u4ed6\u4eec\u5bf9AI\u5199\u4f5c\u7684\u504f\u597d\u5f15\u53d1\u4e86\u8eab\u4efd\u5371\u673a\uff0c\u524a\u5f31\u4e86\u5ba1\u7f8e\u81ea\u4fe1\uff0c\u8d28\u7591\u4e86\"\u597d\u5199\u4f5c\"\u7684\u5b9a\u4e49", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u5173\u4e8eAI\u521b\u610f\u5c40\u9650\u6027\u7684\u4f20\u7edf\u8bba\u8ff0\uff0c\u63d0\u51fa\u4e86\u5173\u4e8e\u521b\u610f\u52b3\u52a8\u672a\u6765\u7684\u6839\u672c\u6027\u95ee\u9898\u3002AI\u5728\u6a21\u4eff\u5199\u4f5c\u98ce\u683c\u65b9\u9762\u7684\u80fd\u529b\u5df2\u7ecf\u8fbe\u5230\u751a\u81f3\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\u6c34\u5e73\uff0c\u8fd9\u5bf9\u521b\u610f\u5199\u4f5c\u9886\u57df\u7684\u4e13\u4e1a\u8eab\u4efd\u548c\u5ba1\u7f8e\u6807\u51c6\u6784\u6210\u4e86\u6df1\u523b\u6311\u6218"}}
{"id": "2601.18383", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18383", "abs": "https://arxiv.org/abs/2601.18383", "authors": ["Zhenyuan Guo", "Tong Chen", "Wenlong Meng", "Chen Gong", "Xin Yu", "Chengkun Wei", "Wenzhi Chen"], "title": "Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDynTS\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u51b3\u7b56token\u5e76\u4ec5\u4fdd\u7559\u5176KV\u7f13\u5b58\uff0c\u6765\u4f18\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u751f\u6210\u63a8\u7406\u8f68\u8ff9\u65f6\u4f1a\u4ea7\u751f\u5927\u91cf\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u6210\u4e3a\u6548\u7387\u74f6\u9888\u3002\u7814\u7a76\u53d1\u73b0\u53ea\u6709\u90e8\u5206\u51b3\u7b56\u5173\u952etoken\u771f\u6b63\u5f71\u54cd\u6700\u7ec8\u7b54\u6848\uff0c\u5176\u4ed6token\u8d21\u732e\u5f88\u5c0f", "method": "\u63d0\u51fa\u52a8\u6001\u601d\u7ef4token\u9009\u62e9(DynTS)\u65b9\u6cd5\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u56fe\u5206\u6790\u63a8\u7406\u8f68\u8ff9\u7684\u5f71\u54cd\uff0c\u8bc6\u522b\u51b3\u7b56\u5173\u952etoken\uff0c\u5728\u63a8\u7406\u65f6\u4ec5\u4fdd\u7559\u8fd9\u4e9b\u5173\u952etoken\u7684KV\u7f13\u5b58\u72b6\u6001\uff0c\u5254\u9664\u5197\u4f59\u6761\u76ee", "result": "\u901a\u8fc7\u4ec5\u4fdd\u7559\u5173\u952e\u51b3\u7b56token\u7684KV\u7f13\u5b58\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u4f18\u5316\u4e86\u63a8\u7406\u6548\u7387", "conclusion": "DynTS\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u6027\u4fdd\u7559\u5173\u952etoken\u7684KV\u7f13\u5b58\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u5e26\u6765\u7684\u6548\u7387\u74f6\u9888\u95ee\u9898"}}
{"id": "2601.18496", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18496", "abs": "https://arxiv.org/abs/2601.18496", "authors": ["Zihan wang", "Hao Wang", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Yiqun Zhang", "Jinghao Lin", "Haihua Yang", "Xiaozhong Ji"], "title": "DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference", "comment": null, "summary": "Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus \"find it but fail to use it,\" leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\\% on average and outperforms larger medical reasoning and DR models.", "AI": {"tldr": "DeepMed\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u533b\u5b66\u9886\u57df\u7684\u6df1\u5ea6\u7814\u7a76\u6a21\u578b\uff0c\u901a\u8fc7\u89e3\u51b3\u4efb\u52a1\u7279\u6027\u548c\u5de5\u5177\u4f7f\u7528\u6269\u5c55\u4e24\u4e2a\u5173\u952e\u5dee\u8ddd\uff0c\u5728\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u533b\u5b66\u63a8\u7406\u6a21\u578b\u53d7\u9650\u4e8e\u53c2\u6570\u5316\u77e5\u8bc6\uff0c\u5bb9\u6613\u9057\u5fd8\u548c\u4ea7\u751f\u5e7b\u89c9\u3002\u901a\u7528\u6df1\u5ea6\u7814\u7a76\u6a21\u578b\u867d\u7136\u80fd\u5728\u4e00\u822c\u9886\u57df\u57fa\u4e8e\u5de5\u5177\u9a8c\u8bc1\u8bc1\u636e\uff0c\u4f46\u76f4\u63a5\u5e94\u7528\u4e8e\u533b\u5b66\u9886\u57df\u6548\u679c\u6709\u9650\uff0c\u4e3b\u8981\u5b58\u5728\u4e24\u4e2a\u5dee\u8ddd\uff1a\u4efb\u52a1\u7279\u6027\u5dee\u8ddd\uff08\u533b\u5b66\u95ee\u9898\u9700\u8981\u5728\u77e5\u8bc6\u5bc6\u96c6\u7684\u4e34\u5e8a\u73af\u5883\u4e2d\u89e3\u91ca\u8bc1\u636e\uff09\u548c\u5de5\u5177\u4f7f\u7528\u6269\u5c55\u5dee\u8ddd\uff08\u76f2\u76ee\u6269\u5c55\u5de5\u5177\u8c03\u7528\u4f1a\u5f15\u5165\u566a\u58f0\uff0c\u5e72\u6270\u654f\u611f\u7684\u533b\u5b66\u63a8\u7406\uff09\u3002", "method": "\u63d0\u51faDeepMed\u6a21\u578b\uff1a1\uff09\u6570\u636e\u65b9\u9762\uff0c\u91c7\u7528\u591a\u8df3\u533b\u5b66\u641c\u7d22QA\u5408\u6210\u65b9\u6cd5\uff0c\u652f\u6301\u6a21\u578b\u5728\u533b\u5b66\u73af\u5883\u4e2d\u5e94\u7528\u6df1\u5ea6\u7814\u7a76\u8303\u5f0f\uff1b2\uff09\u8bad\u7ec3\u65b9\u9762\uff0c\u5f15\u5165\u96be\u5ea6\u611f\u77e5\u7684\u56de\u5408\u60e9\u7f5a\u673a\u5236\uff0c\u6291\u5236\u8fc7\u5ea6\u7684\u5de5\u5177\u8c03\u7528\u589e\u957f\uff1b3\uff09\u63a8\u7406\u65b9\u9762\uff0c\u52a0\u5165\u76d1\u63a7\u5668\u5e2e\u52a9\u5728\u53ef\u63a7\u6b65\u9aa4\u5185\u9a8c\u8bc1\u5047\u8bbe\uff0c\u907f\u514d\u4e0a\u4e0b\u6587\u6c61\u67d3\u3002", "result": "\u5728\u4e03\u4e2a\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeepMed\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u5e73\u5747\u63d0\u53479.79%\uff0c\u5e76\u4e14\u8d85\u8d8a\u4e86\u66f4\u5927\u7684\u533b\u5b66\u63a8\u7406\u548c\u6df1\u5ea6\u7814\u7a76\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u9488\u5bf9\u533b\u5b66\u9886\u57df\u7279\u70b9\u8bbe\u8ba1\u7684\u6df1\u5ea6\u7814\u7a76\u65b9\u6cd5\uff0cDeepMed\u6709\u6548\u89e3\u51b3\u4e86\u901a\u7528\u6df1\u5ea6\u7814\u7a76\u6a21\u578b\u5728\u533b\u5b66\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u5b66\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2601.18554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18554", "abs": "https://arxiv.org/abs/2601.18554", "authors": ["Alberto Purpura", "Li Wang", "Sahil Badyal", "Eugenio Beaufrand", "Adam Faulkner"], "title": "Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities", "comment": "Paper accepted to EACL 2026", "summary": "Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.", "AI": {"tldr": "MOSAIC\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u751f\u6210\u5305\u542b\u591a\u8fbe20\u4e2a\u5e94\u7528\u5bfc\u5411\u7ea6\u675f\u7684\u6570\u636e\u96c6\uff0c\u5bf9LLM\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u8fdb\u884c\u6a21\u5757\u5316\u8bc4\u4f30\uff0c\u53d1\u73b0\u5408\u89c4\u6027\u53d7\u7ea6\u675f\u7c7b\u578b\u3001\u6570\u91cf\u548c\u4f4d\u7f6e\u5f71\u54cd\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u96be\u4ee5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u4f7f\u7528\u60c5\u51b5\uff0c\u4e14\u65e0\u6cd5\u5c06\u5408\u89c4\u6027\u4e0e\u4efb\u52a1\u6210\u529f\u5206\u79bb\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u53ef\u9760\u5730\u786e\u4fddLLM\u9075\u5faa\u590d\u6742\u6307\u4ee4\u3002", "method": "\u63d0\u51faMOSAIC\u6846\u67b6\uff0c\u4f7f\u7528\u52a8\u6001\u751f\u6210\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u8fbe20\u4e2a\u5e94\u7528\u5bfc\u5411\u7684\u751f\u6210\u7ea6\u675f\uff0c\u5bf9\u4e94\u79cd\u4e0d\u540c\u5bb6\u65cf\u7684LLM\u8fdb\u884c\u6a21\u5757\u5316\u8bc4\u4f30\u3002", "result": "\u5408\u89c4\u6027\u4e0d\u662f\u5355\u4e00\u80fd\u529b\uff0c\u800c\u662f\u968f\u7ea6\u675f\u7c7b\u578b\u3001\u6570\u91cf\u548c\u4f4d\u7f6e\u663e\u8457\u53d8\u5316\uff1b\u63ed\u793a\u4e86\u6a21\u578b\u7279\u5b9a\u5f31\u70b9\u3001\u6307\u4ee4\u95f4\u7684\u534f\u540c\u4e0e\u51b2\u7a81\u4ea4\u4e92\uff0c\u4ee5\u53ca\u9996\u56e0\u6548\u5e94\u548c\u8fd1\u56e0\u6548\u5e94\u7b49\u4f4d\u7f6e\u504f\u5dee\u3002", "conclusion": "\u8fd9\u4e9b\u7ec6\u7c92\u5ea6\u6d1e\u5bdf\u5bf9\u4e8e\u8bca\u65ad\u6a21\u578b\u5931\u8d25\u548c\u5f00\u53d1\u9700\u8981\u4e25\u683c\u9075\u5faa\u590d\u6742\u6307\u4ee4\u7684\u7cfb\u7edf\u4e2d\u7684\u66f4\u53ef\u9760LLM\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.18588", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18588", "abs": "https://arxiv.org/abs/2601.18588", "authors": ["Xianzhe Meng", "Qiangsheng Zeng", "Ling Luo", "Qinghan Yang", "Jiarui Hao", "Wenbo Wu", "Qinyu Wang", "Rui Yin", "Lin Qi", "Renzhi Lu"], "title": "Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs", "comment": null, "summary": "Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bad\u7ec3\u7a33\u5b9a\u6027\u4e0e\u751f\u6210\u8d28\u91cf\u5e76\u4e0d\u4e00\u81f4\uff1a\u7a33\u5b9a\u7684\u53c2\u6570\u8f68\u8ff9\u4f1a\u5bfc\u81f4\u6a21\u578b\u96c6\u4e2d\u5728\u6709\u9650\u7684\u6a21\u5f0f\u4e0a\uff0c\u964d\u4f4e\u751f\u6210\u71b5\uff0c\u4ea7\u751f\u91cd\u590d\u6027\u8f93\u51fa\uff0c\u5c3d\u7ba1\u635f\u5931\u51fd\u6570\u5e73\u6ed1\u6536\u655b\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u8bad\u7ec3\u7a33\u5b9a\u6027\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u9760\u4f18\u5316\u7684\u524d\u63d0\uff0c\u4f46\u672c\u6587\u65e8\u5728\u5206\u6790\u8bad\u7ec3\u7a33\u5b9a\u6027\u5982\u4f55\u5f71\u54cd\u751f\u6210\u5206\u5e03\uff0c\u63a2\u8ba8\u7a33\u5b9a\u6027\u662f\u5426\u771f\u6b63\u4fdd\u8bc1\u751f\u6210\u8d28\u91cf\u3002", "method": "\u7406\u8bba\u5206\u6790\u6807\u51c6\u6700\u5927\u4f3c\u7136\u8bad\u7ec3\u4e0b\u7a33\u5b9a\u53c2\u6570\u8f68\u8ff9\u7684\u6570\u5b66\u7279\u6027\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u53cd\u9988\u7684\u8bad\u7ec3\u6846\u67b6\u6765\u7a33\u5b9a\u5185\u90e8\u751f\u6210\u7edf\u8ba1\u91cf\uff0c\u5728\u4e0d\u540c\u67b6\u6784\u548c\u968f\u673a\u79cd\u5b50\u4e0b\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u7a33\u5b9a\u8bad\u7ec3\u5bfc\u81f4\u6a21\u578b\u8fd1\u4f3c\u6700\u5c0f\u5316\u524d\u5411KL\u6563\u5ea6\uff0c\u540c\u65f6\u9690\u5f0f\u964d\u4f4e\u751f\u6210\u71b5\uff0c\u4f7f\u6a21\u578b\u96c6\u4e2d\u5728\u6709\u9650\u7684\u6a21\u5f0f\u4e0a\uff0c\u4ea7\u751f\u4f4e\u71b5\u8f93\u51fa\u548c\u91cd\u590d\u6027\u884c\u4e3a\uff0c\u5c3d\u7ba1\u635f\u5931\u51fd\u6570\u5e73\u6ed1\u6536\u655b\u3002", "conclusion": "\u4f18\u5316\u7a33\u5b9a\u6027\u4e0e\u751f\u6210\u8868\u8fbe\u80fd\u529b\u5e76\u4e0d\u5185\u5728\u4e00\u81f4\uff0c\u7a33\u5b9a\u6027\u672c\u8eab\u4e0d\u8db3\u4ee5\u4f5c\u4e3a\u751f\u6210\u8d28\u91cf\u7684\u6307\u6807\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6807\u51c6\u6765\u786e\u4fdd\u6a21\u578b\u7684\u751f\u6210\u591a\u6837\u6027\u3002"}}
{"id": "2601.18595", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18595", "abs": "https://arxiv.org/abs/2601.18595", "authors": ["Joseph Cotnareanu", "Didier Chetelat", "Yingxue Zhang", "Mark Coates"], "title": "A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic", "comment": null, "summary": "Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LLM\u548c\u903b\u8f91\u6c42\u89e3\u5668\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u53cd\u9988\u673a\u5236\u8865\u5145\u7f3a\u5931\u7684\u5e38\u8bc6\u5173\u7cfb\uff0c\u63d0\u5347\u590d\u6742\u63a8\u7406\u95ee\u9898\u7684\u89e3\u51b3\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f62\u5f0f\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u590d\u6742\u8bc1\u660e\u89c4\u5212\u7684\u95ee\u9898\u4e0a\u5e38\u5e38\u5931\u6548\u3002\u4f20\u7edf\u903b\u8f91\u6c42\u89e3\u5668\u867d\u7136\u63a8\u7406\u6548\u7387\u66f4\u9ad8\uff0c\u4f46\u5047\u8bbe\u6240\u6709\u76f8\u5173\u4e8b\u5b9e\u90fd\u5df2\u63d0\u4f9b\uff0c\u65e0\u6cd5\u5904\u7406\u7f3a\u5931\u7684\u5e38\u8bc6\u5173\u7cfb\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u5e73\u8861\u795e\u7ecf\u548c\u7b26\u53f7\u5143\u7d20\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8fed\u4ee3\u65b9\u6cd5\uff1a\u4f7f\u7528\u903b\u8f91\u6c42\u89e3\u5668\u7684\u53cd\u9988\u6765\u589e\u5f3a\u903b\u8f91\u95ee\u9898\uff0c\u901a\u8fc7LLM\u63d0\u4f9b\u5e38\u8bc6\u5173\u7cfb\u3002\u91c7\u7528\u641c\u7d22\u7a0b\u5e8f\u904d\u5386\u6f5c\u5728\u7684\u5e38\u8bc6\u5047\u8bbe\uff0c\u6700\u5927\u5316\u627e\u5230\u6709\u7528\u4e8b\u5b9e\u7684\u673a\u4f1a\uff0c\u540c\u65f6\u4fdd\u6301\u6210\u672c\u53ef\u63a7\u3002", "result": "\u5728\u4e00\u7ec4\u7eaf\u903b\u8f91\u63a8\u7406\u6570\u636e\u96c6\u4e0a\uff08\u5176\u4e2d\u90e8\u5206\u5e38\u8bc6\u4fe1\u606f\u5df2\u88ab\u79fb\u9664\uff09\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u59cb\u7ec8\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff0c\u8bc1\u660e\u4e86\u5728\u4eba\u7c7b\u8bed\u5883\u4e2d\u5e73\u8861\u795e\u7ecf\u548c\u7b26\u53f7\u5143\u7d20\u7684\u4ef7\u503c\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408LLM\u7684\u5e38\u8bc6\u63a8\u7406\u80fd\u529b\u548c\u903b\u8f91\u6c42\u89e3\u5668\u7684\u5f62\u5f0f\u63a8\u7406\u6548\u7387\uff0c\u63d0\u51fa\u7684\u8fed\u4ee3\u53cd\u9988\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u9700\u8981\u590d\u6742\u8bc1\u660e\u89c4\u5212\u548c\u5e38\u8bc6\u8865\u5145\u7684\u63a8\u7406\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5\u7684\u4f18\u52bf\u3002"}}
{"id": "2601.18630", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.18630", "abs": "https://arxiv.org/abs/2601.18630", "authors": ["Abeer Badawi", "Md Tahmid Rahman Laskar", "Elahe Rahimi", "Sheri Grach", "Lindsay Bertrand", "Lames Danok", "Frank Rudzicz", "Jimmy Huang", "Elham Dolatabadi"], "title": "Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation", "comment": null, "summary": "The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u7c7b\u8bc4\u4f30\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLMs\u5728\u8ba4\u77e5\u652f\u6301\u65b9\u9762\u8868\u73b0\u53ef\u9760\uff0c\u4f46\u5728\u60c5\u611f\u5171\u9e23\u65b9\u9762\u5b58\u5728\u4e0d\u7a33\u5b9a\uff0c\u63ed\u793a\u4e86\u8ba4\u77e5-\u60c5\u611f\u5dee\u8ddd\u3002", "motivation": "\u5168\u7403\u5fc3\u7406\u5065\u5eb7\u5371\u673a\u65e5\u76ca\u4e25\u91cd\uff0c\u5b58\u5728\u6cbb\u7597\u7f3a\u53e3\u548c\u5408\u683c\u6cbb\u7597\u5e08\u77ed\u7f3a\u7684\u95ee\u9898\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684\u652f\u6301\u9014\u5f84\u5177\u6709\u6f5c\u529b\u3002\u7136\u800c\uff0cLLMs\u7684\u53ef\u9760\u6027\u3001\u6cbb\u7597\u76f8\u5173\u6027\u548c\u4e0e\u4eba\u7c7b\u6807\u51c6\u7684\u5bf9\u9f50\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u8bc4\u4f30\u6846\u67b6\u6765\u786e\u4fdd\u5176\u5728\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u4e2d\u7684\u8d28\u91cf\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u7c7b\u8bc4\u4f30\u7684\u65b9\u6cd5\uff1a1) \u4ece\u771f\u5b9e\u4e16\u754c\u573a\u666f\u6570\u636e\u96c6\u4e2d\u6574\u7406500\u4e2a\u5fc3\u7406\u5065\u5eb7\u5bf9\u8bdd\uff1b2) \u8bc4\u4f309\u4e2a\u4e0d\u540cLLMs\uff08\u5305\u62ec\u95ed\u6e90\u548c\u5f00\u6e90\u6a21\u578b\uff09\u751f\u6210\u7684\u54cd\u5e94\uff1b3) \u7531\u4e24\u4f4d\u7ecf\u8fc7\u7cbe\u795e\u75c5\u5b66\u57f9\u8bad\u7684\u4e13\u5bb6\u72ec\u7acb\u4f7f\u75285\u70b9\u674e\u514b\u7279\u91cf\u8868\u5bf9\u6bcf\u4e2a\u54cd\u5e94\u8fdb\u884c\u8bc4\u5206\uff1b4) \u4f7f\u7528\u5305\u542b6\u4e2a\u5c5e\u6027\u7684\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u91cd\u70b9\u5173\u6ce8\u8ba4\u77e5\u652f\u6301\u548c\u60c5\u611f\u5171\u9e23\u4e24\u4e2a\u7ef4\u5ea6\u3002", "result": "\u5206\u6790\u663e\u793a\uff1a1) LLMs\u5728\u8ba4\u77e5\u53ef\u9760\u6027\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u80fd\u591f\u63d0\u4f9b\u5b89\u5168\u3001\u8fde\u8d2f\u4e14\u4e34\u5e8a\u9002\u5f53\u7684\u4fe1\u606f\uff1b2) \u4f46\u5728\u60c5\u611f\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u4e0d\u7a33\u5b9a\uff1b3) \u95ed\u6e90\u6a21\u578b\uff08\u5982GPT-4o\uff09\u63d0\u4f9b\u66f4\u5e73\u8861\u7684\u6cbb\u7597\u54cd\u5e94\uff1b4) \u5f00\u6e90\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u5927\u7684\u53d8\u5f02\u6027\u548c\u60c5\u611f\u5e73\u6de1\uff1b5) \u63ed\u793a\u4e86\u6301\u7eed\u7684\u8ba4\u77e5-\u60c5\u611f\u5dee\u8ddd\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u9700\u8981\u5efa\u7acb\u5177\u6709\u5931\u8d25\u610f\u8bc6\u3001\u57fa\u4e8e\u4e34\u5e8a\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u5fc3\u7406\u5065\u5eb7\u5bfc\u5411\u7684LLMs\u4e2d\u4f18\u5148\u8003\u8651\u5173\u7cfb\u654f\u611f\u6027\u800c\u4e0d\u4ec5\u4ec5\u662f\u4fe1\u606f\u51c6\u786e\u6027\u3002\u63d0\u5021\u91c7\u7528\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u5e73\u8861\u8bc4\u4f30\u534f\u8bae\uff0c\u91cd\u70b9\u5173\u6ce8\u6cbb\u7597\u654f\u611f\u6027\uff0c\u5e76\u4e3a\u5fc3\u7406\u5065\u5eb7\u5bfc\u5411\u7684\u5bf9\u8bddAI\u63d0\u4f9b\u8d1f\u8d23\u4efb\u8bbe\u8ba1\u548c\u4e34\u5e8a\u76d1\u7763\u7684\u6846\u67b6\u3002"}}
{"id": "2601.18631", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.18631", "abs": "https://arxiv.org/abs/2601.18631", "authors": ["Mingyang Song", "Haoyu Sun", "Jiawei Gu", "Linjie Li", "Luxin Xu", "Ranjay Krishna", "Yu Cheng"], "title": "AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning", "comment": "28 pages, 10 figures and 13 tables", "summary": "When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \\textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.", "AI": {"tldr": "AdaReasoner\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6a21\u578b\u5bb6\u65cf\uff0c\u901a\u8fc7\u5b66\u4e60\u5de5\u5177\u4f7f\u7528\u4f5c\u4e3a\u901a\u7528\u63a8\u7406\u6280\u80fd\u800c\u975e\u7279\u5b9a\u5de5\u5177\u6216\u663e\u5f0f\u76d1\u7763\u884c\u4e3a\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u5de5\u5177\u81ea\u9002\u5e94\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u4eba\u7c7b\u5728\u9762\u5bf9\u8d85\u51fa\u81ea\u8eab\u80fd\u529b\u7684\u95ee\u9898\u65f6\u4f1a\u4f9d\u8d56\u5de5\u5177\uff0c\u8fd9\u4e3a\u63d0\u9ad8\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u8303\u5f0f\u3002\u6709\u6548\u7684\u63a8\u7406\u9700\u8981\u77e5\u9053\u4f7f\u7528\u54ea\u4e9b\u5de5\u5177\u3001\u4f55\u65f6\u8c03\u7528\u5b83\u4eec\u4ee5\u53ca\u5982\u4f55\u5728\u591a\u6b65\u9aa4\u4e2d\u7ec4\u5408\u5b83\u4eec\uff0c\u5373\u4f7f\u9762\u5bf9\u65b0\u5de5\u5177\u6216\u65b0\u4efb\u52a1\u65f6\u4e5f\u662f\u5982\u6b64\u3002", "method": "AdaReasoner\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\u5b9e\u73b0\uff1a(1)\u53ef\u6269\u5c55\u7684\u6570\u636e\u6574\u7406\u6d41\u7a0b\uff0c\u8ba9\u6a21\u578b\u63a5\u89e6\u957f\u89c6\u91ce\u3001\u591a\u6b65\u9aa4\u7684\u5de5\u5177\u4ea4\u4e92\uff1b(2)Tool-GRPO\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u57fa\u4e8e\u6700\u7ec8\u4efb\u52a1\u6210\u529f\u4f18\u5316\u5de5\u5177\u9009\u62e9\u548c\u5e8f\u5217\uff1b(3)\u81ea\u9002\u5e94\u5b66\u4e60\u673a\u5236\uff0c\u52a8\u6001\u8c03\u8282\u5de5\u5177\u4f7f\u7528\u9891\u7387\u3002", "result": "AdaReasoner\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u5de5\u5177\u81ea\u9002\u5e94\u548c\u6cdb\u5316\u884c\u4e3a\uff1a\u81ea\u4e3b\u91c7\u7528\u6709\u76ca\u5de5\u5177\u3001\u6291\u5236\u65e0\u5173\u5de5\u5177\u3001\u6839\u636e\u4efb\u52a1\u9700\u6c42\u8c03\u6574\u5de5\u5177\u4f7f\u7528\u9891\u7387\uff0c\u5c3d\u7ba1\u4ece\u672a\u88ab\u660e\u786e\u8bad\u7ec3\u8fd9\u6837\u505a\u3002\u8fd9\u4e9b\u80fd\u529b\u8f6c\u5316\u4e3a\u5728\u591a\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5c067B\u57fa\u7840\u6a21\u578b\u5e73\u5747\u63d0\u534724.9%\uff0c\u5e76\u5728VSP\u548cJigsaw\u7b49\u591a\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8d8aGPT-5\u7b49\u5f3a\u5927\u4e13\u6709\u7cfb\u7edf\u3002", "conclusion": "AdaReasoner\u901a\u8fc7\u5b66\u4e60\u5de5\u5177\u4f7f\u7528\u4f5c\u4e3a\u901a\u7528\u63a8\u7406\u6280\u80fd\uff0c\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u5de5\u5177\u81ea\u9002\u5e94\u548c\u6cdb\u5316\uff0c\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002"}}
{"id": "2601.18706", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18706", "abs": "https://arxiv.org/abs/2601.18706", "authors": ["Zhichao Yang", "Sepehr Janghorbani", "Dongxu Zhang", "Jun Han", "Qian Qian", "Andrew Ressler", "Gregory D. Lyng", "Sanjit Singh Batra", "Robert E. Tillman"], "title": "Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs", "comment": null, "summary": "Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.", "AI": {"tldr": "Health-SCORE\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u91cf\u89c4\u7684LLM\u8bad\u7ec3\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u533b\u7597\u9886\u57df\u91cf\u89c4\u5f00\u53d1\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u8bc4\u4f30\u8d28\u91cf\u3002", "motivation": "\u5728\u533b\u7597\u7b49\u5b89\u5168\u5173\u952e\u9886\u57df\uff0c\u57fa\u4e8e\u91cf\u89c4\u8bc4\u4f30\u5f00\u653e\u5f0fLLM\u54cd\u5e94\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u521b\u5efa\u9ad8\u8d28\u91cf\u3001\u9886\u57df\u7279\u5b9a\u7684\u91cf\u89c4\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u65f6\u95f4\u548c\u5f00\u53d1\u6210\u672c\uff0c\u96be\u4ee5\u89c4\u6a21\u5316\u3002", "method": "\u5f00\u53d1Health-SCORE\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u901a\u7528\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u91cf\u89c4\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u7cfb\u7edf\uff0c\u663e\u8457\u51cf\u5c11\u91cf\u89c4\u5f00\u53d1\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "result": "Health-SCORE\u5728\u5f00\u653e\u5f0f\u533b\u7597\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e0e\u4eba\u5de5\u521b\u5efa\u91cf\u89c4\u76f8\u5f53\u7684\u8bc4\u4f30\u8d28\u91cf\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5f00\u53d1\u5de5\u4f5c\u91cf\uff0c\u4f7f\u57fa\u4e8e\u91cf\u89c4\u7684\u8bc4\u4f30\u548c\u8bad\u7ec3\u66f4\u5177\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "Health-SCORE\u6846\u67b6\u4e0d\u4ec5\u63d0\u4f9b\u8bc4\u4f30\u529f\u80fd\uff0c\u8fd8\u53ef\u4f5c\u4e3a\u7ed3\u6784\u5316\u5956\u52b1\u4fe1\u53f7\u6307\u5bfc\u5f3a\u5316\u5b66\u4e60\uff0c\u5e76\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u76f4\u63a5\u878d\u5165\u63d0\u793a\u4e2d\u63d0\u9ad8\u54cd\u5e94\u8d28\u91cf\uff0c\u4e3a\u533b\u7597\u9886\u57dfLLM\u8bc4\u4f30\u548c\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.18716", "categories": ["cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2601.18716", "abs": "https://arxiv.org/abs/2601.18716", "authors": ["Naeyma N. Islam", "Thomas R. Caulfield"], "title": "Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules", "comment": "30 pages, 8 figures", "summary": "Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdAI\u8f85\u52a9\u7684\u836f\u7269\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7E3\u8fde\u63a5\u9176\u5bfc\u5411\u7684\u5206\u5b50\u80f6\u4fc3\u8fdbA\u03b2-42\u7684\u9776\u5411\u964d\u89e3\uff0c\u7528\u4e8e\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u6cbb\u7597\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u4ee5A\u03b2-42\u7684\u75c5\u7406\u6027\u79ef\u7d2f\u4e3a\u7279\u5f81\uff0c\u5bfc\u81f4\u7a81\u89e6\u529f\u80fd\u969c\u788d\u548c\u795e\u7ecf\u9000\u884c\u6027\u53d8\u3002\u867d\u7136\u7ec6\u80de\u5916\u6dc0\u7c89\u6837\u6591\u5757\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u8d8a\u6765\u8d8a\u591a\u7684\u8bc1\u636e\u8868\u660e\u7ec6\u80de\u5185A\u03b2-42\u662f\u75be\u75c5\u8fdb\u5c55\u7684\u65e9\u671f\u548c\u6bd2\u6027\u9a71\u52a8\u56e0\u7d20\u3002\u9700\u8981\u5f00\u53d1\u65b0\u7684\u6cbb\u7597\u65b9\u6cd5\u6765\u9776\u5411\u964d\u89e3A\u03b2-42\u3002", "method": "\u91c7\u7528AI\u8f85\u52a9\u836f\u7269\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5efa\u6a21\u3001ADMET\u7b5b\u9009\u548c\u5bf9\u63a5\u8bc4\u4f30A\u03b2-42\u4e0e\u4e09\u79cdE3\u8fde\u63a5\u9176\uff08CRBN\u3001VHL\u3001MDM2\uff09\u7684\u4e09\u5143\u590d\u5408\u7269\u5f62\u6210\u6f5c\u529b\u3002\u5f00\u53d1\u4e86\u8fde\u63a5\u9176\u6761\u4ef6\u5316\u8fde\u63a5\u6811\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08LC-JT-VAE\uff09\uff0c\u7ed3\u5408\u86cb\u767d\u8d28\u5e8f\u5217\u5d4c\u5165\u548c\u626d\u8f6c\u89d2\u611f\u77e5\u5206\u5b50\u56fe\uff0c\u751f\u6210\u8fde\u63a5\u9176\u7279\u5f02\u6027\u5c0f\u5206\u5b50\u3002", "result": "\u751f\u6210\u6a21\u578b\u80fd\u591f\u4ea7\u751f\u5316\u5b66\u6709\u6548\u3001\u65b0\u9896\u4e14\u9776\u5411\u7279\u5f02\u6027\u7684\u5206\u5b50\u80f6\uff0c\u80fd\u591f\u4fc3\u8fdbA\u03b2-42\u7684\u964d\u89e3\u3002\u8be5\u65b9\u6cd5\u4e3a\u8bbe\u8ba1UPS\u9776\u5411\u7597\u6cd5\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6846\u67b6\u3002", "conclusion": "\u8fd9\u79cd\u96c6\u6210\u65b9\u6cd5\u4e3a\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u8bbe\u8ba1UPS\u9776\u5411\u7597\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u6846\u67b6\uff0c\u901a\u8fc7AI\u8f85\u52a9\u751f\u6210\u5206\u5b50\u80f6\u6765\u4fc3\u8fdbA\u03b2-42\u7684\u9776\u5411\u964d\u89e3\u3002"}}
{"id": "2601.18744", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18744", "abs": "https://arxiv.org/abs/2601.18744", "authors": ["Fangxu Yu", "Xingang Guo", "Lingzhi Yuan", "Haoqiang Kang", "Hongyu Zhao", "Lianhui Qin", "Furong Huang", "Bin Hu", "Tianyi Zhou"], "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models", "comment": null, "summary": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.", "AI": {"tldr": "TSRBench\u662f\u4e00\u4e2a\u5168\u9762\u7684\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b4125\u4e2a\u95ee\u9898\u300114\u4e2a\u9886\u57df\u30014\u4e2a\u7ef4\u5ea6\uff0c\u8bc4\u4f30\u4e8630\u591a\u4e2a\u9886\u5148\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u611f\u77e5\u548c\u63a8\u7406\u7684\u6269\u5c55\u89c4\u5f8b\u3001\u9884\u6d4b\u4e2d\u7684\u8bed\u4e49\u7406\u89e3\u4e0e\u6570\u503c\u9884\u6d4b\u8131\u8282\u7b49\u95ee\u9898\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u65e0\u5904\u4e0d\u5728\u4e14\u5bf9\u5173\u952e\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u901a\u7528\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7f3a\u4e4f\u65f6\u95f4\u5e8f\u5217\u7ef4\u5ea6\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9700\u8981\u521b\u5efa\u4e00\u4e2a\u5168\u9762\u7684\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u57fa\u51c6\u6765\u8bc4\u4f30\u901a\u7528\u6a21\u578b\u7684\u5b9e\u8df5\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002", "method": "\u5f15\u5165TSRBench\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b4125\u4e2a\u6765\u81ea14\u4e2a\u9886\u57df\u7684\u95ee\u9898\uff0c\u5206\u4e3a\u611f\u77e5\u3001\u63a8\u7406\u3001\u9884\u6d4b\u548c\u51b3\u7b564\u4e2a\u4e3b\u8981\u7ef4\u5ea6\uff0c\u5305\u542b15\u4e2a\u4efb\u52a1\u8bc4\u4f30\u57fa\u672c\u63a8\u7406\u80fd\u529b\u3002\u5bf930\u591a\u4e2a\u9886\u5148\u7684\u4e13\u6709\u548c\u5f00\u6e90LLM\u3001VLM\u548cTSLLM\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u6269\u5c55\u89c4\u5f8b\u9002\u7528\u4e8e\u611f\u77e5\u548c\u63a8\u7406\u4f46\u5728\u9884\u6d4b\u4e2d\u5931\u6548\uff1b2\uff09\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u4e0d\u80fd\u4fdd\u8bc1\u51c6\u786e\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u9884\u6d4b\uff0c\u8868\u660e\u8bed\u4e49\u7406\u89e3\u548c\u6570\u503c\u9884\u6d4b\u4e4b\u95f4\u5b58\u5728\u8131\u8282\uff1b3\uff09\u5c3d\u7ba1\u65f6\u95f4\u5e8f\u5217\u7684\u6587\u672c\u548c\u89c6\u89c9\u8868\u793a\u5177\u6709\u4e92\u8865\u6027\uff0c\u4f46\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u672a\u80fd\u6709\u6548\u878d\u5408\u5b83\u4eec\u4ee5\u83b7\u5f97\u76f8\u4e92\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "TSRBench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u8bc4\u4f30\u5e73\u53f0\uff0c\u4e0d\u4ec5\u7a81\u663e\u4e86\u73b0\u6709\u6311\u6218\uff0c\u8fd8\u4e3a\u63a8\u8fdb\u901a\u7528\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
