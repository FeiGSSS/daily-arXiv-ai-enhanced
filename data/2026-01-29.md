<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 23]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Agentic Business Process Management Systems](https://arxiv.org/abs/2601.18833)
*Marlon Dumas,Fredrik Milani,David Chapela-Campa*

Main category: cs.AI

TL;DR: 本文提出基于生成式AI和智能体的新型业务流程管理系统（A-BPMS），将流程管理从自动化转向自主化，从设计驱动转向数据驱动，通过流程挖掘技术实现智能体的感知、推理和行动能力。


<details>
  <summary>Details</summary>
Motivation: 业务流程管理（BPM）领域自90年代以来经历了多轮自动化技术浪潮。生成式AI和智能体技术的兴起开启了新一轮变革，这次变革的核心是从自动化转向自主化，从设计驱动管理转向数据驱动管理，需要新的架构来支持这一转变。

Method: 提出Agentic Business Process Management Systems（A-BPMS）架构愿景，整合自主性、推理和学习能力。该架构基于流程挖掘技术，使智能体能够感知流程状态、推理改进机会并采取行动优化性能。支持从人工驱动到完全自主的连续流程谱系。

Result: 提出了A-BPMS的新型平台架构，重新定义了流程自动化和治理的边界。该架构能够支持智能体在业务流程中的自主决策和持续优化，为下一代业务流程管理系统提供了理论框架。

Conclusion: 生成式AI和智能体技术正在推动BPM领域的根本性转变，从自动化转向自主化。A-BPMS架构通过整合流程挖掘、智能体技术和数据驱动方法，为这一转变提供了可行的技术路径，将重新定义业务流程管理的未来发展方向。

Abstract: Since the early 90s, the evolution of the Business Process Management (BPM) discipline has been punctuated by successive waves of automation technologies. Some of these technologies enable the automation of individual tasks, while others focus on orchestrating the execution of end-to-end processes. The rise of Generative and Agentic Artificial Intelligence (AI) is opening the way for another such wave. However, this wave is poised to be different because it shifts the focus from automation to autonomy and from design-driven management of business processes to data-driven management, leveraging process mining techniques. This position paper, based on a keynote talk at the 2025 Workshop on AI for BPM, outlines how process mining has laid the foundations on top of which agents can sense process states, reason about improvement opportunities, and act to maintain and optimize performance. The paper proposes an architectural vision for Agentic Business Process Management Systems (A-BPMS): a new class of platforms that integrate autonomy, reasoning, and learning into process management and execution. The paper contends that such systems must support a continuum of processes, spanning from human-driven to fully autonomous, thus redefining the boundaries of process automation and governance.

</details>


### [2] [LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties](https://arxiv.org/abs/2601.18846)
*Urban Skvorc,Niki van Stein,Moritz Seiler,Britta Grimme,Thomas Bäck,Heike Trautmann*

Main category: cs.AI

TL;DR: 使用LLM在进化循环中生成具有明确高层景观特征的优化问题，通过ELA属性预测器评分，引入ELA空间适应度共享机制增加多样性，生成的问题扩展了BBOB实例空间


<details>
  <summary>Details</summary>
Motivation: 现有BBOB等测试套件的结构多样性有限，阻碍了连续黑盒优化的基准测试。需要探索是否可以使用嵌入进化循环的大型语言模型来设计具有明确定义的高层景观特征的优化问题。

Method: 使用LLaMEA框架，通过自然语言描述目标属性（包括多模态性、可分离性、盆地大小同质性、搜索空间同质性和全局-局部最优对比度）来指导LLM生成问题代码。在循环中使用基于ELA的属性预测器对候选方案进行评分，并引入ELA空间适应度共享机制来增加种群多样性并避免冗余景观。

Result: 通过吸引盆分析、统计测试和视觉检查验证了许多生成函数确实表现出预期的结构特征。t-SNE嵌入显示这些函数扩展了BBOB实例空间而不是形成无关的聚类。生成的库为景观分析和下游任务（如自动算法选择）提供了广泛、可解释且可重复的基准问题集。

Conclusion: 该方法成功生成了具有明确定义景观特征的优化问题，扩展了现有基准测试套件的多样性，为景观分析和算法选择等任务提供了有价值的工具。

Abstract: Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape characteristics. Using the LLaMEA framework, we guide an LLM to generate problem code from natural-language descriptions of target properties, including multimodality, separability, basin-size homogeneity, search-space homogeneity and globallocal optima contrast. Inside the loop we score candidates through ELA-based property predictors. We introduce an ELA-space fitness-sharing mechanism that increases population diversity and steers the generator away from redundant landscapes. A complementary basin-of-attraction analysis, statistical testing and visual inspection, verifies that many of the generated functions indeed exhibit the intended structural traits. In addition, a t-SNE embedding shows that they expand the BBOB instance space rather than forming an unrelated cluster. The resulting library provides a broad, interpretable, and reproducible set of benchmark problems for landscape analysis and downstream tasks such as automated algorithm selection.

</details>


### [3] [Explainable Uncertainty Quantification for Wastewater Treatment Energy Prediction via Interval Type-2 Neuro-Fuzzy System](https://arxiv.org/abs/2601.18897)
*Qusai Khaled,Bahjat Mallak,Uzay Kaymak,Laura Genga*

Main category: cs.AI

TL;DR: 开发基于区间二型自适应神经模糊推理系统（IT2-ANFIS）的废水处理厂能耗预测模型，提供可解释的不确定性量化，支持风险感知决策


<details>
  <summary>Details</summary>
Motivation: 废水处理厂消耗全球1-3%的电力，准确能耗预测对运营优化和可持续发展至关重要。现有机器学习模型仅提供点预测，缺乏安全关键基础设施所需的可解释不确定性量化

Method: 提出区间二型自适应神经模糊推理系统（IT2-ANFIS），通过模糊规则结构生成可解释的预测区间。框架将不确定性分解为三个层次：特征级（识别引入模糊性的变量）、规则级（分析局部模型置信度）和实例级（量化整体预测不确定性）

Result: 在墨尔本水务公司东部处理厂数据集上验证，IT2-ANFIS实现与一阶ANFIS相当的预测性能，同时显著降低训练运行间的方差，并提供可解释的不确定性估计，将预测置信度直接与运营条件和输入变量关联

Conclusion: IT2-ANFIS框架为废水处理厂能耗预测提供了可解释的不确定性量化方法，支持风险感知决策，优于黑盒概率方法，对安全关键基础设施的运营优化具有重要意义

Abstract: Wastewater treatment plants consume 1-3% of global electricity, making accurate energy forecasting critical for operational optimization and sustainability. While machine learning models provide point predictions, they lack explainable uncertainty quantification essential for risk-aware decision-making in safety-critical infrastructure. This study develops an Interval Type-2 Adaptive Neuro-Fuzzy Inference System (IT2-ANFIS) that generates interpretable prediction intervals through fuzzy rule structures. Unlike black-box probabilistic methods, the proposed framework decomposes uncertainty across three levels: feature-level, footprint of uncertainty identify which variables introduce ambiguity, rule-level analysis reveals confidence in local models, and instance-level intervals quantify overall prediction uncertainty. Validated on Melbourne Water's Eastern Treatment Plant dataset, IT2-ANFIS achieves comparable predictive performance to first order ANFIS with substantially reduced variance across training runs, while providing explainable uncertainty estimates that link prediction confidence directly to operational conditions and input variables.

</details>


### [4] [RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures](https://arxiv.org/abs/2601.18924)
*Andrew Jaffe,Noah Reicin,Jinho D. Choi*

Main category: cs.AI

TL;DR: 论文引入RIFT测试平台，通过重新排序的Jeopardy问答对测试LLMs的指令跟随能力，发现跳跃提示下准确率下降高达72%，揭示LLMs对位置连续性的强依赖


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂工作流中的应用日益增多，但其维持指令流的能力尚未充分探索。现有基准测试将任务复杂性与结构顺序混为一谈，难以分离提示拓扑结构对性能的影响

Method: 引入RIFT（重新排序指令跟随测试平台），使用重新表述的Jeopardy问答对，测试两种提示结构：线性提示（顺序进行）和跳跃提示（内容相同但需要非顺序遍历）。在6个最先进的开源LLMs上进行10,000次评估

Result: 跳跃条件下准确率相比基线下降高达72%，显示对位置连续性的强依赖。约50%的失败源于指令顺序违反和语义漂移，表明当前架构将指令跟随内化为顺序模式而非推理技能

Conclusion: 结构敏感性是当前架构的基本限制，对需要非顺序控制流的应用（如工作流自动化和多智能体系统）有直接影响。LLMs将指令跟随视为顺序模式而非推理能力

Abstract: Large Language Models (LLMs) are increasingly relied upon for complex workflows, yet their ability to maintain flow of instructions remains underexplored. Existing benchmarks conflate task complexity with structural ordering, making it difficult to isolate the impact of prompt topology on performance. We introduce RIFT, Reordered Instruction Following Testbed, to assess instruction following by disentangling structure from content. Using rephrased Jeopardy! question-answer pairs, we test LLMs across two prompt structures: linear prompts, which progress sequentially, and jumping prompts, which preserve identical content but require non-sequential traversal. Across 10,000 evaluations spanning six state-of-the-art open-source LLMs, accuracy dropped by up to 72% under jumping conditions (compared to baseline), revealing a strong dependence on positional continuity. Error analysis shows that approximately 50% of failures stem from instruction-order violations and semantic drift, indicating that current architectures internalize instruction following as a sequential pattern rather than a reasoning skill. These results reveal structural sensitivity as a fundamental limitation in current architectures, with direct implications for applications requiring non-sequential control flow such as workflow automation and multi-agent systems.

</details>


### [5] [Neural Theorem Proving for Verification Conditions: A Real-World Benchmark](https://arxiv.org/abs/2601.18944)
*Qiyuan Xu,Xiaokun Luan,Renxi Wang,Joshua Ong Jun Leang,Peixin Wang,Haonan Li,Wenda Li,Conrad Watt*

Main category: cs.AI

TL;DR: 该论文提出了首个针对程序验证中验证条件（VC）证明的真实世界多语言基准测试NTP4VC，评估了LLM在VC证明中的表现，发现虽然LLM显示出潜力，但与实际程序验证需求仍有较大差距。


<details>
  <summary>Details</summary>
Motivation: 程序验证中的验证条件（VC）自动证明是主要瓶颈，现有自动定理证明器无法处理困难的VC，导致需要大量手动证明，阻碍了实际应用。虽然神经定理证明在数学竞赛中取得成功，但在程序验证（特别是VC证明）中的应用尚未充分探索。

Method: 从Linux和Contiki-OS内核等真实项目中，利用工业级工具链（Why3和Frama-C）生成跨形式语言（Isabelle、Lean、Rocq）的语义等价测试用例，构建了首个真实世界多语言基准测试NTP4VC。评估了通用大语言模型和专门针对定理证明微调的LLM在该基准上的表现。

Result: 评估结果表明，虽然LLM在VC证明中显示出一定的潜力，但在程序验证方面仍面临重大挑战，揭示了当前方法与实际需求之间的巨大差距，为未来研究提供了机会。

Conclusion: 该工作填补了神经定理证明在程序验证领域应用的空白，提出了首个针对VC证明的基准测试，展示了LLM在该任务上的初步能力，但强调了仍需解决的重要挑战，为未来研究指明了方向。

Abstract: Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.

</details>


### [6] [Uncertainty-Aware 3D Emotional Talking Face Synthesis with Emotion Prior Distillation](https://arxiv.org/abs/2601.19112)
*Nanhan Shen,Zhilei Liu*

Main category: cs.AI

TL;DR: UA-3DTalk提出了一种不确定性感知的3D情感说话人脸合成方法，通过情感先验蒸馏解决现有方法中音频-视觉情感对齐不佳和多视图融合策略单一的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D情感说话人脸合成方法面临两个关键挑战：1) 音频-视觉情感对齐不佳，表现为音频情感提取困难和对情感微表情控制不足；2) 采用一刀切的多视图融合策略，忽略了不确定性和特征质量差异，影响了渲染质量。

Method: UA-3DTalk包含三个核心模块：先验提取模块将音频解耦为内容同步特征和个性化特征；情感蒸馏模块引入多模态注意力加权融合机制和4D高斯编码；不确定性形变模块部署不确定性块来估计视图特定的不确定性，实现自适应多视图融合。

Result: 在常规和情感数据集上的实验表明，UA-3DTalk在情感对齐方面比DEGSTalk和EDTalk等最先进方法在E-FID指标上提升5.2%，在唇部同步方面SyncC指标提升3.1%，在渲染质量方面LPIPS指标提升0.015。

Conclusion: UA-3DTalk通过不确定性感知和情感先验蒸馏，有效解决了3D情感说话人脸合成中的音频-视觉情感对齐和多视图融合问题，显著提升了合成质量。

Abstract: Emotional Talking Face synthesis is pivotal in multimedia and signal processing, yet existing 3D methods suffer from two critical challenges: poor audio-vision emotion alignment, manifested as difficult audio emotion extraction and inadequate control over emotional micro-expressions; and a one-size-fits-all multi-view fusion strategy that overlooks uncertainty and feature quality differences, undermining rendering quality. We propose UA-3DTalk, Uncertainty-Aware 3D Emotional Talking Face Synthesis with emotion prior distillation, which has three core modules: the Prior Extraction module disentangles audio into content-synchronized features for alignment and person-specific complementary features for individualization; the Emotion Distillation module introduces a multi-modal attention-weighted fusion mechanism and 4D Gaussian encoding with multi-resolution code-books, enabling fine-grained audio emotion extraction and precise control of emotional micro-expressions; the Uncertainty-based Deformation deploys uncertainty blocks to estimate view-specific aleatoric (input noise) and epistemic (model parameters) uncertainty, realizing adaptive multi-view fusion and incorporating a multi-head decoder for Gaussian primitive optimization to mitigate the limitations of uniform-weight fusion. Extensive experiments on regular and emotional datasets show UA-3DTalk outperforms state-of-the-art methods like DEGSTalk and EDTalk by 5.2% in E-FID for emotion alignment, 3.1% in SyncC for lip synchronization, and 0.015 in LPIPS for rendering quality. Project page: https://mrask999.github.io/UA-3DTalk

</details>


### [7] [Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach](https://arxiv.org/abs/2601.19122)
*Weiran Guo,Bing Bo,Shaoxiang Wu,Jingsheng Yang*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习的对抗性数据增强方法，通过训练查询模型生成对抗性查询来挑战函数调用模型，从而提高LLM函数调用能力的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有提升LLM函数调用能力的方法依赖于手动标注或模型自动生成的数据进行微调，但这些方法缺乏针对性设计，受限于固定模式和数据分布，限制了函数调用LLM的泛化能力和鲁棒性。

Method: 提出一种新颖的对抗性数据增强方法，使用强化学习训练查询模型生成专门挑战函数调用模型的对抗性查询。采用零和博弈框架，让查询模型和函数调用模型进行迭代交替训练。

Result: 该方法能够系统地识别和针对函数调用LLM的弱点，推动开发更鲁棒的函数调用模型，为识别和纠正LLM与外部工具交互能力的弱点提供了系统化方法。

Conclusion: 基于强化学习的对抗性数据增强方法有效解决了现有函数调用能力提升方法的局限性，通过针对性挑战模型弱点，显著增强了LLM函数调用能力的泛化性和鲁棒性。

Abstract: Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generation by models, and use this data to finetune the LLMs. However, these methods often lack targeted design and are constrained by fixed patterns and data distributions, which limits their effectiveness in enhancing the generalization and robustness of function call LLMs. To address this limitation, we propose a novel adversarial data augmentation method that employs reinforcement learning to systematically identify and target the weaknesses of function call LLMs. Our training framework introduces a query model trained with reinforcement learning (RL) to generate adversarial queries that are specifically designed to challenge function call (FC) models. This approach adopts a zero sum game formulation, where the query model and the FC model engage in iterative alternating training. Overall, our method advances the development of more robust FC models and provides a systematic way to identify and correct weaknesses in the ability of LLMs to interact with external tools.

</details>


### [8] [TS-Debate: Multimodal Collaborative Debate for Zero-Shot Time Series Reasoning](https://arxiv.org/abs/2601.19151)
*Patara Trirat,Jin Myung Kwak,Jay Heo,Heejun Lee,Sung Ju Hwang*

Main category: cs.AI

TL;DR: TS-Debate：一种用于零样本时间序列推理的模态专业化协作多智能体辩论框架，通过专用专家智能体处理文本、视觉和数值信号，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在时间序列分析中虽然展现出潜力，但在数值保真度、模态干扰和跨模态整合方面存在局限性，需要更稳健的解决方案

Method: 提出TS-Debate框架，包含三个专用专家智能体分别处理文本上下文、视觉模式和数值信号，采用结构化辩论协议协调交互，通过验证-冲突-校准机制评估智能体主张

Result: 在涵盖三个公共基准的20个任务中，TS-Debate相比强基线（包括标准多模态辩论）实现了持续且显著的性能提升

Conclusion: TS-Debate通过模态专业化、结构化辩论和程序化验证，有效保持了模态保真度、暴露了冲突证据并减轻了数值幻觉，无需任务特定微调

Abstract: Recent progress at the intersection of large language models (LLMs) and time series (TS) analysis has revealed both promise and fragility. While LLMs can reason over temporal structure given carefully engineered context, they often struggle with numeric fidelity, modality interference, and principled cross-modal integration. We present TS-Debate, a modality-specialized, collaborative multi-agent debate framework for zero-shot time series reasoning. TS-Debate assigns dedicated expert agents to textual context, visual patterns, and numerical signals, preceded by explicit domain knowledge elicitation, and coordinates their interaction via a structured debate protocol. Reviewer agents evaluate agent claims using a verification-conflict-calibration mechanism, supported by lightweight code execution and numerical lookup for programmatic verification. This architecture preserves modality fidelity, exposes conflicting evidence, and mitigates numeric hallucinations without task-specific fine-tuning. Across 20 tasks spanning three public benchmarks, TS-Debate achieves consistent and significant performance improvements over strong baselines, including standard multimodal debate in which all agents observe all inputs.

</details>


### [9] [Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement](https://arxiv.org/abs/2601.19170)
*Wangyang Ying,Yanchi Liu,Xujiang Zhao,Wei Cheng,Zhengzhang Chen,Wenchao Yu,Yanjie Fu,Haifeng Chen*

Main category: cs.AI

TL;DR: 提出一个多智能体框架，用于从自然语言中提取工作流程序图，通过结构化和逻辑反馈迭代改进提取结果


<details>
  <summary>Details</summary>
Motivation: 从自然语言自动提取工作流程序图是一个有前景但尚未充分探索的领域，需要同时保证结构有效性和逻辑一致性。现有大型语言模型虽然显示出潜力，但经常产生结构不良或逻辑流误解的结果。

Method: 提出一个多智能体框架，将程序图提取建模为多轮推理过程，包含三个迭代阶段：1) 图构建智能体进行初始提取；2) 模拟智能体诊断和解释结构缺陷；3) 语义智能体对齐流程逻辑与源文本语义线索。通过自然语言反馈优先处理重要问题并注入后续提示。

Result: 实验表明，该方法在结构正确性和逻辑一致性方面相比强基线模型取得了显著改进。

Conclusion: 该多智能体框架通过模块化设计，使智能体能够针对不同类型的错误进行无监督或参数更新的改进，实现了可解释和可控的程序图提取优化。

Abstract: Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.

</details>


### [10] [CollectiveKV: Decoupling and Sharing Collaborative Information in Sequential Recommendation](https://arxiv.org/abs/2601.19178)
*Jingyu Li,Zhaocheng Du,Qianhui Zhu,kaiyuan Li,Zhicheng Zhang,Song-Li Wu,Chaolang Li,Pengwen Dai*

Main category: cs.AI

TL;DR: KV缓存技术可降低序列推荐系统推理延迟，但存储开销大。研究发现不同用户的KV序列存在显著相似性，大部分信息可跨用户共享。提出CollectiveKV机制，通过全局KV池捕获共享信息，用户推理时结合共享KV与少量用户特定KV，将KV缓存压缩至原大小的0.8%且保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 序列推荐系统面临严格的延迟要求，Transformer注意力机制的计算复杂度随序列长度增长，KV缓存技术可降低推理延迟但引入巨大存储开销。研究发现不同用户的KV序列存在显著相似性，表明KV中存在协作信号，大部分信息可跨用户共享，少量为用户特定，这为KV压缩提供了机会。

Method: 提出CollectiveKV跨用户KV共享机制：1）通过奇异值分解分析发现KV信息可分为跨用户共享信息和用户特定信息两部分；2）构建可学习的全局KV池来捕获跨用户共享信息；3）推理时，每个用户从全局KV池检索高维共享KV，与低维用户特定KV拼接得到最终KV；4）在五个序列推荐模型和三个数据集上进行实验验证。

Result: 实验结果表明：1）CollectiveKV能将KV缓存压缩至原始大小的0.8%；2）在保持甚至提升模型性能的同时显著减少存储开销；3）在五个不同的序列推荐模型和三个数据集上均验证了方法的有效性。

Conclusion: KV序列中存在显著的跨用户相似性，大部分信息可共享。CollectiveKV通过全局KV池捕获共享信息，结合少量用户特定信息，实现了高效的KV缓存压缩，在保持性能的同时大幅减少存储开销，为解决序列推荐系统中KV缓存存储问题提供了有效方案。

Abstract: Sequential recommendation models are widely used in applications, yet they face stringent latency requirements. Mainstream models leverage the Transformer attention mechanism to improve performance, but its computational complexity grows with the sequence length, leading to a latency challenge for long sequences. Consequently, KV cache technology has recently been explored in sequential recommendation systems to reduce inference latency. However, KV cache introduces substantial storage overhead in sequential recommendation systems, which often have a large user base with potentially very long user history sequences. In this work, we observe that KV sequences across different users exhibit significant similarities, indicating the existence of collaborative signals in KV. Furthermore, we analyze the KV using singular value decomposition (SVD) and find that the information in KV can be divided into two parts: the majority of the information is shareable across users, while a small portion is user-specific. Motivated by this, we propose CollectiveKV, a cross-user KV sharing mechanism. It captures the information shared across users through a learnable global KV pool. During inference, each user retrieves high-dimensional shared KV from the pool and concatenates them with low-dimensional user-specific KV to obtain the final KV. Experiments on five sequential recommendation models and three datasets show that our method can compress the KV cache to only 0.8% of its original size, while maintaining or even enhancing model performance.

</details>


### [11] [CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning](https://arxiv.org/abs/2601.19193)
*Van-Quang Nguyen,Takayuki Okatani*

Main category: cs.AI

TL;DR: CoReTab是一个代码驱动的推理框架，通过将多步推理与可执行Python代码结合，为多模态表格理解提供可扩展、可解释且可自动验证的标注，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集如MMTab主要提供简短的事实性答案，缺乏明确的多步推理监督，导致模型生成的回答准确性不足且可解释性有限。

Method: 提出CoReTab框架，将多步推理与可执行Python代码结合生成可验证标注；构建包含115K验证样本的数据集；通过三阶段流水线微调开源MLLMs。

Result: 在17个MMTab基准测试中，CoReTab训练模型在表格问答、事实验证和表格结构理解任务上分别比MMTab训练基线提升+6.2%、+5.7%和+25.6%，同时产生透明可验证的推理轨迹。

Conclusion: CoReTab作为一个稳健且可泛化的监督框架，显著提升了多模态表格理解中的多步推理能力，提供了透明和可验证的推理过程。

Abstract: Existing datasets for multimodal table understanding, such as MMTab, primarily provide short factual answers without explicit multi-step reasoning supervision. Models trained on these datasets often generate brief responses that offers insufficient accuracy and limited interpretability into how these models arrive at the final answer. We introduce CoReTab, a code-driven reasoning framework that produces scalable, interpretable, and automatically verifiable annotations by coupling multi-step reasoning with executable Python code. Using the CoReTab framework, we curate a dataset of 115K verified samples averaging 529 tokens per response and fine-tune open-source MLLMs through a three-stage pipeline. We evaluate the resulting model trained on CoReTab across 17 MMTab benchmarks spanning table question answering, fact verification, and table structure understanding. Our model achieves significant gains of +6.2%, +5.7%, and +25.6%, respectively, over MMTab-trained baselines, while producing transparent and verifiable reasoning traces. These results establish CoReTab as a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding.

</details>


### [12] [MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning](https://arxiv.org/abs/2601.19204)
*Zhixi Cai,Fucai Ke,Kevin Leo,Sukai Huang,Maria Garcia de la Banda,Peter J. Stuckey,Hamid Rezatofighi*

Main category: cs.AI

TL;DR: MATA是一个用于视觉推理的多智能体分层可训练自动机系统，通过可训练的超智能体选择顶层状态转移，每个智能体运行基于规则的子自动机，共享内存实现透明执行历史，在多个视觉推理基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型具有强大的感知能力，但其隐式推理难以解释，在复杂查询上容易产生幻觉。组合方法提高了可解释性，但大多数依赖单一智能体或手工制作的流水线，无法决定何时在互补智能体之间协作或在重叠智能体之间竞争。

Method: 提出MATA（多智能体分层可训练自动机），这是一个作为分层有限状态自动机的多智能体系统，顶层转移由可训练的超智能体选择。每个智能体对应超自动机中的一个状态，运行小型基于规则的子自动机进行可靠的微控制。所有智能体读写共享内存，产生透明的执行历史。通过构建转移轨迹树并转换为内存到下一状态对，创建MATA-SFT-90K数据集用于监督微调。

Result: 在多个视觉推理基准测试中，MATA相比单一模型和组合基线方法取得了最先进的结果。微调后的LLM作为转移策略能够理解查询和智能体能力，有效选择最优智能体解决任务。

Conclusion: MATA通过多智能体分层可训练自动机框架，结合了感知模型的强大能力和组合方法的可解释性优势，实现了透明、可靠的视觉推理，在性能和可解释性方面都表现出色。

Abstract: Recent vision-language models have strong perceptual ability but their implicit reasoning is hard to explain and easily generates hallucinations on complex queries. Compositional methods improve interpretability, but most rely on a single agent or hand-crafted pipeline and cannot decide when to collaborate across complementary agents or compete among overlapping ones. We introduce MATA (Multi-Agent hierarchical Trainable Automaton), a multi-agent system presented as a hierarchical finite-state automaton for visual reasoning whose top-level transitions are chosen by a trainable hyper agent. Each agent corresponds to a state in the hyper automaton, and runs a small rule-based sub-automaton for reliable micro-control. All agents read and write a shared memory, yielding transparent execution history. To supervise the hyper agent's transition policy, we build transition-trajectory trees and transform to memory-to-next-state pairs, forming the MATA-SFT-90K dataset for supervised finetuning (SFT). The finetuned LLM as the transition policy understands the query and the capacity of agents, and it can efficiently choose the optimal agent to solve the task. Across multiple visual reasoning benchmarks, MATA achieves the state-of-the-art results compared with monolithic and compositional baselines. The code and dataset are available at https://github.com/ControlNet/MATA.

</details>


### [13] [Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection](https://arxiv.org/abs/2601.19245)
*Yongxin Deng,Zhen Fang,Yixuan Li,Ling Chen*

Main category: cs.AI

TL;DR: 该论文提出了一种可泛化的幻觉检测方法SpikeScore，通过量化多轮对话中的不确定性突变来区分幻觉和非幻觉响应，在跨域泛化方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法在训练和测试数据来自同一领域时表现良好，但在跨域泛化方面表现不佳。论文研究了一个重要但被忽视的问题——可泛化幻觉检测(GHD)，旨在在单一领域数据上训练幻觉检测器，同时确保在不同相关领域中具有鲁棒性能。

Method: 通过模拟LLM初始响应后的多轮对话，观察到幻觉引发的多轮对话在不同领域中普遍表现出比事实性对话更大的不确定性波动。基于这一现象，提出了SpikeScore评分，用于量化多轮对话中的突然波动。通过理论分析和实证验证，证明SpikeScore在幻觉和非幻觉响应之间实现了强大的跨域可分离性。

Result: 在多个LLM和基准测试上的实验表明，基于SpikeScore的检测方法在跨域泛化方面优于代表性基线方法，并且超越了先进的面向泛化的方法，验证了该方法在跨域幻觉检测中的有效性。

Conclusion: SpikeScore方法通过量化多轮对话中的不确定性波动，为可泛化幻觉检测提供了有效的解决方案，在跨域场景中表现出色，为LLM在实际应用中的可靠部署提供了重要支持。

Abstract: Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this paper, we study an important yet overlooked problem, termed generalizable hallucination detection (GHD), which aims to train hallucination detectors on data from a single domain while ensuring robust performance across diverse related domains. In studying GHD, we simulate multi-turn dialogues following LLMs initial response and observe an interesting phenomenon: hallucination-initiated multi-turn dialogues universally exhibit larger uncertainty fluctuations than factual ones across different domains. Based on the phenomenon, we propose a new score SpikeScore, which quantifies abrupt fluctuations in multi-turn dialogues. Through both theoretical analysis and empirical validation, we demonstrate that SpikeScore achieves strong cross-domain separability between hallucinated and non-hallucinated responses. Experiments across multiple LLMs and benchmarks demonstrate that the SpikeScore-based detection method outperforms representative baselines in cross-domain generalization and surpasses advanced generalization-oriented methods, verifying the effectiveness of our method in cross-domain hallucination detection.

</details>


### [14] [GLOVE: Global Verifier for LLM Memory-Environment Realignment](https://arxiv.org/abs/2601.19249)
*Xingkun Yin,Hongyang Du*

Main category: cs.AI

TL;DR: GLOVE框架通过主动探测记忆与观察的不一致性，建立相对真理概念，实现无监督记忆更新，提升LLM在动态环境中的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM记忆增强方法依赖外部评估器或模型内省来验证记忆有效性，但在动态漂移的实际环境中这些假设往往失效，需要更鲁棒的记忆验证机制。

Method: 提出GLOVE框架，通过主动探测检索记忆与新鲜观察之间的不一致性，建立相对真理概念，实现无监督记忆-环境重新对齐，不依赖真实监督或强模型内省。

Result: 在网页导航、规划和控制等多样化基准测试中，加入受控环境漂移后，GLOVE显著提高了智能体成功率。

Conclusion: GLOVE为LLM记忆系统提供了新的设计维度，通过相对真理验证机制，为实现能够自我进化的认知智能体提供了鲁棒路径。

Abstract: Most existing memory-enhanced Large Language Model (LLM) approaches implicitly assume that memory validity can be established either through external evaluators that provide task-specific success signals or through internal model cognition, such as reflection, for editing memory entries. However, these assumptions often break down in practical environments with dynamic drifts. We propose the Global Verifier (GLOVE), a framework that introduces a new design dimension for LLM memory systems by establishing a relative notion of truth. Through active probing to detect inconsistencies between retrieved memories and fresh observations, GLOVE enables memory-environment realignment by verifying and updating memory without access to ground-truth supervision or strong reliance on model introspection. We evaluate GLOVE on diverse benchmarks spanning web navigation, planning, and control, augmented with controlled environmental drifts that introduce non-stationarity beyond the original benchmark settings. Our results show that GLOVE substantially improves agent success rates, suggesting a robust pathway to cognitive agents capable of self-evolving.

</details>


### [15] [RPO:Reinforcement Fine-Tuning with Partial Reasoning Optimization](https://arxiv.org/abs/2601.19404)
*Hongzhu Yi,Xinming Wang,Zhenghao zhang,Tianyu Zong,Yuanxiang Wang,Jun Xie,Tao Yu,Haopeng Jin,Zhepeng Wang,Kaixin Xu,Feng Chen,Jiahuan Chen,Yujia Yang,Zhenyu Guan,Bingkang Shi,Jungang Xu*

Main category: cs.AI

TL;DR: RPO是一种强化微调算法，通过仅生成推理路径的后缀来减少训练时的token生成，相比传统方法可降低约95%的rollout阶段token生成，显著加速训练。


<details>
  <summary>Details</summary>
Motivation: 传统强化微调算法需要从输入查询开始生成完整的推理轨迹，这在训练rollout阶段会产生巨大的计算开销。为了解决这个问题，研究者分析了推理路径不同部分对最终结果正确性的影响。

Method: 提出RPO（强化微调与部分推理优化）算法，这是一种即插即用的强化微调算法。与传统生成完整推理路径的方法不同，RPO通过经验缓存生成推理路径的后缀来训练模型，在rollout阶段大幅减少token生成。

Result: RPO在rollout阶段减少了约95%的token生成，显著降低了理论时间开销。对于1.5B模型，训练时间减少了90%；对于7B模型，训练时间减少了72%。同时，RPO可以与GRPO、DAPO等典型算法集成，在保持性能的同时实现训练加速。

Conclusion: RPO是一种高效的强化微调算法，通过部分推理优化显著减少了训练时的计算开销，同时保持了与传统方法相当的性能，为大规模语言模型的强化微调提供了实用的加速方案。

Abstract: Within the domain of large language models, reinforcement fine-tuning algorithms necessitate the generation of a complete reasoning trajectory beginning from the input query, which incurs significant computational overhead during the rollout phase of training. To address this issue, we analyze the impact of different segments of the reasoning path on the correctness of the final result and, based on these insights, propose Reinforcement Fine-Tuning with Partial Reasoning Optimization (RPO), a plug-and-play reinforcement fine-tuning algorithm. Unlike traditional reinforcement fine-tuning algorithms that generate full reasoning paths, RPO trains the model by generating suffixes of the reasoning path using experience cache. During the rollout phase of training, RPO reduces token generation in this phase by approximately 95%, greatly lowering the theoretical time overhead. Compared with full-path reinforcement fine-tuning algorithms, RPO reduces the training time of the 1.5B model by 90% and the 7B model by 72%. At the same time, it can be integrated with typical algorithms such as GRPO and DAPO, enabling them to achieve training acceleration while maintaining performance comparable to the original algorithms. Our code is open-sourced at https://github.com/yhz5613813/RPO.

</details>


### [16] [Fuzzy expert system for the process of collecting and purifying acidic water: a digital twin approach](https://arxiv.org/abs/2601.19527)
*Temirbolat Maratuly,Pakizar Shamoi,Timur Samigulin*

Main category: cs.AI

TL;DR: 本文提出了一种结合数字孪生的模糊专家系统，用于酸性水净化过程的自动化控制，通过模拟人类推理来维持关键参数在期望水平，并开发了基于Web的仿真界面进行测试验证。


<details>
  <summary>Details</summary>
Motivation: 酸性水净化对于减少排放、降低腐蚀风险、实现处理后水的再利用以及降低运营成本至关重要。自动化净化过程可以减少人工参与，降低工人安全风险。原油中的酸性成分在加工过程中会释放到酸性水中，如果不妥善处理会对环境造成严重威胁并加速管道设备腐蚀。

Method: 开发了模糊专家系统与定制数字孪生相结合的控制策略。数字孪生使用Honeywell UniSim Design R492开发，阀门动态通过MATLAB系统识别建模，实时数据交换使用OPC DA实现。模糊控制器采用分程控制策略控制两个阀门，在21种不同初始压力条件下使用5种不同的去模糊化策略进行了105个测试场景的验证。

Result: 系统性能使用误差指标（MSE、RMSE、MAE、IAE、ISE、ITAE）和动态响应指标（超调量、欠调量、上升时间、下降时间、稳定时间、稳态误差）进行评估。开发了基于Python Streamlit框架的Web仿真界面。

Conclusion: 虽然本文以酸性水处理为例进行演示，但所提出的模糊专家系统具有通用性，控制策略简单直观，允许初级或非专业人员有效与系统交互。

Abstract: Purifying sour water is essential for reducing emissions, minimizing corrosion risks, enabling the reuse of treated water in industrial or domestic applications, and ultimately lowering operational costs. Moreover, automating the purification process helps reduce the risk of worker harm by limiting human involvement. Crude oil contains acidic components such as hydrogen sulfide, carbon dioxide, and other chemical compounds. During processing, these substances are partially released into sour water. If not properly treated, sour water poses serious environmental threats and accelerates the corrosion of pipelines and equipment. This paper presents a fuzzy expert system, combined with a custom-generated digital twin, developed from a documented industrial process to maintain key parameters at desired levels by mimicking human reasoning. The control strategy is designed to be simple and intuitive, allowing junior or non-expert personnel to interact with the system effectively. The digital twin was developed using Honeywell UniSim Design R492 to simulate real industrial behavior accurately. Valve dynamics were modeled through system identification in MATLAB, and real-time data exchange between the simulator and controller was established using OPC DA. The fuzzy controller applies split-range control to two valves and was tested under 21 different initial pressure conditions using five distinct defuzzification strategies, resulting in a total of 105 unique test scenarios. System performance was evaluated using both error-based metrics (MSE, RMSE, MAE, IAE, ISE, ITAE) and dynamic response metrics, including overshoot, undershoot, rise time, fall time, settling time, and steady-state error. A web-based simulation interface was developed in Python using the Streamlit framework. Although demonstrated here for sour water treatment, the proposed fuzzy expert system is general-purpose.

</details>


### [17] [Benchmarks Saturate When The Model Gets Smarter Than The Judge](https://arxiv.org/abs/2601.19532)
*Marthe Ballon,Andres Algaba,Brecht Verbeken,Vincent Ginis*

Main category: cs.AI

TL;DR: Omni-MATH-2是对Omni-MATH数据集的修订版本，包含4181个干净问题和247个标记问题，通过人工审核确保可编译性、可解性和可验证性，显著减少数据集噪声，提供更精确的模型性能评估。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型基准测试存在数据集不准确和评估方法不可靠的问题，这些问题削弱了基准测试的有效性。需要更高质量的数据集和更可靠的评估方法来准确评估模型性能。

Method: 创建Omni-MATH-2数据集：1）人工审核所有问题，确保LaTeX可编译性、可解性和可验证性；2）添加缺失图形或信息；3）标记需要证明、估计或图像的问题；4）移除杂乱内容；5）使用GPT-5 mini和原始Omni-Judge评估法官引起的噪声。

Result: 1）修订后的数据集显著减少数据集引起的噪声；2）比较GPT-5 mini和Omni-Judge发现法官间存在显著差异；3）专家标注显示在法官分歧中，Omni-Judge在96.4%的情况下是错误的；4）随着问题难度增加，需要更胜任的法官来防止法官错误掩盖模型间的真实差异；5）两种法官都无法识别标记问题子集的当前失败模式。

Conclusion: 数据集质量和法官可靠性对于开发准确的模型性能基准测试都至关重要。仅改进数据集或评估方法都不足以确保基准测试的有效性，需要同时关注这两个方面。

Abstract: Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset ($n{=}4181$) and a tagged, non-standard subset ($n{=}247$). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in $96.4\%$ of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.

</details>


### [18] [Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search](https://arxiv.org/abs/2601.19622)
*Thomas Bömer,Nico Koltermann,Max Disselnmeyer,Bastian Amberg,Anne Meyer*

Main category: cs.AI

TL;DR: 本文提出A-CEoH框架，通过将A*算法代码融入提示词，利用上下文学习自动生成A*搜索的启发式函数，在UPMP和SPP问题上超越了专家设计的启发式函数。


<details>
  <summary>Details</summary>
Motivation: 传统启发式函数需要专家手工设计，耗时耗力。大语言模型和进化框架的发展为自动化启发式设计提供了可能，但现有方法仍有改进空间。

Method: 扩展EoH框架，提出A-CEoH方法，采用领域无关的提示增强策略，将A*算法代码融入提示词以利用上下文学习能力。

Result: 在Unit-Load Pre-Marshalling Problem和滑动拼图问题上，A-CEoH生成的启发式函数质量显著提升，甚至超越了专家设计的启发式函数。

Conclusion: A-CEoH框架能够有效自动化启发式函数设计，通过算法上下文学习提升生成质量，为A*搜索等树搜索算法提供了新的启发式生成方法。

Abstract: Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.

</details>


### [19] [Agentic Design Patterns: A System-Theoretic Framework](https://arxiv.org/abs/2601.19752)
*Minh-Dung Dao,Quy Minh Le,Hoang Thanh Lam,Duc-Trong Le,Quoc-Viet Pham,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: 本文提出了一种基于系统理论的AI智能体工程化方法，包括一个五子系统框架和12种设计模式，旨在解决现有智能体系统不可靠、设计随意的问题。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型的发展，智能体AI系统受到更多关注，但其固有的幻觉、推理能力差等问题，加上系统设计常常是临时性的，导致应用不可靠且脆弱。现有描述智能体设计模式的工作缺乏严格的系统理论基础，导致难以实施的高级或便利性分类法。

Method: 提出两个主要贡献：1）一个新颖的系统理论框架，将智能体AI系统解构为五个核心交互功能子系统：推理与世界模型、感知与接地、动作执行、学习与适应、智能体间通信；2）基于此架构并直接映射到全面的智能体挑战分类法，提出12种智能体设计模式，分为基础类、认知与决策类、执行与交互类、适应与学习类。

Result: 通过ReAct框架的案例研究展示了该框架的实用性，展示了所提出的模式如何纠正系统性架构缺陷。该工作为研究人员和工程师提供了标准化的智能体设计交流基础语言和结构化方法。

Conclusion: 这项工作提供了基础语言和结构化方法，用于标准化研究人员和工程师之间的智能体设计交流，从而产生更模块化、可理解和可靠的自适应系统。

Abstract: With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.

</details>


### [20] [GAVEL: Towards rule-based safety through activation monitoring](https://arxiv.org/abs/2601.19768)
*Shir Rozenfeld,Rahul Pankajakshan,Itay Zloczower,Eyal Lenga,Gilad Gressel,Yisroel Mirsky*

Main category: cs.AI

TL;DR: 论文提出基于规则的激活安全新范式，将LLM激活建模为可组合的认知元素，通过谓词规则实时检测违规行为，提高精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于激活的安全监控方法存在精度低、灵活性差、缺乏可解释性等问题，需要一种更精确、可定制、可审计的AI安全治理方案。

Method: 提出基于规则的激活安全范式：1) 将激活建模为细粒度、可解释的认知元素；2) 定义认知元素上的谓词规则；3) 实时检测规则违规；4) 提供开源框架GAVEL和自动规则创建工具。

Result: 基于规则的激活安全方法提高了检测精度，支持领域定制，为可扩展、可解释、可审计的AI治理奠定了基础。

Conclusion: 组合式基于规则的激活安全是改进LLM安全监控的有效方法，通过认知元素表示和规则系统实现了更高的精度、灵活性和透明度。

Abstract: Large language models (LLMs) are increasingly paired with activation-based monitoring to detect and prevent harmful behaviors that may not be apparent at the surface-text level. However, existing activation safety approaches, trained on broad misuse datasets, struggle with poor precision, limited flexibility, and lack of interpretability. This paper introduces a new paradigm: rule-based activation safety, inspired by rule-sharing practices in cybersecurity. We propose modeling activations as cognitive elements (CEs), fine-grained, interpretable factors such as ''making a threat'' and ''payment processing'', that can be composed to capture nuanced, domain-specific behaviors with higher precision. Building on this representation, we present a practical framework that defines predicate rules over CEs and detects violations in real time. This enables practitioners to configure and update safeguards without retraining models or detectors, while supporting transparency and auditability. Our results show that compositional rule-based activation safety improves precision, supports domain customization, and lays the groundwork for scalable, interpretable, and auditable AI governance. We will release GAVEL as an open-source framework and provide an accompanying automated rule creation tool.

</details>


### [21] [An Interpretable Recommendation Model for Psychometric Data, With an Application to Gerontological Primary Care](https://arxiv.org/abs/2601.19824)
*Andre Paulino de Lima,Paula Castro,Suzana Carvalho Vaz de Andrade,Rosa Maria Marcucci,Ruth Caldeira de Melo,Marcelo Garcia Manzato*

Main category: cs.AI

TL;DR: 该研究提出了一种用于老年初级保健的推荐系统模型，利用心理测量数据结构提供可视化解释，以解决医疗推荐系统中的数据稀缺、可解释性差、风险不确定等挑战。


<details>
  <summary>Details</summary>
Motivation: 医疗环境中推荐系统面临多重挑战：缺乏公开临床数据、用户难以理解推荐理由、遵循推荐存在风险、推荐效果不确定性。特别是在老年初级保健领域，随着人口老龄化，对个性化护理计划的需求日益增长。

Method: 提出一种推荐模型，利用心理测量数据结构生成可视化解释，这些解释既忠实于模型又能被护理专业人员理解。模型专注于老年初级保健这一细分领域，通过离线性能评估和用户研究验证效果。

Result: 在巴西研究合作伙伴收集的医疗数据集上进行了比较离线性能评估，同时进行了用户研究评估模型生成的可视化解释的可解释性。结果表明模型在该医疗细分领域具有应用前景。

Conclusion: 提出的模型能够推进推荐系统在老年初级保健领域的应用，随着人口结构变化，该领域的需求、机会和信息技术需求预计将不断增长。

Abstract: There are challenges that must be overcome to make recommender systems useful in healthcare settings. The reasons are varied: the lack of publicly available clinical data, the difficulty that users may have in understanding the reasons why a recommendation was made, the risks that may be involved in following that recommendation, and the uncertainty about its effectiveness. In this work, we address these challenges with a recommendation model that leverages the structure of psychometric data to provide visual explanations that are faithful to the model and interpretable by care professionals. We focus on a narrow healthcare niche, gerontological primary care, to show that the proposed recommendation model can assist the attending professional in the creation of personalised care plans. We report results of a comparative offline performance evaluation of the proposed model on healthcare datasets that were collected by research partners in Brazil, as well as the results of a user study that evaluates the interpretability of the visual explanations the model generates. The results suggest that the proposed model can advance the application of recommender systems in this healthcare niche, which is expected to grow in demand , opportunities, and information technology needs as demographic changes become more pronounced.

</details>


### [22] [Routing End User Queries to Enterprise Databases](https://arxiv.org/abs/2601.19825)
*Saikrishna Sudarshan,Tanay Kulkarni,Manasi Patwardhan,Lovekesh Vig,Ashwin Srinivasan,Tanmay Tulsidas Verlekar*

Main category: cs.AI

TL;DR: 该论文提出了一种用于多数据库企业环境中自然语言查询路由的模块化推理驱动重排序策略，通过建模模式覆盖、结构连通性和细粒度语义对齐，显著优于嵌入方法和直接LLM提示基线。


<details>
  <summary>Details</summary>
Motivation: 在多数据库企业环境中，随着数据库规模增大和领域重叠，自然语言查询路由变得越来越具有挑战性，特别是面对模糊查询时，需要更结构化、更鲁棒的基于推理的解决方案。

Method: 提出模块化推理驱动的重排序策略，通过显式建模三个关键维度：模式覆盖（schema coverage）、结构连通性（structural connectivity）和细粒度语义对齐（fine-grained semantic alignment）。

Result: 该方法在所有评估指标上一致优于仅使用嵌入的方法和直接LLM提示的基线方法，通过扩展现有NL-to-SQL数据集构建的现实基准验证了其有效性。

Conclusion: 在多数据库查询路由任务中，结构化推理方法比简单的嵌入或直接LLM提示更有效，特别是在处理大规模、领域重叠的数据库存储库和模糊查询时。

Abstract: We address the task of routing natural language queries in multi-database enterprise environments. We construct realistic benchmarks by extending existing NL-to-SQL datasets. Our study shows that routing becomes increasingly challenging with larger, domain-overlapping DB repositories and ambiguous queries, motivating the need for more structured and robust reasoning-based solutions. By explicitly modelling schema coverage, structural connectivity, and fine-grained semantic alignment, the proposed modular, reasoning-driven reranking strategy consistently outperforms embedding-only and direct LLM-prompting baselines across all the metrics.

</details>


### [23] [Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models](https://arxiv.org/abs/2601.19834)
*Jialong Wu,Xiaoying Zhang,Hongyi Yuan,Xiangcheng Zhang,Tianhao Huang,Changjing He,Chaoyi Deng,Renrui Zhang,Youbin Wu,Mingsheng Long*

Main category: cs.AI

TL;DR: 本文首次系统研究视觉生成何时及如何提升推理能力，提出视觉优越性假说：在物理世界相关任务中，视觉生成能更自然地作为世界模型，而纯语言世界模型会遭遇表征限制或先验知识不足的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在数学、编程等抽象领域已取得专家级表现，但在物理和空间智能等需要丰富表征和先验知识的领域仍远落后于人类。统一多模态模型的出现引发了人们对基于互补多模态路径的更类人推理的兴趣，但其益处尚不明确。

Method: 从世界模型视角出发，理论层面将内部世界建模形式化为CoT推理的核心组件，分析不同形式世界模型的区别；实证层面识别需要交错视觉-语言CoT推理的任务，构建新的评估套件VisWorld-Eval，并在最先进的统一多模态模型上进行控制实验。

Result: 在有利于视觉世界建模的任务上，交错CoT显著优于纯语言CoT，但在其他任务上没有明显优势。这证实了视觉优越性假说：对于某些任务（特别是物理世界相关的），视觉生成能更自然地作为世界模型。

Conclusion: 这项工作阐明了多模态世界建模对于更强大、更类人的多模态AI的潜力，为理解视觉生成在推理中的作用提供了原则性框架。

Abstract: Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind humans in domains like physical and spatial intelligence, which require richer representations and prior knowledge. The emergence of unified multimodal models (UMMs) capable of both verbal and visual generation has therefore sparked interest in more human-like reasoning grounded in complementary multimodal pathways, though their benefits remain unclear. From a world-model perspective, this paper presents the first principled study of when and how visual generation benefits reasoning. Our key position is the visual superiority hypothesis: for certain tasks--particularly those grounded in the physical world--visual generation more naturally serves as world models, whereas purely verbal world models encounter bottlenecks arising from representational limitations or insufficient prior knowledge. Theoretically, we formalize internal world modeling as a core component of CoT reasoning and analyze distinctions among different forms of world models. Empirically, we identify tasks that necessitate interleaved visual-verbal CoT reasoning, constructing a new evaluation suite, VisWorld-Eval. Controlled experiments on a state-of-the-art UMM show that interleaved CoT significantly outperforms purely verbal CoT on tasks that favor visual world modeling, but offers no clear advantage otherwise. Together, this work clarifies the potential of multimodal world modeling for more powerful, human-like multimodal AI.

</details>
