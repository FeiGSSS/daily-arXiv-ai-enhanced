<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [NeuroAI and Beyond](https://arxiv.org/abs/2601.19955)
*Jean-Marc Fellous,Gert Cauwenberghs,Cornelia Fermüller,Yulia Sandamisrkaya,Terrence Sejnowski*

Main category: cs.AI

TL;DR: 该论文基于2025年8月研讨会，探讨神经科学与人工智能的协同发展，提出NeuroAI概念，旨在通过神经科学启发改进AI算法，同时深化对生物神经计算的理解。


<details>
  <summary>Details</summary>
Motivation: 神经科学与人工智能在过去几年都取得了显著进展，但两者之间的连接仍然松散。作者希望通过整合这两个领域，开发出受神经科学启发的人工智能（NeuroAI），以提升AI算法的范围和效率，同时改变对生物神经计算的理解方式。

Method: 基于2025年8月举办的研讨会，聚焦于具身认知、语言与通信、机器人学、人类与机器学习以及神经形态工程等子领域，评估当前进展并探索未来发展方向。收集了多位顶尖研究人员的个人观点，并附上研究人员和学员进行的SWOT分析。

Result: 提出了NeuroAI的概念框架，强调神经科学与人工智能的协同潜力。通过研讨会讨论和专家意见，识别了当前和未来的合作领域，并提供了SWOT分析来评估NeuroAI的优势、劣势、机会和威胁。

Conclusion: 倡导发展NeuroAI——一种受神经科学启发的人工智能，认为这不仅能显著提升AI算法的范围和效率，还能改变我们对生物神经计算的理解方式。通过整合两个领域的优势，有望推动人工智能和神经科学的共同进步。

Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.

</details>


### [2] [Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning](https://arxiv.org/abs/2601.20014)
*Shuhui Qu*

Main category: cs.AI

TL;DR: SQ-BCP是一种在部分可观测环境下进行推理时规划的方法，通过显式表示前提条件状态、自我查询和桥接假设来解决LLM在缺失关键前提时产生幻觉或违反约束的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在部分可观测环境下进行推理时规划经常失败：当任务关键前提条件在查询时未指定时，模型倾向于幻觉缺失事实或产生违反硬约束的计划。

Method: 引入自我查询双向分类规划(SQ-BCP)，显式表示前提条件状态(Sat/Viol/Unk)，通过(i)针对性的自我查询到预言机/用户或(ii)桥接假设（通过额外动作建立缺失条件）来解析未知状态。SQ-BCP执行双向搜索，并调用基于回拉的验证器作为目标兼容性的分类证书，同时仅使用基于距离的分数进行排序和剪枝。

Result: 在WikiHow和RecipeNLG任务中，当预条件被保留时，SQ-BCP将资源违规率降低到14.9%和5.8%（相比最佳基线的26.0%和15.7%），同时保持竞争力的参考质量。

Conclusion: SQ-BCP在部分可观测环境下提供了一种有效的推理时规划方法，通过显式处理未知前提条件和验证机制，显著减少了计划违反约束的情况，并在理论上保证了当验证器成功且硬约束通过确定性检查时，接受的计划与目标要求兼容。

Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \textbf{14.9\%} and \textbf{5.8\%} (vs.\ \textbf{26.0\%} and \textbf{15.7\%} for the best baseline), while maintaining competitive reference quality.

</details>


### [3] [Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints](https://arxiv.org/abs/2601.20021)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 提出模糊范畴论规划(FCP)方法，处理自然语言规划中的模糊谓词问题，通过[0,1]区间标注动作质量，使用Łukasiewicz t-范数组合计划质量，同时保持严格的执行性检查


<details>
  <summary>Details</summary>
Motivation: 现有范畴论规划器将适用性视为二值判断，需要阈值处理，这会抹杀有意义的区别，且无法跟踪多步计划中的质量退化。自然语言规划常涉及模糊谓词（如"合适的替代品"、"足够稳定"），其满足度本质上是分级的

Method: FCP为每个动作（态射）标注[0,1]区间的程度值，使用Łukasiewicz t-范数组合计划质量，通过拉回验证保持严格的执行性检查。使用LLM进行k样本中位数聚合从语言中获取分级适用性，支持基于剩余的后向需求的中间相遇搜索

Result: 在RecipeNLG-Subs（基于RecipeNLG、Recipe1MSubs和FoodKG构建的食谱替代规划基准）上，FCP相比LLM-only和ReAct风格基线提高了成功率并减少了硬约束违反，同时与经典PDDL3规划器保持竞争力

Conclusion: FCP成功地将模糊逻辑与范畴论规划相结合，有效处理自然语言规划中的模糊谓词问题，在保持严格执行性检查的同时，能够跟踪和组合多步计划中的质量退化

Abstract: Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verification, but treat applicability as crisp, forcing thresholding that collapses meaningful distinctions and cannot track quality degradation across multi-step plans. We propose Fuzzy Category-theoretic Planning (FCP), which annotates each action (morphism) with a degree in [0,1], composes plan quality via a t-norm Lukasiewicz, and retains crisp executability checks via pullback verification. FCP grounds graded applicability from language using an LLM with k-sample median aggregation and supports meeting-in-the-middle search using residuum-based backward requirements. We evaluate on (i) public PDDL3 preference/oversubscription benchmarks and (ii) RecipeNLG-Subs, a missing-substitute recipe-planning benchmark built from RecipeNLG with substitution candidates from Recipe1MSubs and FoodKG. FCP improves success and reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines, while remaining competitive with classical PDDL3 planners.

</details>


### [4] [Insight Agents: An LLM-Based Multi-Agent System for Data Insights](https://arxiv.org/abs/2601.20048)
*Jincheng Bai,Zhenyu Zhang,Jennifer Zhang,Zhihuai Zhu*

Main category: cs.AI

TL;DR: 开发了一个名为Insight Agents的对话式多智能体数据洞察系统，通过自动化信息检索为电商卖家提供个性化数据和业务洞察，旨在降低卖家决策成本并提高决策速度。


<details>
  <summary>Details</summary>
Motivation: 电商卖家面临两大挑战：难以发现和有效利用可用程序工具，以及难以理解和利用各种工具的丰富数据。因此需要开发一个能够提供个性化数据洞察的系统，作为卖家的"力量倍增器"。

Method: 基于计划-执行范式构建了分层多智能体系统，包括管理智能体和两个工作智能体（数据呈现和洞察生成）。管理智能体采用轻量级编码器-解码器模型进行OOD检测和BERT分类器进行智能体路由。工作智能体中设计了API数据模型的战略规划，将查询分解为细粒度组件，并动态注入领域知识以增强洞察生成。

Result: 系统已在美国亚马逊卖家平台上线，基于人工评估达到90%的高准确率，P90延迟低于15秒。

Conclusion: Insight Agents系统通过创新的多智能体架构和ML解决方案，成功为电商卖家提供了高效、准确的数据洞察服务，验证了其作为卖家"力量倍增器"的假设。

Abstract: Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Insight Agents (IA), a conversational multi-agent Data Insight system, to provide E-commerce sellers with personalized data and business insights through automated information retrieval. Our hypothesis is that IA will serve as a force multiplier for sellers, thereby driving incremental seller adoption by reducing the effort required and increase speed at which sellers make good business decisions. In this paper, we introduce this novel LLM-backed end-to-end agentic system built on a plan-and-execute paradigm and designed for comprehensive coverage, high accuracy, and low latency. It features a hierarchical multi-agent structure, consisting of manager agent and two worker agents: data presentation and insight generation, for efficient information retrieval and problem-solving. We design a simple yet effective ML solution for manager agent that combines Out-of-Domain (OOD) detection using a lightweight encoder-decoder model and agent routing through a BERT-based classifier, optimizing both accuracy and latency. Within the two worker agents, a strategic planning is designed for API-based data model that breaks down queries into granular components to generate more accurate responses, and domain knowledge is dynamically injected to to enhance the insight generator. IA has been launched for Amazon sellers in US, which has achieved high accuracy of 90% based on human evaluation, with latency of P90 below 15s.

</details>


### [5] [Towards Intelligent Urban Park Development Monitoring: LLM Agents for Multi-Modal Information Fusion and Analysis](https://arxiv.org/abs/2601.20206)
*Zixuan Xiao,Chunguang Hu,Jun Ma*

Main category: cs.AI

TL;DR: 提出多模态LLM智能体框架，用于城市新建公园发展监测，通过数据对齐机制和领域工具包解决传统遥感方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统基于遥感影像的变化检测方法在城市公园发展监测中存在局限性，难以满足当前城市规划管理对复杂多模态数据分析的需求，特别是在高层次智能分析和多样化应用场景方面存在不足。

Method: 提出多模态LLM智能体框架，设计通用的水平和垂直数据对齐机制确保多模态数据一致性和有效追踪，构建特定工具包缓解LLM因缺乏领域知识而产生的幻觉问题。

Result: 相比vanilla GPT-4o和其他智能体，该方法实现了稳健的多模态信息融合与分析，为城市公园发展监测提供了可靠且可扩展的解决方案。

Conclusion: 该多模态LLM智能体框架能够充分利用LLM的语义理解和推理能力，有效应对城市公园发展监测中的挑战，满足多样化和不断变化的需求。

Abstract: As an important part of urbanization, the development monitoring of newly constructed parks is of great significance for evaluating the effect of urban planning and optimizing resource allocation. However, traditional change detection methods based on remote sensing imagery have obvious limitations in high-level and intelligent analysis, and thus are difficult to meet the requirements of current urban planning and management. In face of the growing demand for complex multi-modal data analysis in urban park development monitoring, these methods often fail to provide flexible analysis capabilities for diverse application scenarios. This study proposes a multi-modal LLM agent framework, which aims to make full use of the semantic understanding and reasoning capabilities of LLM to meet the challenges in urban park development monitoring. In this framework, a general horizontal and vertical data alignment mechanism is designed to ensure the consistency and effective tracking of multi-modal data. At the same time, a specific toolkit is constructed to alleviate the hallucination issues of LLM due to the lack of domain-specific knowledge. Compared to vanilla GPT-4o and other agents, our approach enables robust multi-modal information fusion and analysis, offering reliable and scalable solutions tailored to the diverse and evolving demands of urban park development monitoring.

</details>


### [6] [AMA: Adaptive Memory via Multi-Agent Collaboration](https://arxiv.org/abs/2601.20352)
*Weiquan Huang,Zixuan Wang,Hehai Lin,Sudong Wang,Bo Xu,Qian Li,Beier Zhu,Linyi Yang,Chengwei Qin*

Main category: cs.AI

TL;DR: AMA框架通过多智能体协作实现自适应记忆管理，显著提升长期记忆一致性并减少80%的token消耗


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体记忆系统存在检索粒度僵化、维护策略积累过重、更新机制粗糙等问题，导致存储信息与任务需求不匹配，长期积累逻辑不一致性

Method: 提出AMA框架，采用分层记忆设计，通过Constructor和Retriever实现多粒度记忆构建和自适应查询路由，Judge验证相关性和一致性，Refresher执行针对性更新或删除过时条目

Result: 在挑战性长上下文基准测试中显著优于现有最先进基线，相比全上下文方法减少约80%的token消耗，在保持检索精度和长期记忆一致性方面表现出色

Conclusion: AMA框架通过多智能体协作有效解决了LLM智能体记忆系统的核心挑战，实现了自适应记忆管理和长期一致性维护

Abstract: The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.

</details>


### [7] [Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution](https://arxiv.org/abs/2601.20379)
*Zhengbo Jiao,Hongyu Xian,Qinglong Wang,Yunpu Ma,Zhebo Wang,Zifan Zhang,Dezhang Kong,Meng Han*

Main category: cs.AI

TL;DR: PoT框架通过在线优化策略，让LLM从执行反馈中学习，显著提升复杂推理能力，4B模型在LiveCodeBench上超越GPT-4o等大模型


<details>
  <summary>Details</summary>
Motivation: 当前LLM在复杂长程推理中存在困难，现有方法仅将执行反馈作为外部信号用于轨迹过滤或重写，未能将其内化以改进底层推理策略。受波普尔"猜想与反驳"认识论启发，认为智能需要从失败尝试中实时演化模型策略

Method: 提出Policy of Thoughts (PoT)框架，将推理重新定义为实例内的在线优化过程：1) 通过高效探索机制生成多样化候选解；2) 使用组相对策略优化(GRPO)基于执行反馈更新瞬态LoRA适配器，实现闭环动态优化

Result: PoT显著提升性能：4B模型在LiveCodeBench上达到49.71%准确率，超越GPT-4o和DeepSeek-V3，尽管模型规模小50倍以上

Conclusion: PoT框架通过在线策略优化使LLM能够从执行反馈中学习，实现实例特定的推理策略动态优化，为提升LLM复杂推理能力提供了新方向

Abstract: Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of "conjectures and refutations," we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.

</details>


### [8] [CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning](https://arxiv.org/abs/2601.20467)
*Zhenxuan Fan,Jie Cao,Yang Dai,Zheqi Lv,Wenqiao Zhang,Zhongle Xie,Peng LU,Beng Chin Ooi*

Main category: cs.AI

TL;DR: CtrlCoT是一个双粒度CoT压缩框架，通过语义抽象和token级剪枝的协调，在减少30.7%token的同时提升7.6%准确率


<details>
  <summary>Details</summary>
Motivation: 现有CoT提示方法存在高延迟和高内存成本的问题，而现有的CoT压缩方法要么语义级压缩过于保守，要么token级剪枝过于激进导致准确性下降，且两者结合存在序列依赖、任务无关剪枝和分布不匹配等挑战

Method: 提出CtrlCoT框架，包含三个组件：1) 分层推理抽象，生成多粒度语义CoT；2) 逻辑保持蒸馏，训练逻辑感知剪枝器保留关键推理线索；3) 分布对齐生成，对齐压缩轨迹与推理风格以避免碎片化

Result: 在MATH-500数据集上使用Qwen2.5-7B-Instruct模型，CtrlCoT相比最强基线减少30.7%token使用，同时准确率提升7.6个百分点

Conclusion: CtrlCoT通过协调语义抽象和token级剪枝，实现了更高效可靠的推理，在保持正确性的同时显著降低了CoT的延迟和内存成本

Abstract: Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.

</details>


### [9] [Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function](https://arxiv.org/abs/2601.20554)
*Yaacov Pariente,Vadim Indelman*

Main category: cs.AI

TL;DR: 该研究将迭代条件风险价值（ICVaR）动态风险度量应用于部分可观测环境下的风险敏感规划，开发了具有有限时间性能保证的策略评估算法，并将三种主流在线规划算法扩展为优化ICVaR值函数而非期望回报的风险敏感版本。


<details>
  <summary>Details</summary>
Motivation: 传统部分可观测马尔可夫决策过程（POMDP）规划通常优化期望回报，忽略了尾部风险。在安全关键应用中，需要避免极端不利结果，因此需要开发能够明确考虑风险敏感性的规划算法。

Method: 1. 开发了ICVaR策略评估算法，具有与动作空间基数无关的有限时间性能保证；2. 将三种在线规划算法（稀疏采样、PFT-DPW、POMCPOW）扩展为优化ICVaR值函数的风险敏感版本；3. 为ICVaR稀疏采样建立了风险敏感目标下的有限时间性能保证，并设计了针对ICVaR的探索策略。

Result: 实验在基准POMDP领域表明，提出的ICVaR规划器相比风险中性版本实现了更低的尾部风险。算法引入风险参数α，α=1时恢复标准期望规划，α<1时增加风险规避程度。

Conclusion: 该研究成功将动态风险度量ICVaR集成到部分可观测规划中，提供了具有理论保证的风险敏感规划框架，在安全关键应用中能够有效降低尾部风险，为风险敏感决策提供了实用工具。

Abstract: We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $α$, where $α= 1$ recovers standard expectation-based planning and $α< 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.

</details>


### [10] [Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies](https://arxiv.org/abs/2601.20604)
*Gray Cox*

Main category: cs.AI

TL;DR: 论文提出通过结构化多模型对话实证测试AI对齐策略的方法框架，基于和平研究传统，将AI对齐从控制问题重构为关系问题，通过对话推理发展"病毒式协作智慧"方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐研究缺乏实证测试方法，需要开发可复现的框架来评估AI系统是否能够实质性地参与复杂的对齐框架讨论，为实施前压力测试对齐提案提供工具。

Method: 采用结构化多模型对话实验设计，为不同AI系统分配四个角色（提议者、响应者、监督者、翻译者），在六个条件下测试大型语言模型，使用Claude、Gemini和GPT-4o进行72轮对话，总计576,822字符的结构化交流。

Result: AI系统能够有意义地参与和平研究概念讨论，从不同架构视角提出互补性异议，并产生初始框架中未出现的新见解（如"VCW作为过渡框架"）。不同模型关注点不同：Claude强调验证挑战，Gemini关注偏见和可扩展性，GPT-4o突出实施障碍。

Conclusion: 该框架为研究人员提供了实施前压力测试对齐提案的可复现方法，初步证据表明AI具备VCW所提出的对话推理能力。局限性包括对话更多关注过程元素而非AI本质的基础主张，未来研究方向包括人-AI混合协议和扩展对话研究。

Abstract: This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning.
  Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange.
  Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of "VCW as transitional framework." Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers.
  The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.

</details>


### [11] [Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation](https://arxiv.org/abs/2601.20614)
*Yanqi Dai,Yuxiang Ji,Xiao Zhang,Yong Wang,Xiangxiang Chu,Zhiwu Lu*

Main category: cs.AI

TL;DR: MathForge框架通过难度感知组策略优化算法和多方面问题重构策略，针对数学推理中的难题进行优化，显著提升大模型数学推理能力


<details>
  <summary>Details</summary>
Motivation: 现有强化学习与可验证奖励方法在算法和数据层面都缺乏对更具挑战性问题的关注，这限制了模型在数学推理中未充分开发能力的提升

Method: 提出MathForge框架，包含两个核心组件：1) 难度感知组策略优化算法，通过难度平衡组优势估计纠正GRPO中的隐式不平衡，并使用难度感知问题级加权优先处理难题；2) 多方面问题重构策略，从多个方面重构问题以增加难度同时保持原始正确答案

Result: 在多种数学推理任务上，MathForge显著优于现有方法，形成了协同循环：MQR扩展数据边界，DGPO有效学习增强数据

Conclusion: MathForge通过算法和数据层面的双重改进，有效提升了大型语言模型在数学推理任务上的性能，特别是针对更具挑战性的问题

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.

</details>


### [12] [Investigating the Development of Task-Oriented Communication in Vision-Language Models](https://arxiv.org/abs/2601.20641)
*Boaz Carmeli,Orr Paradise,Shafi Goldwasser,Yonatan Belinkov,Ron Meir*

Main category: cs.AI

TL;DR: LLM智能体能在协作推理任务中发展出不同于自然语言的任务导向通信协议，这些协议具有高效性和隐蔽性，引发透明度和控制方面的担忧。


<details>
  <summary>Details</summary>
Motivation: 研究LLM智能体是否能在协作任务中发展出不同于标准自然语言的任务导向通信协议，特别关注这些协议可能表现出的两个核心特性：高效性（更简洁地传递任务相关信息）和隐蔽性（外部观察者难以解读）。

Method: 使用指称游戏框架，让视觉语言模型（VLM）智能体进行通信，提供一个可控、可测量的环境来评估语言变体。通过实验观察VLM是否能发展出有效的、适应任务的通信模式。

Result: 实验表明：1）VLM能够发展出有效的、适应任务的通信模式；2）它们能够发展出对人类和外部智能体都难以解读的隐蔽协议；3）观察到相似模型之间在没有明确共享协议的情况下自发协调。

Conclusion: 研究结果凸显了任务导向通信的潜力和风险，并将指称游戏定位为该领域未来工作的有价值测试平台。这些发现对透明度和控制问题提出了重要警示。

Abstract: We investigate whether \emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.

</details>


### [13] [Implementing Metric Temporal Answer Set Programming](https://arxiv.org/abs/2601.20735)
*Arvid Becker,Pedro Cabalar,Martin Diéguez,Susana Hahn,Javier Romero,Torsten Schaub*

Main category: cs.AI

TL;DR: 该论文提出了一种计算性度量答案集编程方法，用于处理定量时间约束，通过解耦时间粒度来保持可扩展性


<details>
  <summary>Details</summary>
Motivation: 传统答案集编程在处理细粒度时间约束时面临可扩展性问题，特别是时间精度会导致ASP的grounding瓶颈显著恶化

Method: 利用带有差分约束的ASP扩展来处理时间相关方面，将度量ASP与时间粒度解耦，使用简化的线性约束形式

Result: 开发出不受时间精度影响的解决方案，有效解决了细粒度时间约束下的可扩展性问题

Conclusion: 通过外部处理时间约束的方法，实现了度量ASP的可扩展性，使其能够有效表达持续时间、截止日期等定量时间约束

Abstract: We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.

</details>


### [14] [MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents](https://arxiv.org/abs/2601.20831)
*Vishnu Sashank Dorbala,Dinesh Manocha*

Main category: cs.AI

TL;DR: MemCtrl框架使用多模态大语言模型进行在线记忆剪枝，通过可训练的记忆头μ决定在探索过程中保留、更新或丢弃哪些观察或反思，显著提升了具身智能体的任务完成能力。


<details>
  <summary>Details</summary>
Motivation: 现有记忆压缩和检索系统通常将记忆视为大型离线存储空间，这不适合需要在严格内存和计算约束下在线操作的具身智能体。基础模型依赖上下文学习进行个性化决策，但有限的上下文窗口大小需要更有效的在线记忆管理方法。

Method: 提出MemCtrl框架，为多模态大语言模型添加可训练的记忆头μ，作为门控机制决定在探索过程中保留、更新或丢弃哪些观察或反思。评估了两种μ训练方式：1)通过离线专家训练，2)通过在线强化学习训练。

Result: 在EmbodiedBench基准测试的多个子集上，μ增强的MLLMs平均提升了约16%的任务完成能力，在特定指令子集上提升超过20%。对μ收集的记忆片段进行定性分析显示，μ增强的MLLMs在长而复杂的指令类型上表现优异。

Conclusion: MemCtrl框架通过在线记忆剪枝有效提升了具身智能体的任务完成能力，特别是在复杂指令场景下表现突出，为在严格资源约束下的在线记忆管理提供了有效解决方案。

Abstract: Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head μthat acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of μ, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on μ-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that μ-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by μ, noting the superior performance of μaugmented MLLMs on long and complex instruction types.

</details>


### [15] [SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models](https://arxiv.org/abs/2601.20856)
*Sebastiano Monti,Carlo Nicolini,Gianni Pellegrini,Jacopo Staiano,Bruno Lepri*

Main category: cs.AI

TL;DR: 论文评估大语言模型在长时程规划能力上的局限性，发现当需要超过25步规划时性能显著下降，表明存在固有架构限制。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在复杂推理任务上的能力已被广泛测试，但其长时程规划能力尚未得到系统研究。本研究旨在评估当前最先进大推理模型在规划和长时程推理方面的能力。

Method: 提出基于推箱子游戏的新基准测试，故意简化以隔离长时程规划与状态持续性。使用PDDL解析、验证和求解工具增强LRMs，评估规划性能。

Result: 发现当需要超过25步移动才能达到解决方案时，规划性能持续下降。配备PDDL工具仅带来适度改进，表明存在固有架构限制。

Conclusion: 大推理模型在长时程规划方面存在根本性约束，这些限制可能无法仅通过测试时扩展方法克服，需要更深入的架构改进。

Abstract: Although the capabilities of large language models have been increasingly tested on complex reasoning tasks, their long-horizon planning abilities have not yet been extensively investigated. In this work, we provide a systematic assessment of the planning and long-horizon reasoning capabilities of state-of-the-art Large Reasoning Models (LRMs). We propose a novel benchmark based on Sokoban puzzles, intentionally simplified to isolate long-horizon planning from state persistence. Our findings reveal a consistent degradation in planning performance when more than 25 moves are required to reach the solution, suggesting a fundamental constraint on forward planning capacity. We show that equipping LRMs with Planning Domain Definition Language (PDDL) parsing, validation, and solving tools allows for modest improvements, suggesting inherent architectural limitations which might not be overcome by test-time scaling approaches alone.

</details>
