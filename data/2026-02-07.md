<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 39]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence](https://arxiv.org/abs/2602.04986)
*Kendra Chilson,Eric Schwitzgebel*

Main category: cs.AI

TL;DR: 论文批判AI发展的线性模型，提出"熟悉智能"和"陌生智能"概念，认为AI智能更可能是陌生智能，在不同领域表现出超人类和亚人类能力的混合，支持非线性智能模型。


<details>
  <summary>Details</summary>
Motivation: 作者旨在挑战AI发展的线性模型假设，指出当前对AI智能的理解过于简单化，需要更准确地描述AI智能的本质特征，特别是其在不同领域表现出的非均匀能力分布。

Method: 通过概念分析，引入"熟悉智能"和"陌生智能"两个新概念，发展并辩护非线性智能模型，认为"通用智能"不是统一能力，而是在广泛环境中实现广泛目标的能力。

Result: 提出AI智能更可能是陌生智能，具有超人类和亚人类能力的混合特征，即使在相同领域也可能同时表现出超人类洞察力和令人惊讶的错误。

Conclusion: AI智能的非线性模型对评估AI能力有重要启示：即使最先进的系统也可能在看似简单的任务上失败，单一任务的优秀表现不能证明广泛的通用智能，反之亦然。

Abstract: We endorse and expand upon Susan Schneider's critique of the linear model of AI progress and introduce two novel concepts: "familiar intelligence" and "strange intelligence". AI intelligence is likely to be strange intelligence, defying familiar patterns of ability and inability, combining superhuman capacities in some domains with subhuman performance in other domains, and even within domains sometimes combining superhuman insight with surprising errors that few humans would make. We develop and defend a nonlinear model of intelligence on which "general intelligence" is not a unified capacity but instead the ability to achieve a broad range of goals in a broad range of environments, in a manner that defies nonarbitrary reduction to a single linear quantity. We conclude with implications for adversarial testing approaches to evaluating AI capacities. If AI is strange intelligence, we should expect that even the most capable systems will sometimes fail in seemingly obvious tasks. On a nonlinear model of AI intelligence, such errors on their own do not demonstrate a system's lack of outstanding general intelligence. Conversely, excellent performance on one type of task, such as an IQ test, cannot warrant assumptions of broad capacities beyond that task domain.

</details>


### [2] [Evaluating Large Language Models on Solved and Unsolved Problems in Graph Theory: Implications for Computing Education](https://arxiv.org/abs/2602.05059)
*Adithya Kulkarni,Mohna Chakraborty,Jay Bagga*

Main category: cs.AI

TL;DR: LLM在已解决的图论问题上表现良好，能正确理解定义、回忆相关结果并构建有效证明，但在开放问题上仅能提供合理解释和探索策略，无法推进解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被学生用于探索计算机科学高级内容（如图论），需要了解它们在支持数学严谨思维方面的可靠性，特别是在本科和研究生课程中的应用。

Method: 使用八阶段评估协议，反映真实的数学探究过程，包括解释、探索、策略形成和证明构建。研究LLM在两个图论问题上的表现：一个是已解决的线图优美性问题，另一个是当前未知解的开放问题。

Result: 在已解决问题上，模型表现强劲：正确生成定义、识别相关结构、无幻觉地回忆适当结果，并构建了图论专家确认的有效证明。在开放问题上，模型生成连贯解释和合理探索策略，但未推进解决方案，且未捏造结果，承认不确定性。

Conclusion: LLM能支持已建立材料的学习探索，但在需要新颖数学洞察或关键结构推理的任务上仍有局限。对于计算教育，这强调了指导学生使用LLM进行概念探索，同时依赖独立验证和严谨论证进行正式问题解决的重要性。

Abstract: Large Language Models are increasingly used by students to explore advanced material in computer science, including graph theory. As these tools become integrated into undergraduate and graduate coursework, it is important to understand how reliably they support mathematically rigorous thinking. This study examines the performance of a LLM on two related graph theoretic problems: a solved problem concerning the gracefulness of line graphs and an open problem for which no solution is currently known. We use an eight stage evaluation protocol that reflects authentic mathematical inquiry, including interpretation, exploration, strategy formation, and proof construction.
  The model performed strongly on the solved problem, producing correct definitions, identifying relevant structures, recalling appropriate results without hallucination, and constructing a valid proof confirmed by a graph theory expert. For the open problem, the model generated coherent interpretations and plausible exploratory strategies but did not advance toward a solution. It did not fabricate results and instead acknowledged uncertainty, which is consistent with the explicit prompting instructions that directed the model to avoid inventing theorems or unsupported claims.
  These findings indicate that LLMs can support exploration of established material but remain limited in tasks requiring novel mathematical insight or critical structural reasoning. For computing education, this distinction highlights the importance of guiding students to use LLMs for conceptual exploration while relying on independent verification and rigorous argumentation for formal problem solving.

</details>


### [3] [Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents](https://arxiv.org/abs/2602.05073)
*Changdae Oh,Seongheon Park,To Eun Kim,Jiatong Li,Wendi Li,Samuel Yeh,Xuefeng Du,Hamed Hassani,Paul Bogdan,Dawn Song,Sharon Li*

Main category: cs.AI

TL;DR: 该论文提出需要将LLM不确定性量化研究从单轮问答扩展到交互式智能体场景，并建立了首个通用的智能体UQ框架，提出了条件不确定性减少的新视角。


<details>
  <summary>Details</summary>
Motivation: 当前LLM不确定性量化研究主要集中在单轮问答场景，但实际应用中LLM智能体越来越多地部署在复杂的交互任务中，需要建立适用于智能体交互场景的UQ框架。

Method: 提出了首个通用的智能体UQ框架，将现有UQ设置统一到该框架下；提出了条件不确定性减少的新视角，强调智能体动作的"交互性"；建立了概念框架为LLM智能体UQ设计提供指导。

Result: 揭示了先前工作隐含地将LLM UQ视为不确定性积累过程，这种观点在开放世界的交互式智能体中失效；提出了条件不确定性减少过程的新视角，能够显式建模智能体轨迹中的可减少不确定性。

Conclusion: 智能体UQ研究对前沿LLM开发和领域特定应用具有重要实践意义，论文为交互式LLM智能体的不确定性量化提供了理论基础和设计指导，并指出了未来研究方向。

Abstract: Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on single-turn question-answering. We argue that UQ research must shift to realistic settings with interactive agents, and that a new principled framework for agent UQ is needed. This paper presents the first general formulation of agent UQ that subsumes broad classes of existing UQ setups. Under this formulation, we show that prior works implicitly treat LLM UQ as an uncertainty accumulation process, a viewpoint that breaks down for interactive agents in an open world. In contrast, we propose a novel perspective, a conditional uncertainty reduction process, that explicitly models reducible uncertainty over an agent's trajectory by highlighting "interactivity" of actions. From this perspective, we outline a conceptual framework to provide actionable guidance for designing UQ in LLM agent setups. Finally, we conclude with practical implications of the agent UQ in frontier LLM development and domain-specific applications, as well as open remaining problems.

</details>


### [4] [Evaluating Robustness and Adaptability in Learning-Based Mission Planning for Active Debris Removal](https://arxiv.org/abs/2602.05091)
*Agni Bandyopadhyay,Günther Waxenegger-Wilfing*

Main category: cs.AI

TL;DR: 比较三种自主碎片清除任务规划器：固定参数训练的PPO、域随机化训练的PPO和MCTS，在燃料和时间约束下的性能表现


<details>
  <summary>Details</summary>
Motivation: 自主碎片清除任务规划需要在效率、适应性和严格的燃料与任务时间约束之间取得平衡，需要评估不同规划方法在实际约束条件下的表现

Method: 比较三种规划器：1) 固定任务参数训练的Masked PPO；2) 在变化任务约束下训练的域随机化Masked PPO；3) 蒙特卡洛树搜索基准。在高保真轨道模拟中进行评估，包含加油、真实转移动力学和随机碎片场

Result: 固定参数PPO在训练匹配条件下表现最佳，但在分布偏移时性能急剧下降；域随机化PPO适应性更好，仅适度损失名义性能；MCTS处理约束变化最好但计算时间高几个数量级

Conclusion: 学习策略的速度与搜索方法的适应性之间存在权衡，结合训练时多样性和在线规划可能是未来弹性ADR任务规划的有前景路径

Abstract: Autonomous mission planning for Active Debris Removal (ADR) must balance efficiency, adaptability, and strict feasibility constraints on fuel and mission duration. This work compares three planners for the constrained multi-debris rendezvous problem in Low Earth Orbit: a nominal Masked Proximal Policy Optimization (PPO) policy trained under fixed mission parameters, a domain-randomized Masked PPO policy trained across varying mission constraints for improved robustness, and a plain Monte Carlo Tree Search (MCTS) baseline. Evaluations are conducted in a high-fidelity orbital simulation with refueling, realistic transfer dynamics, and randomized debris fields across 300 test cases in nominal, reduced fuel, and reduced mission time scenarios. Results show that nominal PPO achieves top performance when conditions match training but degrades sharply under distributional shift, while domain-randomized PPO exhibits improved adaptability with only moderate loss in nominal performance. MCTS consistently handles constraint changes best due to online replanning but incurs orders-of-magnitude higher computation time. The findings underline a trade-off between the speed of learned policies and the adaptability of search-based methods, and suggest that combining training-time diversity with online planning could be a promising path for future resilient ADR mission planners.

</details>


### [5] [Democratic Preference Alignment via Sortition-Weighted RLHF](https://arxiv.org/abs/2602.05113)
*Suvadip Sana,Jinzhou Wu,Martin T. Wells*

Main category: cs.AI

TL;DR: DemPO框架通过算法抽签构建代表性人类评分者小组，在偏好对齐训练中实现人口统计学代表性，相比传统方法显著提升模型与代表性公众价值观的一致性。


<details>
  <summary>Details</summary>
Motivation: 当前AI偏好对齐方法（如RLHF）依赖的人类评分者通常是便利样本，存在人口统计学代表性偏差，无法反映更广泛人群的价值观。

Method: 提出民主偏好优化（DemPO）框架，应用算法抽签机制构建代表性评分小组。提供两种训练方案：硬面板（仅使用抽签选出的代表性小组数据）和软面板（保留所有数据但按抽签概率重新加权）。

Result: 在1B到8B参数的Llama模型上实验，使用包含人口统计信息的公共偏好数据集和代表性美国小组制定的宪法。硬面板在六种聚合方法中始终排名第一，软面板始终优于未加权基线，且模型容量越大效果越明显。

Conclusion: 在偏好收集阶段强制执行人口统计学代表性（而非事后修正）能产生更符合代表性公众价值观的模型行为，DemPO框架为实现这一目标提供了有效方法。

Abstract: Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference Optimization, or DemPO, a framework that applies algorithmic sortition, the same mechanism used to construct citizen assemblies, to preference based fine tuning. DemPO offers two training schemes. Hard Panel trains exclusively on preferences from a quota satisfying mini public sampled via sortition. Soft Panel retains all data but reweights each rater by their inclusion probability under the sortition lottery. We prove that Soft Panel weighting recovers the expected Hard Panel objective in closed form. Using a public preference dataset that pairs human judgments with rater demographics and a seventy five clause constitution independently elicited from a representative United States panel, we evaluate Llama models from one billion to eight billion parameters fine tuned under each scheme. Across six aggregation methods, the Hard Panel consistently ranks first and the Soft Panel consistently outperforms the unweighted baseline, with effect sizes growing as model capacity increases. These results demonstrate that enforcing demographic representativeness at the preference collection stage, rather than post hoc correction, yields models whose behavior better reflects values elicited from representative publics.

</details>


### [6] [CAST-CKT: Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer for Traffic Flow Prediction](https://arxiv.org/abs/2602.05133)
*Abdul Joseph Fofanah,Lian Wen,David Chen,Alpha Alimamy Kamara,Zhongyi Zhang*

Main category: cs.AI

TL;DR: 提出CAST-CKT框架，通过混沌分析量化交通可预测性机制，实现跨城市少样本交通预测，在MAE和RMSE指标上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 数据稀缺的跨城市交通预测面临复杂非线性动力学和领域偏移的挑战，现有方法难以捕捉交通固有的混沌特性进行有效的少样本学习。

Method: CAST-CKT框架包含：高效混沌分析器量化交通可预测性机制；混沌感知注意力实现机制自适应时序建模；自适应拓扑学习处理动态空间依赖；混沌一致性跨城市对齐实现知识迁移；提供具有不确定性量化的特定时间范围预测。

Result: 在四个基准数据集上的跨城市少样本实验中，CAST-CKT在MAE和RMSE指标上显著优于现有最先进方法，同时提供可解释的机制分析。

Conclusion: CAST-CKT通过混沌感知的时空建模和跨城市知识迁移，有效解决了数据稀缺环境下的交通预测问题，理论分析显示改进的泛化边界，代码已开源。

Abstract: Traffic prediction in data-scarce, cross-city settings is challenging due to complex nonlinear dynamics and domain shifts. Existing methods often fail to capture traffic's inherent chaotic nature for effective few-shot learning. We propose CAST-CKT, a novel Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer framework. It employs an efficient chaotic analyser to quantify traffic predictability regimes, driving several key innovations: chaos-aware attention for regime-adaptive temporal modelling; adaptive topology learning for dynamic spatial dependencies; and chaotic consistency-based cross-city alignment for knowledge transfer. The framework also provides horizon-specific predictions with uncertainty quantification. Theoretical analysis shows improved generalisation bounds. Extensive experiments on four benchmarks in cross-city few-shot settings show CAST-CKT outperforms state-of-the-art methods by significant margins in MAE and RMSE, while offering interpretable regime analysis. Code is available at https://github.com/afofanah/CAST-CKT.

</details>


### [7] [First Proof](https://arxiv.org/abs/2602.05192)
*Mohammed Abouzaid,Andrew J. Blumberg,Martin Hairer,Joe Kileel,Tamara G. Kolda,Paul D. Nelson,Daniel Spielman,Nikhil Srivastava,Rachel Ward,Shmuel Weinberger,Lauren Williams*

Main category: cs.AI

TL;DR: 作者分享10个研究级数学问题评估当前AI系统能力，这些问题来自作者实际研究过程，首次公开且答案暂时加密


<details>
  <summary>Details</summary>
Motivation: 评估当前人工智能系统在回答研究级数学问题方面的能力，通过实际研究过程中自然产生的问题来测试AI的数学推理水平

Method: 作者从自身研究过程中提取10个未公开的数学问题，这些问题具有研究级难度，答案暂时加密以进行客观评估

Result: 创建了一个包含10个研究级数学问题的测试集，这些问题来自真实研究背景，可用于评估AI系统的数学推理能力

Conclusion: 通过分享这些研究级数学问题，为评估AI系统的数学能力提供了一个有价值的基准测试工具

Abstract: To assess the ability of current AI systems to correctly answer research-level mathematics questions, we share a set of ten math questions which have arisen naturally in the research process of the authors. The questions had not been shared publicly until now; the answers are known to the authors of the questions but will remain encrypted for a short time.

</details>


### [8] [Traceable Cross-Source RAG for Chinese Tibetan Medicine Question Answering](https://arxiv.org/abs/2602.05195)
*Fengxian Chen,Zhilong Tao,Jiaxuan Li,Yunlong Li,Qingguo Zhou*

Main category: cs.AI

TL;DR: 该论文针对多知识库检索增强生成中的权威性偏差问题，提出DAKS路由与对齐图融合方法，在藏医药领域提升跨知识库证据覆盖和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 在多知识库RAG系统中，不同知识库存在权威性差异（如百科全书条目密集易匹配但权威性较低，经典文献和临床论文更权威但检索困难），导致检索结果偏向密集但权威性较低的来源，影响答案质量。

Method: 提出两种互补方法：1) DAKS进行知识库路由和预算检索，缓解密度驱动偏差，在适当时优先权威来源；2) 使用对齐图指导证据融合和覆盖感知打包，改善跨知识库证据覆盖，避免简单拼接。

Result: 实验在500个查询基准上（包含单知识库和跨知识库问题）显示，系统在路由质量和跨知识库证据覆盖方面持续提升，完整系统在保持强忠实性和引用正确性的同时，达到最佳CrossEv@5指标。

Conclusion: 通过DAKS路由和对齐图融合方法，能够有效解决多知识库RAG中的权威性偏差问题，提升跨知识库证据覆盖和可追溯性，为领域特定知识库集成提供实用解决方案。

Abstract: Retrieval-augmented generation (RAG) promises grounded question answering, yet domain settings with multiple heterogeneous knowledge bases (KBs) remain challenging. In Chinese Tibetan medicine, encyclopedia entries are often dense and easy to match, which can dominate retrieval even when classics or clinical papers provide more authoritative evidence. We study a practical setting with three KBs (encyclopedia, classics, and clinical papers) and a 500-query benchmark (cutoff $K{=}5$) covering both single-KB and cross-KB questions. We propose two complementary methods to improve traceability, reduce hallucinations, and enable cross-KB verification. First, DAKS performs KB routing and budgeted retrieval to mitigate density-driven bias and to prioritize authoritative sources when appropriate. Second, we use an alignment graph to guide evidence fusion and coverage-aware packing, improving cross-KB evidence coverage without relying on naive concatenation. All answers are generated by a lightweight generator, \textsc{openPangu-Embedded-7B}. Experiments show consistent gains in routing quality and cross-KB evidence coverage, with the full system achieving the best CrossEv@5 while maintaining strong faithfulness and citation correctness.

</details>


### [9] [Surgery: Mitigating Harmful Fine-Tuning for Large Language Models via Attention Sink](https://arxiv.org/abs/2602.05228)
*Guozhi Liu,Weiwei Lin,Tiansheng Huang,Ruichao Mo,Qi Mu,Xiumin Wang,Li Shen*

Main category: cs.AI

TL;DR: 本文提出Surgery方法，利用注意力汇聚机制来防御有害微调，通过抑制sink divergence的正值来减少模型学习有害模式


<details>
  <summary>Details</summary>
Motivation: 有害微调会破坏大语言模型的安全对齐，带来显著安全风险。现有防御方法效果有限，需要更有效的微调阶段防御机制。

Method: 首先测量每个注意力头的sink divergence统计量，发现不同注意力头呈现两种不同的sink divergence符号。基于可分离sink divergence假设，提出Surgery防御方法，使用正则化器抑制sink divergence，引导注意力头向负sink divergence组移动。

Result: 实验表明，Surgery在BeaverTails、HarmBench和SorryBench基准上分别将防御性能提升了5.90%、11.25%和9.55%。

Conclusion: Surgery方法通过注意力汇聚机制有效防御有害微调，减少模型学习有害模式的倾向，为语言模型安全对齐提供了有效的微调阶段防御方案。

Abstract: Harmful fine-tuning can invalidate safety alignment of large language models, exposing significant safety risks. In this paper, we utilize the attention sink mechanism to mitigate harmful fine-tuning. Specifically, we first measure a statistic named \emph{sink divergence} for each attention head and observe that \emph{different attention heads exhibit two different signs of sink divergence}. To understand its safety implications, we conduct experiments and find that the number of attention heads of positive sink divergence increases along with the increase of the model's harmfulness when undergoing harmful fine-tuning. Based on this finding, we propose a separable sink divergence hypothesis -- \emph{attention heads associating with learning harmful patterns during fine-tuning are separable by their sign of sink divergence}. Based on the hypothesis, we propose a fine-tuning-stage defense, dubbed Surgery. Surgery utilizes a regularizer for sink divergence suppression, which steers attention heads toward the negative sink divergence group, thereby reducing the model's tendency to learn and amplify harmful patterns. Extensive experiments demonstrate that Surgery improves defense performance by 5.90\%, 11.25\%, and 9.55\% on the BeaverTails, HarmBench, and SorryBench benchmarks, respectively. Source code is available on https://github.com/Lslland/Surgery.

</details>


### [10] [Automatic Cognitive Task Generation for In-Situ Evaluation of Embodied Agents](https://arxiv.org/abs/2602.05249)
*Xinyi He,Ying Yang,Chuanjian Fu,Sihan Guo,Songchun Zhu,Lifeng Fan,Zhenliang Zhang,Yujia Peng*

Main category: cs.AI

TL;DR: 提出TEA方法，通过动态原位任务生成评估智能体在未见3D环境中的能力，避免数据污染问题，实验显示现有模型在基本感知任务上表现不佳


<details>
  <summary>Details</summary>
Motivation: 随着智能体将广泛部署到多样化的家庭环境中，针对每个独特未见3D环境的评估变得至关重要。现有基准存在严重的数据污染问题，缺乏场景特异性，不足以评估智能体在未见环境中的能力。

Method: 提出TEA（Task Generation for Embodied Agents）方法，采用受人类认知启发的动态原位任务生成。通过结构化图表示定义任务，构建两阶段交互-演化任务生成系统：交互阶段智能体与环境主动交互，在任务执行和生成间形成循环；演化阶段通过任务图建模重组和重用现有任务生成新任务，无需外部数据。

Result: 在10个未见场景中，TEA在两个周期内自动生成了87,876个任务，经人工验证这些任务物理合理且涵盖基本日常认知能力。在SOTA模型与人类对比实验中，发现尽管模型在公共基准上表现出色，但在基本感知任务上表现惊人地差，严重缺乏3D交互意识，且在推理中对任务类型高度敏感。

Conclusion: 这些令人警醒的发现突显了在将智能体部署到真实世界人类环境之前进行原位评估的必要性。TEA方法为解决数据污染和场景特异性问题提供了有效途径。

Abstract: As general intelligent agents are poised for widespread deployment in diverse households, evaluation tailored to each unique unseen 3D environment has become a critical prerequisite. However, existing benchmarks suffer from severe data contamination and a lack of scene specificity, inadequate for assessing agent capabilities in unseen settings. To address this, we propose a dynamic in-situ task generation method for unseen environments inspired by human cognition. We define tasks through a structured graph representation and construct a two-stage interaction-evolution task generation system for embodied agents (TEA). In the interaction stage, the agent actively interacts with the environment, creating a loop between task execution and generation that allows for continuous task generation. In the evolution stage, task graph modeling allows us to recombine and reuse existing tasks to generate new ones without external data. Experiments across 10 unseen scenes demonstrate that TEA automatically generated 87,876 tasks in two cycles, which human verification confirmed to be physically reasonable and encompassing essential daily cognitive capabilities. Benchmarking SOTA models against humans on our in-situ tasks reveals that models, despite excelling on public benchmarks, perform surprisingly poorly on basic perception tasks, severely lack 3D interaction awareness and show high sensitivity to task types in reasoning. These sobering findings highlight the necessity of in-situ evaluation before deploying agents into real-world human environments.

</details>


### [11] [Beyond Cosine Similarity](https://arxiv.org/abs/2602.05266)
*Xinbo Ai*

Main category: cs.AI

TL;DR: 提出新的相似度度量recos，通过排序向量分量来归一化点积，比余弦相似度更好地捕捉语义空间中的非线性关系


<details>
  <summary>Details</summary>
Motivation: 余弦相似度基于柯西-施瓦茨不等式，只能捕捉线性关系，无法建模真实语义空间中的复杂非线性结构

Method: 推导出比经典柯西-施瓦茨界限更紧的点积上界，基于此提出recos度量，通过排序向量分量来归一化点积，将完美相似的条件从严格线性依赖放宽到序数一致性

Result: 在11种嵌入模型（静态、上下文化、通用类型）上的实验表明，recos在标准语义文本相似性基准测试中始终优于传统余弦相似度，与人类判断的相关性更高

Conclusion: recos是一个数学原理严谨且经验上更优的替代方案，为复杂嵌入空间中的语义分析提供了更高的准确性

Abstract: Cosine similarity, the standard metric for measuring semantic similarity in vector spaces, is mathematically grounded in the Cauchy-Schwarz inequality, which inherently limits it to capturing linear relationships--a constraint that fails to model the complex, nonlinear structures of real-world semantic spaces. We advance this theoretical underpinning by deriving a tighter upper bound for the dot product than the classical Cauchy-Schwarz bound. This new bound leads directly to recos, a similarity metric that normalizes the dot product by the sorted vector components. recos relaxes the condition for perfect similarity from strict linear dependence to ordinal concordance, thereby capturing a broader class of relationships. Extensive experiments across 11 embedding models--spanning static, contextualized, and universal types--demonstrate that recos consistently outperforms traditional cosine similarity, achieving higher correlation with human judgments on standard Semantic Textual Similarity (STS) benchmarks. Our work establishes recos as a mathematically principled and empirically superior alternative, offering enhanced accuracy for semantic analysis in complex embedding spaces.

</details>


### [12] [ProAct: Agentic Lookahead in Interactive Environments](https://arxiv.org/abs/2602.05327)
*Yangbin Yu,Mingyu Yang,Junyou Li,Yiming Gao,Feiyu Liu,Yijun Yang,Zichuan Lin,Jiafei Lyu,Yicheng Liu,Zhicong Lu,Deheng Ye,Jie Jiang*

Main category: cs.AI

TL;DR: ProAct框架通过两阶段训练解决LLM智能体在交互环境中的长程规划问题：第一阶段使用GLAD进行监督微调，将复杂搜索树压缩为因果推理链；第二阶段使用MC-Critic增强策略梯度算法，通过轻量级环境模拟校准价值估计。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型智能体在需要长程规划的交互环境中表现不佳，主要原因是模拟未来状态时会产生累积误差。需要一种方法让智能体能够内化准确的前瞻推理能力。

Method: 提出ProAct框架，包含两个核心组件：1) Grounded LookAhead Distillation (GLAD)：通过基于环境的搜索轨迹进行监督微调，将复杂搜索树压缩为简洁的因果推理链；2) Monte-Carlo Critic (MC-Critic)：一个即插即用的辅助价值估计器，通过轻量级环境模拟来校准价值估计，增强PPO和GRPO等策略梯度算法。

Result: 在随机环境（如2048）和确定性环境（如Sokoban）上的实验表明，ProAct显著提高了规划准确性。使用ProAct训练的4B参数模型超越了所有开源基线，并与最先进的闭源模型相媲美，同时在未见环境中表现出强大的泛化能力。

Conclusion: ProAct框架通过将前瞻推理能力内化到LLM智能体中，有效解决了长程规划中的累积误差问题，实现了在推理时无需复杂搜索的高效规划，同时通过MC-Critic提供了稳定的策略优化信号。

Abstract: Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a two-stage training paradigm. First, we introduce Grounded LookAhead Distillation (GLAD), where the agent undergoes supervised fine-tuning on trajectories derived from environment-based search. By compressing complex search trees into concise, causal reasoning chains, the agent learns the logic of foresight without the computational overhead of inference-time search. Second, to further refine decision accuracy, we propose the Monte-Carlo Critic (MC-Critic), a plug-and-play auxiliary value estimator designed to enhance policy-gradient algorithms like PPO and GRPO. By leveraging lightweight environment rollouts to calibrate value estimates, MC-Critic provides a low-variance signal that facilitates stable policy optimization without relying on expensive model-based value approximation. Experiments on both stochastic (e.g., 2048) and deterministic (e.g., Sokoban) environments demonstrate that ProAct significantly improves planning accuracy. Notably, a 4B parameter model trained with ProAct outperforms all open-source baselines and rivals state-of-the-art closed-source models, while demonstrating robust generalization to unseen environments. The codes and models are available at https://github.com/GreatX3/ProAct

</details>


### [13] [RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs](https://arxiv.org/abs/2602.05367)
*Youngcheon You,Banseok Lee,Minseop Choi,Seonyoung Kim,Hyochan Chong,Changdong Kim,Youngmin Kim,Dongkyu Kim*

Main category: cs.AI

TL;DR: RaBiT框架通过算法强制残差层次结构解决二进制路径间的特征共适应问题，实现2位量化下SOTA性能，推理速度比全精度模型快4.49倍


<details>
  <summary>Details</summary>
Motivation: 大语言模型部署需要极端量化，但低比特效率与性能之间存在关键权衡。残差二值化虽然能实现硬件友好的无矩阵乘法推理，但存在病态特征共适应问题，特别是并行残差二进制路径学习冗余特征，限制了模型表达能力。

Method: 提出RaBiT量化框架，通过算法强制残差层次结构解决共适应问题。核心机制是从单个共享全精度权重顺序推导每个二进制路径，确保每个路径纠正前一个路径的误差。使用鲁棒初始化优先功能保持而非权重近似。

Result: 重新定义了2位精度-效率前沿：达到最先进的性能，甚至可与硬件密集的向量量化方法竞争，在RTX 4090上实现比全精度模型快4.49倍的推理速度。

Conclusion: RaBiT通过解决残差二值化中的特征共适应问题，实现了高效的2位量化，在保持高性能的同时显著提升推理速度，为大语言模型部署提供了有效的极端量化解决方案。

Abstract: Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary ($\pm$1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy. Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers a $4.49\times$ inference speed-up over full-precision models on an RTX 4090.

</details>


### [14] [Clinical Validation of Medical-based Large Language Model Chatbots on Ophthalmic Patient Queries with LLM-based Evaluation](https://arxiv.org/abs/2602.05381)
*Ting Fang Tan,Kabilan Elangovan,Andreas Pollreisz,Kevin Bryan Dy,Wei Yan Ng,Joy Le Yi Wong,Jin Liyuan,Chrystie Quek Wan Ning,Ashley Shuen Ying Hong,Arun James Thirunavukarasu,Shelley Yin-His Chang,Jie Yao,Dylan Hong,Wang Zhaoran,Amrita Gupta,Daniel SW Ting*

Main category: cs.AI

TL;DR: 本研究评估了四个小型医疗大语言模型在眼科患者问答中的表现，并测试了基于LLM评估与临床医生评分的可行性。Meerkat-7B表现最佳，MedLLaMA3-v20表现最差且有25.5%的响应包含幻觉或误导性内容。GPT-4-Turbo评估与临床医生评分高度一致，支持LLM评估在大规模基准测试中的可行性。


<details>
  <summary>Details</summary>
Motivation: 随着特定领域大语言模型在眼科患者教育、分诊和临床决策支持中的应用日益增多，需要进行严格评估以确保安全性和准确性。本研究旨在评估小型医疗LLM在回答眼科患者查询方面的表现，并探索基于LLM的评估与临床医生评分的可行性。

Method: 采用横断面研究设计，使用四个参数规模小于100亿的小型医疗LLM（Meerkat-7B、BioMistral-7B、OpenBioLLM-8B、MedLLaMA3-v20）回答180个眼科患者查询，共生成2160个响应。由三名不同资历的眼科医生和GPT-4-Turbo使用S.C.O.R.E.框架（安全性、共识与上下文、客观性、可重复性、可解释性）进行五级李克特量表评分。使用Spearman秩相关、Kendall tau统计和核密度估计分析评估LLM与临床医生评分的一致性。

Result: Meerkat-7B表现最佳，分别获得高级顾问3.44分、顾问4.08分、住院医师4.18分的平均分。MedLLaMA3-v20表现最差，25.5%的响应包含幻觉或临床误导性内容，包括虚构术语。GPT-4-Turbo评估与临床医生整体评估高度一致（Spearman rho=0.80，Kendall tau=0.67），但高级顾问评分更为保守。

Conclusion: 医疗LLM在眼科问答中显示出安全应用的潜力，但在临床深度和共识方面仍存在差距。研究支持基于LLM的评估在大规模基准测试中的可行性，并强调需要结合自动化评估和临床医生审查的混合框架来指导安全的临床部署。

Abstract: Domain specific large language models are increasingly used to support patient education, triage, and clinical decision making in ophthalmology, making rigorous evaluation essential to ensure safety and accuracy. This study evaluated four small medical LLMs Meerkat-7B, BioMistral-7B, OpenBioLLM-8B, and MedLLaMA3-v20 in answering ophthalmology related patient queries and assessed the feasibility of LLM based evaluation against clinician grading. In this cross sectional study, 180 ophthalmology patient queries were answered by each model, generating 2160 responses. Models were selected for parameter sizes under 10 billion to enable resource efficient deployment. Responses were evaluated by three ophthalmologists of differing seniority and by GPT-4-Turbo using the S.C.O.R.E. framework assessing safety, consensus and context, objectivity, reproducibility, and explainability, with ratings assigned on a five point Likert scale. Agreement between LLM and clinician grading was assessed using Spearman rank correlation, Kendall tau statistics, and kernel density estimate analyses. Meerkat-7B achieved the highest performance with mean scores of 3.44 from Senior Consultants, 4.08 from Consultants, and 4.18 from Residents. MedLLaMA3-v20 performed poorest, with 25.5 percent of responses containing hallucinations or clinically misleading content, including fabricated terminology. GPT-4-Turbo grading showed strong alignment with clinician assessments overall, with Spearman rho of 0.80 and Kendall tau of 0.67, though Senior Consultants graded more conservatively. Overall, medical LLMs demonstrated potential for safe ophthalmic question answering, but gaps remained in clinical depth and consensus, supporting the feasibility of LLM based evaluation for large scale benchmarking and the need for hybrid automated and clinician review frameworks to guide safe clinical deployment.

</details>


### [15] [THOR: Inductive Link Prediction over Hyper-Relational Knowledge Graphs](https://arxiv.org/abs/2602.05424)
*Weijian Yu,Yuhuan Lu,Dingqi Yang*

Main category: cs.AI

TL;DR: THOR：一种用于超关系知识图谱的归纳式链接预测方法，通过关系基础图和实体基础图建模跨图谱的结构不变性，支持完全归纳推理。


<details>
  <summary>Details</summary>
Motivation: 现有超关系知识图谱链接预测方法大多局限于传导式设置，只能在特定词汇表内进行预测，缺乏对未见词汇的泛化能力。需要开发能够跨不同词汇表进行推理的归纳式方法。

Method: 提出THOR方法：1）构建关系基础图和实体基础图，建模超关系知识图谱中关系和实体的基本交互模式；2）使用两个并行图编码器学习基础图表示；3）通过Transformer解码器支持高效掩码训练和完全归纳推理。

Result: 在12个数据集上的实验表明，THOR在超关系链接预测任务中显著优于现有方法：比最佳规则方法提升66.1%，比最佳半归纳方法提升55.9%，比最佳完全归纳方法提升20.4%。消融研究验证了关键设计因素的有效性。

Conclusion: THOR通过建模超关系知识图谱中的结构不变性，实现了有效的归纳式链接预测，能够泛化到未见过的词汇表，为超关系知识图谱的推理提供了新的解决方案。

Abstract: Knowledge graphs (KGs) have become a key ingredient supporting a variety of applications. Beyond the traditional triplet representation of facts where a relation connects two entities, modern KGs observe an increasing number of hyper-relational facts, where an arbitrary number of qualifiers associated with a triplet provide auxiliary information to further describe the rich semantics of the triplet, which can effectively boost the reasoning performance in link prediction tasks. However, existing link prediction techniques over such hyper-relational KGs (HKGs) mostly focus on a transductive setting, where KG embedding models are learned from the specific vocabulary of a given KG and subsequently can only make predictions within the same vocabulary, limiting their generalizability to previously unseen vocabularies. Against this background, we propose THOR, an inducTive link prediction technique for Hyper-relational knOwledge gRaphs. Specifically, we first introduce both relation and entity foundation graphs, modeling their fundamental inter- and intra-fact interactions in HKGs, which are agnostic to any specific relations and entities. Afterward, THOR is designed to learn from the two foundation graphs with two parallel graph encoders followed by a transformer decoder, which supports efficient masked training and fully-inductive inference. We conduct a thorough evaluation of THOR in hyper-relational link prediction tasks on 12 datasets with different settings. Results show that THOR outperforms a sizable collection of baselines, yielding 66.1%, 55.9%, and 20.4% improvement over the best-performing rule-based, semi-inductive, and fully-inductive techniques, respectively. A series of ablation studies also reveals our key design factors capturing the structural invariance transferable across HKGs for inductive tasks.

</details>


### [16] [Day-Ahead Electricity Price Forecasting for Volatile Markets Using Foundation Models with Regularization Strategy](https://arxiv.org/abs/2602.05430)
*Kritchanat Ponyuenyong,Pengyu Tu,Jia Wei Tan,Wei Soon Cheong,Jamie Ng Suat Ling,Lianlian Jiang*

Main category: cs.AI

TL;DR: 该研究评估了时间序列基础模型在波动性电力市场中的日前电价预测性能，发现这些模型相比传统统计和深度学习模型能提升最多37.4%的预测精度。


<details>
  <summary>Details</summary>
Motivation: 电力市场价格预测对能源市场参与者至关重要，但由于价格信号固有的波动性和非线性，传统统计和深度学习模型难以有效捕捉复杂的时间依赖关系并整合异构数据。虽然时间序列基础模型在一般时间序列预测任务中表现出色，但在波动性市场的日前电价预测中的有效性尚未得到充分探索。

Method: 提出尖峰正则化策略，并评估了多种时间序列基础模型（包括Tiny Time Mixers、MOIRAI、MOMENT和TimesFM），与传统统计和深度学习模型（ARIMA、LSTM、CNN-LSTM）进行比较。使用新加坡具有波动趋势的半小时批发市场数据，并在适用模型中纳入天气和日历变量等外生因素。

Result: 时间序列基础模型在所有评估设置中一致优于传统方法，在MAPE指标上实现了高达37.4%的改进。

Conclusion: 研究结果为提高波动性电力市场中的预测准确性和决策制定提供了实用指导，证明了时间序列基础模型在复杂电价预测任务中的优越性能。

Abstract: Electricity price forecasting (EPF) is essential for energy markets stakeholders (e.g. grid operators, energy traders, policymakers) but remains challenging due to the inherent volatility and nonlinearity of price signals. Traditional statistical and deep learning (DL) models often struggle to capture complex temporal dependencies and integrate heterogeneous data effectively. While time series foundation models (TSFMs) have shown strong performance in general time series forecasting tasks, such as traffic forecasting and weather forecasting. However, their effectiveness in day-ahead EPF, particularly in volatile markets, remains underexplored. This paper presents a spike regularization strategy and evaluates a wide range of TSFMs, including Tiny Time Mixers (TTMs), MOIRAI, MOMENT, and TimesFM, against traditional statistical and DL models such as Autoregressive Integrated Moving Average (ARIMA), Long-short Term Memory (LSTM), and Convolutional Neural Network - LSTM (CNN-LSTM) using half-hourly wholesale market data with volatile trends in Singapore. Exogenous factors (e.g. weather and calendar variables) are also incorporated into models where applicable. Results demonstrate that TSFMs consistently outperform traditional approaches, achieving up to 37.4% improvement in MAPE across various evaluation settings. The findings offer practical guidance for improving forecast accuracy and decision-making in volatile electricity markets.

</details>


### [17] [Refine and Purify: Orthogonal Basis Optimization with Null-Space Denoising for Conditional Representation Learning](https://arxiv.org/abs/2602.05464)
*Jiaquan Wang,Yan Lyu,Chen Li,Yuheng Jia*

Main category: cs.AI

TL;DR: OD-CRL提出自适应正交基优化和零空间去噪投影，解决条件表示学习中基向量敏感性和子空间干扰问题，在多个定制化任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有条件表示学习方法存在两个关键限制：1) 对子空间基向量的敏感性；2) 容易受到子空间间干扰的影响。这些限制影响了条件特征提取的质量和鲁棒性。

Method: 提出OD-CRL框架，包含两个核心技术：1) 自适应正交基优化(AOBO)：通过奇异值分解和基于曲率的截断构建正交语义基；2) 零空间去噪投影(NSDP)：通过将嵌入投影到无关子空间的零空间来抑制非目标语义干扰。

Result: 在定制化聚类、定制化分类和定制化检索任务上进行了广泛实验，OD-CRL在所有任务上都达到了新的最先进性能，并表现出优异的泛化能力。

Conclusion: OD-CRL通过正交基优化和零空间投影有效解决了条件表示学习中的基向量敏感性和子空间干扰问题，为定制化任务提供了更鲁棒和有效的特征表示方法。

Abstract: Conditional representation learning aims to extract criterion-specific features for customized tasks. Recent studies project universal features onto the conditional feature subspace spanned by an LLM-generated text basis to obtain conditional representations. However, such methods face two key limitations: sensitivity to subspace basis and vulnerability to inter-subspace interference. To address these challenges, we propose OD-CRL, a novel framework integrating Adaptive Orthogonal Basis Optimization (AOBO) and Null-Space Denoising Projection (NSDP). Specifically, AOBO constructs orthogonal semantic bases via singular value decomposition with a curvature-based truncation. NSDP suppresses non-target semantic interference by projecting embeddings onto the null space of irrelevant subspaces. Extensive experiments conducted across customized clustering, customized classification, and customized retrieval tasks demonstrate that OD-CRL achieves a new state-of-the-art performance with superior generalization.

</details>


### [18] [ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation](https://arxiv.org/abs/2602.05472)
*Yiwen Duan,Jing Ye,Xinpei Zhao*

Main category: cs.AI

TL;DR: ALIVE框架通过对抗学习和指导性语言反馈，让LLM内部化推理逻辑，摆脱传统强化学习对稀缺标量奖励的依赖，实现无人工监督的推理对齐。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖的标量奖励存在成本高、跨领域脆弱、无法捕捉解决方案底层逻辑等问题，阻碍了LLM达到专家级推理水平，需要新的对齐框架来让模型内部化推理原则。

Method: ALIVE框架基于"认知协同"原则，将问题提出、解决和评判统一在单一策略模型中，通过对抗学习和指导性语言反馈，让模型直接从原始语料中内部化评估标准。

Result: 在数学推理、代码生成和一般逻辑推理基准测试中，ALIVE持续缓解了奖励信号限制，在相同数据和计算条件下实现了准确率提升、跨领域泛化能力显著改善以及更高的自我纠正率。

Conclusion: 推理三位一体（问题提出、解决、评判）促进了能力增长的自我维持轨迹，使ALIVE成为无需人工监督的通用推理对齐的可扩展基础。

Abstract: The quest for expert-level reasoning in Large Language Models (LLMs) has been hampered by a persistent \textit{reward bottleneck}: traditional reinforcement learning (RL) relies on scalar rewards that are \textbf{costly} to scale, \textbf{brittle} across domains, and \textbf{blind} to the underlying logic of a solution. This reliance on external, impoverished signals prevents models from developing a deep, self-contained understanding of reasoning principles. We introduce \textbf{ALIVE} (\emph{Adversarial Learning with Instructive Verbal Evaluation}), a hands-free alignment framework that moves beyond scalar reward optimization toward intrinsic reasoning acquisition. Grounded in the principle of \emph{Cognitive Synergy}, ALIVE unifies problem posing, solving, and judging within a single policy model to internalize the logic of correctness. By coupling adversarial learning with instructive verbal feedback, ALIVE enables models to internalize evaluative criteria directly from raw corpora, effectively transforming external critiques into an endogenous reasoning faculty. Empirical evaluations across mathematical reasoning, code generation, and general logical inference benchmarks demonstrate that ALIVE consistently mitigates reward signal limitations. With identical data and compute, it achieves accuracy gains, markedly improved cross-domain generalization, and higher self-correction rates. These results indicate that the reasoning trinity fosters a self-sustaining trajectory of capability growth, positioning ALIVE as a scalable foundation for general-purpose reasoning alignment without human-in-the-loop supervision.

</details>


### [19] [Phi-Former: A Pairwise Hierarchical Approach for Compound-Protein Interactions Prediction](https://arxiv.org/abs/2602.05479)
*Zhe Wang,Zijing Liu,Chencheng Xu,Yuan Yao*

Main category: cs.AI

TL;DR: Phi-former是一种用于预测化合物-蛋白质相互作用的分层表示学习方法，通过原子-原子、基序-基序和原子-基序三个层次的成对建模来更好地反映生物识别机制。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的化合物-蛋白质相互作用预测方法虽然比传统能量方法更高效准确，但往往忽略了化学现实：分子片段（基序或功能基团）通常是生物识别和结合的主要单元。现有模型未能充分整合基序在生物识别中的关键作用。

Method: 提出Phi-former方法：1）对化合物和蛋白质进行分层表示；2）采用成对预训练框架，系统建模原子-原子、基序-基序和原子-基序三个层次的相互作用；3）设计层内和层间学习流程，使不同交互层次相互促进。

Result: Phi-former在CPI相关任务上表现出优越性能。案例研究表明，该方法能准确识别在CPI中被激活的特定原子或基序，提供可解释的模型解释。

Conclusion: Phi-former通过整合基序的生物作用，提供了更符合化学现实的CPI预测方法，其可解释性洞察有助于指导合理的药物设计和精准医疗应用。

Abstract: Drug discovery remains time-consuming, labor-intensive, and expensive, often requiring years and substantial investment per drug candidate. Predicting compound-protein interactions (CPIs) is a critical component in this process, enabling the identification of molecular interactions between drug candidates and target proteins. Recent deep learning methods have successfully modeled CPIs at the atomic level, achieving improved efficiency and accuracy over traditional energy-based approaches. However, these models do not always align with chemical realities, as molecular fragments (motifs or functional groups) typically serve as the primary units of biological recognition and binding. In this paper, we propose Phi-former, a pairwise hierarchical interaction representation learning method that addresses this gap by incorporating the biological role of motifs in CPIs. Phi-former represents compounds and proteins hierarchically and employs a pairwise pre-training framework to model interactions systematically across atom-atom, motif-motif, and atom-motif levels, reflecting how biological systems recognize molecular partners. We design intra-level and inter-level learning pipelines that make different interaction levels mutually beneficial. Experimental results demonstrate that Phi-former achieves superior performance on CPI-related tasks. A case study shows that our method accurately identifies specific atoms or motifs activated in CPIs, providing interpretable model explanations. These insights may guide rational drug design and support precision medicine applications.

</details>


### [20] [SDFP: Speculative Decoding with FIT-Pruned Models for Training-Free and Plug-and-Play LLM Acceleration](https://arxiv.org/abs/2602.05499)
*Hanyu Wei,Zunhai Su,Peng Lu,Chao Li,Spandan Tiwari,Ashish Sirasao,Yuhan Dong*

Main category: cs.AI

TL;DR: SDFP是一种无需训练、即插即用的推测解码框架，通过基于Fisher信息迹的层剪枝从现有LLM构建轻量级草稿模型，实现1.32-1.5倍解码加速


<details>
  <summary>Details</summary>
Motivation: LLMs在多媒体应用中存在自回归解码延迟高的问题。现有推测解码方法需要额外训练或维护草稿模型，部署成本高且复杂

Method: 提出SDFP框架，使用Fisher信息迹评估层敏感性，剪除对输出扰动影响小的层，从原LLM构建紧凑草稿模型，保持与原模型的兼容性用于标准推测验证

Result: 在基准测试中实现1.32-1.5倍解码加速，不改变目标模型的输出分布，支持低延迟多媒体应用

Conclusion: SDFP提供了一种无需额外训练、超参数调优或单独维护草稿模型的快速部署方案，有效降低LLMs解码延迟

Abstract: Large language models (LLMs) underpin interactive multimedia applications such as captioning, retrieval, recommendation, and creative content generation, yet their autoregressive decoding incurs substantial latency. Speculative decoding reduces latency using a lightweight draft model, but deployment is often limited by the cost and complexity of acquiring, tuning, and maintaining an effective draft model. Recent approaches usually require auxiliary training or specialization, and even training-free methods incur costly search or optimization. We propose SDFP, a fully training-free and plug-and-play framework that builds the draft model via Fisher Information Trace (FIT)-based layer pruning of a given LLM. Using layer sensitivity as a proxy for output perturbation, SDFP removes low-impact layers to obtain a compact draft while preserving compatibility with the original model for standard speculative verification. SDFP needs no additional training, hyperparameter tuning, or separately maintained drafts, enabling rapid, deployment-friendly draft construction. Across benchmarks, SDFP delivers 1.32x-1.5x decoding speedup without altering the target model's output distribution, supporting low-latency multimedia applications.

</details>


### [21] [A Unified Multimodal Framework for Dataset Construction and Model-Based Diagnosis of Ameloblastoma](https://arxiv.org/abs/2602.05515)
*Ajo Babu George,Anna Mariam John,Athul Anoop,Balu Bhasuran*

Main category: cs.AI

TL;DR: 研究人员创建了一个专门针对成釉细胞瘤的多模态数据集，并开发了深度学习模型，显著提高了变体分类准确率和异常组织检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能在颌面病理学诊断中的应用面临数据不足和格式不一致的问题，特别是针对成釉细胞瘤的高质量多模态数据集缺乏，这限制了直接模型训练和临床应用。

Method: 1. 创建专门针对成釉细胞瘤的多模态数据集，整合放射学、组织病理学和口腔临床图像；2. 使用自然语言处理技术从文本报告中提取临床相关特征；3. 对图像数据进行领域特定的预处理和增强；4. 开发多模态深度学习模型，用于分类变体、评估复发风险和支持手术规划。

Result: 1. 变体分类准确率从46.2%提高到65.9%；2. 异常组织检测F1分数从43.0%提高到90.3%；3. 相比MultiCaRe等现有资源，该工作提供了更强大的数据集和适应性强的多模态AI框架。

Conclusion: 这项工作通过提供专门的多模态数据集和可适应的AI框架，显著推进了患者特异性决策支持在成釉细胞瘤诊断和治疗中的应用。

Abstract: Artificial intelligence (AI)-enabled diagnostics in maxillofacial pathology require structured, high-quality multimodal datasets. However, existing resources provide limited ameloblastoma coverage and lack the format consistency needed for direct model training. We present a newly curated multimodal dataset specifically focused on ameloblastoma, integrating annotated radiological, histopathological, and intraoral clinical images with structured data derived from case reports. Natural language processing techniques were employed to extract clinically relevant features from textual reports, while image data underwent domain specific preprocessing and augmentation. Using this dataset, a multimodal deep learning model was developed to classify ameloblastoma variants, assess behavioral patterns such as recurrence risk, and support surgical planning. The model is designed to accept clinical inputs such as presenting complaint, age, and gender during deployment to enhance personalized inference. Quantitative evaluation demonstrated substantial improvements; variant classification accuracy increased from 46.2 percent to 65.9 percent, and abnormal tissue detection F1-score improved from 43.0 percent to 90.3 percent. Benchmarked against resources like MultiCaRe, this work advances patient-specific decision support by providing both a robust dataset and an adaptable multimodal AI framework.

</details>


### [22] [Emulating Aggregate Human Choice Behavior and Biases with GPT Conversational Agents](https://arxiv.org/abs/2602.05597)
*Stephen Pilli,Vivek Nallur*

Main category: cs.AI

TL;DR: LLMs能准确预测个体层面的认知偏见并模拟人类在交互决策中的偏见行为，特别是在认知负荷等情境因素影响下。


<details>
  <summary>Details</summary>
Motivation: 虽然已知LLMs能重现常见偏见，但更关键的问题是LLMs能否预测个体层面的偏见，并模拟偏见与认知负荷等情境因素交互时的人类行为动态。

Method: 将三个经典决策场景改编为对话形式，进行人类实验(N=1100)，参与者通过简单或复杂对话与聊天机器人互动。使用参与者人口统计数据和对话记录，基于GPT-4和GPT-5模拟相同条件。

Result: 人类实验显示出显著的偏见模式。LLMs能够精确重现人类偏见，不同模型在模拟人类行为对齐方面存在明显差异。

Conclusion: LLMs能够有效模拟交互情境中的人类偏见行为，这对设计和评估具有偏见感知能力的自适应LLM系统具有重要意义。

Abstract: Cognitive biases often shape human decisions. While large language models (LLMs) have been shown to reproduce well-known biases, a more critical question is whether LLMs can predict biases at the individual level and emulate the dynamics of biased human behavior when contextual factors, such as cognitive load, interact with these biases. We adapted three well-established decision scenarios into a conversational setting and conducted a human experiment (N=1100). Participants engaged with a chatbot that facilitates decision-making through simple or complex dialogues. Results revealed robust biases. To evaluate how LLMs emulate human decision-making under similar interactive conditions, we used participant demographics and dialogue transcripts to simulate these conditions with LLMs based on GPT-4 and GPT-5. The LLMs reproduced human biases with precision. We found notable differences between models in how they aligned human behavior. This has important implications for designing and evaluating adaptive, bias-aware LLM-based AI systems in interactive contexts.

</details>


### [23] [Reactive Knowledge Representation and Asynchronous Reasoning](https://arxiv.org/abs/2602.05625)
*Simon Kohaut,Benedict Flade,Julian Eggert,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.AI

TL;DR: 提出Resin概率编程语言和Reactive Circuits结构，通过异步反应式推理实现高效精确推理，在无人机群仿真中获得数量级加速


<details>
  <summary>Details</summary>
Motivation: 复杂概率模型中的精确推理计算成本过高，特别是在动态环境中需要频繁实时更新的自主智能体。现有方法在持续推理中效率低下，因为它们对任何变化都重新评估整个模型，未能利用现实世界信息流具有异构更新率的特点。

Method: 1. 提出Resin（Reactive Signal Inference）概率编程语言，将概率逻辑与反应式编程相结合；2. 提出Reactive Circuits（RCs）作为Resin的高效精确语义，RCs是基于代数电路和异步数据流的元结构，是能够根据输入信号波动自主调整的时间动态有向无环图。

Result: 在高保真无人机群仿真中，该方法相比频率无关推理实现了几个数量级的加速。RCs的结构调整成功捕捉环境动态，显著降低延迟并促进反应式实时推理。

Conclusion: 通过基于异步输入变化频率估计来划分计算，大型推理任务可以分解为单独记忆化的子问题。这确保只有受新信息影响的模型特定组件被重新评估，在流式上下文中大幅减少冗余计算。

Abstract: Exact inference in complex probabilistic models often incurs prohibitive computational costs. This challenge is particularly acute for autonomous agents in dynamic environments that require frequent, real-time belief updates. Existing methods are often inefficient for ongoing reasoning, as they re-evaluate the entire model upon any change, failing to exploit that real-world information streams have heterogeneous update rates. To address this, we approach the problem from a reactive, asynchronous, probabilistic reasoning perspective. We first introduce Resin (Reactive Signal Inference), a probabilistic programming language that merges probabilistic logic with reactive programming. Furthermore, to provide efficient and exact semantics for Resin, we propose Reactive Circuits (RCs). Formulated as a meta-structure over Algebraic Circuits and asynchronous data streams, RCs are time-dynamic Directed Acyclic Graphs that autonomously adapt themselves based on the volatility of input signals. In high-fidelity drone swarm simulations, our approach achieves several orders of magnitude of speedup over frequency-agnostic inference. We demonstrate that RCs' structural adaptations successfully capture environmental dynamics, significantly reducing latency and facilitating reactive real-time reasoning. By partitioning computations based on the estimated Frequency of Change in the asynchronous inputs, large inference tasks can be decomposed into individually memoized sub-problems. This ensures that only the specific components of a model affected by new information are re-evaluated, drastically reducing redundant computation in streaming contexts.

</details>


### [24] [Generative Ontology: When Structured Knowledge Learns to Create](https://arxiv.org/abs/2602.05636)
*Benny Cheung*

Main category: cs.AI

TL;DR: 提出Generative Ontology框架，结合传统本体论的结构严谨性与大语言模型的创造性，通过可执行的Pydantic模式约束LLM生成，实现结构化且创新的设计生成。


<details>
  <summary>Details</summary>
Motivation: 传统本体论擅长描述领域结构但无法生成新内容，而大语言模型能流畅生成但缺乏结构有效性，经常产生幻觉输出。需要结合两者的优势：本体论提供语法结构，LLM提供创造力。

Method: 将领域知识编码为可执行的Pydantic模式，通过DSPy签名约束LLM生成。采用多智能体管道，为不同本体领域分配专门角色（如机制架构师、主题编织者、平衡批评家），每个智能体带有专业"焦虑"防止浅层输出。结合检索增强生成和迭代验证确保机制与组件的一致性。

Result: 通过GameGrammar系统展示了该框架的有效性，能够根据主题提示生成结构完整、可玩的桌面游戏设计，包括机制、组件、胜利条件和设置说明，既满足本体约束又保持真正的创造性。

Conclusion: 该框架可推广到游戏以外的领域，任何具有专业词汇、有效性约束和积累范例的领域（如音乐创作、软件架构、烹饪艺术）都适合使用Generative Ontology。约束不是限制创造力，而是使其成为可能，正如语法使诗歌成为可能一样。

Abstract: Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework that synthesizes these complementary strengths: ontology provides the grammar; the LLM provides the creativity.
  Generative Ontology encodes domain knowledge as executable Pydantic schemas that constrain LLM generation via DSPy signatures. A multi-agent pipeline assigns specialized roles to different ontology domains: a Mechanics Architect designs game systems, a Theme Weaver integrates narrative, a Balance Critic identifies exploits. Each agent carrying a professional "anxiety" that prevents shallow, agreeable outputs. Retrieval-augmented generation grounds novel designs in precedents from existing exemplars, while iterative validation ensures coherence between mechanisms and components.
  We demonstrate the framework through GameGrammar, a system for generating complete tabletop game designs. Given a thematic prompt ("bioluminescent fungi competing in a cave ecosystem"), the pipeline produces structurally complete, playable game specifications with mechanisms, components, victory conditions, and setup instructions. These outputs satisfy ontological constraints while remaining genuinely creative.
  The pattern generalizes beyond games. Any domain with expert vocabulary, validity constraints, and accumulated exemplars (music composition, software architecture, culinary arts) is a candidate for Generative Ontology. We argue that constraints do not limit creativity but enable it: just as grammar makes poetry possible, ontology makes structured generation possible.

</details>


### [25] [Graph-based Agent Memory: Taxonomy, Techniques, and Applications](https://arxiv.org/abs/2602.05665)
*Chang Yang,Chuang Zhou,Yilin Xiao,Su Dong,Luyao Zhuang,Yujing Zhang,Zhu Wang,Zijin Hong,Zheng Yuan,Zhishang Xiang,Shengyuan Chen,Huachi Zhou,Qinggang Zhang,Ninghao Liu,Jinsong Su,Xinrun Wang,Yi Chang,Xiao Huang*

Main category: cs.AI

TL;DR: 这篇综述论文系统回顾了基于图的智能体记忆系统，分析了记忆分类、生命周期关键技术、开源工具和应用场景，为开发更高效可靠的图记忆系统提供指导。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体在复杂长时任务中的应用日益广泛，记忆成为核心模块。图结构因其能够建模关系依赖、组织层次信息和支持高效检索而成为强大的智能体记忆结构。本文旨在全面回顾基于图的智能体记忆研究现状。

Method: 首先提出智能体记忆的分类法（短期/长期记忆、知识/经验记忆、非结构化/结构化记忆），并从图实现视角分析。其次按照记忆生命周期系统分析关键技术：记忆提取、存储、检索和演化。最后总结开源库、基准测试和应用场景。

Result: 建立了基于图的智能体记忆系统分析框架，收集整理了相关研究论文、开源数据和项目资源，形成了https://github.com/DEEP-PolyU/Awesome-GraphMemory资源库，为社区提供系统参考。

Conclusion: 基于图的智能体记忆系统在复杂任务中具有重要价值，但仍面临挑战。本文为开发更高效可靠的图记忆系统提供了行动指南，并指出了未来研究方向。

Abstract: Memory emerges as the core module in the Large Language Model (LLM)-based agents for long-horizon complex tasks (e.g., multi-turn dialogue, game playing, scientific discovery), where memory can enable knowledge accumulation, iterative reasoning and self-evolution. Among diverse paradigms, graph stands out as a powerful structure for agent memory due to the intrinsic capabilities to model relational dependencies, organize hierarchical information, and support efficient retrieval. This survey presents a comprehensive review of agent memory from the graph-based perspective. First, we introduce a taxonomy of agent memory, including short-term vs. long-term memory, knowledge vs. experience memory, non-structural vs. structural memory, with an implementation view of graph-based memory. Second, according to the life cycle of agent memory, we systematically analyze the key techniques in graph-based agent memory, covering memory extraction for transforming the data into the contents, storage for organizing the data efficiently, retrieval for retrieving the relevant contents from memory to support reasoning, and evolution for updating the contents in the memory. Third, we summarize the open-sourced libraries and benchmarks that support the development and evaluation of self-evolving agent memory. We also explore diverse application scenarios. Finally, we identify critical challenges and future research directions. This survey aims to offer actionable insights to advance the development of more efficient and reliable graph-based agent memory systems. All the related resources, including research papers, open-source data, and projects, are collected for the community in https://github.com/DEEP-PolyU/Awesome-GraphMemory.

</details>


### [26] [Determining Energy Efficiency Sweet Spots in Production LLM Inference](https://arxiv.org/abs/2602.05695)
*Hiari Pizzini Cavagna,Andrea Proia,Giacomo Madella,Giovanni B. Esposito,Francesco Antici,Daniele Cesarini,Zeynep Kiziltan,Andrea Bartolini*

Main category: cs.AI

TL;DR: 本文提出了一种基于Transformer架构计算和内存访问复杂度的分析模型，能够准确描述LLM推理能效与输入输出序列长度的非线性关系，发现存在能效"甜点区"，合理调整序列长度可显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推理在现代AI应用中至关重要，但现有方法通常通过输入输出序列长度的简单线性函数来估计能耗，而实际观测显示能效存在明显的非线性依赖关系，需要更准确的分析模型来理解和优化能耗。

Method: 基于Transformer架构的计算和内存访问复杂度推导出分析模型，使用TensorRT-LLM在NVIDIA H100 GPU上评估从1B到9B参数的各种LLM（包括OPT、LLaMA、Gemma、Falcon、Qwen2和Granite），测试输入输出长度从64到4096个token。

Result: 模型平均绝对百分比误差（MAPE）为1.79%，发现能效存在明显的"甜点区"：短到中等输入和中等长度输出时能效最高，而长输入或非常短的输出时能效急剧下降。将序列长度与这些能效甜点区对齐可大幅降低能耗。

Conclusion: 提出的分析模型能够准确描述LLM推理能效的非线性特性，识别能效甜点区，为生产系统中的信息截断、摘要生成和自适应生成策略提供依据，支持更节能的LLM部署。

Abstract: Large Language Models (LLMs) inference is central in modern AI applications, making it critical to understand their energy footprint. Existing approaches typically estimate energy consumption through simple linear functions of input and output sequence lengths, yet our observations reveal clear Energy Efficiency regimes: peak efficiency occurs with short-to-moderate inputs and medium-length outputs, while efficiency drops sharply for long inputs or very short outputs, indicating a non-linear dependency. In this work, we propose an analytical model derived from the computational and memory-access complexity of the Transformer architecture, capable of accurately characterizing the efficiency curve as a function of input and output lengths. To assess its accuracy, we evaluate energy consumption using TensorRT-LLM on NVIDIA H100 GPUs across a diverse set of LLMs ranging from 1B to 9B parameters, including OPT, LLaMA, Gemma, Falcon, Qwen2, and Granite, tested over input and output lengths from 64 to 4096 tokens, achieving a mean MAPE of 1.79%. Our results show that aligning sequence lengths with these efficiency "Sweet Spots" can substantially reduce energy usage, supporting informed truncation, summarization, and adaptive generation strategies in production systems.

</details>


### [27] [Nonlinearity as Rank: Generative Low-Rank Adapter with Radial Basis Functions](https://arxiv.org/abs/2602.05709)
*Yihao Ouyang,Shiwei Li,Haozhao Wang,Xiandi Luo,Zhuoqi Hu,Yuetong Song,Qiyu Qin,Yichen Li,Ruixuan Li*

Main category: cs.AI

TL;DR: GenLoRA提出用非线性函数生成低秩矩阵的基向量，替代显式存储，实现更高参数效率的LoRA微调


<details>
  <summary>Details</summary>
Motivation: 标准LoRA采用显式秩范式，增加模型容量需要添加更多行或列（基向量），导致参数大幅增长。研究发现这些基向量存在显著参数冗余，可以通过轻量级非线性函数紧凑表示。

Method: 提出生成式低秩适配器（GenLoRA），用非线性基向量生成替代显式基向量存储。为每个低秩矩阵维护一个潜在向量，并使用一组轻量级径向基函数（RBFs）合成基向量。每个RBF需要的参数远少于显式基向量。

Result: 在多个数据集和架构上的广泛实验表明，GenLoRA在更小的参数预算下获得更高的有效LoRA秩，从而实现更优的微调性能。

Conclusion: GenLoRA通过非线性基向量生成机制，显著提高了LoRA的参数效率，在有限参数预算下实现了更好的微调效果。

Abstract: Low-rank adaptation (LoRA) approximates the update of a pretrained weight matrix using the product of two low-rank matrices. However, standard LoRA follows an explicit-rank paradigm, where increasing model capacity requires adding more rows or columns (i.e., basis vectors) to the low-rank matrices, leading to substantial parameter growth. In this paper, we find that these basis vectors exhibit significant parameter redundancy and can be compactly represented by lightweight nonlinear functions. Therefore, we propose Generative Low-Rank Adapter (GenLoRA), which replaces explicit basis vector storage with nonlinear basis vector generation. Specifically, GenLoRA maintains a latent vector for each low-rank matrix and employs a set of lightweight radial basis functions (RBFs) to synthesize the basis vectors. Each RBF requires far fewer parameters than an explicit basis vector, enabling higher parameter efficiency in GenLoRA. Extensive experiments across multiple datasets and architectures show that GenLoRA attains higher effective LoRA ranks under smaller parameter budgets, resulting in superior fine-tuning performance. The code is available at https://anonymous.4open.science/r/GenLoRA-1519.

</details>


### [28] [Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification](https://arxiv.org/abs/2602.05717)
*Tianyi Wang,Long Li,Hongcan Guo,Yibiao Chen,Yixia Li,Yong Wang,Yun Chen,Guanhua Chen*

Main category: cs.AI

TL;DR: 论文提出锚定策略优化（APO）方法，解决强化学习中奖励可验证性导致的递归空间收缩问题，通过支持覆盖而非形状匹配来平衡效率与多样性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习中的KL正则化方法存在形状匹配约束与正确性所需的锐化之间的梯度冲突，导致递归空间收缩（RSC）问题，即有效替代方案的采样概率消失。

Method: 提出锚定策略优化（APO），将范式从全局形状匹配转向支持覆盖，定义基于参考模型高置信度支持的安全流形，允许积极锐化以提高效率，同时在错误校正时选择性调用恢复力以防止崩溃。

Result: 在数学基准测试中，APO打破了准确性与多样性的权衡，显著提高了Pass@1指标，同时恢复了标准策略梯度方法通常损失的Pass@K多样性。

Conclusion: APO作为一种梯度对齐机制，通过最大化支持覆盖实现弹性恢复，有效防止强化学习中的递归空间收缩问题，平衡了效率与多样性需求。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is increasingly viewed as a tree pruning mechanism. However, we identify a systemic pathology termed Recursive Space Contraction (RSC), an irreversible collapse driven by the combined dynamics of positive sharpening and negative squeezing, where the sampling probability of valid alternatives vanishes. While Kullback-Leibler (KL) regularization aims to mitigate this, it imposes a rigid Shape Matching constraint that forces the policy to mimic the reference model's full density, creating a gradient conflict with the sharpening required for correctness. We propose Anchored Policy Optimization (APO), shifting the paradigm from global Shape Matching to Support Coverage. By defining a Safe Manifold based on the reference model's high-confidence support, APO permits aggressive sharpening for efficiency while selectively invoking a restorative force during error correction to prevent collapse. We theoretically derive that APO serves as a gradient-aligned mechanism to maximize support coverage, enabling an Elastic Recovery that re-inflates valid branches. Empirical evaluations on mathematical benchmarks demonstrate that APO breaks the accuracy-diversity trade-off, significantly improving Pass@1 while restoring the Pass@K diversity typically lost by standard policy gradient methods.

</details>


### [29] [Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification](https://arxiv.org/abs/2602.05723)
*Taoye Yin,Haoyuan Hu,Yaxin Fan,Xinhao Chen,Xinya Wu,Kai Deng,Kezun Zhang,Feng Wang*

Main category: cs.AI

TL;DR: 提出RLFKV框架，通过细粒度知识验证和强化学习减少金融RAG系统中的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 金融RAG系统虽然依赖检索文档，但生成的响应仍存在与检索信息矛盾的幻觉问题，需要更精确的优化信号来改善一致性

Method: 提出RLFKV框架：1) 将金融响应分解为原子知识单元；2) 评估每个单元的正确性计算细粒度忠实度奖励；3) 加入信息量奖励防止奖励攻击；4) 使用强化学习优化模型

Result: 在公开的FDD任务和新提出的FDD-ANT数据集上实验，均显示出一致的改进，证实了方法的有效性

Conclusion: RLFKV框架通过细粒度知识验证和强化学习，有效减少了金融RAG系统中的幻觉问题，提高了响应与检索文档的一致性

Abstract: In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucinations that contradict the retrieved information. To mitigate this inconsistency, we propose a Reinforcement Learning framework enhanced with Fine-grained Knowledge Verification (RLFKV). Our method decomposes financial responses into atomic knowledge units and assesses the correctness of each unit to compute the fine-grained faithful reward. This reward offers more precise optimization signals, thereby improving alignment with the retrieved documents. Additionally, to prevent reward hacking (e.g., overly concise replies), we incorporate an informativeness reward that encourages the policy model to retain at least as many knowledge units as the base model. Experiments conducted on the public Financial Data Description (FDD) task and our newly proposed FDD-ANT dataset demonstrate consistent improvements, confirming the effectiveness of our approach.

</details>


### [30] [RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism](https://arxiv.org/abs/2602.05765)
*Zhong Guan,Haoran Sun,Yongjian Guo,Shuai Di,Xiaodong Bai,Jing Long,Tianyun Zhao,Mingxi Luo,Chen Zhou,Yucheng Guo,Qiming Yang,Wanting Xu,Wen Huang,Yunxuan Ma,Hongke Zhao,Likang Wu,Xiaotie Deng,Xi Xiao,Sheng Wen,Yicheng Gong,Junwu Xiong*

Main category: cs.AI

TL;DR: 本文提出首个完全异步的VLA模型训练框架，通过环境交互、策略生成和模型更新的全流程异步化，显著提升训练效率，在LIBERO基准上实现最高126.67%的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型的RL训练框架（如RLinf）采用同步执行方式，导致环境交互、策略生成和模型更新阶段的资源利用率低下和吞吐量受限，成为训练效率的主要瓶颈。

Method: 提出完全异步策略训练框架，采用多层次解耦架构：1) 环境交互与轨迹收集的异步并行化；2) 策略生成的流式执行；3) 训练更新的解耦调度。借鉴大模型RL中的异步优化思想。

Result: 在LIBERO基准上，相比现有同步策略，吞吐量提升最高达59.25%；深度优化分离策略后，吞吐量提升可达126.67%。消融实验验证了各异步组件的有效性，8-256 GPU规模验证显示良好的可扩展性。

Conclusion: 提出的完全异步训练框架有效解决了VLA模型训练中的效率瓶颈，通过全流程异步化显著提升训练吞吐量和资源利用率，为大规模VLA模型训练提供了高效解决方案。

Abstract: In recent years, Vision-Language-Action (VLA) models have emerged as a crucial pathway towards general embodied intelligence, yet their training efficiency has become a key bottleneck. Although existing reinforcement learning (RL)-based training frameworks like RLinf can enhance model generalization, they still rely on synchronous execution, leading to severe resource underutilization and throughput limitations during environment interaction, policy generation (rollout), and model update phases (actor). To overcome this challenge, this paper, for the first time, proposes and implements a fully-asynchronous policy training framework encompassing the entire pipeline from environment interaction, rollout generation, to actor policy updates. Systematically drawing inspiration from asynchronous optimization ideas in large model RL, our framework designs a multi-level decoupled architecture. This includes asynchronous parallelization of environment interaction and trajectory collection, streaming execution for policy generation, and decoupled scheduling for training updates. We validated the effectiveness of our method across diverse VLA models and environments. On the LIBERO benchmark, the framework achieves throughput improvements of up to 59.25\% compared to existing synchronous strategies. When deeply optimizing separation strategies, throughput can be increased by as much as 126.67\%. We verified the effectiveness of each asynchronous component via ablation studies. Scaling law validation across 8 to 256 GPUs demonstrates our method's excellent scalability under most conditions.

</details>


### [31] [FiMI: A Domain-Specific Language Model for Indian Finance Ecosystem](https://arxiv.org/abs/2602.05794)
*Aboli Kathar,Aman Kumar,Anusha Kamath,Araveeti Srujan,Ashish Sharma,Chandra Bhushan,Dilip Asbe,Divya Sorate,Duddu Prasanth Kumar,Evan Acharya,Harsh Sharma,Hrithik Kadam,Kanishk Singla,Keyur Doshi,Kiran Praveen,Kolisetty Krishna SK,Krishanu Adhikary,Lokesh MPT,Mayurdeep Sonowal,Nadeem Shaikh,Navya Prakash,Nimit Kothari,Nitin Kukreja,Prashant Devadiga,Rakesh Paul,Ratanjeet Pratap Chauhan,Raunak Kalani,Raviraj Joshi,Shamanth MH,Shantanu Pandey,Shubham Soni,Siddharth Dixit,Smriti Jopat,Sunil Patel,Suraj Singh,Suvradip Paul,Tulasi Pilla,Utkarsh Vaidya,Vineeth Nambiar,Vishal Kanvaty,Yatharth Dedhia*

Main category: cs.AI

TL;DR: FiMI是专门为印度数字支付系统开发的金融语言模型，基于Mistral Small 24B架构，通过多阶段训练流程构建，在金融推理和工具调用方面显著优于基础模型。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对印度数字支付系统的金融语言模型，解决现有通用模型在印度金融场景下的不足，特别是处理多语言（英语、印地语、印英混合语）金融数据和实际工作流程的需求。

Method: 采用Mistral Small 24B架构，通过多阶段训练流程：1）在680亿个经过筛选的金融、多语言和合成数据上进行持续预训练；2）指令微调；3）针对多轮工具驱动对话的领域特定监督微调，模拟交易纠纷和授权生命周期管理等实际工作流程。

Result: FiMI Base在金融推理基准测试中比Mistral Small 24B Base模型提升20%；FiMI Instruct在领域特定工具调用方面比Mistral Small 24B Instruct模型提升87%；同时在与相似规模模型的通用基准测试中保持相当性能。

Conclusion: FiMI成功开发了专门针对印度数字支付系统的金融语言模型，在保持通用能力的同时，在金融领域特定任务上取得了显著性能提升，证明了领域专业化模型的有效性。

Abstract: We present FiMI (Finance Model for India), a domain-specialized financial language model developed for Indian digital payment systems. We develop two model variants: FiMI Base and FiMI Instruct. FiMI adapts the Mistral Small 24B architecture through a multi-stage training pipeline, beginning with continuous pre-training on 68 Billion tokens of curated financial, multilingual (English, Hindi, Hinglish), and synthetic data. This is followed by instruction fine-tuning and domain-specific supervised fine-tuning focused on multi-turn, tool-driven conversations that model real-world workflows, such as transaction disputes and mandate lifecycle management. Evaluations reveal that FiMI Base achieves a 20% improvement over the Mistral Small 24B Base model on finance reasoning benchmark, while FiMI Instruct outperforms the Mistral Small 24B Instruct model by 87% on domain-specific tool-calling. Moreover, FiMI achieves these significant domain gains while maintaining comparable performance to models of similar size on general benchmarks.

</details>


### [32] [TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.05818)
*Zihao Jiang,Miao Peng,Zhenyan Shan,Wenjie Xu,Ben Liu,Gong Chen,Ziqi Gao,Min Peng*

Main category: cs.AI

TL;DR: TKG-Thinker：一种具有自主规划和自适应检索能力的智能体，通过动态多轮交互和双训练策略（SFT+RL）解决TKGQA中的推理幻觉和静态提示限制问题，在基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的TKGQA方法存在两个主要问题：1）在复杂时间约束下容易产生推理幻觉；2）静态提示限制了模型自主性和泛化能力，缺乏与TKG环境的动态交互优化。

Method: 提出TKG-Thinker智能体，通过动态多轮交互与TKG进行深度时间推理。采用双训练策略：首先使用思维链数据进行监督微调（SFT）培养核心规划能力，然后通过强化学习（RL）阶段利用多维奖励在复杂时间约束下优化推理策略。

Result: 在基准数据集上使用三个开源LLM进行实验，TKG-Thinker实现了最先进的性能，并在复杂TKGQA设置中表现出强大的泛化能力。

Conclusion: TKG-Thinker通过自主规划和自适应检索能力，有效解决了TKGQA中的推理幻觉和静态提示限制问题，为时间知识图谱问答提供了更有效的解决方案。

Abstract: Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain their efficacy in two primary ways. First, they are prone to reasoning hallucinations under complex temporal constraints. Second, static prompting limits model autonomy and generalization, as it lack optimization through dynamic interaction with temporal knowledge graphs (TKGs) environments. To address these limitations, we propose \textbf{TKG-Thinker}, a novel agent equipped with autonomous planning and adaptive retrieval capabilities for reasoning over TKGs. Specifically, TKG-Thinker performs in-depth temporal reasoning through dynamic multi-turn interactions with TKGs via a dual-training strategy. We first apply Supervised Fine-Tuning (SFT) with chain-of thought data to instill core planning capabilities, followed by a Reinforcement Learning (RL) stage that leverages multi-dimensional rewards to refine reasoning policies under intricate temporal constraints. Experimental results on benchmark datasets with three open-source LLMs show that TKG-Thinker achieves state-of-the-art performance and exhibits strong generalization across complex TKGQA settings.

</details>


### [33] [OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention](https://arxiv.org/abs/2602.05847)
*Zhangquan Chen,Jiale Tao,Ruihuang Li,Yihao Hu,Ruitao Chen,Zhantao Yang,Xinlei Yu,Haodong Jing,Manyuan Zhang,Shuai Shao,Biao Wang,Qinglin Lu,Ruqi Huang*

Main category: cs.AI

TL;DR: OmniVideo-R1：一种通过查询密集型定位和模态注意力融合增强多模态推理的强化框架，在音频-视觉理解任务上显著优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 人类通过多种模态协同感知世界，但现有的全视频模型在音频-视觉理解任务上仍面临重大挑战，需要提升混合模态推理能力。

Method: 提出OmniVideo-R1强化框架，采用两种关键策略：1）基于自监督学习的查询密集型定位；2）基于对比学习的模态注意力融合。

Result: 在多个基准测试上的广泛实验表明，OmniVideo-R1始终优于强基线模型，显示出其有效性和强大的泛化能力。

Conclusion: OmniVideo-R1通过"全模态线索思考"的方式显著提升了模型的混合模态推理能力，为全视频理解提供了有效的解决方案。

Abstract: While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinforced framework that improves mixed-modality reasoning. OmniVideo-R1 empowers models to "think with omnimodal cues" by two key strategies: (1) query-intensive grounding based on self-supervised learning paradigms; and (2) modality-attentive fusion built upon contrastive learning paradigms. Extensive experiments on multiple benchmarks demonstrate that OmniVideo-R1 consistently outperforms strong baselines, highlighting its effectiveness and robust generalization capabilities.

</details>


### [34] [BABE: Biology Arena BEnchmark](https://arxiv.org/abs/2602.05857)
*Junting Zhou,Jin Chen,Linfeng Hao,Denghui Cao,Zheyu Wang,Qiguang Chen,Chaoyou Fu,Jiaze Chen,Yuchen Wu,Ge Zhang,Mingxuan Wang,Wenhao Huang,Tong Yang*

Main category: cs.AI

TL;DR: BABE是一个评估生物AI系统实验推理能力的基准测试，基于同行评审研究论文和真实生物研究构建，专注于因果推理和跨尺度推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有生物学基准测试未能充分评估研究人员所需的关键能力：将实验结果与背景知识整合以得出有意义结论的能力。大型语言模型能力已从基本对话扩展到高级科学推理，但缺乏评估实验推理能力的基准。

Method: 从同行评审研究论文和真实世界生物研究中构建BABE基准测试，确保任务反映实际科学探究的复杂性和跨学科性质。基准设计挑战模型进行因果推理和跨尺度推理。

Result: BABE提供了一个稳健的评估框架，用于评估AI系统如何像实践科学家一样推理，为衡量AI对生物研究贡献潜力提供了更真实的度量标准。

Conclusion: BABE基准填补了现有生物学评估的空白，通过基于真实研究材料构建的测试，能够更准确地评估AI系统的实验推理能力，为生物AI系统的发展提供了重要评估工具。

Abstract: The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogue to advanced scientific reasoning. However, existing benchmarks in biology often fail to assess a critical skill required of researchers: the ability to integrate experimental results with contextual knowledge to derive meaningful conclusions. To address this gap, we introduce BABE(Biology Arena BEnchmark), a comprehensive benchmark designed to evaluate the experimental reasoning capabilities of biological AI systems. BABE is uniquely constructed from peer-reviewed research papers and real-world biological studies, ensuring that tasks reflect the complexity and interdisciplinary nature of actual scientific inquiry. BABE challenges models to perform causal reasoning and cross-scale inference. Our benchmark provides a robust framework for assessing how well AI systems can reason like practicing scientists, offering a more authentic measure of their potential to contribute to biological research.

</details>


### [35] [Beyond Manual Planning: Seating Allocation for Large Organizations](https://arxiv.org/abs/2602.05875)
*Anton Ipsen,Michael Cashmore,Kirsty Fielding,Nicolas Marchesotti,Parisa Zehtabi,Daniele Magazzeni,Manuela Veloso*

Main category: cs.AI

TL;DR: 论文提出了层次化座位分配问题（HSAP），旨在为具有层次化结构的组织团队在平面图上分配最优座位安排，确保有紧密层级关系的团队座位相邻。


<details>
  <summary>Details</summary>
Motivation: 大型组织具有复杂的层级结构，需要确保有紧密层级关系的团队（如研究小组）座位相邻，形成连续区域。目前这个问题主要通过人工管理，导致重新规划频率低且效果不理想。

Method: 提出端到端框架解决HSAP：使用概率路线图（PRM）和快速探索随机树（RRT）计算座位间距离，结合启发式搜索和动态规划方法，通过整数规划解决座位分配问题。

Result: 在不同规模实例下评估PRM框架和后续分配方案，从定量和定性两方面展示了方法的有效性。

Conclusion: 该框架能够自动化解决层次化座位分配问题，减少人工干预，为大型组织提供更优的座位规划方案。

Abstract: We introduce the Hierarchical Seating Allocation Problem (HSAP) which addresses the optimal assignment of hierarchically structured organizational teams to physical seating arrangements on a floor plan. This problem is driven by the necessity for large organizations with large hierarchies to ensure that teams with close hierarchical relationships are seated in proximity to one another, such as ensuring a research group occupies a contiguous area. Currently, this problem is managed manually leading to infrequent and suboptimal replanning efforts. To alleviate this manual process, we propose an end-to-end framework to solve the HSAP. A scalable approach to calculate the distance between any pair of seats using a probabilistic road map (PRM) and rapidly-exploring random trees (RRT) which is combined with heuristic search and dynamic programming approach to solve the HSAP using integer programming. We demonstrate our approach under different sized instances by evaluating the PRM framework and subsequent allocations both quantitatively and qualitatively.

</details>


### [36] [A Guide to Large Language Models in Modeling and Simulation: From Core Techniques to Critical Challenges](https://arxiv.org/abs/2602.05883)
*Philippe J. Giabbanelli*

Main category: cs.AI

TL;DR: 本文为建模与仿真（M&S）领域的大语言模型（LLMs）使用提供实用指南，指出看似简单的实践可能带来微妙问题、不必要复杂性甚至更差结果，强调原则性设计选择、诊断策略和实证评估。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在建模与仿真工作流中的广泛应用，许多看似直接的使用实践可能引入微妙问题、不必要复杂性或导致次优结果。作者旨在为M&S应用提供全面实用的LLMs使用指导，帮助建模者做出明智决策。

Method: 通过讨论常见困惑来源，包括非确定性、知识增强（RAG和LoRA）、M&S数据分解和超参数设置，强调原则性设计选择、诊断策略和实证评估方法。

Result: 论文提供了关于LLMs在M&S中使用的综合指导框架，识别了多个潜在陷阱（如模型崩溃、过度输入、无效微调等），并提出了相应的解决方案和最佳实践。

Conclusion: 在建模与仿真中使用大语言模型需要谨慎的方法，避免常见误区，通过系统性的设计选择、诊断和评估，建模者可以更有效地决定何时、如何以及是否依赖LLMs，从而获得更好的结果。

Abstract: Large language models (LLMs) have rapidly become familiar tools to researchers and practitioners. Concepts such as prompting, temperature, or few-shot examples are now widely recognized, and LLMs are increasingly used in Modeling & Simulation (M&S) workflows. However, practices that appear straightforward may introduce subtle issues, unnecessary complexity, or may even lead to inferior results. Adding more data can backfire (e.g., deteriorating performance through model collapse or inadvertently wiping out existing guardrails), spending time on fine-tuning a model can be unnecessary without a prior assessment of what it already knows, setting the temperature to 0 is not sufficient to make LLMs deterministic, providing a large volume of M&S data as input can be excessive (LLMs cannot attend to everything) but naive simplifications can lose information. We aim to provide comprehensive and practical guidance on how to use LLMs, with an emphasis on M&S applications. We discuss common sources of confusion, including non-determinism, knowledge augmentation (including RAG and LoRA), decomposition of M&S data, and hyper-parameter settings. We emphasize principled design choices, diagnostic strategies, and empirical evaluation, with the goal of helping modelers make informed decisions about when, how, and whether to rely on LLMs.

</details>


### [37] [Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2602.05920)
*Eva Andrés*

Main category: cs.AI

TL;DR: 该论文比较了经典和量子强化学习方法解决带容量约束的车辆路径问题，发现量子增强模型在路由距离、紧凑性和重叠度方面优于经典基线，混合架构表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索量子强化学习在复杂组合优化问题（特别是带容量约束的车辆路径问题）中的应用潜力，比较经典、全量子和混合方法在解决这类实际问题中的性能差异。

Method: 采用优势演员-评论家（A2C）智能体，实现了经典、全量子和混合三种变体，结合transformer架构通过自注意力和交叉注意力机制捕捉车辆、客户和仓库之间的关系。实验针对20个客户和4辆车的多车辆容量约束场景，进行了10次独立运行。

Result: 所有三种方法都能学习有效的路由策略，但量子增强模型在路由距离、路线紧凑性和路线重叠度方面优于经典基线，产生更稳健的路线组织。混合架构在距离、紧凑性和路线重叠度方面实现了最佳整体性能。定性可视化显示量子模型生成更结构化、更连贯的路由解决方案。

Conclusion: 混合量子-经典强化学习模型在解决复杂组合优化问题（如带容量约束的车辆路径问题）方面具有显著潜力，量子增强方法能够产生更优、更稳健的路由解决方案。

Abstract: This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integrating transformer architectures to capture the relationships between vehicles, clients, and the depot through self- and cross-attention mechanisms. The experiments focus on multi-vehicle scenarios with capacity constraints, considering 20 clients and 4 vehicles, and are conducted over ten independent runs. Performance is assessed using routing distance, route compactness, and route overlap. The results show that all three approaches are capable of learning effective routing policies. However, quantum-enhanced models outperform the classical baseline and produce more robust route organization, with the hybrid architecture achieving the best overall performance across distance, compactness, and route overlap. In addition to quantitative improvements, qualitative visualizations reveal that quantum-based models generate more structured and coherent routing solutions. These findings highlight the potential of hybrid quantum-classical reinforcement learning models for addressing complex combinatorial optimization problems such as the CVRP.

</details>


### [38] [Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods](https://arxiv.org/abs/2602.06000)
*Ali Shendabadi,Parnia Izadirad,Mostafa Salehi,Mahmoud Bijankhan*

Main category: cs.AI

TL;DR: 该研究探索了预训练ASR模型Whisper在语音情感识别中的潜力，提出了两种基于注意力的池化方法来降维并保留情感特征，在英语和波斯语数据集上取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别研究因缺乏标准化大规模数据集而受限，现有研究多利用预训练模型提取特征。本研究旨在探索Whisper这一预训练ASR系统在语音情感识别中的能力。

Method: 提出了两种基于注意力的池化方法：多头注意力平均池化和QKV池化，用于高效降低Whisper表示的维度同时保留情感特征。在英语IEMOCAP和波斯语ShEMO数据集上使用Whisper Tiny和Small模型进行实验。

Result: 多头QKV架构在ShEMO数据集上取得了最先进的结果，未加权准确率提高了2.47%。发现中间层在波斯语数据集上的SER表现更好，为HuBERT X-Large等大型模型提供了轻量高效的替代方案。

Conclusion: Whisper作为SER表示提取器具有巨大潜力，基于注意力的池化方法在维度减少方面非常有效，为语音情感识别提供了轻量高效的解决方案。

Abstract: Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, a pre-trained ASR system, in speech emotion recognition by proposing two attention-based pooling methods, Multi-head Attentive Average Pooling and QKV Pooling, designed to efficiently reduce the dimensionality of Whisper representations while preserving emotional features. We experiment on English and Persian, using the IEMOCAP and ShEMO datasets respectively, with Whisper Tiny and Small. Our multi-head QKV architecture achieves state-of-the-art results on the ShEMO dataset, with a 2.47% improvement in unweighted accuracy. We further compare the performance of different Whisper encoder layers and find that intermediate layers often perform better for SER on the Persian dataset, providing a lightweight and efficient alternative to much larger models such as HuBERT X-Large. Our findings highlight the potential of Whisper as a representation extractor for SER and demonstrate the effectiveness of attention-based pooling for dimension reduction.

</details>


### [39] [AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions](https://arxiv.org/abs/2602.06008)
*Xianyang Liu,Shangding Gu,Dawn Song*

Main category: cs.AI

TL;DR: AgenticPay是一个用于多智能体买卖谈判的基准测试和模拟框架，通过自然语言驱动，包含110多个任务，评估LLM在语言经济互动中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏评估多智能体语言经济互动的原则性设置，而LLM智能体在自主谈判、协调和交易方面的应用日益增多，需要专门的评估框架。

Method: 构建AgenticPay框架，模拟买卖双方具有私有约束和产品依赖估值的市场环境，支持多轮语言谈判而非单纯数字竞价，包含双边议价到多对多市场的多样化任务，提供结构化动作提取和可行性、效率、福利等指标。

Result: 对最先进的专有和开源LLM进行基准测试，发现谈判性能存在显著差距，突显了长期战略推理的挑战，确立了AgenticPay作为研究智能商务和语言市场互动的基础。

Conclusion: AgenticPay为评估多智能体语言经济互动提供了系统框架，揭示了当前LLM在谈判和战略推理方面的局限性，为未来研究智能商务和基于语言的市场互动奠定了基础。

Abstract: Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay.

</details>
