{"id": "2602.05143", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05143", "abs": "https://arxiv.org/abs/2602.05143", "authors": ["Nengbo Wang", "Tuo Liang", "Vikash Singh", "Chaoda Song", "Van Yang", "Yu Yin", "Jing Ma", "Jagdip Singh", "Vipin Chaudhary"], "title": "HugRAG: Hierarchical Causal Knowledge Graph Design for RAG", "comment": null, "summary": "Retrieval augmented generation (RAG) has enhanced large language models by enabling access to external knowledge, with graph-based RAG emerging as a powerful paradigm for structured retrieval and reasoning. However, existing graph-based methods often over-rely on surface-level node matching and lack explicit causal modeling, leading to unfaithful or spurious answers. Prior attempts to incorporate causality are typically limited to local or single-document contexts and also suffer from information isolation that arises from modular graph structures, which hinders scalability and cross-module causal reasoning. To address these challenges, we propose HugRAG, a framework that rethinks knowledge organization for graph-based RAG through causal gating across hierarchical modules. HugRAG explicitly models causal relationships to suppress spurious correlations while enabling scalable reasoning over large-scale knowledge graphs. Extensive experiments demonstrate that HugRAG consistently outperforms competitive graph-based RAG baselines across multiple datasets and evaluation metrics. Our work establishes a principled foundation for structured, scalable, and causally grounded RAG systems.", "AI": {"tldr": "HugRAG\u662f\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u95e8\u63a7\u7684\u5c42\u6b21\u5316\u56feRAG\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u56e0\u679c\u5173\u7cfb\u6765\u6291\u5236\u865a\u5047\u76f8\u5173\u6027\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u4e0a\u7684\u53ef\u6269\u5c55\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684RAG\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u8868\u9762\u8282\u70b9\u5339\u914d\uff0c\u7f3a\u4e4f\u663e\u5f0f\u56e0\u679c\u5efa\u6a21\uff0c\u5bfc\u81f4\u7b54\u6848\u4e0d\u53ef\u9760\u6216\u865a\u5047\u3002\u5148\u524d\u5c1d\u8bd5\u878d\u5165\u56e0\u679c\u5173\u7cfb\u7684\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u5c40\u90e8\u6216\u5355\u6587\u6863\u4e0a\u4e0b\u6587\uff0c\u4e14\u53d7\u6a21\u5757\u5316\u56fe\u7ed3\u6784\u5bfc\u81f4\u7684\u4fe1\u606f\u9694\u79bb\u95ee\u9898\u5f71\u54cd\uff0c\u963b\u788d\u4e86\u53ef\u6269\u5c55\u6027\u548c\u8de8\u6a21\u5757\u56e0\u679c\u63a8\u7406\u3002", "method": "\u63d0\u51faHugRAG\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u95e8\u63a7\u91cd\u65b0\u601d\u8003\u57fa\u4e8e\u56fe\u7684RAG\u77e5\u8bc6\u7ec4\u7ec7\u65b9\u5f0f\uff0c\u5728\u5c42\u6b21\u5316\u6a21\u5757\u95f4\u5b9e\u73b0\u56e0\u679c\u95e8\u63a7\uff0c\u663e\u5f0f\u5efa\u6a21\u56e0\u679c\u5173\u7cfb\u4ee5\u6291\u5236\u865a\u5047\u76f8\u5173\u6027\uff0c\u540c\u65f6\u652f\u6301\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u4e0a\u7684\u53ef\u6269\u5c55\u63a8\u7406\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cHugRAG\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u7ade\u4e89\u6027\u7684\u57fa\u4e8e\u56fe\u7684RAG\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u6269\u5c55\u4e14\u57fa\u4e8e\u56e0\u679c\u57fa\u7840\u7684RAG\u7cfb\u7edf\u5efa\u7acb\u4e86\u539f\u5219\u6027\u57fa\u7840\u3002"}}
{"id": "2602.05279", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.05279", "abs": "https://arxiv.org/abs/2602.05279", "authors": ["Kim Hammar", "Tansu Alpcan", "Emil Lupu"], "title": "Hallucination-Resistant Security Planning with a Large Language Model", "comment": "Accepted to IEEE/IFIP Network Operations and Management Symposium 2026. To appear in the conference proceedings", "summary": "Large language models (LLMs) are promising tools for supporting security management tasks, such as incident response planning. However, their unreliability and tendency to hallucinate remain significant challenges. In this paper, we address these challenges by introducing a principled framework for using an LLM as decision support in security management. Our framework integrates the LLM in an iterative loop where it generates candidate actions that are checked for consistency with system constraints and lookahead predictions. When consistency is low, we abstain from the generated actions and instead collect external feedback, e.g., by evaluating actions in a digital twin. This feedback is then used to refine the candidate actions through in-context learning (ICL). We prove that this design allows to control the hallucination risk by tuning the consistency threshold. Moreover, we establish a bound on the regret of ICL under certain assumptions. To evaluate our framework, we apply it to an incident response use case where the goal is to generate a response and recovery plan based on system logs. Experiments on four public datasets show that our framework reduces recovery times by up to 30% compared to frontier LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\uff0c\u5c06LLM\u96c6\u6210\u5230\u5b89\u5168\u7ba1\u7406\u7684\u51b3\u7b56\u652f\u6301\u4e2d\uff0c\u901a\u8fc7\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u6570\u5b57\u5b6a\u751f\u53cd\u9988\u63a7\u5236\u5e7b\u89c9\u98ce\u9669\uff0c\u5728\u4e8b\u4ef6\u54cd\u5e94\u7528\u4f8b\u4e2d\u76f8\u6bd4\u524d\u6cbfLLM\u51cf\u5c1130%\u6062\u590d\u65f6\u95f4\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u652f\u6301\u5b89\u5168\u7ba1\u7406\u4efb\u52a1\uff08\u5982\u4e8b\u4ef6\u54cd\u5e94\u89c4\u5212\uff09\u65b9\u9762\u5f88\u6709\u524d\u666f\uff0c\u4f46\u5176\u4e0d\u53ef\u9760\u6027\u548c\u5e7b\u89c9\u503e\u5411\u4ecd\u7136\u662f\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u4ee5\u63d0\u9ad8LLM\u5728\u5b89\u5168\u9886\u57df\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\uff0c\u5c06LLM\u96c6\u6210\u5230\u8fed\u4ee3\u5faa\u73af\u4e2d\uff1aLLM\u751f\u6210\u5019\u9009\u884c\u52a8\uff0c\u68c0\u67e5\u4e0e\u7cfb\u7edf\u7ea6\u675f\u548c\u524d\u77bb\u9884\u6d4b\u7684\u4e00\u81f4\u6027\uff1b\u5f53\u4e00\u81f4\u6027\u4f4e\u65f6\uff0c\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u7b49\u5916\u90e8\u53cd\u9988\u6536\u96c6\u4fe1\u606f\uff0c\u7136\u540e\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u4f18\u5316\u5019\u9009\u884c\u52a8\u3002", "result": "\u8bc1\u660e\u8be5\u8bbe\u8ba1\u53ef\u901a\u8fc7\u8c03\u6574\u4e00\u81f4\u6027\u9608\u503c\u63a7\u5236\u5e7b\u89c9\u98ce\u9669\uff0c\u5e76\u5728\u67d0\u4e9b\u5047\u8bbe\u4e0b\u5efa\u7acb\u4e86ICL\u7684\u9057\u61be\u754c\u9650\u3002\u5728\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u76f8\u6bd4\u524d\u6cbfLLM\u5c06\u6062\u590d\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe30%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5728\u5b89\u5168\u7ba1\u7406\u4e2d\u4f7f\u7528LLM\u4f5c\u4e3a\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u5916\u90e8\u53cd\u9988\u6709\u6548\u63a7\u5236\u5e7b\u89c9\u98ce\u9669\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4e8b\u4ef6\u54cd\u5e94\u89c4\u5212\u7684\u6548\u679c\u3002"}}
{"id": "2602.05302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05302", "abs": "https://arxiv.org/abs/2602.05302", "authors": ["Chris Zhu", "Sasha Cui", "Will Sanok Dufallo", "Runzhi Jin", "Zhen Xu", "Linjun Zhang", "Daylian Cain"], "title": "PieArena: Frontier Language Agents Achieve MBA-Level Negotiation Performance and Reveal Novel Behavioral Differences", "comment": null, "summary": "We present an in-depth evaluation of LLMs' ability to negotiate, a central business task that requires strategic reasoning, theory of mind, and economic value creation. To do so, we introduce PieArena, a large-scale negotiation benchmark grounded in multi-agent interactions over realistic scenarios drawn from an MBA negotiation course at an elite business school. We find systematic evidence of AGI-level performance in which a representative frontier agent (GPT-5) matches or outperforms trained business-school students, despite a semester of general negotiation instruction and targeted coaching immediately prior to the task. We further study the effects of joint-intentionality agentic scaffolding and find asymmetric gains, with large improvements for mid- and lower-tier LMs and diminishing returns for frontier LMs. Beyond deal outcomes, PieArena provides a multi-dimensional negotiation behavioral profile, revealing novel cross-model heterogeneity, masked by deal-outcome-only benchmarks, in deception, computation accuracy, instruction compliance, and perceived reputation. Overall, our results suggest that frontier language agents are already intellectually and psychologically capable of deployment in high-stakes economic settings, but deficiencies in robustness and trustworthiness remain open challenges.", "AI": {"tldr": "GPT-5\u5728PieArena\u8c08\u5224\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6216\u8d85\u8d8a\u5546\u5b66\u9662\u5b66\u751f\u6c34\u5e73\uff0c\u4f46\u4e2d\u4f4e\u7aef\u6a21\u578b\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u8c08\u5224\u884c\u4e3a\u5206\u6790\u63ed\u793a\u4e86\u6a21\u578b\u95f4\u7684\u5f02\u8d28\u6027\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u8c08\u5224\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u8c08\u5224\u662f\u5546\u4e1a\u6838\u5fc3\u4efb\u52a1\uff0c\u9700\u8981\u6218\u7565\u63a8\u7406\u3001\u5fc3\u667a\u7406\u8bba\u548c\u7ecf\u6d4e\u4ef7\u503c\u521b\u9020\u80fd\u529b\u3002", "method": "\u5f15\u5165PieArena\u5927\u89c4\u6a21\u8c08\u5224\u57fa\u51c6\uff0c\u57fa\u4e8e\u7cbe\u82f1\u5546\u5b66\u9662MBA\u8c08\u5224\u8bfe\u7a0b\u7684\u771f\u5b9e\u573a\u666f\uff0c\u8fdb\u884c\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u8bc4\u4f30\uff0c\u7814\u7a76\u8054\u5408\u610f\u5411\u6027\u667a\u80fd\u4f53\u652f\u67b6\u7684\u6548\u679c\u3002", "result": "\u524d\u6cbf\u6a21\u578bGPT-5\u8fbe\u5230\u6216\u8d85\u8d8a\u7ecf\u8fc7\u4e00\u5b66\u671f\u8c08\u5224\u8bad\u7ec3\u548c\u9488\u5bf9\u6027\u6307\u5bfc\u7684\u5546\u5b66\u9662\u5b66\u751f\uff1b\u8054\u5408\u610f\u5411\u6027\u652f\u67b6\u5bf9\u4e2d\u4f4e\u7aef\u6a21\u578b\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f46\u5bf9\u524d\u6cbf\u6a21\u578b\u6536\u76ca\u9012\u51cf\uff1b\u8c08\u5224\u884c\u4e3a\u5206\u6790\u63ed\u793a\u4e86\u6a21\u578b\u5728\u6b3a\u9a97\u3001\u8ba1\u7b97\u51c6\u786e\u6027\u3001\u6307\u4ee4\u9075\u4ece\u548c\u611f\u77e5\u58f0\u8a89\u65b9\u9762\u7684\u5f02\u8d28\u6027\u3002", "conclusion": "\u524d\u6cbf\u8bed\u8a00\u667a\u80fd\u4f53\u5728\u667a\u529b\u548c\u5fc3\u7406\u4e0a\u5df2\u5177\u5907\u5728\u9ad8\u98ce\u9669\u7ecf\u6d4e\u73af\u5883\u4e2d\u90e8\u7f72\u7684\u80fd\u529b\uff0c\u4f46\u5728\u9c81\u68d2\u6027\u548c\u53ef\u4fe1\u8d56\u6027\u65b9\u9762\u4ecd\u5b58\u5728\u6311\u6218\u3002"}}
{"id": "2602.05407", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05407", "abs": "https://arxiv.org/abs/2602.05407", "authors": ["Jun-Min Lee", "Meong Hi Son", "Edward Choi"], "title": "H-AdminSim: A Multi-Agent Simulator for Realistic Hospital Administrative Workflows with FHIR Integration", "comment": null, "summary": "Hospital administration departments handle a wide range of operational tasks and, in large hospitals, process over 10,000 requests per day, driving growing interest in LLM-based automation. However, prior work has focused primarily on patient--physician interactions or isolated administrative subtasks, failing to capture the complexity of real administrative workflows. To address this gap, we propose H-AdminSim, a comprehensive end-to-end simulation framework that combines realistic data generation with multi-agent-based simulation of hospital administrative workflows. These tasks are quantitatively evaluated using detailed rubrics, enabling systematic comparison of LLMs. Through FHIR integration, H-AdminSim provides a unified and interoperable environment for testing administrative workflows across heterogeneous hospital settings, serving as a standardized testbed for assessing the feasibility and performance of LLM-driven administrative automation.", "AI": {"tldr": "H-AdminSim\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u533b\u9662\u7ba1\u7406\u6a21\u62df\u6846\u67b6\uff0c\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u751f\u6210\u548c\u591a\u667a\u80fd\u4f53\u6a21\u62df\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30LLM\u5728\u533b\u9662\u884c\u653f\u5de5\u4f5c\u6d41\u7a0b\u81ea\u52a8\u5316\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u533b\u9662\u884c\u653f\u90e8\u95e8\u6bcf\u5929\u5904\u7406\u5927\u91cf\u4efb\u52a1\uff08\u8d85\u8fc710,000\u4e2a\u8bf7\u6c42\uff09\uff0c\u5bf9LLM\u81ea\u52a8\u5316\u6709\u5f3a\u70c8\u9700\u6c42\u3002\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u533b\u60a3\u4ea4\u4e92\u6216\u5b64\u7acb\u7684\u7ba1\u7406\u5b50\u4efb\u52a1\uff0c\u672a\u80fd\u6355\u6349\u771f\u5b9e\u884c\u653f\u5de5\u4f5c\u6d41\u7a0b\u7684\u590d\u6742\u6027\u3002", "method": "\u63d0\u51faH-AdminSim\u6846\u67b6\uff0c\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u751f\u6210\u548c\u591a\u667a\u80fd\u4f53\u6a21\u62df\u533b\u9662\u884c\u653f\u5de5\u4f5c\u6d41\u7a0b\u3002\u901a\u8fc7FHIR\u96c6\u6210\u63d0\u4f9b\u7edf\u4e00\u3001\u53ef\u4e92\u64cd\u4f5c\u7684\u73af\u5883\uff0c\u4f7f\u7528\u8be6\u7ec6\u8bc4\u5206\u6807\u51c6\u5bf9\u4efb\u52a1\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u8bc4\u4f30LLM\u9a71\u52a8\u7684\u884c\u653f\u81ea\u52a8\u5316\u53ef\u884c\u6027\u548c\u6027\u80fd\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u6d4b\u8bd5\u5e73\u53f0\uff0c\u80fd\u591f\u8de8\u5f02\u6784\u533b\u9662\u73af\u5883\u6d4b\u8bd5\u884c\u653f\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "H-AdminSim\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u6a21\u62df\u6846\u67b6\u89e3\u51b3\u4e86\u533b\u9662\u884c\u653f\u5de5\u4f5c\u6d41\u7a0b\u7684\u590d\u6742\u6027\uff0c\u4e3a\u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540cLLM\u5728\u884c\u653f\u81ea\u52a8\u5316\u4e2d\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.05532", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.05532", "abs": "https://arxiv.org/abs/2602.05532", "authors": ["Florian Dietz", "William Wale", "Oscar Gilg", "Robert McCarthy", "Felix Michalak", "Gustavo Ewbank Rodrigues Danon", "Miguelito de Guzman", "Dietrich Klakow"], "title": "Split Personality Training: Revealing Latent Knowledge Through Alternate Personalities", "comment": null, "summary": "Detecting misalignment in large language models is challenging because models may learn to conceal misbehavior during training. Standard auditing techniques fall short: black-box methods often cannot distinguish misaligned outputs from benign ones, and mechanistic interpretability does not scale with model capabilities. We introduce Split Personality Training (SPT), which fine-tunes a second ``honest persona'' into LoRA parameters that remain inactive during normal operation. After the main model responds, we activate the LoRA adapter and insert a trigger string, enabling the honest persona to review the response while accessing the main model's latent states. We test our method on the Anthropic Auditing Game Model Organism, a benchmark where Llama-3.3-70B is trained to exploit reward hacks while concealing this behavior. SPT achieves 96% overall accuracy, whereas Anthropic reports near 0% accuracy. The honest persona reveals latent knowledge inaccessible to external observers, such as the fictional biases the compromised model was trained on.", "AI": {"tldr": "SPT\u65b9\u6cd5\u901a\u8fc7\u5728LoRA\u53c2\u6570\u4e2d\u8bad\u7ec3\u4e00\u4e2a\"\u8bda\u5b9e\u4eba\u683c\"\uff0c\u5728\u6a21\u578b\u6b63\u5e38\u54cd\u5e94\u540e\u6fc0\u6d3b\u8be5\u4eba\u683c\u6765\u5ba1\u67e5\u4e3b\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u6709\u6548\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9519\u4f4d\u884c\u4e3a\uff0c\u5728Anthropic\u5ba1\u8ba1\u6e38\u620f\u57fa\u51c6\u4e0a\u8fbe\u523096%\u51c6\u786e\u7387\u3002", "motivation": "\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9519\u4f4d\u884c\u4e3a\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u6a21\u578b\u53ef\u80fd\u5728\u8bad\u7ec3\u4e2d\u5b66\u4f1a\u9690\u85cf\u4e0d\u826f\u884c\u4e3a\u3002\u4f20\u7edf\u5ba1\u8ba1\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff1a\u9ed1\u76d2\u65b9\u6cd5\u96be\u4ee5\u533a\u5206\u9519\u4f4d\u8f93\u51fa\u4e0e\u826f\u6027\u8f93\u51fa\uff0c\u800c\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u65e0\u6cd5\u968f\u6a21\u578b\u80fd\u529b\u6269\u5c55\u3002", "method": "\u5f15\u5165Split Personality Training (SPT)\u65b9\u6cd5\uff0c\u5728LoRA\u53c2\u6570\u4e2d\u5fae\u8c03\u4e00\u4e2a\"\u8bda\u5b9e\u4eba\u683c\"\uff0c\u8be5\u4eba\u683c\u5728\u6b63\u5e38\u64cd\u4f5c\u65f6\u4fdd\u6301\u975e\u6fc0\u6d3b\u72b6\u6001\u3002\u4e3b\u6a21\u578b\u54cd\u5e94\u540e\uff0c\u6fc0\u6d3bLoRA\u9002\u914d\u5668\u5e76\u63d2\u5165\u89e6\u53d1\u5b57\u7b26\u4e32\uff0c\u4f7f\u8bda\u5b9e\u4eba\u683c\u80fd\u591f\u5ba1\u67e5\u54cd\u5e94\u540c\u65f6\u8bbf\u95ee\u4e3b\u6a21\u578b\u7684\u6f5c\u5728\u72b6\u6001\u3002", "result": "\u5728Anthropic\u5ba1\u8ba1\u6e38\u620f\u6a21\u578b\u751f\u7269\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSPT\u8fbe\u523096%\u7684\u603b\u4f53\u51c6\u786e\u7387\uff0c\u800cAnthropic\u62a5\u544a\u63a5\u8fd10%\u51c6\u786e\u7387\u3002\u8bda\u5b9e\u4eba\u683c\u63ed\u793a\u4e86\u5916\u90e8\u89c2\u5bdf\u8005\u65e0\u6cd5\u8bbf\u95ee\u7684\u6f5c\u5728\u77e5\u8bc6\uff0c\u5982\u53d7\u635f\u6a21\u578b\u8bad\u7ec3\u65f6\u4f7f\u7528\u7684\u865a\u6784\u504f\u89c1\u3002", "conclusion": "SPT\u65b9\u6cd5\u901a\u8fc7\u521b\u5efa\u72ec\u7acb\u7684\u8bda\u5b9e\u5ba1\u67e5\u4eba\u683c\uff0c\u6709\u6548\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9690\u85cf\u9519\u4f4d\u884c\u4e3a\uff0c\u4e3a\u89e3\u51b3\u6a21\u578b\u6b3a\u9a97\u6027\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.06023", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.06023", "abs": "https://arxiv.org/abs/2602.06023", "authors": ["Christopher A. McClurg", "Alan R. Wagner"], "title": "Learning Event-Based Shooter Models from Virtual Reality Experiments", "comment": "Preprint under review for conference publication. 9 pages, 4 figures, 4 tables", "summary": "Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.", "AI": {"tldr": "\u5f00\u53d1\u6570\u636e\u9a71\u52a8\u7684\u79bb\u6563\u4e8b\u4ef6\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u8bc4\u4f30\u5b66\u6821\u5b89\u5168\u5e72\u9884\u7b56\u7565\uff0c\u7279\u522b\u662f\u673a\u5668\u4eba\u5e94\u5bf9\u67aa\u51fb\u4e8b\u4ef6\u7684\u65b9\u6848\uff0c\u89e3\u51b3VR\u7814\u7a76\u4e2d\u62db\u52df\u53c2\u4e0e\u8005\u56f0\u96be\u7684\u95ee\u9898\u3002", "motivation": "VR\u867d\u7136\u80fd\u6709\u6548\u8bc4\u4f30\u5b66\u6821\u5b89\u5168\u63aa\u65bd\uff0c\u4f46\u6bcf\u6b21\u6761\u4ef6\u53d8\u5316\u90fd\u9700\u8981\u62db\u52df\u65b0\u53c2\u4e0e\u8005\uff0c\u4f7f\u5f97\u5927\u89c4\u6a21\u6216\u8fed\u4ee3\u8bc4\u4f30\u53d8\u5f97\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u573a\u666f\u7684\u5b66\u4e60\u6709\u6548\u5e72\u9884\u7b56\u7565\u65f6\u3002", "method": "\u5f00\u53d1\u6570\u636e\u9a71\u52a8\u7684\u79bb\u6563\u4e8b\u4ef6\u6a21\u62df\u5668\uff0c\u5c06\u67aa\u624b\u79fb\u52a8\u548c\u533a\u57df\u5185\u884c\u52a8\u5efa\u6a21\u4e3a\u4eceVR\u7814\u7a76\u4e2d\u53c2\u4e0e\u8005\u884c\u4e3a\u5b66\u4e60\u7684\u968f\u673a\u8fc7\u7a0b\uff0c\u7528\u4e8e\u8bc4\u4f30\u673a\u5668\u4eba\u5e72\u9884\u7b56\u7565\u3002", "result": "\u6a21\u62df\u5668\u80fd\u591f\u91cd\u73b0\u5173\u952e\u7ecf\u9a8c\u6a21\u5f0f\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5e72\u9884\u7b56\u7565\u8bc4\u4f30\u548c\u5b66\u4e60\uff0c\u8fd9\u4e9b\u7b56\u7565\u96be\u4ee5\u76f4\u63a5\u901a\u8fc7\u4eba\u7c7b\u53d7\u8bd5\u8005\u8fdb\u884c\u8bad\u7ec3\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4e00\u4e2a\u9ad8\u5230\u4e2d\u4fdd\u771f\u5ea6\u7684\u6a21\u62df\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4e3a\u5f00\u53d1\u548c\u8bc4\u4f30\u81ea\u4e3b\u5b66\u6821\u5b89\u5168\u5e72\u9884\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
