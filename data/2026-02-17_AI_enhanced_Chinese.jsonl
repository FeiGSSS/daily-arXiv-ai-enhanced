{"id": "2602.12316", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.12316", "abs": "https://arxiv.org/abs/2602.12316", "authors": ["Pepijn Cobben", "Xuanqiang Angelo Huang", "Thao Amelia Pham", "Isabel Dahlgren", "Terry Jingchen Zhang", "Zhijing Jin"], "title": "GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory", "comment": null, "summary": "Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly understood. We introduce GT-HarmBench, a benchmark of 2,009 high-stakes scenarios spanning game-theoretic structures such as the Prisoner's Dilemma, Stag Hunt and Chicken. Scenarios are drawn from realistic AI risk contexts in the MIT AI Risk Repository. Across 15 frontier models, agents choose socially beneficial actions in only 62% of cases, frequently leading to harmful outcomes. We measure sensitivity to game-theoretic prompt framing and ordering, and analyze reasoning patterns driving failures. We further show that game-theoretic interventions improve socially beneficial outcomes by up to 18%. Our results highlight substantial reliability gaps and provide a broad standardized testbed for studying alignment in multi-agent environments. The benchmark and code are available at https://github.com/causalNLP/gt-harmbench.", "AI": {"tldr": "GT-HarmBench\u662f\u4e00\u4e2a\u5305\u542b2009\u4e2a\u9ad8\u98ce\u9669\u573a\u666f\u7684\u591a\u667a\u80fd\u4f53\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8986\u76d6\u56da\u5f92\u56f0\u5883\u3001\u730e\u9e7f\u535a\u5f08\u7b49\u535a\u5f08\u8bba\u7ed3\u6784\uff0c\u8bc4\u4f30\u524d\u6cbfAI\u7cfb\u7edf\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u534f\u8c03\u5931\u8d25\u548c\u51b2\u7a81\u98ce\u9669\u3002", "motivation": "\u73b0\u6709AI\u5b89\u5168\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u5355\u667a\u80fd\u4f53\uff0c\u800c\u524d\u6cbfAI\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u90e8\u7f72\u5728\u9ad8\u98ce\u9669\u7684\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\uff0c\u5bfc\u81f4\u534f\u8c03\u5931\u8d25\u548c\u51b2\u7a81\u7b49\u591a\u667a\u80fd\u4f53\u98ce\u9669\u7f3a\u4e4f\u5145\u5206\u7406\u89e3\u548c\u8bc4\u4f30\u3002", "method": "\u5f00\u53d1\u4e86GT-HarmBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b2009\u4e2a\u4eceMIT AI\u98ce\u9669\u5e93\u4e2d\u63d0\u53d6\u7684\u73b0\u5b9eAI\u98ce\u9669\u573a\u666f\uff0c\u6db5\u76d6\u56da\u5f92\u56f0\u5883\u3001\u730e\u9e7f\u535a\u5f08\u3001\u80c6\u5c0f\u9b3c\u535a\u5f08\u7b49\u535a\u5f08\u8bba\u7ed3\u6784\u3002\u8bc4\u4f30\u4e8615\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u6d4b\u91cf\u4e86\u535a\u5f08\u8bba\u63d0\u793a\u6846\u67b6\u548c\u987a\u5e8f\u7684\u654f\u611f\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5bfc\u81f4\u5931\u8d25\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "result": "\u572815\u4e2a\u524d\u6cbf\u6a21\u578b\u4e2d\uff0c\u667a\u80fd\u4f53\u4ec5\u572862%\u7684\u60c5\u51b5\u4e0b\u9009\u62e9\u5bf9\u793e\u4f1a\u6709\u76ca\u7684\u884c\u52a8\uff0c\u7ecf\u5e38\u5bfc\u81f4\u6709\u5bb3\u7ed3\u679c\u3002\u7814\u7a76\u53d1\u73b0\u535a\u5f08\u8bba\u5e72\u9884\u53ef\u4ee5\u5c06\u793e\u4f1a\u6709\u76ca\u7ed3\u679c\u63d0\u9ad8\u591a\u8fbe18%\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u524d\u6cbfAI\u7cfb\u7edf\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u5b58\u5728\u663e\u8457\u7684\u53ef\u9760\u6027\u5dee\u8ddd\uff0cGT-HarmBench\u4e3a\u7814\u7a76\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u7684\u6807\u51c6\u6d4b\u8bd5\u5e73\u53f0\u3002\u57fa\u51c6\u6d4b\u8bd5\u548c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.12566", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12566", "abs": "https://arxiv.org/abs/2602.12566", "authors": ["Haoqing Wang", "Xiang Long", "Ziheng Li", "Yilong Xu", "Tingguang Li", "Yehui Tang"], "title": "To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, such as coding or math. When a general multi-domain expert-level model is required, we need to carefully consider the collaboration of RLVR across different domains. The current state-of-the-art models mainly employ two different training paradigms for multi-domain RLVR: mixed multi-task RLVR and separate RLVR followed by model merging. However, most of the works did not provide a detailed comparison and analysis about these paradigms. To this end, we choose multiple commonly used high-level tasks (e.g., math, coding, science, and instruction following) as our target domains and design extensive qualitative and quantitative experiments using open-source datasets. We find the RLVR across domains exhibits few mutual interferences, and reasoning-intensive domains demonstrate mutually synergistic effects. Furthermore, we analyze the internal mechanisms of mutual gains from the perspectives of weight space geometry, model prediction behavior, and information constraints. This project is named as M2RL that means Mixed multi-task training or separate training followed by model Merging for Reinforcement Learning, and the homepage is at https://github.com/mosAI25/M2RL", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u9886\u57df\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u7684\u4e24\u79cd\u8bad\u7ec3\u8303\u5f0f\uff1a\u6df7\u5408\u591a\u4efb\u52a1\u8bad\u7ec3\u548c\u5355\u72ec\u8bad\u7ec3\u540e\u6a21\u578b\u5408\u5e76\uff0c\u53d1\u73b0\u8de8\u9886\u57dfRLVR\u5b58\u5728\u76f8\u4e92\u589e\u76ca\u6548\u5e94", "motivation": "\u5f53\u524d\u5728\u591a\u9886\u57dfRLVR\u8bad\u7ec3\u4e2d\u4e3b\u8981\u91c7\u7528\u6df7\u5408\u591a\u4efb\u52a1\u8bad\u7ec3\u548c\u5355\u72ec\u8bad\u7ec3\u540e\u6a21\u578b\u5408\u5e76\u4e24\u79cd\u8303\u5f0f\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u8303\u5f0f\u7684\u8be6\u7ec6\u6bd4\u8f83\u5206\u6790\u3002\u7814\u7a76\u65e8\u5728\u6df1\u5165\u63a2\u8ba8\u8fd9\u4e24\u79cd\u8303\u5f0f\u5728\u4e0d\u540c\u9886\u57df\u7684\u8868\u73b0\u548c\u76f8\u4e92\u5f71\u54cd", "method": "\u9009\u62e9\u6570\u5b66\u3001\u7f16\u7a0b\u3001\u79d1\u5b66\u548c\u6307\u4ee4\u8ddf\u968f\u7b49\u591a\u4e2a\u5e38\u7528\u9ad8\u7ea7\u4efb\u52a1\u4f5c\u4e3a\u76ee\u6807\u9886\u57df\uff0c\u4f7f\u7528\u5f00\u6e90\u6570\u636e\u96c6\u8bbe\u8ba1\u5e7f\u6cdb\u7684\u5b9a\u6027\u548c\u5b9a\u91cf\u5b9e\u9a8c\uff0c\u4ece\u6743\u91cd\u7a7a\u95f4\u51e0\u4f55\u3001\u6a21\u578b\u9884\u6d4b\u884c\u4e3a\u548c\u4fe1\u606f\u7ea6\u675f\u7b49\u89d2\u5ea6\u5206\u6790\u5185\u90e8\u673a\u5236", "result": "\u53d1\u73b0\u8de8\u9886\u57dfRLVR\u5b58\u5728\u8f83\u5c11\u7684\u76f8\u4e92\u5e72\u6270\uff0c\u63a8\u7406\u5bc6\u96c6\u578b\u9886\u57df\u8868\u73b0\u51fa\u76f8\u4e92\u534f\u540c\u6548\u5e94\u3002\u4ece\u6743\u91cd\u7a7a\u95f4\u51e0\u4f55\u7b49\u89d2\u5ea6\u5206\u6790\u4e86\u76f8\u4e92\u589e\u76ca\u7684\u5185\u90e8\u673a\u5236", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u9886\u57dfRLVR\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6df1\u5165\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u63ed\u793a\u4e86\u8de8\u9886\u57df\u8bad\u7ec3\u7684\u534f\u540c\u6548\u5e94\uff0c\u6709\u52a9\u4e8e\u6307\u5bfc\u672a\u6765\u591a\u9886\u57df\u4e13\u5bb6\u7ea7\u6a21\u578b\u7684\u5f00\u53d1\u3002\u9879\u76ee\u547d\u540d\u4e3aM2RL\uff08\u6df7\u5408\u591a\u4efb\u52a1\u8bad\u7ec3\u6216\u5355\u72ec\u8bad\u7ec3\u540e\u6a21\u578b\u5408\u5e76\u7684\u5f3a\u5316\u5b66\u4e60\uff09"}}
{"id": "2602.12586", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12586", "abs": "https://arxiv.org/abs/2602.12586", "authors": ["Joshua Ong Jun Leang", "Yu Zhao", "Mihaela C\u0103t\u0103lina Stoian", "Wenda Li", "Shay B. Cohen", "Eleonora Giunchiglia"], "title": "Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models", "comment": "8 pages, preprint", "summary": "While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs.", "AI": {"tldr": "McDiffuSE\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4f18\u5316\u63a9\u7801\u6269\u6563\u6a21\u578b\u4e2d\u7684\u69fd\u586b\u5145\u987a\u5e8f\uff0c\u901a\u8fc7\u524d\u77bb\u6a21\u62df\u8bc4\u4f30\u90e8\u5206\u5b8c\u6210\u60c5\u51b5\uff0c\u5728\u6570\u5b66\u548c\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u63a9\u7801\u6269\u6563\u6a21\u578b\u4e2d\u7684\u8ba1\u5212-\u586b\u5145\u89e3\u7801\u65b9\u6cd5\u5728\u6570\u5b66\u548c\u4ee3\u7801\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u6027\u80fd\u5bf9\u69fd\u586b\u5145\u987a\u5e8f\u9ad8\u5ea6\u654f\u611f\uff0c\u5bfc\u81f4\u8f93\u51fa\u65b9\u5dee\u5927\uff0c\u9700\u8981\u4f18\u5316\u586b\u5145\u987a\u5e8f", "method": "\u5c06\u69fd\u9009\u62e9\u95ee\u9898\u5efa\u6a21\u4e3a\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4f18\u5316\u586b\u5145\u987a\u5e8f\uff0c\u901a\u8fc7\u524d\u77bb\u6a21\u62df\u8bc4\u4f30\u90e8\u5206\u5b8c\u6210\u60c5\u51b5\uff0c\u7cfb\u7edf\u63a2\u7d22\u751f\u6210\u987a\u5e8f\u7684\u7ec4\u5408\u7a7a\u95f4", "result": "\u76f8\u6bd4\u81ea\u56de\u5f52\u57fa\u7ebf\u5e73\u5747\u63d0\u53473.2%\uff0c\u76f8\u6bd4\u57fa\u7ebf\u8ba1\u5212-\u586b\u5145\u65b9\u6cd5\u63d0\u53478.0%\uff0c\u5728MBPP\u4e0a\u63d0\u534719.5%\uff0c\u5728MATH500\u4e0a\u63d0\u53474.9%", "conclusion": "MCTS\u89c4\u5212\u662f\u63d0\u5347\u63a9\u7801\u6269\u6563\u6a21\u578b\u751f\u6210\u8d28\u91cf\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u867d\u7136\u4e3b\u8981\u9075\u5faa\u987a\u5e8f\u751f\u6210\uff0c\u4f46\u7ed3\u5408\u975e\u987a\u5e8f\u751f\u6210\u5bf9\u6700\u5927\u5316\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u66f4\u5927\u7684\u63a2\u7d22\u5e38\u6570\u800c\u975e\u66f4\u591a\u6a21\u62df\u6765\u514b\u670d\u6a21\u578b\u7f6e\u4fe1\u5ea6\u504f\u5dee"}}
{"id": "2602.12631", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.12631", "abs": "https://arxiv.org/abs/2602.12631", "authors": ["Jackie Baek", "Yaopeng Fu", "Will Ma", "Tianyi Peng"], "title": "AI Agents for Inventory Control: Human-LLM-OR Complementarity", "comment": null, "summary": "Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it remains unclear how best to incorporate LLM-based methods into traditional decision-making pipelines.\n  We study how OR algorithms, LLMs, and humans can interact and complement each other in a multi-period inventory control setting. We construct InventoryBench, a benchmark of over 1,000 inventory instances spanning both synthetic and real-world demand data, designed to stress-test decision rules under demand shifts, seasonality, and uncertain lead times. Through this benchmark, we find that OR-augmented LLM methods outperform either method in isolation, suggesting that these methods are complementary rather than substitutes.\n  We further investigate the role of humans through a controlled classroom experiment that embeds LLM recommendations into a human-in-the-loop decision pipeline. Contrary to prior findings that human-AI collaboration can degrade performance, we show that, on average, human-AI teams achieve higher profits than either humans or AI agents operating alone. Beyond this population-level finding, we formalize an individual-level complementarity effect and derive a distribution-free lower bound on the fraction of individuals who benefit from AI collaboration; empirically, we find this fraction to be substantial.", "AI": {"tldr": "LLM\u589e\u5f3a\u7684\u8fd0\u7b79\u5b66\u7b97\u6cd5\u5728\u5e93\u5b58\u63a7\u5236\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u8fd0\u7b79\u5b66\u6216LLM\u65b9\u6cd5\uff0c\u4eba\u673a\u534f\u4f5c\u56e2\u961f\u6bd4\u5355\u72ec\u7684\u4eba\u7c7b\u6216AI\u83b7\u5f97\u66f4\u9ad8\u5229\u6da6", "motivation": "\u4f20\u7edf\u8fd0\u7b79\u5b66\u7b97\u6cd5\u4f9d\u8d56\u521a\u6027\u5efa\u6a21\u5047\u8bbe\uff0c\u5728\u9700\u6c42\u5206\u5e03\u53d8\u5316\u6216\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u4fe1\u606f\u65f6\u8868\u73b0\u4e0d\u4f73\uff1bLLM\u80fd\u591f\u7075\u6d3b\u63a8\u7406\u5e76\u6574\u5408\u4e30\u5bcc\u4e0a\u4e0b\u6587\u4fe1\u53f7\uff0c\u4f46\u5982\u4f55\u5c06LLM\u65b9\u6cd5\u6709\u6548\u6574\u5408\u5230\u4f20\u7edf\u51b3\u7b56\u6d41\u7a0b\u4e2d\u4ecd\u4e0d\u660e\u786e", "method": "\u6784\u5efaInventoryBench\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u542b1000\u591a\u4e2a\u5e93\u5b58\u5b9e\u4f8b\uff0c\u6db5\u76d6\u5408\u6210\u548c\u771f\u5b9e\u9700\u6c42\u6570\u636e\uff09\uff0c\u6d4b\u8bd5\u9700\u6c42\u53d8\u5316\u3001\u5b63\u8282\u6027\u548c\u4e0d\u786e\u5b9a\u4ea4\u8d27\u671f\u4e0b\u7684\u51b3\u7b56\u89c4\u5219\uff1b\u901a\u8fc7\u8bfe\u5802\u5b9e\u9a8c\u7814\u7a76\u4eba\u7c7b\u5728\u51b3\u7b56\u6d41\u7a0b\u4e2d\u4e0eLLM\u63a8\u8350\u534f\u4f5c\u7684\u6548\u679c", "result": "\u8fd0\u7b79\u5b66\u589e\u5f3a\u7684LLM\u65b9\u6cd5\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u65b9\u6cd5\uff1b\u4eba\u673a\u534f\u4f5c\u56e2\u961f\u5e73\u5747\u5229\u6da6\u9ad8\u4e8e\u5355\u72ec\u7684\u4eba\u7c7b\u6216AI\uff1b\u63a8\u5bfc\u4e86\u4e2a\u4f53\u5c42\u9762\u4e92\u8865\u6548\u5e94\u7684\u65e0\u5206\u5e03\u4e0b\u754c\uff0c\u5b9e\u8bc1\u53d1\u73b0\u53d7\u76ca\u4e8eAI\u534f\u4f5c\u7684\u4e2a\u4f53\u6bd4\u4f8b\u5f88\u5927", "conclusion": "\u8fd0\u7b79\u5b66\u7b97\u6cd5\u3001LLM\u548c\u4eba\u7c7b\u5728\u5e93\u5b58\u63a7\u5236\u4e2d\u5177\u6709\u4e92\u8865\u6027\u800c\u975e\u66ff\u4ee3\u6027\uff0c\u901a\u8fc7\u9002\u5f53\u6574\u5408\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u51b3\u7b56\u6027\u80fd\uff0c\u4eba\u673a\u534f\u4f5c\u80fd\u591f\u5e26\u6765\u5b9e\u8d28\u6027\u6548\u76ca"}}
{"id": "2602.12662", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.12662", "abs": "https://arxiv.org/abs/2602.12662", "authors": ["Ruihan Yang", "Fanghua Ye", "Xiang We", "Ruoqing Zhao", "Kang Luo", "Xinbo Xu", "Bo Zhao", "Ruotian Ma", "Shanyi Wang", "Zhaopeng Tu", "Xiaolong Li", "Deqing Yang", "Linus"], "title": "Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we introduce CogRouter, a framework that trains agents to dynamically adapt cognitive depth at each step. Grounded in ACT-R theory, we design four hierarchical cognitive levels ranging from instinctive responses to strategic planning. Our two-stage training approach includes Cognition-aware Supervised Fine-tuning (CoSFT) to instill stable level-specific patterns, and Cognition-aware Policy Optimization (CoPO) for step-level credit assignment via confidence-aware advantage reweighting. The key insight is that appropriate cognitive depth should maximize the confidence of the resulting action. Experiments on ALFWorld and ScienceWorld demonstrate that CogRouter achieves state-of-the-art performance with superior efficiency. With Qwen2.5-7B, it reaches an 82.3% success rate, outperforming GPT-4o (+40.3%), OpenAI-o3 (+18.3%), and GRPO (+14.0%), while using 62% fewer tokens.", "AI": {"tldr": "CogRouter\u662f\u4e00\u4e2a\u8ba9LLM\u667a\u80fd\u4f53\u52a8\u6001\u8c03\u6574\u8ba4\u77e5\u6df1\u5ea6\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u8ba4\u77e5\u7ea7\u522b\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u6548\u51b3\u7b56\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u91c7\u7528\u56fa\u5b9a\u7684\u8ba4\u77e5\u6a21\u5f0f\uff1a\u975e\u601d\u8003\u6a21\u578b\u7acb\u5373\u54cd\u5e94\uff0c\u601d\u8003\u6a21\u578b\u5219\u7edf\u4e00\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\u3002\u8fd9\u79cd\u521a\u6027\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u6548\u7387\u4f4e\u4e0b\uff0c\u56e0\u4e3a\u4e0d\u540c\u6b65\u9aa4\u7684\u8ba4\u77e5\u9700\u6c42\u5dee\u5f02\u5f88\u5927\uff0c\u6709\u4e9b\u9700\u8981\u6218\u7565\u89c4\u5212\uff0c\u6709\u4e9b\u53ea\u9700\u5e38\u89c4\u6267\u884c\u3002", "method": "\u57fa\u4e8eACT-R\u7406\u8bba\u8bbe\u8ba1\u56db\u4e2a\u5206\u5c42\u8ba4\u77e5\u7ea7\u522b\uff08\u4ece\u672c\u80fd\u53cd\u5e94\u5230\u6218\u7565\u89c4\u5212\uff09\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u8ba4\u77e5\u611f\u77e5\u76d1\u7763\u5fae\u8c03\uff08CoSFT\uff09\u5efa\u7acb\u7a33\u5b9a\u7684\u7ea7\u522b\u7279\u5b9a\u6a21\u5f0f\uff0c\u8ba4\u77e5\u611f\u77e5\u7b56\u7565\u4f18\u5316\uff08CoPO\uff09\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u611f\u77e5\u4f18\u52bf\u91cd\u52a0\u6743\u8fdb\u884c\u6b65\u9aa4\u7ea7\u4fe1\u7528\u5206\u914d\u3002\u6838\u5fc3\u6d1e\u5bdf\u662f\u9002\u5f53\u7684\u8ba4\u77e5\u6df1\u5ea6\u5e94\u6700\u5927\u5316\u6700\u7ec8\u52a8\u4f5c\u7684\u7f6e\u4fe1\u5ea6\u3002", "result": "\u5728ALFWorld\u548cScienceWorld\u5b9e\u9a8c\u4e2d\uff0cCogRouter\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002\u4f7f\u7528Qwen2.5-7B\u6a21\u578b\uff0c\u6210\u529f\u7387\u8fbe\u523082.3%\uff0c\u4f18\u4e8eGPT-4o\uff08+40.3%\uff09\u3001OpenAI-o3\uff08+18.3%\uff09\u548cGRPO\uff08+14.0%\uff09\uff0c\u540c\u65f6\u51cf\u5c1162%\u7684token\u4f7f\u7528\u91cf\u3002", "conclusion": "CogRouter\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8ba4\u77e5\u6df1\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u667a\u80fd\u4f53\u5728\u957f\u65f6\u7a0b\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u9002\u5e94\u6027\u8ba4\u77e5\u7b56\u7565\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.12665", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12665", "abs": "https://arxiv.org/abs/2602.12665", "authors": ["Na\u00efm Es-sebbani", "Esteban Marquer", "Yakoub Salhi", "Zied Bouraoui"], "title": "Evaluating Robustness of Reasoning Models on Parameterized Logical Problems", "comment": null, "summary": "Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine satisfiability. We introduce a diagnostic benchmark for 2-SAT built from parameterized families of structured 2--CNF formulas, where satisfiability is characterized by the implication graph and can be tuned along interpretable axes. Our generators isolate distinct competencies and failure modes: (i) contradiction-cycle UNSAT cores with controllable size and imbalance, (ii) SAT instances with a prescribed fraction of free variables to control solution multiplicity, (iii) planted backbones that modulate propagation, (iv) late bridge clauses that couple otherwise monotone regions to probe sensitivity to ordering and revision, and (v) symmetry/duplication variants that test abstraction under renaming and redundant structure. We evaluate LLM-based reasoners on decision accuracy and assignment validity, and quantify robustness under semantics-preserving perturbations such as clause reordering, filler clauses, and variable renaming. Across models, we observe sharp performance transitions under targeted structural interventions even when surface statistics are held fixed, revealing brittleness regimes that are invisible to aggregate SAT accuracy.", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u8bca\u65ad\u6027\u76842-SAT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u516c\u5f0f\u5bb6\u65cf\u6765\u5206\u79bb\u8868\u9762\u96be\u5ea6\u548c\u7ed3\u6784\u73b0\u8c61\uff0c\u63ed\u793aLLM\u63a8\u7406\u5668\u7684\u7279\u5b9a\u80fd\u529b\u548c\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u6807\u51c6SAT\u57fa\u51c6\u6d4b\u8bd5\u5e38\u5e38\u5c06\u8868\u9762\u96be\u5ea6\uff08\u957f\u5ea6\u3001\u63aa\u8f9e\u3001\u5b50\u53e5\u987a\u5e8f\uff09\u4e0e\u51b3\u5b9a\u53ef\u6ee1\u8db3\u6027\u7684\u7ed3\u6784\u73b0\u8c61\u6df7\u4e3a\u4e00\u8c08\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u7cbe\u7ec6\u7684\u8bca\u65ad\u5de5\u5177\u6765\u8bc4\u4f30LLM\u63a8\u7406\u5668\u7684\u771f\u5b9e\u80fd\u529b\u3002", "method": "\u6784\u5efa\u53c2\u6570\u5316\u7684\u7ed3\u6784\u53162-CNF\u516c\u5f0f\u5bb6\u65cf\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u7ef4\u5ea6\u63a7\u5236\u53ef\u6ee1\u8db3\u6027\u7279\u5f81\uff0c\u5305\u62ec\uff1a\u77db\u76fe\u5faa\u73afUNSAT\u6838\u5fc3\u3001\u63a7\u5236\u89e3\u591a\u6837\u6027\u7684\u81ea\u7531\u53d8\u91cf\u6bd4\u4f8b\u3001\u9884\u8bbe\u9aa8\u5e72\u53d8\u91cf\u3001\u665a\u671f\u6865\u63a5\u5b50\u53e5\u3001\u5bf9\u79f0/\u91cd\u590d\u53d8\u4f53\u7b49\u3002", "result": "\u5728\u4e0d\u540c\u6a21\u578b\u4e0a\u89c2\u5bdf\u5230\uff0c\u5373\u4f7f\u8868\u9762\u7edf\u8ba1\u7279\u5f81\u4fdd\u6301\u4e0d\u53d8\uff0c\u9488\u5bf9\u6027\u7684\u7ed3\u6784\u5e72\u9884\u4e5f\u4f1a\u5bfc\u81f4\u6027\u80fd\u7684\u6025\u5267\u53d8\u5316\uff0c\u63ed\u793a\u4e86\u5728\u805a\u5408SAT\u51c6\u786e\u7387\u4e2d\u4e0d\u53ef\u89c1\u7684\u8106\u5f31\u6027\u533a\u57df\u3002", "conclusion": "\u8be5\u8bca\u65ad\u57fa\u51c6\u80fd\u591f\u5206\u79bbLLM\u63a8\u7406\u5668\u7684\u7279\u5b9a\u80fd\u529b\u548c\u5931\u8d25\u6a21\u5f0f\uff0c\u4e3a\u8bc4\u4f30\u63a8\u7406\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5bf9\u7ed3\u6784\u53d8\u5316\u7684\u654f\u611f\u6027\u800c\u975e\u8868\u9762\u7279\u5f81\u3002"}}
{"id": "2602.12748", "categories": ["cs.AI", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.12748", "abs": "https://arxiv.org/abs/2602.12748", "authors": ["Tobias Labarta", "Nhi Hoang", "Maximilian Dreyer", "Jim Berend", "Oleg Hein", "Jackie Ma", "Wojciech Samek", "Sebastian Lapuschkin"], "title": "X-SYS: A Reference Architecture for Interactive Explanation Systems", "comment": "18 pages, 8 figures", "summary": "The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilities that maintain explanation usability across repeated queries, evolving models and data, and governance constraints. We argue that operationalizing XAI requires treating explainability as an information systems problem where user interaction demands induce specific system requirements. We introduce X-SYS, a reference architecture for interactive explanation systems, that guides (X)AI researchers, developers and practitioners in connecting interactive explanation user interfaces (XUI) with system capabilities. X-SYS organizes around four quality attributes named STAR (scalability, traceability, responsiveness, and adaptability), and specifies a five-component decomposition (XUI Services, Explanation Services, Model Services, Data Services, Orchestration and Governance). It maps interaction patterns to system capabilities to decouple user interface evolution from backend computation. We implement X-SYS through SemanticLens, a system for semantic search and activation steering in vision-language models. SemanticLens demonstrates how contract-based service boundaries enable independent evolution, offline/online separation ensures responsiveness, and persistent state management supports traceability. Together, this work provides a reusable blueprint and concrete instantiation for interactive explanation systems supporting end-to-end design under operational constraints.", "AI": {"tldr": "X-SYS\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u53ef\u89e3\u91caAI\u7cfb\u7edf\u7684\u53c2\u8003\u67b6\u6784\uff0c\u901a\u8fc7STAR\u8d28\u91cf\u5c5e\u6027\u548c\u4e94\u7ec4\u4ef6\u5206\u89e3\uff0c\u5c06\u7528\u6237\u754c\u9762\u4e0e\u540e\u7aef\u8ba1\u7b97\u89e3\u8026\uff0c\u5e76\u5728SemanticLens\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u3002", "motivation": "\u867d\u7136\u53ef\u89e3\u91caAI\u7814\u7a76\u63d0\u51fa\u4e86\u8bb8\u591a\u6280\u672f\u65b9\u6cd5\uff0c\u4f46\u5c06\u53ef\u89e3\u91ca\u6027\u4f5c\u4e3a\u7cfb\u7edf\u90e8\u7f72\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7cfb\u7edf\u9700\u8981\u5408\u9002\u7684\u7b97\u6cd5\u548c\u7cfb\u7edf\u80fd\u529b\uff0c\u4ee5\u5728\u91cd\u590d\u67e5\u8be2\u3001\u6a21\u578b\u548c\u6570\u636e\u6f14\u5316\u4ee5\u53ca\u6cbb\u7406\u7ea6\u675f\u4e0b\u4fdd\u6301\u89e3\u91ca\u53ef\u7528\u6027\u3002\u4f5c\u8005\u8ba4\u4e3a\uff0c\u5c06XAI\u64cd\u4f5c\u5316\u9700\u8981\u5c06\u53ef\u89e3\u91ca\u6027\u89c6\u4e3a\u4fe1\u606f\u7cfb\u7edf\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86X-SYS\u53c2\u8003\u67b6\u6784\uff0c\u56f4\u7ed5STAR\u56db\u4e2a\u8d28\u91cf\u5c5e\u6027\uff08\u53ef\u6269\u5c55\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u3001\u54cd\u5e94\u6027\u548c\u9002\u5e94\u6027\uff09\u7ec4\u7ec7\uff0c\u5e76\u6307\u5b9a\u4e86\u4e94\u4e2a\u7ec4\u4ef6\u5206\u89e3\uff08XUI\u670d\u52a1\u3001\u89e3\u91ca\u670d\u52a1\u3001\u6a21\u578b\u670d\u52a1\u3001\u6570\u636e\u670d\u52a1\u3001\u7f16\u6392\u4e0e\u6cbb\u7406\uff09\u3002\u8be5\u67b6\u6784\u5c06\u4ea4\u4e92\u6a21\u5f0f\u6620\u5c04\u5230\u7cfb\u7edf\u80fd\u529b\uff0c\u5b9e\u73b0\u7528\u6237\u754c\u9762\u4e0e\u540e\u7aef\u8ba1\u7b97\u7684\u89e3\u8026\u3002\u901a\u8fc7SemanticLens\u7cfb\u7edf\uff08\u7528\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u641c\u7d22\u548c\u6fc0\u6d3b\u5f15\u5bfc\uff09\u5b9e\u73b0\u4e86X-SYS\u3002", "result": "X-SYS\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u91cd\u7528\u7684\u84dd\u56fe\uff0c\u901a\u8fc7\u57fa\u4e8e\u5951\u7ea6\u7684\u670d\u52a1\u8fb9\u754c\u5b9e\u73b0\u72ec\u7acb\u6f14\u5316\uff0c\u79bb\u7ebf/\u5728\u7ebf\u5206\u79bb\u786e\u4fdd\u54cd\u5e94\u6027\uff0c\u6301\u4e45\u72b6\u6001\u7ba1\u7406\u652f\u6301\u53ef\u8ffd\u6eaf\u6027\u3002SemanticLens\u5c55\u793a\u4e86\u8be5\u67b6\u6784\u7684\u5177\u4f53\u5b9e\u4f8b\u5316\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u7684\u84dd\u56fe\u548c\u5177\u4f53\u5b9e\u4f8b\u5316\uff0c\u652f\u6301\u5728\u64cd\u4f5c\u7ea6\u675f\u4e0b\u7684\u7aef\u5230\u7aef\u8bbe\u8ba1\uff0c\u5e2e\u52a9XAI\u7814\u7a76\u4eba\u5458\u3001\u5f00\u53d1\u8005\u548c\u4ece\u4e1a\u8005\u8fde\u63a5\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7528\u6237\u754c\u9762\u4e0e\u7cfb\u7edf\u80fd\u529b\u3002"}}
{"id": "2602.12963", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12963", "abs": "https://arxiv.org/abs/2602.12963", "authors": ["Alfred Harwood", "Jose Faustino", "Alex Altair"], "title": "Information-theoretic analysis of world models in optimal reward maximizers", "comment": "28 pages, 0 figures. Not submitted to any conference yet", "summary": "An important question in the field of AI is the extent to which successful behaviour requires an internal representation of the world. In this work, we quantify the amount of information an optimal policy provides about the underlying environment. We consider a Controlled Markov Process (CMP) with $n$ states and $m$ actions, assuming a uniform prior over the space of possible transition dynamics. We prove that observing a deterministic policy that is optimal for any non-constant reward function then conveys exactly $n \\log m$ bits of information about the environment. Specifically, we show that the mutual information between the environment and the optimal policy is $n \\log m$ bits. This bound holds across a broad class of objectives, including finite-horizon, infinite-horizon discounted, and time-averaged reward maximization. These findings provide a precise information-theoretic lower bound on the \"implicit world model'' necessary for optimality.", "AI": {"tldr": "\u6700\u4f18\u7b56\u7565\u5305\u542b\u5173\u4e8e\u73af\u5883\u7684\u7cbe\u786e\u4fe1\u606f\u91cf\uff1a\u5728n\u4e2a\u72b6\u6001\u3001m\u4e2a\u52a8\u4f5c\u7684\u53d7\u63a7\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u4e2d\uff0c\u4efb\u4f55\u975e\u6052\u5b9a\u5956\u52b1\u51fd\u6570\u7684\u6700\u4f18\u786e\u5b9a\u6027\u7b56\u7565\u90fd\u6070\u597d\u4f20\u9012n log m\u6bd4\u7279\u7684\u73af\u5883\u4fe1\u606f\u3002", "motivation": "\u7814\u7a76AI\u9886\u57df\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\uff1a\u6210\u529f\u884c\u4e3a\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u9700\u8981\u4e16\u754c\u7684\u5185\u90e8\u8868\u793a\u3002\u91cf\u5316\u6700\u4f18\u7b56\u7565\u63d0\u4f9b\u7684\u5173\u4e8e\u5e95\u5c42\u73af\u5883\u7684\u4fe1\u606f\u91cf\uff0c\u4e3a\"\u9690\u5f0f\u4e16\u754c\u6a21\u578b\"\u63d0\u4f9b\u4fe1\u606f\u8bba\u4e0b\u754c\u3002", "method": "\u8003\u8651\u5177\u6709n\u4e2a\u72b6\u6001\u548cm\u4e2a\u52a8\u4f5c\u7684\u53d7\u63a7\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\uff0c\u5047\u8bbe\u5728\u53ef\u80fd\u7684\u8f6c\u79fb\u52a8\u6001\u7a7a\u95f4\u4e0a\u5177\u6709\u5747\u5300\u5148\u9a8c\u3002\u8bc1\u660e\u89c2\u5bdf\u4efb\u4f55\u975e\u6052\u5b9a\u5956\u52b1\u51fd\u6570\u7684\u6700\u4f18\u786e\u5b9a\u6027\u7b56\u7565\u6070\u597d\u4f20\u9012n log m\u6bd4\u7279\u7684\u73af\u5883\u4fe1\u606f\u3002", "result": "\u8bc1\u660e\u73af\u5883\u4e0e\u6700\u4f18\u7b56\u7565\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u4e3an log m\u6bd4\u7279\u3002\u8fd9\u4e00\u754c\u9650\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u76ee\u6807\u7c7b\u522b\uff0c\u5305\u62ec\u6709\u9650\u65f6\u57df\u3001\u65e0\u9650\u65f6\u57df\u6298\u6263\u548c\u65f6\u5747\u5956\u52b1\u6700\u5927\u5316\u3002", "conclusion": "\u4e3a\u6700\u4f18\u6027\u6240\u9700\u7684\"\u9690\u5f0f\u4e16\u754c\u6a21\u578b\"\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u4fe1\u606f\u8bba\u4e0b\u754c\uff0c\u8868\u660e\u6700\u4f18\u7b56\u7565\u5fc5\u7136\u7f16\u7801\u4e86\u5173\u4e8e\u73af\u5883\u7ed3\u6784\u7684\u91cd\u8981\u4fe1\u606f\u3002"}}
{"id": "2602.13093", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13093", "abs": "https://arxiv.org/abs/2602.13093", "authors": ["Yubo Li", "Ramayya Krishnan", "Rema Padman"], "title": "Consistency of Large Reasoning Models Under Multi-Turn Attacks", "comment": null, "summary": "Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e869\u4e2a\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u63a8\u7406\u80fd\u529b\u80fd\u63d0\u4f9b\u6709\u610f\u4e49\u4f46\u4e0d\u5b8c\u5168\u7684\u9c81\u68d2\u6027\uff0c\u63a8\u7406\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u6307\u4ee4\u8c03\u4f18\u57fa\u7ebf\uff0c\u4f46\u6240\u6709\u6a21\u578b\u90fd\u5b58\u5728\u7279\u5b9a\u6f0f\u6d1e\u6a21\u5f0f\uff0c\u5e76\u8bc6\u522b\u51fa5\u79cd\u4e3b\u8981\u5931\u6548\u6a21\u5f0f\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u591a\u8f6e\u5bf9\u6297\u538b\u529b\u4e0b\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u63a8\u7406\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u8868\u73b0\uff0c\u4e86\u89e3\u63a8\u7406\u80fd\u529b\u662f\u5426\u81ea\u52a8\u5e26\u6765\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e869\u4e2a\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u8f68\u8ff9\u5206\u6790\u8bc6\u522b\u5931\u6548\u6a21\u5f0f\uff0c\u5e76\u6d4b\u8bd5\u4e86\u7f6e\u4fe1\u5ea6\u611f\u77e5\u54cd\u5e94\u751f\u6210\uff08CARG\uff09\u9632\u5fa1\u65b9\u6cd5\u5bf9\u63a8\u7406\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u63a8\u7406\u80fd\u529b\u80fd\u63d0\u4f9b\u6709\u610f\u4e49\u4f46\u4e0d\u5b8c\u5168\u7684\u9c81\u68d2\u6027\uff0c\u63a8\u7406\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u6307\u4ee4\u8c03\u4f18\u57fa\u7ebf\uff1b2\uff09\u6240\u6709\u6a21\u578b\u90fd\u5b58\u5728\u7279\u5b9a\u6f0f\u6d1e\u6a21\u5f0f\uff0c\u8bef\u5bfc\u6027\u5efa\u8bae\u666e\u904d\u6709\u6548\uff0c\u793e\u4f1a\u538b\u529b\u5177\u6709\u6a21\u578b\u7279\u5f02\u6027\uff1b3\uff09\u8bc6\u522b\u51fa5\u79cd\u4e3b\u8981\u5931\u6548\u6a21\u5f0f\uff08\u81ea\u6211\u6000\u7591\u3001\u793e\u4f1a\u4ece\u4f17\u3001\u5efa\u8bae\u52ab\u6301\u3001\u60c5\u611f\u6613\u611f\u6027\u3001\u63a8\u7406\u75b2\u52b3\uff09\uff0c\u524d\u4e24\u79cd\u536050%\u5931\u8d25\uff1b4\uff09CARG\u9632\u5fa1\u5bf9\u63a8\u7406\u6a21\u578b\u5931\u6548\uff0c\u56e0\u6269\u5c55\u63a8\u7406\u75d5\u8ff9\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\uff1b5\uff09\u968f\u673a\u7f6e\u4fe1\u5ea6\u5d4c\u5165\u4f18\u4e8e\u9488\u5bf9\u6027\u63d0\u53d6\u3002", "conclusion": "\u63a8\u7406\u80fd\u529b\u4e0d\u4f1a\u81ea\u52a8\u5e26\u6765\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u9488\u5bf9\u63a8\u7406\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u9632\u5fa1\u9700\u8981\u6839\u672c\u6027\u91cd\u65b0\u8bbe\u8ba1\u3002\u7814\u7a76\u63ed\u793a\u4e86\u63a8\u7406\u6a21\u578b\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u672a\u6765\u9c81\u68d2\u63a8\u7406\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2602.13135", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.13135", "abs": "https://arxiv.org/abs/2602.13135", "authors": ["Emanuele De Angelis", "Fabio Fioravanti", "Maria Chiara Meo", "Alberto Pettorossi", "Maurizio Proietti", "Francesca Toni"], "title": "Constrained Assumption-Based Argumentation Frameworks", "comment": "Extended version with proofs and additional results of the full paper accepted at the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026). DOI: https://doi.org/10.65109/KRAP9309", "summary": "Assumption-based Argumentation (ABA) is a well-established form of structured argumentation. ABA frameworks with an underlying atomic language are widely studied, but their applicability is limited by a representational restriction to ground (variable-free) arguments and attacks built from propositional atoms. In this paper, we lift this restriction and propose a novel notion of constrained ABA (CABA), whose components, as well as arguments built from them, may include constrained variables, ranging over possibly infinite domains. We define non-ground semantics for CABA, in terms of various notions of non-ground attacks. We show that the new semantics conservatively generalise standard ABA semantics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u7ea6\u675fABA\uff08CABA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u7ea6\u675f\u53d8\u91cf\u6765\u6269\u5c55\u4f20\u7edfABA\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u975e\u5730\u9762\uff08\u5305\u542b\u53d8\u91cf\uff09\u7684\u8bba\u70b9\u548c\u653b\u51fb\uff0c\u4ece\u800c\u514b\u670d\u4e86\u4f20\u7edfABA\u53ea\u80fd\u5904\u7406\u547d\u9898\u539f\u5b50\u548c\u5730\u9762\u8bba\u70b9\u7684\u9650\u5236\u3002", "motivation": "\u4f20\u7edf\u5047\u8bbe\u8bba\u8bc1\uff08ABA\uff09\u6846\u67b6\u901a\u5e38\u57fa\u4e8e\u539f\u5b50\u8bed\u8a00\uff0c\u53ea\u80fd\u5904\u7406\u5730\u9762\uff08\u65e0\u53d8\u91cf\uff09\u7684\u8bba\u70b9\u548c\u653b\u51fb\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u8868\u8fbe\u80fd\u529b\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u9700\u8981\u6269\u5c55ABA\u6846\u67b6\u4ee5\u652f\u6301\u5305\u542b\u7ea6\u675f\u53d8\u91cf\u7684\u975e\u5730\u9762\u8bba\u70b9\u548c\u653b\u51fb\u3002", "method": "\u63d0\u51fa\u7ea6\u675fABA\uff08CABA\uff09\u6846\u67b6\uff0c\u5141\u8bb8\u7ec4\u4ef6\u548c\u8bba\u70b9\u5305\u542b\u7ea6\u675f\u53d8\u91cf\uff0c\u8fd9\u4e9b\u53d8\u91cf\u53ef\u4ee5\u5728\u53ef\u80fd\u65e0\u9650\u7684\u57df\u4e0a\u53d6\u503c\u3002\u5b9a\u4e49\u4e86CABA\u7684\u975e\u5730\u9762\u8bed\u4e49\uff0c\u5305\u62ec\u5404\u79cd\u975e\u5730\u9762\u653b\u51fb\u7684\u6982\u5ff5\u3002", "result": "\u8bc1\u660e\u4e86\u65b0\u7684CABA\u8bed\u4e49\u80fd\u591f\u4fdd\u5b88\u5730\u63a8\u5e7f\u6807\u51c6ABA\u8bed\u4e49\uff0c\u5373\u5f53\u7ea6\u675f\u53d8\u91cf\u88ab\u5177\u4f53\u5316\u4e3a\u5730\u9762\u5b9e\u4f8b\u65f6\uff0cCABA\u7684\u8bed\u4e49\u4e0e\u6807\u51c6ABA\u8bed\u4e49\u4e00\u81f4\u3002", "conclusion": "CABA\u6846\u67b6\u6210\u529f\u6269\u5c55\u4e86\u4f20\u7edfABA\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u66f4\u4e30\u5bcc\u7684\u975e\u5730\u9762\u8bba\u8bc1\u573a\u666f\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u4f20\u7edfABA\u7684\u8bed\u4e49\u517c\u5bb9\u6027\uff0c\u4e3a\u7ed3\u6784\u5316\u8bba\u8bc1\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2602.13166", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13166", "abs": "https://arxiv.org/abs/2602.13166", "authors": ["Hugo Henry", "Arthur Tsai", "Kelly Cohen"], "title": "Optimal Take-off under Fuzzy Clearances", "comment": "12 pages, 12 figures, conference paper", "summary": "This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6700\u4f18\u63a7\u5236\u4e0e\u6a21\u7cca\u89c4\u5219\u7cfb\u7edf\u7684\u6df7\u5408\u969c\u788d\u89c4\u907f\u67b6\u6784\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u81ea\u9002\u5e94\u7ea6\u675f\u5904\u7406\uff0c\u4f46\u53d1\u73b0\u8f6f\u4ef6\u517c\u5bb9\u6027\u95ee\u9898\u5bfc\u81f4\u7ea6\u675f\u65e0\u6cd5\u6b63\u786e\u6267\u884c\u3002", "motivation": "\u4f20\u7edf\u6700\u4f18\u63a7\u5236\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u4ee5\u53ca\u822a\u7a7a\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u9700\u8981\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u5236\u5b9a\uff0c\u4fc3\u4f7f\u5f00\u53d1\u8fd9\u79cd\u6df7\u5408\u67b6\u6784\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5Takagi-Sugeno-Kang\u6a21\u7cca\u5c42\uff0c\u57fa\u4e8eFAA\u548cEASA\u7684\u76d1\u7ba1\u5206\u79bb\u6700\u5c0f\u503c\u548c\u9002\u822a\u6307\u5357\uff0c\u8c03\u5236\u7ea6\u675f\u534a\u5f84\u3001\u7d27\u6025\u7ea7\u522b\u548c\u6fc0\u6d3b\u51b3\u7b56\uff0c\u7136\u540e\u5c06\u6a21\u7cca\u63a8\u5bfc\u7684\u95f4\u9699\u4f5c\u4e3a\u8f6f\u7ea6\u675f\u7eb3\u5165\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u4f7f\u7528FALCON\u5de5\u5177\u7bb1\u548cIPOPT\u6c42\u89e3\u3002", "result": "\u6982\u5ff5\u9a8c\u8bc1\u663e\u793a\u6bcf\u6b21\u8fed\u4ee3\u8ba1\u7b97\u65f6\u95f4\u4e3a2-3\u79d2\uff0c\u8868\u660e\u8fd1\u5b9e\u65f6\u5e94\u7528\u7684\u53ef\u884c\u6027\uff0c\u4f46\u53d1\u73b0FALCON\u548cIPOPT\u6700\u65b0\u7248\u672c\u5b58\u5728\u8f6f\u4ef6\u4e0d\u517c\u5bb9\u95ee\u9898\uff0c\u5bfc\u81f4\u62c9\u683c\u6717\u65e5\u60e9\u7f5a\u9879\u59cb\u7ec8\u4e3a\u96f6\uff0c\u65e0\u6cd5\u6b63\u786e\u6267\u884c\u7ea6\u675f\u3002", "conclusion": "\u8be5\u6df7\u5408\u67b6\u6784\u5728\u7406\u8bba\u4e0a\u53ef\u884c\uff0c\u4f46\u53d7\u5230\u8f6f\u4ef6\u517c\u5bb9\u6027\u95ee\u9898\u7684\u9650\u5236\u3002\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u9a8c\u8bc1\u8f6f\u4ef6\u56de\u5f52\u95ee\u9898\u3001\u4f18\u5316\u6a21\u7cca\u96b6\u5c5e\u51fd\u6570\uff0c\u4ee5\u53ca\u6269\u5c55\u5230\u66f4\u9ad8\u4fdd\u771f\u5ea6\u98de\u673a\u6a21\u578b\u548c\u968f\u673a\u969c\u788d\u73af\u5883\u3002"}}
